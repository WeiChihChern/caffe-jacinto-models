I0814 18:39:49.541561 10396 caffe.cpp:608] This is NVCaffe 0.16.3 started at Mon Aug 14 18:39:49 2017
I0814 18:39:49.541692 10396 caffe.cpp:611] CuDNN version: 6021
I0814 18:39:49.541695 10396 caffe.cpp:612] CuBLAS version: 8000
I0814 18:39:49.541697 10396 caffe.cpp:613] CUDA version: 8000
I0814 18:39:49.541699 10396 caffe.cpp:614] CUDA driver version: 8000
I0814 18:39:49.811841 10396 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0814 18:39:49.812417 10396 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8278441984, dev_info[0]: total=8506769408 free=8278441984
I0814 18:39:49.812942 10396 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8278441984, dev_info[1]: total=8508145664 free=8379236352
I0814 18:39:49.813460 10396 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8278441984, dev_info[2]: total=8508145664 free=8379236352
I0814 18:39:49.813469 10396 caffe.cpp:208] Using GPUs 0, 1, 2
I0814 18:39:49.813794 10396 caffe.cpp:213] GPU 0: GeForce GTX 1080
I0814 18:39:49.814121 10396 caffe.cpp:213] GPU 1: GeForce GTX 1080
I0814 18:39:49.814445 10396 caffe.cpp:213] GPU 2: GeForce GTX 1080
I0814 18:39:49.814483 10396 solver.cpp:42] Solver data type: FLOAT
I0814 18:39:49.814515 10396 solver.cpp:45] Initializing solver from parameters: 
train_net: "training/cifar10_jacintonet11v2_2017-08-14_18-39-46/initial/train.prototxt"
test_net: "training/cifar10_jacintonet11v2_2017-08-14_18-39-46/initial/test.prototxt"
test_iter: 200
test_interval: 1000
base_lr: 0.1
display: 100
max_iter: 64000
lr_policy: "poly"
gamma: 0.1
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 10000
snapshot_prefix: "training/cifar10_jacintonet11v2_2017-08-14_18-39-46/initial/cifar10_jacintonet11v2"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
snapshot_after_train: true
test_initialization: true
iter_size: 1
type: "SGD"
I0814 18:39:49.821110 10396 solver.cpp:77] Creating training net from train_net file: training/cifar10_jacintonet11v2_2017-08-14_18-39-46/initial/train.prototxt
I0814 18:39:49.821527 10396 net.cpp:443] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top1
I0814 18:39:49.821533 10396 net.cpp:443] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top5
W0814 18:39:49.821555 10396 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 64 to 66
I0814 18:39:49.821755 10396 net.cpp:72] Initializing net from parameters: 
name: "jacintonet11v2_train"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: true
    crop_size: 32
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/cifar10_train_lmdb"
    batch_size: 22
    backend: LMDB
    threads: 1
    parser_threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc10"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc10"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
I0814 18:39:49.821853 10396 net.cpp:104] Using FLOAT as default forward math type
I0814 18:39:49.821859 10396 net.cpp:110] Using FLOAT as default backward math type
I0814 18:39:49.821863 10396 layer_factory.hpp:136] Creating layer 'data' of type 'Data'
I0814 18:39:49.821867 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:49.821923 10396 net.cpp:184] Created Layer data (0)
I0814 18:39:49.821929 10396 net.cpp:530] data -> data
I0814 18:39:49.821943 10396 net.cpp:530] data -> label
I0814 18:39:49.821965 10396 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 22
I0814 18:39:49.821980 10396 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0814 18:39:49.822757 10436 db_lmdb.cpp:24] Opened lmdb ./data/cifar10_train_lmdb
I0814 18:39:49.823855 10396 data_layer.cpp:185] [0] ReshapePrefetch 22, 3, 32, 32
I0814 18:39:49.823918 10396 data_layer.cpp:209] [0] Output data size: 22, 3, 32, 32
I0814 18:39:49.823925 10396 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0814 18:39:49.823942 10396 net.cpp:245] Setting up data
I0814 18:39:49.823951 10396 net.cpp:252] TRAIN Top shape for layer 0 'data' 22 3 32 32 (67584)
I0814 18:39:49.823958 10396 net.cpp:252] TRAIN Top shape for layer 0 'data' 22 (22)
I0814 18:39:49.823966 10396 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0814 18:39:49.823971 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:49.823982 10396 net.cpp:184] Created Layer data/bias (1)
I0814 18:39:49.823987 10396 net.cpp:561] data/bias <- data
I0814 18:39:49.823994 10396 net.cpp:530] data/bias -> data/bias
I0814 18:39:49.825948 10396 net.cpp:245] Setting up data/bias
I0814 18:39:49.825959 10396 net.cpp:252] TRAIN Top shape for layer 1 'data/bias' 22 3 32 32 (67584)
I0814 18:39:49.825969 10396 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0814 18:39:49.825974 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:49.825989 10396 net.cpp:184] Created Layer conv1a (2)
I0814 18:39:49.825994 10396 net.cpp:561] conv1a <- data/bias
I0814 18:39:49.825999 10396 net.cpp:530] conv1a -> conv1a
I0814 18:39:50.112067 10396 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.01G/1 1 0 3  (limit 8.15G, req 0G)
I0814 18:39:50.112087 10396 net.cpp:245] Setting up conv1a
I0814 18:39:50.112094 10396 net.cpp:252] TRAIN Top shape for layer 2 'conv1a' 22 32 32 32 (720896)
I0814 18:39:50.112105 10396 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0814 18:39:50.112112 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.112123 10396 net.cpp:184] Created Layer conv1a/bn (3)
I0814 18:39:50.112128 10396 net.cpp:561] conv1a/bn <- conv1a
I0814 18:39:50.112141 10396 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0814 18:39:50.112795 10396 net.cpp:245] Setting up conv1a/bn
I0814 18:39:50.112804 10396 net.cpp:252] TRAIN Top shape for layer 3 'conv1a/bn' 22 32 32 32 (720896)
I0814 18:39:50.112815 10396 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0814 18:39:50.112819 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.112826 10396 net.cpp:184] Created Layer conv1a/relu (4)
I0814 18:39:50.112830 10396 net.cpp:561] conv1a/relu <- conv1a
I0814 18:39:50.112834 10396 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0814 18:39:50.112850 10396 net.cpp:245] Setting up conv1a/relu
I0814 18:39:50.112855 10396 net.cpp:252] TRAIN Top shape for layer 4 'conv1a/relu' 22 32 32 32 (720896)
I0814 18:39:50.112859 10396 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0814 18:39:50.112862 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.112872 10396 net.cpp:184] Created Layer conv1b (5)
I0814 18:39:50.112876 10396 net.cpp:561] conv1b <- conv1a
I0814 18:39:50.112880 10396 net.cpp:530] conv1b -> conv1b
I0814 18:39:50.120013 10396 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 8.13G, req 0G)
I0814 18:39:50.120026 10396 net.cpp:245] Setting up conv1b
I0814 18:39:50.120033 10396 net.cpp:252] TRAIN Top shape for layer 5 'conv1b' 22 32 32 32 (720896)
I0814 18:39:50.120041 10396 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0814 18:39:50.120045 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.120054 10396 net.cpp:184] Created Layer conv1b/bn (6)
I0814 18:39:50.120059 10396 net.cpp:561] conv1b/bn <- conv1b
I0814 18:39:50.120079 10396 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0814 18:39:50.120684 10396 net.cpp:245] Setting up conv1b/bn
I0814 18:39:50.120695 10396 net.cpp:252] TRAIN Top shape for layer 6 'conv1b/bn' 22 32 32 32 (720896)
I0814 18:39:50.120704 10396 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0814 18:39:50.120708 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.120714 10396 net.cpp:184] Created Layer conv1b/relu (7)
I0814 18:39:50.120718 10396 net.cpp:561] conv1b/relu <- conv1b
I0814 18:39:50.120723 10396 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0814 18:39:50.120728 10396 net.cpp:245] Setting up conv1b/relu
I0814 18:39:50.120733 10396 net.cpp:252] TRAIN Top shape for layer 7 'conv1b/relu' 22 32 32 32 (720896)
I0814 18:39:50.120736 10396 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0814 18:39:50.120740 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.120755 10396 net.cpp:184] Created Layer pool1 (8)
I0814 18:39:50.120759 10396 net.cpp:561] pool1 <- conv1b
I0814 18:39:50.120761 10396 net.cpp:530] pool1 -> pool1
I0814 18:39:50.120839 10396 net.cpp:245] Setting up pool1
I0814 18:39:50.120844 10396 net.cpp:252] TRAIN Top shape for layer 8 'pool1' 22 32 32 32 (720896)
I0814 18:39:50.120847 10396 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0814 18:39:50.120849 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.120857 10396 net.cpp:184] Created Layer res2a_branch2a (9)
I0814 18:39:50.120859 10396 net.cpp:561] res2a_branch2a <- pool1
I0814 18:39:50.120862 10396 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0814 18:39:50.130894 10396 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 8.11G, req 0G)
I0814 18:39:50.130908 10396 net.cpp:245] Setting up res2a_branch2a
I0814 18:39:50.130911 10396 net.cpp:252] TRAIN Top shape for layer 9 'res2a_branch2a' 22 64 32 32 (1441792)
I0814 18:39:50.130918 10396 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0814 18:39:50.130921 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.130926 10396 net.cpp:184] Created Layer res2a_branch2a/bn (10)
I0814 18:39:50.130928 10396 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0814 18:39:50.130930 10396 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0814 18:39:50.131548 10396 net.cpp:245] Setting up res2a_branch2a/bn
I0814 18:39:50.131556 10396 net.cpp:252] TRAIN Top shape for layer 10 'res2a_branch2a/bn' 22 64 32 32 (1441792)
I0814 18:39:50.131562 10396 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0814 18:39:50.131564 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.131569 10396 net.cpp:184] Created Layer res2a_branch2a/relu (11)
I0814 18:39:50.131572 10396 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0814 18:39:50.131573 10396 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0814 18:39:50.131577 10396 net.cpp:245] Setting up res2a_branch2a/relu
I0814 18:39:50.131580 10396 net.cpp:252] TRAIN Top shape for layer 11 'res2a_branch2a/relu' 22 64 32 32 (1441792)
I0814 18:39:50.131584 10396 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0814 18:39:50.131589 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.131600 10396 net.cpp:184] Created Layer res2a_branch2b (12)
I0814 18:39:50.131604 10396 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0814 18:39:50.131608 10396 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0814 18:39:50.138558 10396 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 8.1G, req 0G)
I0814 18:39:50.138571 10396 net.cpp:245] Setting up res2a_branch2b
I0814 18:39:50.138586 10396 net.cpp:252] TRAIN Top shape for layer 12 'res2a_branch2b' 22 64 32 32 (1441792)
I0814 18:39:50.138593 10396 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0814 18:39:50.138599 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.138607 10396 net.cpp:184] Created Layer res2a_branch2b/bn (13)
I0814 18:39:50.138612 10396 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0814 18:39:50.138615 10396 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0814 18:39:50.139381 10396 net.cpp:245] Setting up res2a_branch2b/bn
I0814 18:39:50.139392 10396 net.cpp:252] TRAIN Top shape for layer 13 'res2a_branch2b/bn' 22 64 32 32 (1441792)
I0814 18:39:50.139402 10396 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0814 18:39:50.139407 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.139412 10396 net.cpp:184] Created Layer res2a_branch2b/relu (14)
I0814 18:39:50.139417 10396 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0814 18:39:50.139421 10396 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0814 18:39:50.139437 10396 net.cpp:245] Setting up res2a_branch2b/relu
I0814 18:39:50.139444 10396 net.cpp:252] TRAIN Top shape for layer 14 'res2a_branch2b/relu' 22 64 32 32 (1441792)
I0814 18:39:50.139456 10396 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0814 18:39:50.139461 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.139467 10396 net.cpp:184] Created Layer pool2 (15)
I0814 18:39:50.139472 10396 net.cpp:561] pool2 <- res2a_branch2b
I0814 18:39:50.139477 10396 net.cpp:530] pool2 -> pool2
I0814 18:39:50.139561 10396 net.cpp:245] Setting up pool2
I0814 18:39:50.139569 10396 net.cpp:252] TRAIN Top shape for layer 15 'pool2' 22 64 16 16 (360448)
I0814 18:39:50.139580 10396 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0814 18:39:50.139585 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.139595 10396 net.cpp:184] Created Layer res3a_branch2a (16)
I0814 18:39:50.139600 10396 net.cpp:561] res3a_branch2a <- pool2
I0814 18:39:50.139605 10396 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0814 18:39:50.151162 10396 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 8.09G, req 0.01G)
I0814 18:39:50.151177 10396 net.cpp:245] Setting up res3a_branch2a
I0814 18:39:50.151182 10396 net.cpp:252] TRAIN Top shape for layer 16 'res3a_branch2a' 22 128 16 16 (720896)
I0814 18:39:50.151188 10396 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0814 18:39:50.151191 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.151198 10396 net.cpp:184] Created Layer res3a_branch2a/bn (17)
I0814 18:39:50.151201 10396 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0814 18:39:50.151204 10396 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0814 18:39:50.151818 10396 net.cpp:245] Setting up res3a_branch2a/bn
I0814 18:39:50.151826 10396 net.cpp:252] TRAIN Top shape for layer 17 'res3a_branch2a/bn' 22 128 16 16 (720896)
I0814 18:39:50.151835 10396 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0814 18:39:50.151839 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.151842 10396 net.cpp:184] Created Layer res3a_branch2a/relu (18)
I0814 18:39:50.151845 10396 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0814 18:39:50.151847 10396 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0814 18:39:50.151852 10396 net.cpp:245] Setting up res3a_branch2a/relu
I0814 18:39:50.151855 10396 net.cpp:252] TRAIN Top shape for layer 18 'res3a_branch2a/relu' 22 128 16 16 (720896)
I0814 18:39:50.151859 10396 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0814 18:39:50.151870 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.151878 10396 net.cpp:184] Created Layer res3a_branch2b (19)
I0814 18:39:50.151880 10396 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0814 18:39:50.151883 10396 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0814 18:39:50.156803 10396 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 8.08G, req 0.01G)
I0814 18:39:50.156813 10396 net.cpp:245] Setting up res3a_branch2b
I0814 18:39:50.156817 10396 net.cpp:252] TRAIN Top shape for layer 19 'res3a_branch2b' 22 128 16 16 (720896)
I0814 18:39:50.156821 10396 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0814 18:39:50.156823 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.156827 10396 net.cpp:184] Created Layer res3a_branch2b/bn (20)
I0814 18:39:50.156829 10396 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0814 18:39:50.156833 10396 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0814 18:39:50.157418 10396 net.cpp:245] Setting up res3a_branch2b/bn
I0814 18:39:50.157424 10396 net.cpp:252] TRAIN Top shape for layer 20 'res3a_branch2b/bn' 22 128 16 16 (720896)
I0814 18:39:50.157429 10396 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0814 18:39:50.157433 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.157436 10396 net.cpp:184] Created Layer res3a_branch2b/relu (21)
I0814 18:39:50.157438 10396 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0814 18:39:50.157440 10396 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0814 18:39:50.157444 10396 net.cpp:245] Setting up res3a_branch2b/relu
I0814 18:39:50.157447 10396 net.cpp:252] TRAIN Top shape for layer 21 'res3a_branch2b/relu' 22 128 16 16 (720896)
I0814 18:39:50.157449 10396 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0814 18:39:50.157452 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.157456 10396 net.cpp:184] Created Layer pool3 (22)
I0814 18:39:50.157459 10396 net.cpp:561] pool3 <- res3a_branch2b
I0814 18:39:50.157464 10396 net.cpp:530] pool3 -> pool3
I0814 18:39:50.157524 10396 net.cpp:245] Setting up pool3
I0814 18:39:50.157529 10396 net.cpp:252] TRAIN Top shape for layer 22 'pool3' 22 128 16 16 (720896)
I0814 18:39:50.157533 10396 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0814 18:39:50.157537 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.157546 10396 net.cpp:184] Created Layer res4a_branch2a (23)
I0814 18:39:50.157549 10396 net.cpp:561] res4a_branch2a <- pool3
I0814 18:39:50.157553 10396 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0814 18:39:50.177336 10396 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 8.05G, req 0.01G)
I0814 18:39:50.177356 10396 net.cpp:245] Setting up res4a_branch2a
I0814 18:39:50.177363 10396 net.cpp:252] TRAIN Top shape for layer 23 'res4a_branch2a' 22 256 16 16 (1441792)
I0814 18:39:50.177372 10396 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0814 18:39:50.177377 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.177387 10396 net.cpp:184] Created Layer res4a_branch2a/bn (24)
I0814 18:39:50.177392 10396 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0814 18:39:50.177397 10396 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0814 18:39:50.178074 10396 net.cpp:245] Setting up res4a_branch2a/bn
I0814 18:39:50.178082 10396 net.cpp:252] TRAIN Top shape for layer 24 'res4a_branch2a/bn' 22 256 16 16 (1441792)
I0814 18:39:50.178092 10396 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0814 18:39:50.178103 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.178109 10396 net.cpp:184] Created Layer res4a_branch2a/relu (25)
I0814 18:39:50.178113 10396 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0814 18:39:50.178117 10396 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0814 18:39:50.178124 10396 net.cpp:245] Setting up res4a_branch2a/relu
I0814 18:39:50.178129 10396 net.cpp:252] TRAIN Top shape for layer 25 'res4a_branch2a/relu' 22 256 16 16 (1441792)
I0814 18:39:50.178133 10396 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0814 18:39:50.178138 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.178148 10396 net.cpp:184] Created Layer res4a_branch2b (26)
I0814 18:39:50.178151 10396 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0814 18:39:50.178155 10396 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0814 18:39:50.186637 10396 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 8.04G, req 0.01G)
I0814 18:39:50.186650 10396 net.cpp:245] Setting up res4a_branch2b
I0814 18:39:50.186657 10396 net.cpp:252] TRAIN Top shape for layer 26 'res4a_branch2b' 22 256 16 16 (1441792)
I0814 18:39:50.186664 10396 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0814 18:39:50.186668 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.186676 10396 net.cpp:184] Created Layer res4a_branch2b/bn (27)
I0814 18:39:50.186679 10396 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0814 18:39:50.186684 10396 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0814 18:39:50.187305 10396 net.cpp:245] Setting up res4a_branch2b/bn
I0814 18:39:50.187314 10396 net.cpp:252] TRAIN Top shape for layer 27 'res4a_branch2b/bn' 22 256 16 16 (1441792)
I0814 18:39:50.187325 10396 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0814 18:39:50.187328 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.187333 10396 net.cpp:184] Created Layer res4a_branch2b/relu (28)
I0814 18:39:50.187337 10396 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0814 18:39:50.187343 10396 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0814 18:39:50.187350 10396 net.cpp:245] Setting up res4a_branch2b/relu
I0814 18:39:50.187353 10396 net.cpp:252] TRAIN Top shape for layer 28 'res4a_branch2b/relu' 22 256 16 16 (1441792)
I0814 18:39:50.187357 10396 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0814 18:39:50.187361 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.187367 10396 net.cpp:184] Created Layer pool4 (29)
I0814 18:39:50.187371 10396 net.cpp:561] pool4 <- res4a_branch2b
I0814 18:39:50.187376 10396 net.cpp:530] pool4 -> pool4
I0814 18:39:50.187436 10396 net.cpp:245] Setting up pool4
I0814 18:39:50.187441 10396 net.cpp:252] TRAIN Top shape for layer 29 'pool4' 22 256 8 8 (360448)
I0814 18:39:50.187445 10396 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0814 18:39:50.187449 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.187458 10396 net.cpp:184] Created Layer res5a_branch2a (30)
I0814 18:39:50.187463 10396 net.cpp:561] res5a_branch2a <- pool4
I0814 18:39:50.187466 10396 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0814 18:39:50.230306 10396 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 1  (limit 8.02G, req 0.01G)
I0814 18:39:50.230324 10396 net.cpp:245] Setting up res5a_branch2a
I0814 18:39:50.230331 10396 net.cpp:252] TRAIN Top shape for layer 30 'res5a_branch2a' 22 512 8 8 (720896)
I0814 18:39:50.230339 10396 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0814 18:39:50.230343 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.230362 10396 net.cpp:184] Created Layer res5a_branch2a/bn (31)
I0814 18:39:50.230367 10396 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0814 18:39:50.230372 10396 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0814 18:39:50.231017 10396 net.cpp:245] Setting up res5a_branch2a/bn
I0814 18:39:50.231025 10396 net.cpp:252] TRAIN Top shape for layer 31 'res5a_branch2a/bn' 22 512 8 8 (720896)
I0814 18:39:50.231034 10396 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0814 18:39:50.231039 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.231045 10396 net.cpp:184] Created Layer res5a_branch2a/relu (32)
I0814 18:39:50.231047 10396 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0814 18:39:50.231051 10396 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0814 18:39:50.231058 10396 net.cpp:245] Setting up res5a_branch2a/relu
I0814 18:39:50.231062 10396 net.cpp:252] TRAIN Top shape for layer 32 'res5a_branch2a/relu' 22 512 8 8 (720896)
I0814 18:39:50.231066 10396 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0814 18:39:50.231070 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.231079 10396 net.cpp:184] Created Layer res5a_branch2b (33)
I0814 18:39:50.231083 10396 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0814 18:39:50.231087 10396 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0814 18:39:50.250644 10396 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 5  (limit 8G, req 0.01G)
I0814 18:39:50.250661 10396 net.cpp:245] Setting up res5a_branch2b
I0814 18:39:50.250669 10396 net.cpp:252] TRAIN Top shape for layer 33 'res5a_branch2b' 22 512 8 8 (720896)
I0814 18:39:50.250679 10396 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0814 18:39:50.250684 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.250694 10396 net.cpp:184] Created Layer res5a_branch2b/bn (34)
I0814 18:39:50.250699 10396 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0814 18:39:50.250704 10396 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0814 18:39:50.251466 10396 net.cpp:245] Setting up res5a_branch2b/bn
I0814 18:39:50.251474 10396 net.cpp:252] TRAIN Top shape for layer 34 'res5a_branch2b/bn' 22 512 8 8 (720896)
I0814 18:39:50.251483 10396 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0814 18:39:50.251487 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.251492 10396 net.cpp:184] Created Layer res5a_branch2b/relu (35)
I0814 18:39:50.251497 10396 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0814 18:39:50.251500 10396 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0814 18:39:50.251507 10396 net.cpp:245] Setting up res5a_branch2b/relu
I0814 18:39:50.251512 10396 net.cpp:252] TRAIN Top shape for layer 35 'res5a_branch2b/relu' 22 512 8 8 (720896)
I0814 18:39:50.251516 10396 layer_factory.hpp:136] Creating layer 'pool5' of type 'Pooling'
I0814 18:39:50.251519 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.251525 10396 net.cpp:184] Created Layer pool5 (36)
I0814 18:39:50.251529 10396 net.cpp:561] pool5 <- res5a_branch2b
I0814 18:39:50.251534 10396 net.cpp:530] pool5 -> pool5
I0814 18:39:50.251567 10396 net.cpp:245] Setting up pool5
I0814 18:39:50.251574 10396 net.cpp:252] TRAIN Top shape for layer 36 'pool5' 22 512 1 1 (11264)
I0814 18:39:50.251579 10396 layer_factory.hpp:136] Creating layer 'fc10' of type 'InnerProduct'
I0814 18:39:50.251582 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.251590 10396 net.cpp:184] Created Layer fc10 (37)
I0814 18:39:50.251595 10396 net.cpp:561] fc10 <- pool5
I0814 18:39:50.251598 10396 net.cpp:530] fc10 -> fc10
I0814 18:39:50.251883 10396 net.cpp:245] Setting up fc10
I0814 18:39:50.251890 10396 net.cpp:252] TRAIN Top shape for layer 37 'fc10' 22 10 (220)
I0814 18:39:50.251896 10396 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0814 18:39:50.251900 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.251914 10396 net.cpp:184] Created Layer loss (38)
I0814 18:39:50.251917 10396 net.cpp:561] loss <- fc10
I0814 18:39:50.251921 10396 net.cpp:561] loss <- label
I0814 18:39:50.251926 10396 net.cpp:530] loss -> loss
I0814 18:39:50.252086 10396 net.cpp:245] Setting up loss
I0814 18:39:50.252094 10396 net.cpp:252] TRAIN Top shape for layer 38 'loss' (1)
I0814 18:39:50.252097 10396 net.cpp:256]     with loss weight 1
I0814 18:39:50.252104 10396 net.cpp:323] loss needs backward computation.
I0814 18:39:50.252107 10396 net.cpp:323] fc10 needs backward computation.
I0814 18:39:50.252111 10396 net.cpp:323] pool5 needs backward computation.
I0814 18:39:50.252115 10396 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0814 18:39:50.252120 10396 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0814 18:39:50.252123 10396 net.cpp:323] res5a_branch2b needs backward computation.
I0814 18:39:50.252127 10396 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0814 18:39:50.252138 10396 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0814 18:39:50.252143 10396 net.cpp:323] res5a_branch2a needs backward computation.
I0814 18:39:50.252147 10396 net.cpp:323] pool4 needs backward computation.
I0814 18:39:50.252151 10396 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0814 18:39:50.252156 10396 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0814 18:39:50.252158 10396 net.cpp:323] res4a_branch2b needs backward computation.
I0814 18:39:50.252162 10396 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0814 18:39:50.252166 10396 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0814 18:39:50.252169 10396 net.cpp:323] res4a_branch2a needs backward computation.
I0814 18:39:50.252172 10396 net.cpp:323] pool3 needs backward computation.
I0814 18:39:50.252177 10396 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0814 18:39:50.252182 10396 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0814 18:39:50.252184 10396 net.cpp:323] res3a_branch2b needs backward computation.
I0814 18:39:50.252188 10396 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0814 18:39:50.252192 10396 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0814 18:39:50.252195 10396 net.cpp:323] res3a_branch2a needs backward computation.
I0814 18:39:50.252199 10396 net.cpp:323] pool2 needs backward computation.
I0814 18:39:50.252203 10396 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0814 18:39:50.252207 10396 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0814 18:39:50.252212 10396 net.cpp:323] res2a_branch2b needs backward computation.
I0814 18:39:50.252215 10396 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0814 18:39:50.252218 10396 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0814 18:39:50.252223 10396 net.cpp:323] res2a_branch2a needs backward computation.
I0814 18:39:50.252226 10396 net.cpp:323] pool1 needs backward computation.
I0814 18:39:50.252230 10396 net.cpp:323] conv1b/relu needs backward computation.
I0814 18:39:50.252233 10396 net.cpp:323] conv1b/bn needs backward computation.
I0814 18:39:50.252238 10396 net.cpp:323] conv1b needs backward computation.
I0814 18:39:50.252241 10396 net.cpp:323] conv1a/relu needs backward computation.
I0814 18:39:50.252245 10396 net.cpp:323] conv1a/bn needs backward computation.
I0814 18:39:50.252249 10396 net.cpp:323] conv1a needs backward computation.
I0814 18:39:50.252254 10396 net.cpp:325] data/bias does not need backward computation.
I0814 18:39:50.252259 10396 net.cpp:325] data does not need backward computation.
I0814 18:39:50.252261 10396 net.cpp:367] This network produces output loss
I0814 18:39:50.252296 10396 net.cpp:389] Top memory (TRAIN) required for data: 121110528 diff: 121110536
I0814 18:39:50.252300 10396 net.cpp:392] Bottom memory (TRAIN) required for data: 121110528 diff: 121110528
I0814 18:39:50.252303 10396 net.cpp:395] Shared (in-place) memory (TRAIN) by data: 80740352 diff: 80740352
I0814 18:39:50.252307 10396 net.cpp:398] Parameters memory (TRAIN) required for data: 9450960 diff: 9450960
I0814 18:39:50.252312 10396 net.cpp:401] Parameters shared memory (TRAIN) by data: 0 diff: 0
I0814 18:39:50.252315 10396 net.cpp:407] Network initialization done.
I0814 18:39:50.252663 10396 solver.cpp:176] Creating test net (#0) specified by test_net file: training/cifar10_jacintonet11v2_2017-08-14_18-39-46/initial/test.prototxt
W0814 18:39:50.252710 10396 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 50 to 51
I0814 18:39:50.252833 10396 net.cpp:72] Initializing net from parameters: 
name: "jacintonet11v2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: false
    crop_size: 32
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/cifar10_test_lmdb"
    batch_size: 17
    backend: LMDB
    threads: 1
    parser_threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc10"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc10"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "fc10"
  bottom: "label"
  top: "accuracy/top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "fc10"
  bottom: "label"
  top: "accuracy/top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0814 18:39:50.252926 10396 net.cpp:104] Using FLOAT as default forward math type
I0814 18:39:50.252931 10396 net.cpp:110] Using FLOAT as default backward math type
I0814 18:39:50.252934 10396 layer_factory.hpp:136] Creating layer 'data' of type 'Data'
I0814 18:39:50.252938 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.252950 10396 net.cpp:184] Created Layer data (0)
I0814 18:39:50.252954 10396 net.cpp:530] data -> data
I0814 18:39:50.252959 10396 net.cpp:530] data -> label
I0814 18:39:50.252969 10396 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 17
I0814 18:39:50.252976 10396 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0814 18:39:50.253829 10438 db_lmdb.cpp:24] Opened lmdb ./data/cifar10_test_lmdb
I0814 18:39:50.253896 10396 data_layer.cpp:185] (0) ReshapePrefetch 17, 3, 32, 32
I0814 18:39:50.253962 10396 data_layer.cpp:209] (0) Output data size: 17, 3, 32, 32
I0814 18:39:50.253967 10396 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0814 18:39:50.253981 10396 net.cpp:245] Setting up data
I0814 18:39:50.253986 10396 net.cpp:252] TEST Top shape for layer 0 'data' 17 3 32 32 (52224)
I0814 18:39:50.253989 10396 net.cpp:252] TEST Top shape for layer 0 'data' 17 (17)
I0814 18:39:50.253993 10396 layer_factory.hpp:136] Creating layer 'label_data_1_split' of type 'Split'
I0814 18:39:50.253996 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.254001 10396 net.cpp:184] Created Layer label_data_1_split (1)
I0814 18:39:50.254004 10396 net.cpp:561] label_data_1_split <- label
I0814 18:39:50.254007 10396 net.cpp:530] label_data_1_split -> label_data_1_split_0
I0814 18:39:50.254016 10396 net.cpp:530] label_data_1_split -> label_data_1_split_1
I0814 18:39:50.254019 10396 net.cpp:530] label_data_1_split -> label_data_1_split_2
I0814 18:39:50.254076 10396 net.cpp:245] Setting up label_data_1_split
I0814 18:39:50.254081 10396 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 17 (17)
I0814 18:39:50.254083 10396 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 17 (17)
I0814 18:39:50.254086 10396 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 17 (17)
I0814 18:39:50.254088 10396 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0814 18:39:50.254091 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.254096 10396 net.cpp:184] Created Layer data/bias (2)
I0814 18:39:50.254098 10396 net.cpp:561] data/bias <- data
I0814 18:39:50.254101 10396 net.cpp:530] data/bias -> data/bias
I0814 18:39:50.254235 10396 net.cpp:245] Setting up data/bias
I0814 18:39:50.254240 10396 net.cpp:252] TEST Top shape for layer 2 'data/bias' 17 3 32 32 (52224)
I0814 18:39:50.254245 10396 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0814 18:39:50.254247 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.254256 10396 net.cpp:184] Created Layer conv1a (3)
I0814 18:39:50.254259 10396 net.cpp:561] conv1a <- data/bias
I0814 18:39:50.254261 10396 net.cpp:530] conv1a -> conv1a
I0814 18:39:50.254611 10439 data_layer.cpp:97] (0) Parser threads: 1
I0814 18:39:50.254617 10439 data_layer.cpp:99] (0) Transformer threads: 1
I0814 18:39:50.257423 10396 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 8G, req 0.01G)
I0814 18:39:50.257432 10396 net.cpp:245] Setting up conv1a
I0814 18:39:50.257436 10396 net.cpp:252] TEST Top shape for layer 3 'conv1a' 17 32 32 32 (557056)
I0814 18:39:50.257441 10396 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0814 18:39:50.257443 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.257452 10396 net.cpp:184] Created Layer conv1a/bn (4)
I0814 18:39:50.257455 10396 net.cpp:561] conv1a/bn <- conv1a
I0814 18:39:50.257457 10396 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0814 18:39:50.258085 10396 net.cpp:245] Setting up conv1a/bn
I0814 18:39:50.258092 10396 net.cpp:252] TEST Top shape for layer 4 'conv1a/bn' 17 32 32 32 (557056)
I0814 18:39:50.258098 10396 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0814 18:39:50.258101 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.258105 10396 net.cpp:184] Created Layer conv1a/relu (5)
I0814 18:39:50.258106 10396 net.cpp:561] conv1a/relu <- conv1a
I0814 18:39:50.258108 10396 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0814 18:39:50.258112 10396 net.cpp:245] Setting up conv1a/relu
I0814 18:39:50.258114 10396 net.cpp:252] TEST Top shape for layer 5 'conv1a/relu' 17 32 32 32 (557056)
I0814 18:39:50.258116 10396 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0814 18:39:50.258118 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.258126 10396 net.cpp:184] Created Layer conv1b (6)
I0814 18:39:50.258128 10396 net.cpp:561] conv1b <- conv1a
I0814 18:39:50.258131 10396 net.cpp:530] conv1b -> conv1b
I0814 18:39:50.261278 10396 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'conv1b' with space 0.02G/2 1  (limit 8G, req 0.01G)
I0814 18:39:50.261287 10396 net.cpp:245] Setting up conv1b
I0814 18:39:50.261291 10396 net.cpp:252] TEST Top shape for layer 6 'conv1b' 17 32 32 32 (557056)
I0814 18:39:50.261297 10396 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0814 18:39:50.261301 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.261304 10396 net.cpp:184] Created Layer conv1b/bn (7)
I0814 18:39:50.261313 10396 net.cpp:561] conv1b/bn <- conv1b
I0814 18:39:50.261317 10396 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0814 18:39:50.261984 10396 net.cpp:245] Setting up conv1b/bn
I0814 18:39:50.261996 10396 net.cpp:252] TEST Top shape for layer 7 'conv1b/bn' 17 32 32 32 (557056)
I0814 18:39:50.262006 10396 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0814 18:39:50.262011 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.262015 10396 net.cpp:184] Created Layer conv1b/relu (8)
I0814 18:39:50.262019 10396 net.cpp:561] conv1b/relu <- conv1b
I0814 18:39:50.262023 10396 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0814 18:39:50.262028 10396 net.cpp:245] Setting up conv1b/relu
I0814 18:39:50.262033 10396 net.cpp:252] TEST Top shape for layer 8 'conv1b/relu' 17 32 32 32 (557056)
I0814 18:39:50.262037 10396 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0814 18:39:50.262040 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.262046 10396 net.cpp:184] Created Layer pool1 (9)
I0814 18:39:50.262050 10396 net.cpp:561] pool1 <- conv1b
I0814 18:39:50.262055 10396 net.cpp:530] pool1 -> pool1
I0814 18:39:50.262203 10396 net.cpp:245] Setting up pool1
I0814 18:39:50.262213 10396 net.cpp:252] TEST Top shape for layer 9 'pool1' 17 32 32 32 (557056)
I0814 18:39:50.262219 10396 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0814 18:39:50.262224 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.262233 10396 net.cpp:184] Created Layer res2a_branch2a (10)
I0814 18:39:50.262238 10396 net.cpp:561] res2a_branch2a <- pool1
I0814 18:39:50.262243 10396 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0814 18:39:50.266264 10396 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.99G, req 0.01G)
I0814 18:39:50.266276 10396 net.cpp:245] Setting up res2a_branch2a
I0814 18:39:50.266281 10396 net.cpp:252] TEST Top shape for layer 10 'res2a_branch2a' 17 64 32 32 (1114112)
I0814 18:39:50.266288 10396 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0814 18:39:50.266290 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.266296 10396 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0814 18:39:50.266299 10396 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0814 18:39:50.266302 10396 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0814 18:39:50.266991 10396 net.cpp:245] Setting up res2a_branch2a/bn
I0814 18:39:50.266999 10396 net.cpp:252] TEST Top shape for layer 11 'res2a_branch2a/bn' 17 64 32 32 (1114112)
I0814 18:39:50.267004 10396 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0814 18:39:50.267007 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.267011 10396 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0814 18:39:50.267014 10396 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0814 18:39:50.267015 10396 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0814 18:39:50.267022 10396 net.cpp:245] Setting up res2a_branch2a/relu
I0814 18:39:50.267024 10396 net.cpp:252] TEST Top shape for layer 12 'res2a_branch2a/relu' 17 64 32 32 (1114112)
I0814 18:39:50.267026 10396 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0814 18:39:50.267030 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.267045 10396 net.cpp:184] Created Layer res2a_branch2b (13)
I0814 18:39:50.267047 10396 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0814 18:39:50.267050 10396 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0814 18:39:50.270359 10396 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.98G, req 0.01G)
I0814 18:39:50.270370 10396 net.cpp:245] Setting up res2a_branch2b
I0814 18:39:50.270382 10396 net.cpp:252] TEST Top shape for layer 13 'res2a_branch2b' 17 64 32 32 (1114112)
I0814 18:39:50.270387 10396 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0814 18:39:50.270390 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.270395 10396 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0814 18:39:50.270398 10396 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0814 18:39:50.270401 10396 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0814 18:39:50.271064 10396 net.cpp:245] Setting up res2a_branch2b/bn
I0814 18:39:50.271071 10396 net.cpp:252] TEST Top shape for layer 14 'res2a_branch2b/bn' 17 64 32 32 (1114112)
I0814 18:39:50.271077 10396 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0814 18:39:50.271080 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.271083 10396 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0814 18:39:50.271086 10396 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0814 18:39:50.271088 10396 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0814 18:39:50.271092 10396 net.cpp:245] Setting up res2a_branch2b/relu
I0814 18:39:50.271096 10396 net.cpp:252] TEST Top shape for layer 15 'res2a_branch2b/relu' 17 64 32 32 (1114112)
I0814 18:39:50.271098 10396 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0814 18:39:50.271100 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.271106 10396 net.cpp:184] Created Layer pool2 (16)
I0814 18:39:50.271111 10396 net.cpp:561] pool2 <- res2a_branch2b
I0814 18:39:50.271114 10396 net.cpp:530] pool2 -> pool2
I0814 18:39:50.271183 10396 net.cpp:245] Setting up pool2
I0814 18:39:50.271188 10396 net.cpp:252] TEST Top shape for layer 16 'pool2' 17 64 16 16 (278528)
I0814 18:39:50.271190 10396 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0814 18:39:50.271195 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.271203 10396 net.cpp:184] Created Layer res3a_branch2a (17)
I0814 18:39:50.271208 10396 net.cpp:561] res3a_branch2a <- pool2
I0814 18:39:50.271210 10396 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0814 18:39:50.277293 10396 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.97G, req 0.01G)
I0814 18:39:50.277303 10396 net.cpp:245] Setting up res3a_branch2a
I0814 18:39:50.277307 10396 net.cpp:252] TEST Top shape for layer 17 'res3a_branch2a' 17 128 16 16 (557056)
I0814 18:39:50.277312 10396 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0814 18:39:50.277315 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.277319 10396 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0814 18:39:50.277321 10396 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0814 18:39:50.277324 10396 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0814 18:39:50.277976 10396 net.cpp:245] Setting up res3a_branch2a/bn
I0814 18:39:50.277984 10396 net.cpp:252] TEST Top shape for layer 18 'res3a_branch2a/bn' 17 128 16 16 (557056)
I0814 18:39:50.277992 10396 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0814 18:39:50.277993 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.277997 10396 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0814 18:39:50.277998 10396 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0814 18:39:50.278002 10396 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0814 18:39:50.278004 10396 net.cpp:245] Setting up res3a_branch2a/relu
I0814 18:39:50.278007 10396 net.cpp:252] TEST Top shape for layer 19 'res3a_branch2a/relu' 17 128 16 16 (557056)
I0814 18:39:50.278009 10396 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0814 18:39:50.278019 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.278026 10396 net.cpp:184] Created Layer res3a_branch2b (20)
I0814 18:39:50.278029 10396 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0814 18:39:50.278031 10396 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0814 18:39:50.281338 10396 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.97G, req 0.01G)
I0814 18:39:50.281347 10396 net.cpp:245] Setting up res3a_branch2b
I0814 18:39:50.281350 10396 net.cpp:252] TEST Top shape for layer 20 'res3a_branch2b' 17 128 16 16 (557056)
I0814 18:39:50.281355 10396 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0814 18:39:50.281358 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.281363 10396 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0814 18:39:50.281365 10396 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0814 18:39:50.281368 10396 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0814 18:39:50.282011 10396 net.cpp:245] Setting up res3a_branch2b/bn
I0814 18:39:50.282017 10396 net.cpp:252] TEST Top shape for layer 21 'res3a_branch2b/bn' 17 128 16 16 (557056)
I0814 18:39:50.282023 10396 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0814 18:39:50.282027 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.282029 10396 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0814 18:39:50.282032 10396 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0814 18:39:50.282034 10396 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0814 18:39:50.282038 10396 net.cpp:245] Setting up res3a_branch2b/relu
I0814 18:39:50.282042 10396 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b/relu' 17 128 16 16 (557056)
I0814 18:39:50.282044 10396 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0814 18:39:50.282047 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.282053 10396 net.cpp:184] Created Layer pool3 (23)
I0814 18:39:50.282058 10396 net.cpp:561] pool3 <- res3a_branch2b
I0814 18:39:50.282061 10396 net.cpp:530] pool3 -> pool3
I0814 18:39:50.282132 10396 net.cpp:245] Setting up pool3
I0814 18:39:50.282137 10396 net.cpp:252] TEST Top shape for layer 23 'pool3' 17 128 16 16 (557056)
I0814 18:39:50.282141 10396 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0814 18:39:50.282145 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.282153 10396 net.cpp:184] Created Layer res4a_branch2a (24)
I0814 18:39:50.282157 10396 net.cpp:561] res4a_branch2a <- pool3
I0814 18:39:50.282160 10396 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0814 18:39:50.292865 10396 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.96G, req 0.01G)
I0814 18:39:50.292876 10396 net.cpp:245] Setting up res4a_branch2a
I0814 18:39:50.292879 10396 net.cpp:252] TEST Top shape for layer 24 'res4a_branch2a' 17 256 16 16 (1114112)
I0814 18:39:50.292883 10396 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0814 18:39:50.292887 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.292892 10396 net.cpp:184] Created Layer res4a_branch2a/bn (25)
I0814 18:39:50.292894 10396 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0814 18:39:50.292898 10396 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0814 18:39:50.293781 10396 net.cpp:245] Setting up res4a_branch2a/bn
I0814 18:39:50.293790 10396 net.cpp:252] TEST Top shape for layer 25 'res4a_branch2a/bn' 17 256 16 16 (1114112)
I0814 18:39:50.293797 10396 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0814 18:39:50.293799 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.293814 10396 net.cpp:184] Created Layer res4a_branch2a/relu (26)
I0814 18:39:50.293818 10396 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0814 18:39:50.293823 10396 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0814 18:39:50.293828 10396 net.cpp:245] Setting up res4a_branch2a/relu
I0814 18:39:50.293833 10396 net.cpp:252] TEST Top shape for layer 26 'res4a_branch2a/relu' 17 256 16 16 (1114112)
I0814 18:39:50.293836 10396 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0814 18:39:50.293841 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.293857 10396 net.cpp:184] Created Layer res4a_branch2b (27)
I0814 18:39:50.293860 10396 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0814 18:39:50.293864 10396 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0814 18:39:50.300331 10396 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.95G, req 0.01G)
I0814 18:39:50.300371 10396 net.cpp:245] Setting up res4a_branch2b
I0814 18:39:50.300393 10396 net.cpp:252] TEST Top shape for layer 27 'res4a_branch2b' 17 256 16 16 (1114112)
I0814 18:39:50.300406 10396 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0814 18:39:50.300411 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.300426 10396 net.cpp:184] Created Layer res4a_branch2b/bn (28)
I0814 18:39:50.300431 10396 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0814 18:39:50.300436 10396 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0814 18:39:50.301465 10396 net.cpp:245] Setting up res4a_branch2b/bn
I0814 18:39:50.301483 10396 net.cpp:252] TEST Top shape for layer 28 'res4a_branch2b/bn' 17 256 16 16 (1114112)
I0814 18:39:50.301497 10396 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0814 18:39:50.301503 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.301509 10396 net.cpp:184] Created Layer res4a_branch2b/relu (29)
I0814 18:39:50.301515 10396 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0814 18:39:50.301522 10396 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0814 18:39:50.301528 10396 net.cpp:245] Setting up res4a_branch2b/relu
I0814 18:39:50.301533 10396 net.cpp:252] TEST Top shape for layer 29 'res4a_branch2b/relu' 17 256 16 16 (1114112)
I0814 18:39:50.301538 10396 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0814 18:39:50.301542 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.301549 10396 net.cpp:184] Created Layer pool4 (30)
I0814 18:39:50.301554 10396 net.cpp:561] pool4 <- res4a_branch2b
I0814 18:39:50.301559 10396 net.cpp:530] pool4 -> pool4
I0814 18:39:50.301659 10396 net.cpp:245] Setting up pool4
I0814 18:39:50.301667 10396 net.cpp:252] TEST Top shape for layer 30 'pool4' 17 256 8 8 (278528)
I0814 18:39:50.301672 10396 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0814 18:39:50.301676 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.301688 10396 net.cpp:184] Created Layer res5a_branch2a (31)
I0814 18:39:50.301693 10396 net.cpp:561] res5a_branch2a <- pool4
I0814 18:39:50.301698 10396 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0814 18:39:50.335475 10396 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.94G, req 0.01G)
I0814 18:39:50.335490 10396 net.cpp:245] Setting up res5a_branch2a
I0814 18:39:50.335496 10396 net.cpp:252] TEST Top shape for layer 31 'res5a_branch2a' 17 512 8 8 (557056)
I0814 18:39:50.335502 10396 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0814 18:39:50.335505 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.335528 10396 net.cpp:184] Created Layer res5a_branch2a/bn (32)
I0814 18:39:50.335532 10396 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0814 18:39:50.335536 10396 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0814 18:39:50.336243 10396 net.cpp:245] Setting up res5a_branch2a/bn
I0814 18:39:50.336251 10396 net.cpp:252] TEST Top shape for layer 32 'res5a_branch2a/bn' 17 512 8 8 (557056)
I0814 18:39:50.336256 10396 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0814 18:39:50.336259 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.336262 10396 net.cpp:184] Created Layer res5a_branch2a/relu (33)
I0814 18:39:50.336266 10396 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0814 18:39:50.336267 10396 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0814 18:39:50.336272 10396 net.cpp:245] Setting up res5a_branch2a/relu
I0814 18:39:50.336274 10396 net.cpp:252] TEST Top shape for layer 33 'res5a_branch2a/relu' 17 512 8 8 (557056)
I0814 18:39:50.336277 10396 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0814 18:39:50.336279 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.336284 10396 net.cpp:184] Created Layer res5a_branch2b (34)
I0814 18:39:50.336287 10396 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0814 18:39:50.336290 10396 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0814 18:39:50.352457 10396 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.93G, req 0.01G)
I0814 18:39:50.352468 10396 net.cpp:245] Setting up res5a_branch2b
I0814 18:39:50.352471 10396 net.cpp:252] TEST Top shape for layer 34 'res5a_branch2b' 17 512 8 8 (557056)
I0814 18:39:50.352479 10396 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0814 18:39:50.352483 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.352486 10396 net.cpp:184] Created Layer res5a_branch2b/bn (35)
I0814 18:39:50.352488 10396 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0814 18:39:50.352491 10396 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0814 18:39:50.353164 10396 net.cpp:245] Setting up res5a_branch2b/bn
I0814 18:39:50.353173 10396 net.cpp:252] TEST Top shape for layer 35 'res5a_branch2b/bn' 17 512 8 8 (557056)
I0814 18:39:50.353178 10396 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0814 18:39:50.353180 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.353186 10396 net.cpp:184] Created Layer res5a_branch2b/relu (36)
I0814 18:39:50.353189 10396 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0814 18:39:50.353191 10396 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0814 18:39:50.353195 10396 net.cpp:245] Setting up res5a_branch2b/relu
I0814 18:39:50.353199 10396 net.cpp:252] TEST Top shape for layer 36 'res5a_branch2b/relu' 17 512 8 8 (557056)
I0814 18:39:50.353200 10396 layer_factory.hpp:136] Creating layer 'pool5' of type 'Pooling'
I0814 18:39:50.353202 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.353209 10396 net.cpp:184] Created Layer pool5 (37)
I0814 18:39:50.353212 10396 net.cpp:561] pool5 <- res5a_branch2b
I0814 18:39:50.353214 10396 net.cpp:530] pool5 -> pool5
I0814 18:39:50.353245 10396 net.cpp:245] Setting up pool5
I0814 18:39:50.353250 10396 net.cpp:252] TEST Top shape for layer 37 'pool5' 17 512 1 1 (8704)
I0814 18:39:50.353255 10396 layer_factory.hpp:136] Creating layer 'fc10' of type 'InnerProduct'
I0814 18:39:50.353257 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.353265 10396 net.cpp:184] Created Layer fc10 (38)
I0814 18:39:50.353267 10396 net.cpp:561] fc10 <- pool5
I0814 18:39:50.353271 10396 net.cpp:530] fc10 -> fc10
I0814 18:39:50.353549 10396 net.cpp:245] Setting up fc10
I0814 18:39:50.353566 10396 net.cpp:252] TEST Top shape for layer 38 'fc10' 17 10 (170)
I0814 18:39:50.353572 10396 layer_factory.hpp:136] Creating layer 'fc10_fc10_0_split' of type 'Split'
I0814 18:39:50.353576 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.353584 10396 net.cpp:184] Created Layer fc10_fc10_0_split (39)
I0814 18:39:50.353586 10396 net.cpp:561] fc10_fc10_0_split <- fc10
I0814 18:39:50.353591 10396 net.cpp:530] fc10_fc10_0_split -> fc10_fc10_0_split_0
I0814 18:39:50.353596 10396 net.cpp:530] fc10_fc10_0_split -> fc10_fc10_0_split_1
I0814 18:39:50.353602 10396 net.cpp:530] fc10_fc10_0_split -> fc10_fc10_0_split_2
I0814 18:39:50.353679 10396 net.cpp:245] Setting up fc10_fc10_0_split
I0814 18:39:50.353685 10396 net.cpp:252] TEST Top shape for layer 39 'fc10_fc10_0_split' 17 10 (170)
I0814 18:39:50.353690 10396 net.cpp:252] TEST Top shape for layer 39 'fc10_fc10_0_split' 17 10 (170)
I0814 18:39:50.353694 10396 net.cpp:252] TEST Top shape for layer 39 'fc10_fc10_0_split' 17 10 (170)
I0814 18:39:50.353698 10396 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0814 18:39:50.353703 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.353713 10396 net.cpp:184] Created Layer loss (40)
I0814 18:39:50.353718 10396 net.cpp:561] loss <- fc10_fc10_0_split_0
I0814 18:39:50.353723 10396 net.cpp:561] loss <- label_data_1_split_0
I0814 18:39:50.353727 10396 net.cpp:530] loss -> loss
I0814 18:39:50.353883 10396 net.cpp:245] Setting up loss
I0814 18:39:50.353890 10396 net.cpp:252] TEST Top shape for layer 40 'loss' (1)
I0814 18:39:50.353894 10396 net.cpp:256]     with loss weight 1
I0814 18:39:50.353900 10396 layer_factory.hpp:136] Creating layer 'accuracy/top1' of type 'Accuracy'
I0814 18:39:50.353905 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.353915 10396 net.cpp:184] Created Layer accuracy/top1 (41)
I0814 18:39:50.353919 10396 net.cpp:561] accuracy/top1 <- fc10_fc10_0_split_1
I0814 18:39:50.353924 10396 net.cpp:561] accuracy/top1 <- label_data_1_split_1
I0814 18:39:50.353929 10396 net.cpp:530] accuracy/top1 -> accuracy/top1
I0814 18:39:50.353936 10396 net.cpp:245] Setting up accuracy/top1
I0814 18:39:50.353940 10396 net.cpp:252] TEST Top shape for layer 41 'accuracy/top1' (1)
I0814 18:39:50.353945 10396 layer_factory.hpp:136] Creating layer 'accuracy/top5' of type 'Accuracy'
I0814 18:39:50.353947 10396 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:39:50.353953 10396 net.cpp:184] Created Layer accuracy/top5 (42)
I0814 18:39:50.353956 10396 net.cpp:561] accuracy/top5 <- fc10_fc10_0_split_2
I0814 18:39:50.353961 10396 net.cpp:561] accuracy/top5 <- label_data_1_split_2
I0814 18:39:50.353966 10396 net.cpp:530] accuracy/top5 -> accuracy/top5
I0814 18:39:50.353972 10396 net.cpp:245] Setting up accuracy/top5
I0814 18:39:50.353976 10396 net.cpp:252] TEST Top shape for layer 42 'accuracy/top5' (1)
I0814 18:39:50.353981 10396 net.cpp:325] accuracy/top5 does not need backward computation.
I0814 18:39:50.353986 10396 net.cpp:325] accuracy/top1 does not need backward computation.
I0814 18:39:50.353989 10396 net.cpp:323] loss needs backward computation.
I0814 18:39:50.353993 10396 net.cpp:323] fc10_fc10_0_split needs backward computation.
I0814 18:39:50.353996 10396 net.cpp:323] fc10 needs backward computation.
I0814 18:39:50.354001 10396 net.cpp:323] pool5 needs backward computation.
I0814 18:39:50.354004 10396 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0814 18:39:50.354007 10396 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0814 18:39:50.354010 10396 net.cpp:323] res5a_branch2b needs backward computation.
I0814 18:39:50.354014 10396 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0814 18:39:50.354017 10396 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0814 18:39:50.354022 10396 net.cpp:323] res5a_branch2a needs backward computation.
I0814 18:39:50.354035 10396 net.cpp:323] pool4 needs backward computation.
I0814 18:39:50.354038 10396 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0814 18:39:50.354043 10396 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0814 18:39:50.354046 10396 net.cpp:323] res4a_branch2b needs backward computation.
I0814 18:39:50.354050 10396 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0814 18:39:50.354053 10396 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0814 18:39:50.354058 10396 net.cpp:323] res4a_branch2a needs backward computation.
I0814 18:39:50.354061 10396 net.cpp:323] pool3 needs backward computation.
I0814 18:39:50.354065 10396 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0814 18:39:50.354069 10396 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0814 18:39:50.354074 10396 net.cpp:323] res3a_branch2b needs backward computation.
I0814 18:39:50.354077 10396 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0814 18:39:50.354081 10396 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0814 18:39:50.354084 10396 net.cpp:323] res3a_branch2a needs backward computation.
I0814 18:39:50.354089 10396 net.cpp:323] pool2 needs backward computation.
I0814 18:39:50.354092 10396 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0814 18:39:50.354096 10396 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0814 18:39:50.354100 10396 net.cpp:323] res2a_branch2b needs backward computation.
I0814 18:39:50.354104 10396 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0814 18:39:50.354107 10396 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0814 18:39:50.354111 10396 net.cpp:323] res2a_branch2a needs backward computation.
I0814 18:39:50.354115 10396 net.cpp:323] pool1 needs backward computation.
I0814 18:39:50.354120 10396 net.cpp:323] conv1b/relu needs backward computation.
I0814 18:39:50.354123 10396 net.cpp:323] conv1b/bn needs backward computation.
I0814 18:39:50.354127 10396 net.cpp:323] conv1b needs backward computation.
I0814 18:39:50.354130 10396 net.cpp:323] conv1a/relu needs backward computation.
I0814 18:39:50.354135 10396 net.cpp:323] conv1a/bn needs backward computation.
I0814 18:39:50.354138 10396 net.cpp:323] conv1a needs backward computation.
I0814 18:39:50.354142 10396 net.cpp:325] data/bias does not need backward computation.
I0814 18:39:50.354147 10396 net.cpp:325] label_data_1_split does not need backward computation.
I0814 18:39:50.354152 10396 net.cpp:325] data does not need backward computation.
I0814 18:39:50.354156 10396 net.cpp:367] This network produces output accuracy/top1
I0814 18:39:50.354159 10396 net.cpp:367] This network produces output accuracy/top5
I0814 18:39:50.354162 10396 net.cpp:367] This network produces output loss
I0814 18:39:50.354197 10396 net.cpp:389] Top memory (TEST) required for data: 93585408 diff: 8
I0814 18:39:50.354202 10396 net.cpp:392] Bottom memory (TEST) required for data: 93585408 diff: 93585408
I0814 18:39:50.354204 10396 net.cpp:395] Shared (in-place) memory (TEST) by data: 62390272 diff: 62390272
I0814 18:39:50.354207 10396 net.cpp:398] Parameters memory (TEST) required for data: 9450960 diff: 9450960
I0814 18:39:50.354212 10396 net.cpp:401] Parameters shared memory (TEST) by data: 0 diff: 0
I0814 18:39:50.354215 10396 net.cpp:407] Network initialization done.
I0814 18:39:50.354276 10396 solver.cpp:56] Solver scaffolding done.
I0814 18:39:50.358371 10396 parallel.cpp:106] [0 - 0] P2pSync adding callback
I0814 18:39:50.358381 10396 parallel.cpp:106] [1 - 1] P2pSync adding callback
I0814 18:39:50.358384 10396 parallel.cpp:106] [2 - 2] P2pSync adding callback
I0814 18:39:50.358386 10396 parallel.cpp:59] Starting Optimization
I0814 18:39:50.358391 10396 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0814 18:39:50.358417 10396 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0814 18:39:50.358433 10396 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0814 18:39:50.359093 10451 device_alternate.hpp:116] NVML initialized on thread 140165936875264
I0814 18:39:50.377971 10451 common.cpp:583] NVML succeeded to set CPU affinity on device 0
I0814 18:39:50.378034 10452 device_alternate.hpp:116] NVML initialized on thread 140165928482560
I0814 18:39:50.378907 10452 common.cpp:583] NVML succeeded to set CPU affinity on device 1
I0814 18:39:50.378962 10453 device_alternate.hpp:116] NVML initialized on thread 140165920089856
I0814 18:39:50.379781 10453 common.cpp:583] NVML succeeded to set CPU affinity on device 2
I0814 18:39:50.384420 10452 solver.cpp:42] Solver data type: FLOAT
W0814 18:39:50.384872 10452 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 64 to 66
I0814 18:39:50.385002 10452 net.cpp:104] Using FLOAT as default forward math type
I0814 18:39:50.385009 10452 net.cpp:110] Using FLOAT as default backward math type
I0814 18:39:50.385044 10452 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 22
I0814 18:39:50.385057 10452 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0814 18:39:50.391166 10453 solver.cpp:42] Solver data type: FLOAT
W0814 18:39:50.391777 10453 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 64 to 66
I0814 18:39:50.391800 10454 db_lmdb.cpp:24] Opened lmdb ./data/cifar10_train_lmdb
I0814 18:39:50.391880 10453 net.cpp:104] Using FLOAT as default forward math type
I0814 18:39:50.391896 10453 net.cpp:110] Using FLOAT as default backward math type
I0814 18:39:50.391935 10453 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 22
I0814 18:39:50.391950 10453 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0814 18:39:50.392779 10455 db_lmdb.cpp:24] Opened lmdb ./data/cifar10_train_lmdb
I0814 18:39:50.392915 10452 data_layer.cpp:185] [1] ReshapePrefetch 22, 3, 32, 32
I0814 18:39:50.394026 10453 data_layer.cpp:185] [2] ReshapePrefetch 22, 3, 32, 32
I0814 18:39:50.394227 10452 data_layer.cpp:209] [1] Output data size: 22, 3, 32, 32
I0814 18:39:50.394237 10452 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0814 18:39:50.394244 10453 data_layer.cpp:209] [2] Output data size: 22, 3, 32, 32
I0814 18:39:50.394251 10453 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0814 18:39:50.823902 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.01G/1 1 0 3  (limit 8.25G, req 0G)
I0814 18:39:50.840183 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'conv1a' with space 0.01G/1 1 0 3  (limit 8.25G, req 0G)
I0814 18:39:50.841848 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 8.23G, req 0G)
I0814 18:39:50.849416 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 8.23G, req 0G)
I0814 18:39:50.854476 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 1  (limit 8.21G, req 0G)
I0814 18:39:50.861412 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 8.21G, req 0G)
I0814 18:39:50.863703 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 8.19G, req 0G)
I0814 18:39:50.869792 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 8.19G, req 0G)
I0814 18:39:50.877071 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 8.18G, req 0.01G)
I0814 18:39:50.882418 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 8.18G, req 0.01G)
I0814 18:39:50.883030 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 8.17G, req 0.01G)
I0814 18:39:50.889619 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 8.17G, req 0.01G)
I0814 18:39:50.906919 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 8.15G, req 0.01G)
I0814 18:39:50.913259 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 8.15G, req 0.01G)
I0814 18:39:50.916455 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 1 4 3  (limit 8.14G, req 0.01G)
I0814 18:39:50.924819 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 8.14G, req 0.01G)
I0814 18:39:50.960798 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 1  (limit 8.11G, req 0.01G)
I0814 18:39:50.972846 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 1  (limit 8.11G, req 0.01G)
I0814 18:39:50.982321 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 5  (limit 8.1G, req 0.01G)
I0814 18:39:50.984025 10452 solver.cpp:176] Creating test net (#0) specified by test_net file: training/cifar10_jacintonet11v2_2017-08-14_18-39-46/initial/test.prototxt
W0814 18:39:50.984076 10452 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 50 to 51
I0814 18:39:50.984167 10452 net.cpp:104] Using FLOAT as default forward math type
I0814 18:39:50.984172 10452 net.cpp:110] Using FLOAT as default backward math type
I0814 18:39:50.984191 10452 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 17
I0814 18:39:50.984201 10452 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0814 18:39:50.984936 10458 db_lmdb.cpp:24] Opened lmdb ./data/cifar10_test_lmdb
I0814 18:39:50.985018 10452 data_layer.cpp:185] (1) ReshapePrefetch 17, 3, 32, 32
I0814 18:39:50.985117 10452 data_layer.cpp:209] (1) Output data size: 17, 3, 32, 32
I0814 18:39:50.985123 10452 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0814 18:39:50.985898 10459 data_layer.cpp:97] (1) Parser threads: 1
I0814 18:39:50.985906 10459 data_layer.cpp:99] (1) Transformer threads: 1
I0814 18:39:50.988996 10452 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 8.1G, req 0.01G)
I0814 18:39:50.993538 10452 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'conv1b' with space 0.02G/2 1  (limit 8.09G, req 0.01G)
I0814 18:39:50.997864 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 5  (limit 8.1G, req 0.01G)
I0814 18:39:50.998528 10452 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 8.08G, req 0.01G)
I0814 18:39:50.999745 10453 solver.cpp:176] Creating test net (#0) specified by test_net file: training/cifar10_jacintonet11v2_2017-08-14_18-39-46/initial/test.prototxt
W0814 18:39:50.999796 10453 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 50 to 51
I0814 18:39:50.999893 10453 net.cpp:104] Using FLOAT as default forward math type
I0814 18:39:50.999899 10453 net.cpp:110] Using FLOAT as default backward math type
I0814 18:39:50.999918 10453 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 17
I0814 18:39:50.999927 10453 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0814 18:39:51.001021 10460 db_lmdb.cpp:24] Opened lmdb ./data/cifar10_test_lmdb
I0814 18:39:51.001524 10453 data_layer.cpp:185] (2) ReshapePrefetch 17, 3, 32, 32
I0814 18:39:51.001633 10453 data_layer.cpp:209] (2) Output data size: 17, 3, 32, 32
I0814 18:39:51.001639 10453 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0814 18:39:51.002398 10461 data_layer.cpp:97] (2) Parser threads: 1
I0814 18:39:51.002405 10461 data_layer.cpp:99] (2) Transformer threads: 1
I0814 18:39:51.003576 10452 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 8.08G, req 0.01G)
I0814 18:39:51.006417 10453 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 8.1G, req 0.01G)
I0814 18:39:51.012186 10453 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'conv1b' with space 0.02G/2 1  (limit 8.09G, req 0.01G)
I0814 18:39:51.012718 10452 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 8.07G, req 0.01G)
I0814 18:39:51.017966 10452 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 8.06G, req 0.01G)
I0814 18:39:51.018803 10453 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 8.08G, req 0.01G)
I0814 18:39:51.023053 10453 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 8.08G, req 0.01G)
I0814 18:39:51.030503 10452 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 8.05G, req 0.01G)
I0814 18:39:51.030947 10453 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 8.07G, req 0.01G)
I0814 18:39:51.035485 10453 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 8.06G, req 0.01G)
I0814 18:39:51.037876 10452 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 8.05G, req 0.01G)
I0814 18:39:51.048251 10453 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 8.05G, req 0.01G)
I0814 18:39:51.054787 10453 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 8.05G, req 0.01G)
I0814 18:39:51.070842 10452 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 8.03G, req 0.01G)
I0814 18:39:51.087558 10453 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 8.03G, req 0.01G)
I0814 18:39:51.088632 10452 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 8.02G, req 0.01G)
I0814 18:39:51.091131 10452 solver.cpp:56] Solver scaffolding done.
I0814 18:39:51.105320 10453 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 8.02G, req 0.01G)
I0814 18:39:51.106868 10453 solver.cpp:56] Solver scaffolding done.
I0814 18:39:51.149130 10451 parallel.cpp:161] [0 - 0] P2pSync adding callback
I0814 18:39:51.149155 10453 parallel.cpp:161] [2 - 2] P2pSync adding callback
I0814 18:39:51.149183 10452 parallel.cpp:161] [1 - 1] P2pSync adding callback
I0814 18:39:51.355933 10453 solver.cpp:438] Solving jacintonet11v2_train
I0814 18:39:51.355933 10451 solver.cpp:438] Solving jacintonet11v2_train
I0814 18:39:51.355933 10452 solver.cpp:438] Solving jacintonet11v2_train
I0814 18:39:51.355953 10453 solver.cpp:439] Learning Rate Policy: poly
I0814 18:39:51.355957 10451 solver.cpp:439] Learning Rate Policy: poly
I0814 18:39:51.355963 10452 solver.cpp:439] Learning Rate Policy: poly
I0814 18:39:51.362339 10451 solver.cpp:227] Starting Optimization on GPU 0
I0814 18:39:51.362339 10453 solver.cpp:227] Starting Optimization on GPU 2
I0814 18:39:51.362391 10451 solver.cpp:509] Iteration 0, Testing net (#0)
I0814 18:39:51.362339 10452 solver.cpp:227] Starting Optimization on GPU 1
I0814 18:39:51.362421 10492 device_alternate.hpp:116] NVML initialized on thread 140165164668672
I0814 18:39:51.362447 10492 common.cpp:583] NVML succeeded to set CPU affinity on device 0
I0814 18:39:51.362460 10493 device_alternate.hpp:116] NVML initialized on thread 140165156275968
I0814 18:39:51.362470 10493 common.cpp:583] NVML succeeded to set CPU affinity on device 2
I0814 18:39:51.362699 10494 device_alternate.hpp:116] NVML initialized on thread 140165147883264
I0814 18:39:51.362730 10494 common.cpp:583] NVML succeeded to set CPU affinity on device 1
I0814 18:39:51.370357 10452 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 7.99G, req 0.01G)
I0814 18:39:51.375119 10452 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'conv1b' with space 0.02G/2 1  (limit 7.98G, req 0.01G)
I0814 18:39:51.376451 10453 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 7.99G, req 0.01G)
I0814 18:39:51.376960 10451 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'conv1a' with space 0.01G/1 1  (limit 7.92G, req 0G)
I0814 18:39:51.381806 10453 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'conv1b' with space 0.02G/2 1  (limit 7.98G, req 0.01G)
I0814 18:39:51.382694 10452 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.97G, req 0.01G)
I0814 18:39:51.385715 10451 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'conv1b' with space 0.02G/2 1  (limit 7.9G, req 0G)
I0814 18:39:51.388555 10452 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 1  (limit 7.96G, req 0.01G)
I0814 18:39:51.389809 10453 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.97G, req 0.01G)
I0814 18:39:51.394613 10451 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.89G, req 0G)
I0814 18:39:51.395947 10452 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.94G, req 0.01G)
I0814 18:39:51.396347 10453 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.96G, req 0.01G)
I0814 18:39:51.401144 10451 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.88G, req 0G)
I0814 18:39:51.401532 10452 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.94G, req 0.01G)
I0814 18:39:51.403019 10453 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.94G, req 0.01G)
I0814 18:39:51.407915 10451 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.86G, req 0G)
I0814 18:39:51.408638 10453 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.94G, req 0.01G)
I0814 18:39:51.410404 10452 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.92G, req 0.01G)
I0814 18:39:51.413436 10451 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.85G, req 0G)
I0814 18:39:51.416812 10452 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.91G, req 0.01G)
I0814 18:39:51.418354 10453 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.92G, req 0.01G)
I0814 18:39:51.421033 10451 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.84G, req 0G)
I0814 18:39:51.423805 10453 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.91G, req 0.01G)
I0814 18:39:51.426048 10452 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.9G, req 0.01G)
I0814 18:39:51.430019 10451 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.83G, req 0G)
I0814 18:39:51.431066 10452 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.89G, req 0.01G)
I0814 18:39:51.432898 10453 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.9G, req 0.01G)
I0814 18:39:51.438119 10453 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.89G, req 0.01G)
I0814 18:39:51.439851 10451 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.81G, req 0G)
I0814 18:39:51.444249 10451 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.8G, req 0G)
I0814 18:39:51.446528 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.176471
I0814 18:39:51.446537 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.470588
I0814 18:39:51.446544 10451 solver.cpp:594]     Test net output #2: loss = 71.9242 (* 1 = 71.9242 loss)
I0814 18:39:51.446552 10451 solver.cpp:254] [MultiGPU] Initial Test completed
I0814 18:39:51.446573 10451 blocking_queue.cpp:40] Data layer prefetch queue empty
I0814 18:39:51.455572 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 3  (limit 7.88G, req 0.01G)
I0814 18:39:51.456221 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 0  (limit 7.88G, req 0.01G)
I0814 18:39:51.457500 10451 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 3  (limit 7.8G, req 0G)
I0814 18:39:51.464967 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 7.87G, req 0.01G)
I0814 18:39:51.466501 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 7.87G, req 0.01G)
I0814 18:39:51.466975 10451 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 7.79G, req 0G)
I0814 18:39:51.475109 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 7.86G, req 0.01G)
I0814 18:39:51.476930 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 7.86G, req 0.01G)
I0814 18:39:51.478163 10451 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 7.77G, req 0G)
I0814 18:39:51.483178 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 7.85G, req 0.01G)
I0814 18:39:51.486258 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 7.85G, req 0.01G)
I0814 18:39:51.486573 10451 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 7.76G, req 0G)
I0814 18:39:51.493096 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 7.83G, req 0.01G)
I0814 18:39:51.496953 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 7.83G, req 0.01G)
I0814 18:39:51.498093 10451 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 7.75G, req 0.01G)
I0814 18:39:51.498497 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 7.82G, req 0.01G)
I0814 18:39:51.504009 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 7.82G, req 0.01G)
I0814 18:39:51.505338 10451 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 7.74G, req 0.01G)
I0814 18:39:51.513172 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 7.81G, req 0.01G)
I0814 18:39:51.517796 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 7.81G, req 0.01G)
I0814 18:39:51.519886 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 7.8G, req 0.01G)
I0814 18:39:51.520347 10451 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 7.72G, req 0.01G)
I0814 18:39:51.526244 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 7.8G, req 0.01G)
I0814 18:39:51.527724 10451 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 7.71G, req 0.01G)
I0814 18:39:51.538902 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 1  (limit 7.78G, req 0.01G)
I0814 18:39:51.544909 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 1  (limit 7.78G, req 0.01G)
I0814 18:39:51.545644 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 5  (limit 7.77G, req 0.01G)
I0814 18:39:51.546919 10451 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 1  (limit 7.69G, req 0.01G)
I0814 18:39:51.553565 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 5  (limit 7.77G, req 0.01G)
I0814 18:39:51.554309 10451 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 5  (limit 7.68G, req 0.01G)
I0814 18:39:51.585984 10456 data_layer.cpp:97] [1] Parser threads: 1
I0814 18:39:51.585999 10456 data_layer.cpp:99] [1] Transformer threads: 1
I0814 18:39:51.597975 10437 data_layer.cpp:97] [0] Parser threads: 1
I0814 18:39:51.597986 10437 data_layer.cpp:99] [0] Transformer threads: 1
I0814 18:39:51.598151 10457 data_layer.cpp:97] [2] Parser threads: 1
I0814 18:39:51.598163 10457 data_layer.cpp:99] [2] Transformer threads: 1
I0814 18:39:51.599684 10451 solver.cpp:317] Iteration 0 (0.15309 s), loss = 2.32328
I0814 18:39:51.599701 10451 solver.cpp:334]     Train net output #0: loss = 2.32328 (* 1 = 2.32328 loss)
I0814 18:39:51.599709 10451 sgd_solver.cpp:136] Iteration 0, lr = 0.1, m = 0.9
I0814 18:39:51.627612 10451 solver.cpp:317] Iteration 1 (0.0279183 s), loss = 2.19253
I0814 18:39:51.627660 10451 solver.cpp:334]     Train net output #0: loss = 2.19253 (* 1 = 2.19253 loss)
I0814 18:39:51.638320 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'conv1a' with space 0.64G/1 1 0 3  (limit 7.07G, req 0.01G)
I0814 18:39:51.638914 10451 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.64G/1 1 0 3  (limit 6.98G, req 0.01G)
I0814 18:39:51.639081 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.64G/1 1 0 3  (limit 7.07G, req 0.01G)
I0814 18:39:51.648144 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'conv1b' with space 1.29G/2 1 1 3  (limit 6.43G, req 0.01G)
I0814 18:39:51.649252 10451 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'conv1b' with space 1.29G/2 6 1 3  (limit 6.34G, req 0.01G)
I0814 18:39:51.649538 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'conv1b' with space 1.29G/2 1 1 3  (limit 6.43G, req 0.01G)
I0814 18:39:51.662787 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 1.29G/1 6 4 3  (limit 6.43G, req 0.01G)
I0814 18:39:51.663311 10451 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 1.29G/1 6 4 3  (limit 6.34G, req 0.01G)
I0814 18:39:51.669101 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 1.29G/1 6 4 3  (limit 6.43G, req 0.01G)
I0814 18:39:51.675125 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 1.29G/2 6 4 3  (limit 6.43G, req 0.01G)
I0814 18:39:51.675705 10451 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 1.29G/2 6 4 3  (limit 6.34G, req 0.01G)
I0814 18:39:51.676407 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 1.29G/2 6 4 3  (limit 6.43G, req 0.01G)
I0814 18:39:51.685362 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 1.29G/1 6 4 5  (limit 6.43G, req 0.01G)
I0814 18:39:51.685724 10451 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 1.29G/1 6 4 5  (limit 6.34G, req 0.01G)
I0814 18:39:51.687043 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 1.29G/1 6 4 5  (limit 6.43G, req 0.01G)
I0814 18:39:51.692951 10451 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 1.29G/2 6 4 0  (limit 6.34G, req 0.01G)
I0814 18:39:51.693127 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 1.29G/2 6 4 3  (limit 6.43G, req 0.01G)
I0814 18:39:51.693678 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 1.29G/2 6 4 3  (limit 6.43G, req 0.01G)
I0814 18:39:51.716511 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 1.29G/1 6 4 5  (limit 6.43G, req 0.02G)
I0814 18:39:51.718085 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 1.29G/1 6 4 5  (limit 6.43G, req 0.02G)
I0814 18:39:51.718931 10451 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 1.29G/1 6 4 5  (limit 6.34G, req 0.02G)
I0814 18:39:51.724066 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 1.29G/2 6 4 3  (limit 6.43G, req 0.02G)
I0814 18:39:51.726078 10451 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 1.29G/2 6 4 3  (limit 6.34G, req 0.02G)
I0814 18:39:51.726461 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 1.29G/2 6 4 3  (limit 6.43G, req 0.02G)
I0814 18:39:51.757967 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 1.29G/1 7 5 5  (limit 6.43G, req 0.03G)
I0814 18:39:51.760064 10451 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 1.29G/1 6 5 5  (limit 6.34G, req 0.03G)
I0814 18:39:51.762305 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 1.29G/1 7 5 5  (limit 6.43G, req 0.03G)
I0814 18:39:51.766517 10453 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 1.29G/2 6 4 5  (limit 6.43G, req 0.03G)
I0814 18:39:51.768065 10451 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 1.29G/2 6 4 5  (limit 6.34G, req 0.03G)
I0814 18:39:51.770761 10452 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 1.29G/2 6 4 5  (limit 6.43G, req 0.03G)
I0814 18:39:51.783601 10451 solver.cpp:317] Iteration 2 (0.155979 s), loss = 2.16913
I0814 18:39:51.783612 10451 solver.cpp:334]     Train net output #0: loss = 2.16913 (* 1 = 2.16913 loss)
I0814 18:39:51.783627 10452 cudnn_conv_layer.cpp:292] [1] Layer 'conv1a' reallocating workspace: 1.29G -> 0.07G
I0814 18:39:51.783639 10451 cudnn_conv_layer.cpp:292] [0] Layer 'conv1a' reallocating workspace: 1.29G -> 0.07G
I0814 18:39:51.783790 10453 cudnn_conv_layer.cpp:292] [2] Layer 'conv1a' reallocating workspace: 1.29G -> 0.07G
I0814 18:39:53.294811 10451 solver.cpp:312] Iteration 100 (64.8508 iter/s, 1.51116s/98 iter), loss = 2.5052
I0814 18:39:53.294872 10451 solver.cpp:334]     Train net output #0: loss = 2.5052 (* 1 = 2.5052 loss)
I0814 18:39:53.294889 10451 sgd_solver.cpp:136] Iteration 100, lr = 0.0998438, m = 0.9
I0814 18:39:54.871817 10451 solver.cpp:312] Iteration 200 (63.4133 iter/s, 1.57696s/100 iter), loss = 1.64632
I0814 18:39:54.871841 10451 solver.cpp:334]     Train net output #0: loss = 1.64632 (* 1 = 1.64632 loss)
I0814 18:39:54.871847 10451 sgd_solver.cpp:136] Iteration 200, lr = 0.0996875, m = 0.9
I0814 18:39:56.440872 10451 solver.cpp:312] Iteration 300 (63.7345 iter/s, 1.56901s/100 iter), loss = 1.21452
I0814 18:39:56.440935 10451 solver.cpp:334]     Train net output #0: loss = 1.21452 (* 1 = 1.21452 loss)
I0814 18:39:56.440953 10451 sgd_solver.cpp:136] Iteration 300, lr = 0.0995313, m = 0.9
I0814 18:39:57.978102 10451 solver.cpp:312] Iteration 400 (65.054 iter/s, 1.53718s/100 iter), loss = 1.19043
I0814 18:39:57.978147 10451 solver.cpp:334]     Train net output #0: loss = 1.19043 (* 1 = 1.19043 loss)
I0814 18:39:57.978159 10451 sgd_solver.cpp:136] Iteration 400, lr = 0.099375, m = 0.9
I0814 18:39:59.514072 10451 solver.cpp:312] Iteration 500 (65.1075 iter/s, 1.53592s/100 iter), loss = 1.51405
I0814 18:39:59.514096 10451 solver.cpp:334]     Train net output #0: loss = 1.51405 (* 1 = 1.51405 loss)
I0814 18:39:59.514102 10451 sgd_solver.cpp:136] Iteration 500, lr = 0.0992187, m = 0.9
I0814 18:40:01.058910 10451 solver.cpp:312] Iteration 600 (64.7336 iter/s, 1.54479s/100 iter), loss = 1.09533
I0814 18:40:01.058972 10451 solver.cpp:334]     Train net output #0: loss = 1.09533 (* 1 = 1.09533 loss)
I0814 18:40:01.058990 10451 sgd_solver.cpp:136] Iteration 600, lr = 0.0990625, m = 0.9
I0814 18:40:02.644903 10451 solver.cpp:312] Iteration 700 (63.0539 iter/s, 1.58594s/100 iter), loss = 0.990054
I0814 18:40:02.644949 10451 solver.cpp:334]     Train net output #0: loss = 0.990054 (* 1 = 0.990054 loss)
I0814 18:40:02.644958 10451 sgd_solver.cpp:136] Iteration 700, lr = 0.0989062, m = 0.9
I0814 18:40:03.470002 10436 data_reader.cpp:288] Starting prefetch of epoch 1
I0814 18:40:04.168579 10451 solver.cpp:312] Iteration 800 (65.6329 iter/s, 1.52362s/100 iter), loss = 0.591562
I0814 18:40:04.168643 10451 solver.cpp:334]     Train net output #0: loss = 0.591562 (* 1 = 0.591562 loss)
I0814 18:40:04.168663 10451 sgd_solver.cpp:136] Iteration 800, lr = 0.09875, m = 0.9
I0814 18:40:05.733408 10451 solver.cpp:312] Iteration 900 (63.9066 iter/s, 1.56478s/100 iter), loss = 0.59057
I0814 18:40:05.733559 10451 solver.cpp:334]     Train net output #0: loss = 0.59057 (* 1 = 0.59057 loss)
I0814 18:40:05.733583 10451 sgd_solver.cpp:136] Iteration 900, lr = 0.0985937, m = 0.9
I0814 18:40:07.245594 10451 solver.cpp:509] Iteration 1000, Testing net (#0)
I0814 18:40:08.021127 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.553235
I0814 18:40:08.021147 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.927942
I0814 18:40:08.021152 10451 solver.cpp:594]     Test net output #2: loss = 1.36715 (* 1 = 1.36715 loss)
I0814 18:40:08.021169 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.775554s
I0814 18:40:08.036214 10451 solver.cpp:312] Iteration 1000 (43.4266 iter/s, 2.30274s/100 iter), loss = 1.28443
I0814 18:40:08.036247 10451 solver.cpp:334]     Train net output #0: loss = 1.28443 (* 1 = 1.28443 loss)
I0814 18:40:08.036257 10451 sgd_solver.cpp:136] Iteration 1000, lr = 0.0984375, m = 0.9
I0814 18:40:09.622818 10451 solver.cpp:312] Iteration 1100 (63.0296 iter/s, 1.58656s/100 iter), loss = 0.836491
I0814 18:40:09.622843 10451 solver.cpp:334]     Train net output #0: loss = 0.83649 (* 1 = 0.83649 loss)
I0814 18:40:09.622848 10451 sgd_solver.cpp:136] Iteration 1100, lr = 0.0982813, m = 0.9
I0814 18:40:11.160346 10451 solver.cpp:312] Iteration 1200 (65.0416 iter/s, 1.53748s/100 iter), loss = 0.687889
I0814 18:40:11.160372 10451 solver.cpp:334]     Train net output #0: loss = 0.687888 (* 1 = 0.687888 loss)
I0814 18:40:11.160377 10451 sgd_solver.cpp:136] Iteration 1200, lr = 0.098125, m = 0.9
I0814 18:40:12.731673 10451 solver.cpp:312] Iteration 1300 (63.6424 iter/s, 1.57128s/100 iter), loss = 0.693504
I0814 18:40:12.731732 10451 solver.cpp:334]     Train net output #0: loss = 0.693504 (* 1 = 0.693504 loss)
I0814 18:40:12.731750 10451 sgd_solver.cpp:136] Iteration 1300, lr = 0.0979687, m = 0.9
I0814 18:40:14.346971 10451 solver.cpp:312] Iteration 1400 (61.9101 iter/s, 1.61525s/100 iter), loss = 0.659862
I0814 18:40:14.346994 10451 solver.cpp:334]     Train net output #0: loss = 0.659862 (* 1 = 0.659862 loss)
I0814 18:40:14.347000 10451 sgd_solver.cpp:136] Iteration 1400, lr = 0.0978125, m = 0.9
I0814 18:40:15.920231 10451 solver.cpp:312] Iteration 1500 (63.5642 iter/s, 1.57321s/100 iter), loss = 0.458183
I0814 18:40:15.920253 10451 solver.cpp:334]     Train net output #0: loss = 0.458183 (* 1 = 0.458183 loss)
I0814 18:40:15.920259 10451 sgd_solver.cpp:136] Iteration 1500, lr = 0.0976562, m = 0.9
I0814 18:40:17.480980 10451 solver.cpp:312] Iteration 1600 (64.0736 iter/s, 1.5607s/100 iter), loss = 0.733794
I0814 18:40:17.481047 10451 solver.cpp:334]     Train net output #0: loss = 0.733794 (* 1 = 0.733794 loss)
I0814 18:40:17.481067 10451 sgd_solver.cpp:136] Iteration 1600, lr = 0.0975, m = 0.9
I0814 18:40:19.008615 10451 solver.cpp:312] Iteration 1700 (65.4629 iter/s, 1.52758s/100 iter), loss = 0.578921
I0814 18:40:19.008638 10451 solver.cpp:334]     Train net output #0: loss = 0.578921 (* 1 = 0.578921 loss)
I0814 18:40:19.008642 10451 sgd_solver.cpp:136] Iteration 1700, lr = 0.0973438, m = 0.9
I0814 18:40:20.594066 10451 solver.cpp:312] Iteration 1800 (63.0755 iter/s, 1.5854s/100 iter), loss = 0.372266
I0814 18:40:20.594172 10451 solver.cpp:334]     Train net output #0: loss = 0.372266 (* 1 = 0.372266 loss)
I0814 18:40:20.594179 10451 sgd_solver.cpp:136] Iteration 1800, lr = 0.0971875, m = 0.9
I0814 18:40:22.156193 10451 solver.cpp:312] Iteration 1900 (64.0174 iter/s, 1.56208s/100 iter), loss = 0.698815
I0814 18:40:22.156216 10451 solver.cpp:334]     Train net output #0: loss = 0.698815 (* 1 = 0.698815 loss)
I0814 18:40:22.156222 10451 sgd_solver.cpp:136] Iteration 1900, lr = 0.0970313, m = 0.9
I0814 18:40:23.748343 10451 solver.cpp:509] Iteration 2000, Testing net (#0)
I0814 18:40:24.545991 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.612941
I0814 18:40:24.546010 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.958236
I0814 18:40:24.546015 10451 solver.cpp:594]     Test net output #2: loss = 1.25721 (* 1 = 1.25721 loss)
I0814 18:40:24.546032 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.797666s
I0814 18:40:24.560982 10451 solver.cpp:312] Iteration 2000 (41.5849 iter/s, 2.40472s/100 iter), loss = 0.68712
I0814 18:40:24.560998 10451 solver.cpp:334]     Train net output #0: loss = 0.68712 (* 1 = 0.68712 loss)
I0814 18:40:24.561003 10451 sgd_solver.cpp:136] Iteration 2000, lr = 0.096875, m = 0.9
I0814 18:40:26.098135 10451 solver.cpp:312] Iteration 2100 (65.0576 iter/s, 1.5371s/100 iter), loss = 0.568798
I0814 18:40:26.098160 10451 solver.cpp:334]     Train net output #0: loss = 0.568798 (* 1 = 0.568798 loss)
I0814 18:40:26.098165 10451 sgd_solver.cpp:136] Iteration 2100, lr = 0.0967188, m = 0.9
I0814 18:40:27.609845 10451 solver.cpp:312] Iteration 2200 (66.1522 iter/s, 1.51166s/100 iter), loss = 0.645608
I0814 18:40:27.609869 10451 solver.cpp:334]     Train net output #0: loss = 0.645608 (* 1 = 0.645608 loss)
I0814 18:40:27.609874 10451 sgd_solver.cpp:136] Iteration 2200, lr = 0.0965625, m = 0.9
I0814 18:40:29.149340 10451 solver.cpp:312] Iteration 2300 (64.9585 iter/s, 1.53944s/100 iter), loss = 0.485628
I0814 18:40:29.149365 10451 solver.cpp:334]     Train net output #0: loss = 0.485628 (* 1 = 0.485628 loss)
I0814 18:40:29.149371 10451 sgd_solver.cpp:136] Iteration 2300, lr = 0.0964063, m = 0.9
I0814 18:40:30.701571 10451 solver.cpp:312] Iteration 2400 (64.4254 iter/s, 1.55218s/100 iter), loss = 0.37589
I0814 18:40:30.701620 10451 solver.cpp:334]     Train net output #0: loss = 0.37589 (* 1 = 0.37589 loss)
I0814 18:40:30.701632 10451 sgd_solver.cpp:136] Iteration 2400, lr = 0.09625, m = 0.9
I0814 18:40:32.235842 10451 solver.cpp:312] Iteration 2500 (65.1797 iter/s, 1.53422s/100 iter), loss = 0.193013
I0814 18:40:32.235911 10451 solver.cpp:334]     Train net output #0: loss = 0.193013 (* 1 = 0.193013 loss)
I0814 18:40:32.235935 10451 sgd_solver.cpp:136] Iteration 2500, lr = 0.0960938, m = 0.9
I0814 18:40:33.803396 10451 solver.cpp:312] Iteration 2600 (63.7957 iter/s, 1.5675s/100 iter), loss = 0.588975
I0814 18:40:33.803421 10451 solver.cpp:334]     Train net output #0: loss = 0.588975 (* 1 = 0.588975 loss)
I0814 18:40:33.803427 10451 sgd_solver.cpp:136] Iteration 2600, lr = 0.0959375, m = 0.9
I0814 18:40:35.314620 10451 solver.cpp:312] Iteration 2700 (66.1736 iter/s, 1.51118s/100 iter), loss = 0.274138
I0814 18:40:35.314646 10451 solver.cpp:334]     Train net output #0: loss = 0.274138 (* 1 = 0.274138 loss)
I0814 18:40:35.314651 10451 sgd_solver.cpp:136] Iteration 2700, lr = 0.0957813, m = 0.9
I0814 18:40:36.895692 10451 solver.cpp:312] Iteration 2800 (63.2502 iter/s, 1.58102s/100 iter), loss = 0.281997
I0814 18:40:36.895715 10451 solver.cpp:334]     Train net output #0: loss = 0.281997 (* 1 = 0.281997 loss)
I0814 18:40:36.895721 10451 sgd_solver.cpp:136] Iteration 2800, lr = 0.095625, m = 0.9
I0814 18:40:38.444293 10451 solver.cpp:312] Iteration 2900 (64.5765 iter/s, 1.54855s/100 iter), loss = 0.38425
I0814 18:40:38.444351 10451 solver.cpp:334]     Train net output #0: loss = 0.38425 (* 1 = 0.38425 loss)
I0814 18:40:38.444378 10451 sgd_solver.cpp:136] Iteration 2900, lr = 0.0954688, m = 0.9
I0814 18:40:40.003887 10451 solver.cpp:509] Iteration 3000, Testing net (#0)
I0814 18:40:40.813047 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.678235
I0814 18:40:40.813082 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.975
I0814 18:40:40.813088 10451 solver.cpp:594]     Test net output #2: loss = 0.943818 (* 1 = 0.943818 loss)
I0814 18:40:40.813107 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.809355s
I0814 18:40:40.832739 10451 solver.cpp:312] Iteration 3000 (41.8695 iter/s, 2.38838s/100 iter), loss = 0.624858
I0814 18:40:40.832778 10451 solver.cpp:334]     Train net output #0: loss = 0.624858 (* 1 = 0.624858 loss)
I0814 18:40:40.832798 10451 sgd_solver.cpp:136] Iteration 3000, lr = 0.0953125, m = 0.9
I0814 18:40:42.418480 10451 solver.cpp:312] Iteration 3100 (63.064 iter/s, 1.58569s/100 iter), loss = 0.124433
I0814 18:40:42.418506 10451 solver.cpp:334]     Train net output #0: loss = 0.124433 (* 1 = 0.124433 loss)
I0814 18:40:42.418514 10451 sgd_solver.cpp:136] Iteration 3100, lr = 0.0951563, m = 0.9
I0814 18:40:43.935494 10451 solver.cpp:312] Iteration 3200 (65.9212 iter/s, 1.51696s/100 iter), loss = 0.485795
I0814 18:40:43.935555 10451 solver.cpp:334]     Train net output #0: loss = 0.485795 (* 1 = 0.485795 loss)
I0814 18:40:43.935573 10451 sgd_solver.cpp:136] Iteration 3200, lr = 0.095, m = 0.9
I0814 18:40:45.522627 10451 solver.cpp:312] Iteration 3300 (63.0087 iter/s, 1.58708s/100 iter), loss = 0.0987551
I0814 18:40:45.522791 10451 solver.cpp:334]     Train net output #0: loss = 0.0987549 (* 1 = 0.0987549 loss)
I0814 18:40:45.522879 10451 sgd_solver.cpp:136] Iteration 3300, lr = 0.0948438, m = 0.9
I0814 18:40:47.119879 10451 solver.cpp:312] Iteration 3400 (62.6094 iter/s, 1.5972s/100 iter), loss = 0.358784
I0814 18:40:47.119902 10451 solver.cpp:334]     Train net output #0: loss = 0.358784 (* 1 = 0.358784 loss)
I0814 18:40:47.119906 10451 sgd_solver.cpp:136] Iteration 3400, lr = 0.0946875, m = 0.9
I0814 18:40:48.706596 10451 solver.cpp:312] Iteration 3500 (63.0253 iter/s, 1.58667s/100 iter), loss = 0.631892
I0814 18:40:48.706665 10451 solver.cpp:334]     Train net output #0: loss = 0.631892 (* 1 = 0.631892 loss)
I0814 18:40:48.706686 10451 sgd_solver.cpp:136] Iteration 3500, lr = 0.0945313, m = 0.9
I0814 18:40:50.278697 10451 solver.cpp:312] Iteration 3600 (63.6113 iter/s, 1.57205s/100 iter), loss = 0.336406
I0814 18:40:50.278743 10451 solver.cpp:334]     Train net output #0: loss = 0.336406 (* 1 = 0.336406 loss)
I0814 18:40:50.278755 10451 sgd_solver.cpp:136] Iteration 3600, lr = 0.094375, m = 0.9
I0814 18:40:51.820976 10451 solver.cpp:312] Iteration 3700 (64.8411 iter/s, 1.54223s/100 iter), loss = 0.136329
I0814 18:40:51.821054 10451 solver.cpp:334]     Train net output #0: loss = 0.136329 (* 1 = 0.136329 loss)
I0814 18:40:51.821059 10451 sgd_solver.cpp:136] Iteration 3700, lr = 0.0942188, m = 0.9
I0814 18:40:53.407397 10451 solver.cpp:312] Iteration 3800 (63.0371 iter/s, 1.58637s/100 iter), loss = 0.754933
I0814 18:40:53.407420 10451 solver.cpp:334]     Train net output #0: loss = 0.754932 (* 1 = 0.754932 loss)
I0814 18:40:53.407426 10451 sgd_solver.cpp:136] Iteration 3800, lr = 0.0940625, m = 0.9
I0814 18:40:54.962913 10451 solver.cpp:312] Iteration 3900 (64.2894 iter/s, 1.55547s/100 iter), loss = 0.846896
I0814 18:40:54.962975 10451 solver.cpp:334]     Train net output #0: loss = 0.846896 (* 1 = 0.846896 loss)
I0814 18:40:54.962991 10451 sgd_solver.cpp:136] Iteration 3900, lr = 0.0939062, m = 0.9
I0814 18:40:56.555378 10451 solver.cpp:509] Iteration 4000, Testing net (#0)
I0814 18:40:57.336838 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.691471
I0814 18:40:57.336858 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.977942
I0814 18:40:57.336863 10451 solver.cpp:594]     Test net output #2: loss = 0.923988 (* 1 = 0.923988 loss)
I0814 18:40:57.336877 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.781477s
I0814 18:40:57.351822 10451 solver.cpp:312] Iteration 4000 (41.8613 iter/s, 2.38884s/100 iter), loss = 0.352323
I0814 18:40:57.351855 10451 solver.cpp:334]     Train net output #0: loss = 0.352322 (* 1 = 0.352322 loss)
I0814 18:40:57.351867 10451 sgd_solver.cpp:136] Iteration 4000, lr = 0.09375, m = 0.9
I0814 18:40:58.901474 10451 solver.cpp:312] Iteration 4100 (64.5327 iter/s, 1.5496s/100 iter), loss = 0.211386
I0814 18:40:58.901499 10451 solver.cpp:334]     Train net output #0: loss = 0.211385 (* 1 = 0.211385 loss)
I0814 18:40:58.901504 10451 sgd_solver.cpp:136] Iteration 4100, lr = 0.0935938, m = 0.9
I0814 18:41:00.532707 10451 solver.cpp:312] Iteration 4200 (61.3053 iter/s, 1.63118s/100 iter), loss = 0.462415
I0814 18:41:00.532775 10451 solver.cpp:334]     Train net output #0: loss = 0.462415 (* 1 = 0.462415 loss)
I0814 18:41:00.532796 10451 sgd_solver.cpp:136] Iteration 4200, lr = 0.0934375, m = 0.9
I0814 18:41:02.082767 10451 solver.cpp:312] Iteration 4300 (64.5158 iter/s, 1.55001s/100 iter), loss = 0.174517
I0814 18:41:02.082793 10451 solver.cpp:334]     Train net output #0: loss = 0.174516 (* 1 = 0.174516 loss)
I0814 18:41:02.082800 10451 sgd_solver.cpp:136] Iteration 4300, lr = 0.0932813, m = 0.9
I0814 18:41:03.665261 10451 solver.cpp:312] Iteration 4400 (63.1933 iter/s, 1.58245s/100 iter), loss = 0.534613
I0814 18:41:03.665320 10451 solver.cpp:334]     Train net output #0: loss = 0.534612 (* 1 = 0.534612 loss)
I0814 18:41:03.665338 10451 sgd_solver.cpp:136] Iteration 4400, lr = 0.093125, m = 0.9
I0814 18:41:05.259289 10451 solver.cpp:312] Iteration 4500 (62.7362 iter/s, 1.59398s/100 iter), loss = 0.30862
I0814 18:41:05.259315 10451 solver.cpp:334]     Train net output #0: loss = 0.30862 (* 1 = 0.30862 loss)
I0814 18:41:05.259320 10451 sgd_solver.cpp:136] Iteration 4500, lr = 0.0929688, m = 0.9
I0814 18:41:06.836536 10451 solver.cpp:312] Iteration 4600 (63.4036 iter/s, 1.5772s/100 iter), loss = 0.147161
I0814 18:41:06.836599 10451 solver.cpp:334]     Train net output #0: loss = 0.147161 (* 1 = 0.147161 loss)
I0814 18:41:06.836617 10451 sgd_solver.cpp:136] Iteration 4600, lr = 0.0928125, m = 0.9
I0814 18:41:08.417214 10451 solver.cpp:312] Iteration 4700 (63.266 iter/s, 1.58063s/100 iter), loss = 0.385962
I0814 18:41:08.417271 10451 solver.cpp:334]     Train net output #0: loss = 0.385961 (* 1 = 0.385961 loss)
I0814 18:41:08.417290 10451 sgd_solver.cpp:136] Iteration 4700, lr = 0.0926562, m = 0.9
I0814 18:41:10.001161 10451 solver.cpp:312] Iteration 4800 (63.1354 iter/s, 1.5839s/100 iter), loss = 0.441463
I0814 18:41:10.001307 10451 solver.cpp:334]     Train net output #0: loss = 0.441462 (* 1 = 0.441462 loss)
I0814 18:41:10.001332 10451 sgd_solver.cpp:136] Iteration 4800, lr = 0.0925, m = 0.9
I0814 18:41:11.593833 10451 solver.cpp:312] Iteration 4900 (62.7897 iter/s, 1.59262s/100 iter), loss = 0.217581
I0814 18:41:11.593904 10451 solver.cpp:334]     Train net output #0: loss = 0.21758 (* 1 = 0.21758 loss)
I0814 18:41:11.593920 10451 sgd_solver.cpp:136] Iteration 4900, lr = 0.0923437, m = 0.9
I0814 18:41:13.138423 10451 solver.cpp:509] Iteration 5000, Testing net (#0)
I0814 18:41:13.814885 10438 data_reader.cpp:288] Starting prefetch of epoch 1
I0814 18:41:13.944249 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.780295
I0814 18:41:13.944269 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.986471
I0814 18:41:13.944274 10451 solver.cpp:594]     Test net output #2: loss = 0.639085 (* 1 = 0.639085 loss)
I0814 18:41:13.944288 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.805841s
I0814 18:41:13.959228 10451 solver.cpp:312] Iteration 5000 (42.2775 iter/s, 2.36533s/100 iter), loss = 0.566563
I0814 18:41:13.959242 10451 solver.cpp:334]     Train net output #0: loss = 0.566563 (* 1 = 0.566563 loss)
I0814 18:41:13.959246 10451 sgd_solver.cpp:136] Iteration 5000, lr = 0.0921875, m = 0.9
I0814 18:41:15.538527 10451 solver.cpp:312] Iteration 5100 (63.3213 iter/s, 1.57925s/100 iter), loss = 0.172104
I0814 18:41:15.538552 10451 solver.cpp:334]     Train net output #0: loss = 0.172104 (* 1 = 0.172104 loss)
I0814 18:41:15.538558 10451 sgd_solver.cpp:136] Iteration 5100, lr = 0.0920313, m = 0.9
I0814 18:41:17.054474 10451 solver.cpp:312] Iteration 5200 (65.9674 iter/s, 1.5159s/100 iter), loss = 0.295581
I0814 18:41:17.054519 10451 solver.cpp:334]     Train net output #0: loss = 0.295581 (* 1 = 0.295581 loss)
I0814 18:41:17.054533 10451 sgd_solver.cpp:136] Iteration 5200, lr = 0.091875, m = 0.9
I0814 18:41:18.677471 10451 solver.cpp:312] Iteration 5300 (61.6164 iter/s, 1.62294s/100 iter), loss = 0.354646
I0814 18:41:18.677497 10451 solver.cpp:334]     Train net output #0: loss = 0.354645 (* 1 = 0.354645 loss)
I0814 18:41:18.677503 10451 sgd_solver.cpp:136] Iteration 5300, lr = 0.0917188, m = 0.9
I0814 18:41:20.271773 10451 solver.cpp:312] Iteration 5400 (62.7253 iter/s, 1.59425s/100 iter), loss = 0.3844
I0814 18:41:20.271836 10451 solver.cpp:334]     Train net output #0: loss = 0.384399 (* 1 = 0.384399 loss)
I0814 18:41:20.271855 10451 sgd_solver.cpp:136] Iteration 5400, lr = 0.0915625, m = 0.9
I0814 18:41:21.826975 10451 solver.cpp:312] Iteration 5500 (64.3024 iter/s, 1.55515s/100 iter), loss = 0.248296
I0814 18:41:21.827057 10451 solver.cpp:334]     Train net output #0: loss = 0.248296 (* 1 = 0.248296 loss)
I0814 18:41:21.827066 10451 sgd_solver.cpp:136] Iteration 5500, lr = 0.0914062, m = 0.9
I0814 18:41:23.410621 10451 solver.cpp:312] Iteration 5600 (63.1475 iter/s, 1.58359s/100 iter), loss = 0.207641
I0814 18:41:23.410645 10451 solver.cpp:334]     Train net output #0: loss = 0.20764 (* 1 = 0.20764 loss)
I0814 18:41:23.410650 10451 sgd_solver.cpp:136] Iteration 5600, lr = 0.09125, m = 0.9
I0814 18:41:24.970243 10451 solver.cpp:312] Iteration 5700 (64.1201 iter/s, 1.55957s/100 iter), loss = 0.251728
I0814 18:41:24.970269 10451 solver.cpp:334]     Train net output #0: loss = 0.251728 (* 1 = 0.251728 loss)
I0814 18:41:24.970274 10451 sgd_solver.cpp:136] Iteration 5700, lr = 0.0910937, m = 0.9
I0814 18:41:26.537359 10451 solver.cpp:312] Iteration 5800 (63.8136 iter/s, 1.56706s/100 iter), loss = 0.512637
I0814 18:41:26.537382 10451 solver.cpp:334]     Train net output #0: loss = 0.512637 (* 1 = 0.512637 loss)
I0814 18:41:26.537386 10451 sgd_solver.cpp:136] Iteration 5800, lr = 0.0909375, m = 0.9
I0814 18:41:28.074894 10451 solver.cpp:312] Iteration 5900 (65.0412 iter/s, 1.53749s/100 iter), loss = 0.321882
I0814 18:41:28.074916 10451 solver.cpp:334]     Train net output #0: loss = 0.321882 (* 1 = 0.321882 loss)
I0814 18:41:28.074920 10451 sgd_solver.cpp:136] Iteration 5900, lr = 0.0907812, m = 0.9
I0814 18:41:29.613937 10451 solver.cpp:509] Iteration 6000, Testing net (#0)
I0814 18:41:30.392645 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.817942
I0814 18:41:30.392665 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.988235
I0814 18:41:30.392673 10451 solver.cpp:594]     Test net output #2: loss = 0.568127 (* 1 = 0.568127 loss)
I0814 18:41:30.392690 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.778731s
I0814 18:41:30.411512 10451 solver.cpp:312] Iteration 6000 (42.7983 iter/s, 2.33654s/100 iter), loss = 0.226499
I0814 18:41:30.411559 10451 solver.cpp:334]     Train net output #0: loss = 0.226499 (* 1 = 0.226499 loss)
I0814 18:41:30.411573 10451 sgd_solver.cpp:136] Iteration 6000, lr = 0.090625, m = 0.9
I0814 18:41:31.964139 10451 solver.cpp:312] Iteration 6100 (64.409 iter/s, 1.55258s/100 iter), loss = 0.197113
I0814 18:41:31.964202 10451 solver.cpp:334]     Train net output #0: loss = 0.197112 (* 1 = 0.197112 loss)
I0814 18:41:31.964220 10451 sgd_solver.cpp:136] Iteration 6100, lr = 0.0904688, m = 0.9
I0814 18:41:33.564574 10451 solver.cpp:312] Iteration 6200 (62.4851 iter/s, 1.60038s/100 iter), loss = 0.41035
I0814 18:41:33.564636 10451 solver.cpp:334]     Train net output #0: loss = 0.410349 (* 1 = 0.410349 loss)
I0814 18:41:33.564656 10451 sgd_solver.cpp:136] Iteration 6200, lr = 0.0903125, m = 0.9
I0814 18:41:35.159553 10451 solver.cpp:312] Iteration 6300 (62.6987 iter/s, 1.59493s/100 iter), loss = 0.378435
I0814 18:41:35.159576 10451 solver.cpp:334]     Train net output #0: loss = 0.378435 (* 1 = 0.378435 loss)
I0814 18:41:35.159582 10451 sgd_solver.cpp:136] Iteration 6300, lr = 0.0901562, m = 0.9
I0814 18:41:36.694228 10451 solver.cpp:312] Iteration 6400 (65.1625 iter/s, 1.53463s/100 iter), loss = 0.439886
I0814 18:41:36.694288 10451 solver.cpp:334]     Train net output #0: loss = 0.439886 (* 1 = 0.439886 loss)
I0814 18:41:36.694315 10451 sgd_solver.cpp:136] Iteration 6400, lr = 0.09, m = 0.9
I0814 18:41:38.280915 10451 solver.cpp:312] Iteration 6500 (63.0264 iter/s, 1.58664s/100 iter), loss = 0.217451
I0814 18:41:38.280989 10451 solver.cpp:334]     Train net output #0: loss = 0.21745 (* 1 = 0.21745 loss)
I0814 18:41:38.281011 10451 sgd_solver.cpp:136] Iteration 6500, lr = 0.0898438, m = 0.9
I0814 18:41:39.870195 10451 solver.cpp:312] Iteration 6600 (62.9237 iter/s, 1.58923s/100 iter), loss = 0.241715
I0814 18:41:39.870220 10451 solver.cpp:334]     Train net output #0: loss = 0.241714 (* 1 = 0.241714 loss)
I0814 18:41:39.870225 10451 sgd_solver.cpp:136] Iteration 6600, lr = 0.0896875, m = 0.9
I0814 18:41:41.426816 10451 solver.cpp:312] Iteration 6700 (64.2438 iter/s, 1.55657s/100 iter), loss = 0.167078
I0814 18:41:41.426862 10451 solver.cpp:334]     Train net output #0: loss = 0.167078 (* 1 = 0.167078 loss)
I0814 18:41:41.426868 10451 sgd_solver.cpp:136] Iteration 6700, lr = 0.0895313, m = 0.9
I0814 18:41:43.009126 10451 solver.cpp:312] Iteration 6800 (63.2009 iter/s, 1.58226s/100 iter), loss = 0.244086
I0814 18:41:43.009188 10451 solver.cpp:334]     Train net output #0: loss = 0.244086 (* 1 = 0.244086 loss)
I0814 18:41:43.009207 10451 sgd_solver.cpp:136] Iteration 6800, lr = 0.089375, m = 0.9
I0814 18:41:44.591562 10451 solver.cpp:312] Iteration 6900 (63.1957 iter/s, 1.58239s/100 iter), loss = 0.279012
I0814 18:41:44.591609 10451 solver.cpp:334]     Train net output #0: loss = 0.279011 (* 1 = 0.279011 loss)
I0814 18:41:44.591620 10451 sgd_solver.cpp:136] Iteration 6900, lr = 0.0892188, m = 0.9
I0814 18:41:46.195098 10451 solver.cpp:509] Iteration 7000, Testing net (#0)
I0814 18:41:46.986227 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.762354
I0814 18:41:46.986244 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.985588
I0814 18:41:46.986249 10451 solver.cpp:594]     Test net output #2: loss = 0.790896 (* 1 = 0.790896 loss)
I0814 18:41:46.986265 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.791143s
I0814 18:41:47.001633 10451 solver.cpp:312] Iteration 7000 (41.4938 iter/s, 2.41s/100 iter), loss = 0.266948
I0814 18:41:47.001648 10451 solver.cpp:334]     Train net output #0: loss = 0.266948 (* 1 = 0.266948 loss)
I0814 18:41:47.001652 10451 sgd_solver.cpp:136] Iteration 7000, lr = 0.0890625, m = 0.9
I0814 18:41:48.573235 10451 solver.cpp:312] Iteration 7100 (63.6315 iter/s, 1.57155s/100 iter), loss = 0.125979
I0814 18:41:48.573297 10451 solver.cpp:334]     Train net output #0: loss = 0.125979 (* 1 = 0.125979 loss)
I0814 18:41:48.573317 10451 sgd_solver.cpp:136] Iteration 7100, lr = 0.0889063, m = 0.9
I0814 18:41:50.155082 10451 solver.cpp:312] Iteration 7200 (63.2193 iter/s, 1.58179s/100 iter), loss = 0.417545
I0814 18:41:50.155143 10451 solver.cpp:334]     Train net output #0: loss = 0.417545 (* 1 = 0.417545 loss)
I0814 18:41:50.155163 10451 sgd_solver.cpp:136] Iteration 7200, lr = 0.08875, m = 0.9
I0814 18:41:51.676388 10451 solver.cpp:312] Iteration 7300 (65.7351 iter/s, 1.52126s/100 iter), loss = 0.381239
I0814 18:41:51.676412 10451 solver.cpp:334]     Train net output #0: loss = 0.381238 (* 1 = 0.381238 loss)
I0814 18:41:51.676417 10451 sgd_solver.cpp:136] Iteration 7300, lr = 0.0885938, m = 0.9
I0814 18:41:53.289232 10451 solver.cpp:312] Iteration 7400 (62.0041 iter/s, 1.6128s/100 iter), loss = 0.0937643
I0814 18:41:53.289306 10451 solver.cpp:334]     Train net output #0: loss = 0.0937636 (* 1 = 0.0937636 loss)
I0814 18:41:53.289322 10451 sgd_solver.cpp:136] Iteration 7400, lr = 0.0884375, m = 0.9
I0814 18:41:54.847663 10451 solver.cpp:312] Iteration 7500 (64.1692 iter/s, 1.55838s/100 iter), loss = 0.0600123
I0814 18:41:54.847709 10451 solver.cpp:334]     Train net output #0: loss = 0.0600117 (* 1 = 0.0600117 loss)
I0814 18:41:54.847723 10451 sgd_solver.cpp:136] Iteration 7500, lr = 0.0882813, m = 0.9
I0814 18:41:56.385494 10451 solver.cpp:312] Iteration 7600 (65.0289 iter/s, 1.53778s/100 iter), loss = 0.281466
I0814 18:41:56.385562 10451 solver.cpp:334]     Train net output #0: loss = 0.281465 (* 1 = 0.281465 loss)
I0814 18:41:56.385591 10451 sgd_solver.cpp:136] Iteration 7600, lr = 0.088125, m = 0.9
I0814 18:41:57.929587 10451 solver.cpp:312] Iteration 7700 (64.765 iter/s, 1.54404s/100 iter), loss = 0.0670074
I0814 18:41:57.929612 10451 solver.cpp:334]     Train net output #0: loss = 0.0670067 (* 1 = 0.0670067 loss)
I0814 18:41:57.929618 10451 sgd_solver.cpp:136] Iteration 7700, lr = 0.0879688, m = 0.9
I0814 18:41:59.515604 10451 solver.cpp:312] Iteration 7800 (63.053 iter/s, 1.58597s/100 iter), loss = 0.364437
I0814 18:41:59.515647 10451 solver.cpp:334]     Train net output #0: loss = 0.364436 (* 1 = 0.364436 loss)
I0814 18:41:59.515660 10451 sgd_solver.cpp:136] Iteration 7800, lr = 0.0878125, m = 0.9
I0814 18:42:01.067558 10451 solver.cpp:312] Iteration 7900 (64.437 iter/s, 1.5519s/100 iter), loss = 0.307449
I0814 18:42:01.067582 10451 solver.cpp:334]     Train net output #0: loss = 0.307448 (* 1 = 0.307448 loss)
I0814 18:42:01.067589 10451 sgd_solver.cpp:136] Iteration 7900, lr = 0.0876563, m = 0.9
I0814 18:42:02.609865 10451 solver.cpp:509] Iteration 8000, Testing net (#0)
I0814 18:42:03.398140 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.772942
I0814 18:42:03.398160 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.989706
I0814 18:42:03.398165 10451 solver.cpp:594]     Test net output #2: loss = 0.732179 (* 1 = 0.732179 loss)
I0814 18:42:03.398180 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.788294s
I0814 18:42:03.415071 10451 solver.cpp:312] Iteration 8000 (42.5995 iter/s, 2.34745s/100 iter), loss = 0.307844
I0814 18:42:03.415088 10451 solver.cpp:334]     Train net output #0: loss = 0.307843 (* 1 = 0.307843 loss)
I0814 18:42:03.415094 10451 sgd_solver.cpp:136] Iteration 8000, lr = 0.0875, m = 0.9
I0814 18:42:04.968680 10451 solver.cpp:312] Iteration 8100 (64.3685 iter/s, 1.55356s/100 iter), loss = 0.422737
I0814 18:42:04.968706 10451 solver.cpp:334]     Train net output #0: loss = 0.422736 (* 1 = 0.422736 loss)
I0814 18:42:04.968711 10451 sgd_solver.cpp:136] Iteration 8100, lr = 0.0873438, m = 0.9
I0814 18:42:06.531409 10451 solver.cpp:312] Iteration 8200 (63.9926 iter/s, 1.56268s/100 iter), loss = 0.0939769
I0814 18:42:06.531435 10451 solver.cpp:334]     Train net output #0: loss = 0.0939758 (* 1 = 0.0939758 loss)
I0814 18:42:06.531440 10451 sgd_solver.cpp:136] Iteration 8200, lr = 0.0871875, m = 0.9
I0814 18:42:08.141767 10451 solver.cpp:312] Iteration 8300 (62.1 iter/s, 1.61031s/100 iter), loss = 0.520569
I0814 18:42:08.141815 10451 solver.cpp:334]     Train net output #0: loss = 0.520568 (* 1 = 0.520568 loss)
I0814 18:42:08.141829 10451 sgd_solver.cpp:136] Iteration 8300, lr = 0.0870313, m = 0.9
I0814 18:42:09.793764 10451 solver.cpp:312] Iteration 8400 (60.5348 iter/s, 1.65194s/100 iter), loss = 0.0569333
I0814 18:42:09.793788 10451 solver.cpp:334]     Train net output #0: loss = 0.056932 (* 1 = 0.056932 loss)
I0814 18:42:09.793793 10451 sgd_solver.cpp:136] Iteration 8400, lr = 0.086875, m = 0.9
I0814 18:42:11.361608 10451 solver.cpp:312] Iteration 8500 (63.7838 iter/s, 1.5678s/100 iter), loss = 0.360311
I0814 18:42:11.361654 10451 solver.cpp:334]     Train net output #0: loss = 0.36031 (* 1 = 0.36031 loss)
I0814 18:42:11.361665 10451 sgd_solver.cpp:136] Iteration 8500, lr = 0.0867188, m = 0.9
I0814 18:42:13.033681 10451 solver.cpp:312] Iteration 8600 (59.8079 iter/s, 1.67202s/100 iter), loss = 0.141279
I0814 18:42:13.033720 10451 solver.cpp:334]     Train net output #0: loss = 0.141278 (* 1 = 0.141278 loss)
I0814 18:42:13.033726 10451 sgd_solver.cpp:136] Iteration 8600, lr = 0.0865625, m = 0.9
I0814 18:42:14.703764 10451 solver.cpp:312] Iteration 8700 (59.8791 iter/s, 1.67003s/100 iter), loss = 0.258948
I0814 18:42:14.703789 10451 solver.cpp:334]     Train net output #0: loss = 0.258947 (* 1 = 0.258947 loss)
I0814 18:42:14.703794 10451 sgd_solver.cpp:136] Iteration 8700, lr = 0.0864063, m = 0.9
I0814 18:42:16.388916 10451 solver.cpp:312] Iteration 8800 (59.3437 iter/s, 1.6851s/100 iter), loss = 0.316296
I0814 18:42:16.388941 10451 solver.cpp:334]     Train net output #0: loss = 0.316295 (* 1 = 0.316295 loss)
I0814 18:42:16.388945 10451 sgd_solver.cpp:136] Iteration 8800, lr = 0.08625, m = 0.9
I0814 18:42:18.097640 10451 solver.cpp:312] Iteration 8900 (58.5251 iter/s, 1.70867s/100 iter), loss = 0.216375
I0814 18:42:18.097663 10451 solver.cpp:334]     Train net output #0: loss = 0.216374 (* 1 = 0.216374 loss)
I0814 18:42:18.097674 10451 sgd_solver.cpp:136] Iteration 8900, lr = 0.0860937, m = 0.9
I0814 18:42:19.738920 10451 solver.cpp:509] Iteration 9000, Testing net (#0)
I0814 18:42:20.559623 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.682059
I0814 18:42:20.559641 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.967353
I0814 18:42:20.559646 10451 solver.cpp:594]     Test net output #2: loss = 1.38103 (* 1 = 1.38103 loss)
I0814 18:42:20.559661 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.820718s
I0814 18:42:20.577886 10451 solver.cpp:312] Iteration 9000 (40.3198 iter/s, 2.48017s/100 iter), loss = 0.155422
I0814 18:42:20.577904 10451 solver.cpp:334]     Train net output #0: loss = 0.15542 (* 1 = 0.15542 loss)
I0814 18:42:20.577909 10451 sgd_solver.cpp:136] Iteration 9000, lr = 0.0859375, m = 0.9
I0814 18:42:22.005168 10436 data_reader.cpp:288] Starting prefetch of epoch 2
I0814 18:42:22.210474 10451 solver.cpp:312] Iteration 9100 (61.2544 iter/s, 1.63254s/100 iter), loss = 0.29371
I0814 18:42:22.210497 10451 solver.cpp:334]     Train net output #0: loss = 0.293708 (* 1 = 0.293708 loss)
I0814 18:42:22.210503 10451 sgd_solver.cpp:136] Iteration 9100, lr = 0.0857813, m = 0.9
I0814 18:42:23.834656 10451 solver.cpp:312] Iteration 9200 (61.5714 iter/s, 1.62413s/100 iter), loss = 0.387051
I0814 18:42:23.834746 10451 solver.cpp:334]     Train net output #0: loss = 0.387049 (* 1 = 0.387049 loss)
I0814 18:42:23.834763 10451 sgd_solver.cpp:136] Iteration 9200, lr = 0.085625, m = 0.9
I0814 18:42:25.492686 10451 solver.cpp:312] Iteration 9300 (60.3145 iter/s, 1.65797s/100 iter), loss = 0.194589
I0814 18:42:25.492707 10451 solver.cpp:334]     Train net output #0: loss = 0.194587 (* 1 = 0.194587 loss)
I0814 18:42:25.492710 10451 sgd_solver.cpp:136] Iteration 9300, lr = 0.0854688, m = 0.9
I0814 18:42:27.129860 10451 solver.cpp:312] Iteration 9400 (61.0828 iter/s, 1.63712s/100 iter), loss = 0.40611
I0814 18:42:27.129885 10451 solver.cpp:334]     Train net output #0: loss = 0.406108 (* 1 = 0.406108 loss)
I0814 18:42:27.129891 10451 sgd_solver.cpp:136] Iteration 9400, lr = 0.0853125, m = 0.9
I0814 18:42:28.810974 10451 solver.cpp:312] Iteration 9500 (59.4863 iter/s, 1.68106s/100 iter), loss = 0.136916
I0814 18:42:28.810999 10451 solver.cpp:334]     Train net output #0: loss = 0.136915 (* 1 = 0.136915 loss)
I0814 18:42:28.811004 10451 sgd_solver.cpp:136] Iteration 9500, lr = 0.0851563, m = 0.9
I0814 18:42:30.444152 10451 solver.cpp:312] Iteration 9600 (61.2322 iter/s, 1.63313s/100 iter), loss = 0.282278
I0814 18:42:30.444290 10451 solver.cpp:334]     Train net output #0: loss = 0.282276 (* 1 = 0.282276 loss)
I0814 18:42:30.444309 10451 sgd_solver.cpp:136] Iteration 9600, lr = 0.085, m = 0.9
I0814 18:42:32.056471 10451 solver.cpp:312] Iteration 9700 (62.0245 iter/s, 1.61227s/100 iter), loss = 0.184055
I0814 18:42:32.056535 10451 solver.cpp:334]     Train net output #0: loss = 0.184054 (* 1 = 0.184054 loss)
I0814 18:42:32.056556 10451 sgd_solver.cpp:136] Iteration 9700, lr = 0.0848437, m = 0.9
I0814 18:42:33.752081 10451 solver.cpp:312] Iteration 9800 (58.9778 iter/s, 1.69555s/100 iter), loss = 0.0626927
I0814 18:42:33.752127 10451 solver.cpp:334]     Train net output #0: loss = 0.0626912 (* 1 = 0.0626912 loss)
I0814 18:42:33.752146 10451 sgd_solver.cpp:136] Iteration 9800, lr = 0.0846875, m = 0.9
I0814 18:42:35.394700 10451 solver.cpp:312] Iteration 9900 (60.8804 iter/s, 1.64256s/100 iter), loss = 0.0313934
I0814 18:42:35.394722 10451 solver.cpp:334]     Train net output #0: loss = 0.0313921 (* 1 = 0.0313921 loss)
I0814 18:42:35.394727 10451 sgd_solver.cpp:136] Iteration 9900, lr = 0.0845312, m = 0.9
I0814 18:42:37.043603 10451 solver.cpp:639] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/initial/cifar10_jacintonet11v2_iter_10000.caffemodel
I0814 18:42:37.060371 10451 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/initial/cifar10_jacintonet11v2_iter_10000.solverstate
I0814 18:42:37.064101 10451 solver.cpp:509] Iteration 10000, Testing net (#0)
I0814 18:42:37.448909 10459 blocking_queue.cpp:40] Waiting for datum
I0814 18:42:37.888200 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.79206
I0814 18:42:37.888221 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.988529
I0814 18:42:37.888227 10451 solver.cpp:594]     Test net output #2: loss = 0.65715 (* 1 = 0.65715 loss)
I0814 18:42:37.888248 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.824122s
I0814 18:42:37.908818 10451 solver.cpp:312] Iteration 10000 (39.7765 iter/s, 2.51405s/100 iter), loss = 0.164429
I0814 18:42:37.908834 10451 solver.cpp:334]     Train net output #0: loss = 0.164428 (* 1 = 0.164428 loss)
I0814 18:42:37.908840 10451 sgd_solver.cpp:136] Iteration 10000, lr = 0.084375, m = 0.9
I0814 18:42:39.556673 10451 solver.cpp:312] Iteration 10100 (60.687 iter/s, 1.6478s/100 iter), loss = 0.238966
I0814 18:42:39.556720 10451 solver.cpp:334]     Train net output #0: loss = 0.238965 (* 1 = 0.238965 loss)
I0814 18:42:39.556730 10451 sgd_solver.cpp:136] Iteration 10100, lr = 0.0842188, m = 0.9
I0814 18:42:41.252315 10451 solver.cpp:312] Iteration 10200 (58.9764 iter/s, 1.69559s/100 iter), loss = 0.106979
I0814 18:42:41.252338 10451 solver.cpp:334]     Train net output #0: loss = 0.106978 (* 1 = 0.106978 loss)
I0814 18:42:41.252344 10451 sgd_solver.cpp:136] Iteration 10200, lr = 0.0840625, m = 0.9
I0814 18:42:42.969885 10451 solver.cpp:312] Iteration 10300 (58.2236 iter/s, 1.71752s/100 iter), loss = 0.229476
I0814 18:42:42.969910 10451 solver.cpp:334]     Train net output #0: loss = 0.229475 (* 1 = 0.229475 loss)
I0814 18:42:42.969915 10451 sgd_solver.cpp:136] Iteration 10300, lr = 0.0839063, m = 0.9
I0814 18:42:44.644680 10451 solver.cpp:312] Iteration 10400 (59.7108 iter/s, 1.67474s/100 iter), loss = 0.1535
I0814 18:42:44.644704 10451 solver.cpp:334]     Train net output #0: loss = 0.153498 (* 1 = 0.153498 loss)
I0814 18:42:44.644711 10451 sgd_solver.cpp:136] Iteration 10400, lr = 0.08375, m = 0.9
I0814 18:42:46.298245 10451 solver.cpp:312] Iteration 10500 (60.4772 iter/s, 1.65352s/100 iter), loss = 0.267838
I0814 18:42:46.298306 10451 solver.cpp:334]     Train net output #0: loss = 0.267837 (* 1 = 0.267837 loss)
I0814 18:42:46.298326 10451 sgd_solver.cpp:136] Iteration 10500, lr = 0.0835937, m = 0.9
I0814 18:42:47.949879 10451 solver.cpp:312] Iteration 10600 (60.548 iter/s, 1.65158s/100 iter), loss = 0.427453
I0814 18:42:47.949905 10451 solver.cpp:334]     Train net output #0: loss = 0.427452 (* 1 = 0.427452 loss)
I0814 18:42:47.949913 10451 sgd_solver.cpp:136] Iteration 10600, lr = 0.0834375, m = 0.9
I0814 18:42:49.559361 10451 solver.cpp:312] Iteration 10700 (62.1339 iter/s, 1.60943s/100 iter), loss = 0.179563
I0814 18:42:49.559386 10451 solver.cpp:334]     Train net output #0: loss = 0.179561 (* 1 = 0.179561 loss)
I0814 18:42:49.559391 10451 sgd_solver.cpp:136] Iteration 10700, lr = 0.0832812, m = 0.9
I0814 18:42:51.157871 10451 solver.cpp:312] Iteration 10800 (62.5602 iter/s, 1.59846s/100 iter), loss = 0.354537
I0814 18:42:51.157933 10451 solver.cpp:334]     Train net output #0: loss = 0.354535 (* 1 = 0.354535 loss)
I0814 18:42:51.157953 10451 sgd_solver.cpp:136] Iteration 10800, lr = 0.083125, m = 0.9
I0814 18:42:52.800031 10451 solver.cpp:312] Iteration 10900 (60.8974 iter/s, 1.64211s/100 iter), loss = 0.102046
I0814 18:42:52.800079 10451 solver.cpp:334]     Train net output #0: loss = 0.102044 (* 1 = 0.102044 loss)
I0814 18:42:52.800094 10451 sgd_solver.cpp:136] Iteration 10900, lr = 0.0829687, m = 0.9
I0814 18:42:54.376484 10451 solver.cpp:509] Iteration 11000, Testing net (#0)
I0814 18:42:55.194793 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.764119
I0814 18:42:55.194813 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.988235
I0814 18:42:55.194820 10451 solver.cpp:594]     Test net output #2: loss = 0.865669 (* 1 = 0.865669 loss)
I0814 18:42:55.194836 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.818329s
I0814 18:42:55.210435 10451 solver.cpp:312] Iteration 11000 (41.488 iter/s, 2.41033s/100 iter), loss = 0.144268
I0814 18:42:55.210451 10451 solver.cpp:334]     Train net output #0: loss = 0.144266 (* 1 = 0.144266 loss)
I0814 18:42:55.210456 10451 sgd_solver.cpp:136] Iteration 11000, lr = 0.0828125, m = 0.9
I0814 18:42:56.799346 10451 solver.cpp:312] Iteration 11100 (62.9383 iter/s, 1.58886s/100 iter), loss = 0.0752977
I0814 18:42:56.799368 10451 solver.cpp:334]     Train net output #0: loss = 0.0752961 (* 1 = 0.0752961 loss)
I0814 18:42:56.799373 10451 sgd_solver.cpp:136] Iteration 11100, lr = 0.0826563, m = 0.9
I0814 18:42:58.411156 10451 solver.cpp:312] Iteration 11200 (62.0439 iter/s, 1.61176s/100 iter), loss = 0.140167
I0814 18:42:58.411181 10451 solver.cpp:334]     Train net output #0: loss = 0.140165 (* 1 = 0.140165 loss)
I0814 18:42:58.411187 10451 sgd_solver.cpp:136] Iteration 11200, lr = 0.0825, m = 0.9
I0814 18:42:59.996963 10451 solver.cpp:312] Iteration 11300 (63.0614 iter/s, 1.58576s/100 iter), loss = 0.0883709
I0814 18:42:59.996986 10451 solver.cpp:334]     Train net output #0: loss = 0.0883693 (* 1 = 0.0883693 loss)
I0814 18:42:59.996991 10451 sgd_solver.cpp:136] Iteration 11300, lr = 0.0823437, m = 0.9
I0814 18:43:01.648751 10451 solver.cpp:312] Iteration 11400 (60.5425 iter/s, 1.65173s/100 iter), loss = 0.0467752
I0814 18:43:01.648777 10451 solver.cpp:334]     Train net output #0: loss = 0.0467737 (* 1 = 0.0467737 loss)
I0814 18:43:01.648784 10451 sgd_solver.cpp:136] Iteration 11400, lr = 0.0821875, m = 0.9
I0814 18:43:03.298830 10451 solver.cpp:312] Iteration 11500 (60.6051 iter/s, 1.65003s/100 iter), loss = 0.298181
I0814 18:43:03.298894 10451 solver.cpp:334]     Train net output #0: loss = 0.29818 (* 1 = 0.29818 loss)
I0814 18:43:03.298913 10451 sgd_solver.cpp:136] Iteration 11500, lr = 0.0820312, m = 0.9
I0814 18:43:04.937732 10451 solver.cpp:312] Iteration 11600 (61.0184 iter/s, 1.63885s/100 iter), loss = 0.364951
I0814 18:43:04.937782 10451 solver.cpp:334]     Train net output #0: loss = 0.364949 (* 1 = 0.364949 loss)
I0814 18:43:04.937795 10451 sgd_solver.cpp:136] Iteration 11600, lr = 0.081875, m = 0.9
I0814 18:43:06.612839 10451 solver.cpp:312] Iteration 11700 (59.6996 iter/s, 1.67505s/100 iter), loss = 0.174459
I0814 18:43:06.612864 10451 solver.cpp:334]     Train net output #0: loss = 0.174458 (* 1 = 0.174458 loss)
I0814 18:43:06.612869 10451 sgd_solver.cpp:136] Iteration 11700, lr = 0.0817188, m = 0.9
I0814 18:43:08.244334 10451 solver.cpp:312] Iteration 11800 (61.2955 iter/s, 1.63144s/100 iter), loss = 0.0788061
I0814 18:43:08.244385 10451 solver.cpp:334]     Train net output #0: loss = 0.0788044 (* 1 = 0.0788044 loss)
I0814 18:43:08.244398 10451 sgd_solver.cpp:136] Iteration 11800, lr = 0.0815625, m = 0.9
I0814 18:43:09.912720 10451 solver.cpp:312] Iteration 11900 (59.9401 iter/s, 1.66833s/100 iter), loss = 0.157115
I0814 18:43:09.912750 10451 solver.cpp:334]     Train net output #0: loss = 0.157114 (* 1 = 0.157114 loss)
I0814 18:43:09.912757 10451 sgd_solver.cpp:136] Iteration 11900, lr = 0.0814063, m = 0.9
I0814 18:43:11.491199 10451 solver.cpp:509] Iteration 12000, Testing net (#0)
I0814 18:43:12.314981 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.737648
I0814 18:43:12.315001 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.98
I0814 18:43:12.315006 10451 solver.cpp:594]     Test net output #2: loss = 1.00164 (* 1 = 1.00164 loss)
I0814 18:43:12.315096 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.823873s
I0814 18:43:12.330720 10451 solver.cpp:312] Iteration 12000 (41.3577 iter/s, 2.41793s/100 iter), loss = 0.045548
I0814 18:43:12.330749 10451 solver.cpp:334]     Train net output #0: loss = 0.0455463 (* 1 = 0.0455463 loss)
I0814 18:43:12.330775 10451 sgd_solver.cpp:136] Iteration 12000, lr = 0.08125, m = 0.9
I0814 18:43:13.936175 10451 solver.cpp:312] Iteration 12100 (62.2898 iter/s, 1.6054s/100 iter), loss = 0.0464011
I0814 18:43:13.936200 10451 solver.cpp:334]     Train net output #0: loss = 0.0463995 (* 1 = 0.0463995 loss)
I0814 18:43:13.936205 10451 sgd_solver.cpp:136] Iteration 12100, lr = 0.0810938, m = 0.9
I0814 18:43:15.583387 10451 solver.cpp:312] Iteration 12200 (60.7106 iter/s, 1.64716s/100 iter), loss = 0.117088
I0814 18:43:15.583411 10451 solver.cpp:334]     Train net output #0: loss = 0.117087 (* 1 = 0.117087 loss)
I0814 18:43:15.583416 10451 sgd_solver.cpp:136] Iteration 12200, lr = 0.0809375, m = 0.9
I0814 18:43:17.200248 10451 solver.cpp:312] Iteration 12300 (61.8502 iter/s, 1.61681s/100 iter), loss = 0.190491
I0814 18:43:17.200274 10451 solver.cpp:334]     Train net output #0: loss = 0.190489 (* 1 = 0.190489 loss)
I0814 18:43:17.200280 10451 sgd_solver.cpp:136] Iteration 12300, lr = 0.0807813, m = 0.9
I0814 18:43:18.808799 10451 solver.cpp:312] Iteration 12400 (62.1698 iter/s, 1.6085s/100 iter), loss = 0.201828
I0814 18:43:18.808825 10451 solver.cpp:334]     Train net output #0: loss = 0.201827 (* 1 = 0.201827 loss)
I0814 18:43:18.808830 10451 sgd_solver.cpp:136] Iteration 12400, lr = 0.080625, m = 0.9
I0814 18:43:20.406674 10451 solver.cpp:312] Iteration 12500 (62.5851 iter/s, 1.59782s/100 iter), loss = 0.0807709
I0814 18:43:20.406697 10451 solver.cpp:334]     Train net output #0: loss = 0.0807695 (* 1 = 0.0807695 loss)
I0814 18:43:20.406702 10451 sgd_solver.cpp:136] Iteration 12500, lr = 0.0804688, m = 0.9
I0814 18:43:22.025337 10451 solver.cpp:312] Iteration 12600 (61.7813 iter/s, 1.61861s/100 iter), loss = 0.317818
I0814 18:43:22.025360 10451 solver.cpp:334]     Train net output #0: loss = 0.317817 (* 1 = 0.317817 loss)
I0814 18:43:22.025365 10451 sgd_solver.cpp:136] Iteration 12600, lr = 0.0803125, m = 0.9
I0814 18:43:23.662329 10451 solver.cpp:312] Iteration 12700 (61.0895 iter/s, 1.63694s/100 iter), loss = 0.145552
I0814 18:43:23.662377 10451 solver.cpp:334]     Train net output #0: loss = 0.145551 (* 1 = 0.145551 loss)
I0814 18:43:23.662390 10451 sgd_solver.cpp:136] Iteration 12700, lr = 0.0801563, m = 0.9
I0814 18:43:25.286761 10451 solver.cpp:312] Iteration 12800 (61.5619 iter/s, 1.62438s/100 iter), loss = 0.241692
I0814 18:43:25.286813 10451 solver.cpp:334]     Train net output #0: loss = 0.24169 (* 1 = 0.24169 loss)
I0814 18:43:25.286818 10451 sgd_solver.cpp:136] Iteration 12800, lr = 0.08, m = 0.9
I0814 18:43:26.869617 10451 solver.cpp:312] Iteration 12900 (63.1791 iter/s, 1.5828s/100 iter), loss = 0.0441889
I0814 18:43:26.869643 10451 solver.cpp:334]     Train net output #0: loss = 0.0441876 (* 1 = 0.0441876 loss)
I0814 18:43:26.869649 10451 sgd_solver.cpp:136] Iteration 12900, lr = 0.0798438, m = 0.9
I0814 18:43:28.460041 10451 solver.cpp:509] Iteration 13000, Testing net (#0)
I0814 18:43:29.278812 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.82853
I0814 18:43:29.278838 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.990588
I0814 18:43:29.278847 10451 solver.cpp:594]     Test net output #2: loss = 0.59088 (* 1 = 0.59088 loss)
I0814 18:43:29.278872 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.818807s
I0814 18:43:29.296460 10451 solver.cpp:312] Iteration 13000 (41.2071 iter/s, 2.42677s/100 iter), loss = 0.0993569
I0814 18:43:29.296739 10451 solver.cpp:334]     Train net output #0: loss = 0.0993555 (* 1 = 0.0993555 loss)
I0814 18:43:29.296747 10451 sgd_solver.cpp:136] Iteration 13000, lr = 0.0796875, m = 0.9
I0814 18:43:30.927083 10451 solver.cpp:312] Iteration 13100 (61.3282 iter/s, 1.63057s/100 iter), loss = 0.261867
I0814 18:43:30.927129 10451 solver.cpp:334]     Train net output #0: loss = 0.261866 (* 1 = 0.261866 loss)
I0814 18:43:30.927141 10451 sgd_solver.cpp:136] Iteration 13100, lr = 0.0795313, m = 0.9
I0814 18:43:32.556668 10451 solver.cpp:312] Iteration 13200 (61.3674 iter/s, 1.62953s/100 iter), loss = 0.254124
I0814 18:43:32.556747 10451 solver.cpp:334]     Train net output #0: loss = 0.254123 (* 1 = 0.254123 loss)
I0814 18:43:32.556756 10451 sgd_solver.cpp:136] Iteration 13200, lr = 0.079375, m = 0.9
I0814 18:43:34.177989 10451 solver.cpp:312] Iteration 13300 (61.68 iter/s, 1.62127s/100 iter), loss = 0.0747326
I0814 18:43:34.178036 10451 solver.cpp:334]     Train net output #0: loss = 0.0747312 (* 1 = 0.0747312 loss)
I0814 18:43:34.178048 10451 sgd_solver.cpp:136] Iteration 13300, lr = 0.0792188, m = 0.9
I0814 18:43:35.830471 10451 solver.cpp:312] Iteration 13400 (60.5169 iter/s, 1.65243s/100 iter), loss = 0.0421931
I0814 18:43:35.830497 10451 solver.cpp:334]     Train net output #0: loss = 0.0421917 (* 1 = 0.0421917 loss)
I0814 18:43:35.830500 10451 sgd_solver.cpp:136] Iteration 13400, lr = 0.0790625, m = 0.9
I0814 18:43:37.406162 10451 solver.cpp:312] Iteration 13500 (63.4661 iter/s, 1.57564s/100 iter), loss = 0.152179
I0814 18:43:37.406185 10451 solver.cpp:334]     Train net output #0: loss = 0.152178 (* 1 = 0.152178 loss)
I0814 18:43:37.406191 10451 sgd_solver.cpp:136] Iteration 13500, lr = 0.0789063, m = 0.9
I0814 18:43:39.045737 10451 solver.cpp:312] Iteration 13600 (60.9934 iter/s, 1.63952s/100 iter), loss = 0.0251957
I0814 18:43:39.045759 10451 solver.cpp:334]     Train net output #0: loss = 0.0251941 (* 1 = 0.0251941 loss)
I0814 18:43:39.045765 10451 sgd_solver.cpp:136] Iteration 13600, lr = 0.07875, m = 0.9
I0814 18:43:39.584765 10436 data_reader.cpp:288] Starting prefetch of epoch 3
I0814 18:43:40.660521 10451 solver.cpp:312] Iteration 13700 (61.9297 iter/s, 1.61473s/100 iter), loss = 0.164027
I0814 18:43:40.660542 10451 solver.cpp:334]     Train net output #0: loss = 0.164026 (* 1 = 0.164026 loss)
I0814 18:43:40.660548 10451 sgd_solver.cpp:136] Iteration 13700, lr = 0.0785938, m = 0.9
I0814 18:43:42.255220 10451 solver.cpp:312] Iteration 13800 (62.7098 iter/s, 1.59465s/100 iter), loss = 0.0417317
I0814 18:43:42.255244 10451 solver.cpp:334]     Train net output #0: loss = 0.0417302 (* 1 = 0.0417302 loss)
I0814 18:43:42.255250 10451 sgd_solver.cpp:136] Iteration 13800, lr = 0.0784375, m = 0.9
I0814 18:43:43.862349 10451 solver.cpp:312] Iteration 13900 (62.2248 iter/s, 1.60708s/100 iter), loss = 0.0977415
I0814 18:43:43.862373 10451 solver.cpp:334]     Train net output #0: loss = 0.09774 (* 1 = 0.09774 loss)
I0814 18:43:43.862380 10451 sgd_solver.cpp:136] Iteration 13900, lr = 0.0782812, m = 0.9
I0814 18:43:45.499514 10451 solver.cpp:509] Iteration 14000, Testing net (#0)
I0814 18:43:46.314064 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.77353
I0814 18:43:46.314085 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.969412
I0814 18:43:46.314090 10451 solver.cpp:594]     Test net output #2: loss = 0.967167 (* 1 = 0.967167 loss)
I0814 18:43:46.314105 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.814565s
I0814 18:43:46.330008 10451 solver.cpp:312] Iteration 14000 (40.5254 iter/s, 2.46759s/100 iter), loss = 0.0452544
I0814 18:43:46.330024 10451 solver.cpp:334]     Train net output #0: loss = 0.0452529 (* 1 = 0.0452529 loss)
I0814 18:43:46.330029 10451 sgd_solver.cpp:136] Iteration 14000, lr = 0.078125, m = 0.9
I0814 18:43:47.973815 10451 solver.cpp:312] Iteration 14100 (60.8365 iter/s, 1.64375s/100 iter), loss = 0.112046
I0814 18:43:47.973841 10451 solver.cpp:334]     Train net output #0: loss = 0.112044 (* 1 = 0.112044 loss)
I0814 18:43:47.973847 10451 sgd_solver.cpp:136] Iteration 14100, lr = 0.0779688, m = 0.9
I0814 18:43:49.573822 10451 solver.cpp:312] Iteration 14200 (62.5017 iter/s, 1.59996s/100 iter), loss = 0.0277375
I0814 18:43:49.573845 10451 solver.cpp:334]     Train net output #0: loss = 0.0277361 (* 1 = 0.0277361 loss)
I0814 18:43:49.573851 10451 sgd_solver.cpp:136] Iteration 14200, lr = 0.0778125, m = 0.9
I0814 18:43:51.202647 10451 solver.cpp:312] Iteration 14300 (61.3959 iter/s, 1.62877s/100 iter), loss = 0.091118
I0814 18:43:51.202672 10451 solver.cpp:334]     Train net output #0: loss = 0.0911165 (* 1 = 0.0911165 loss)
I0814 18:43:51.202677 10451 sgd_solver.cpp:136] Iteration 14300, lr = 0.0776563, m = 0.9
I0814 18:43:52.814159 10451 solver.cpp:312] Iteration 14400 (62.0555 iter/s, 1.61146s/100 iter), loss = 0.248979
I0814 18:43:52.814213 10451 solver.cpp:334]     Train net output #0: loss = 0.248978 (* 1 = 0.248978 loss)
I0814 18:43:52.814224 10451 sgd_solver.cpp:136] Iteration 14400, lr = 0.0775, m = 0.9
I0814 18:43:54.461863 10451 solver.cpp:312] Iteration 14500 (60.6925 iter/s, 1.64765s/100 iter), loss = 0.0455427
I0814 18:43:54.461913 10451 solver.cpp:334]     Train net output #0: loss = 0.0455412 (* 1 = 0.0455412 loss)
I0814 18:43:54.461927 10451 sgd_solver.cpp:136] Iteration 14500, lr = 0.0773438, m = 0.9
I0814 18:43:56.119771 10451 solver.cpp:312] Iteration 14600 (60.3189 iter/s, 1.65786s/100 iter), loss = 0.209466
I0814 18:43:56.119876 10451 solver.cpp:334]     Train net output #0: loss = 0.209465 (* 1 = 0.209465 loss)
I0814 18:43:56.119889 10451 sgd_solver.cpp:136] Iteration 14600, lr = 0.0771875, m = 0.9
I0814 18:43:57.740177 10451 solver.cpp:312] Iteration 14700 (61.7148 iter/s, 1.62036s/100 iter), loss = 0.259719
I0814 18:43:57.740201 10451 solver.cpp:334]     Train net output #0: loss = 0.259718 (* 1 = 0.259718 loss)
I0814 18:43:57.740206 10451 sgd_solver.cpp:136] Iteration 14700, lr = 0.0770312, m = 0.9
I0814 18:43:59.362427 10451 solver.cpp:312] Iteration 14800 (61.6448 iter/s, 1.6222s/100 iter), loss = 0.138027
I0814 18:43:59.362450 10451 solver.cpp:334]     Train net output #0: loss = 0.138025 (* 1 = 0.138025 loss)
I0814 18:43:59.362457 10451 sgd_solver.cpp:136] Iteration 14800, lr = 0.076875, m = 0.9
I0814 18:44:01.012573 10451 solver.cpp:312] Iteration 14900 (60.6026 iter/s, 1.6501s/100 iter), loss = 0.111309
I0814 18:44:01.012600 10451 solver.cpp:334]     Train net output #0: loss = 0.111308 (* 1 = 0.111308 loss)
I0814 18:44:01.012607 10451 sgd_solver.cpp:136] Iteration 14900, lr = 0.0767187, m = 0.9
I0814 18:44:02.652148 10451 solver.cpp:509] Iteration 15000, Testing net (#0)
I0814 18:44:03.489470 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.78559
I0814 18:44:03.489488 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.974412
I0814 18:44:03.489493 10451 solver.cpp:594]     Test net output #2: loss = 0.934723 (* 1 = 0.934723 loss)
I0814 18:44:03.489508 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.837338s
I0814 18:44:03.505002 10451 solver.cpp:312] Iteration 15000 (40.1228 iter/s, 2.49235s/100 iter), loss = 0.0478968
I0814 18:44:03.505020 10451 solver.cpp:334]     Train net output #0: loss = 0.0478953 (* 1 = 0.0478953 loss)
I0814 18:44:03.505026 10451 sgd_solver.cpp:136] Iteration 15000, lr = 0.0765625, m = 0.9
I0814 18:44:05.123206 10451 solver.cpp:312] Iteration 15100 (61.7989 iter/s, 1.61815s/100 iter), loss = 0.0737568
I0814 18:44:05.123251 10451 solver.cpp:334]     Train net output #0: loss = 0.0737554 (* 1 = 0.0737554 loss)
I0814 18:44:05.123265 10451 sgd_solver.cpp:136] Iteration 15100, lr = 0.0764063, m = 0.9
I0814 18:44:06.732506 10451 solver.cpp:312] Iteration 15200 (62.1409 iter/s, 1.60925s/100 iter), loss = 0.117436
I0814 18:44:06.732530 10451 solver.cpp:334]     Train net output #0: loss = 0.117435 (* 1 = 0.117435 loss)
I0814 18:44:06.732535 10451 sgd_solver.cpp:136] Iteration 15200, lr = 0.07625, m = 0.9
I0814 18:44:08.373384 10451 solver.cpp:312] Iteration 15300 (60.9449 iter/s, 1.64083s/100 iter), loss = 0.0917573
I0814 18:44:08.373409 10451 solver.cpp:334]     Train net output #0: loss = 0.0917559 (* 1 = 0.0917559 loss)
I0814 18:44:08.373414 10451 sgd_solver.cpp:136] Iteration 15300, lr = 0.0760938, m = 0.9
I0814 18:44:10.018666 10451 solver.cpp:312] Iteration 15400 (60.7818 iter/s, 1.64523s/100 iter), loss = 0.285941
I0814 18:44:10.018689 10451 solver.cpp:334]     Train net output #0: loss = 0.285939 (* 1 = 0.285939 loss)
I0814 18:44:10.018695 10451 sgd_solver.cpp:136] Iteration 15400, lr = 0.0759375, m = 0.9
I0814 18:44:11.671264 10451 solver.cpp:312] Iteration 15500 (60.5126 iter/s, 1.65255s/100 iter), loss = 0.0659411
I0814 18:44:11.671326 10451 solver.cpp:334]     Train net output #0: loss = 0.0659397 (* 1 = 0.0659397 loss)
I0814 18:44:11.671344 10451 sgd_solver.cpp:136] Iteration 15500, lr = 0.0757812, m = 0.9
I0814 18:44:13.316429 10451 solver.cpp:312] Iteration 15600 (60.7861 iter/s, 1.64511s/100 iter), loss = 0.186997
I0814 18:44:13.316478 10451 solver.cpp:334]     Train net output #0: loss = 0.186995 (* 1 = 0.186995 loss)
I0814 18:44:13.316493 10451 sgd_solver.cpp:136] Iteration 15600, lr = 0.075625, m = 0.9
I0814 18:44:14.942283 10451 solver.cpp:312] Iteration 15700 (61.508 iter/s, 1.6258s/100 iter), loss = 0.218465
I0814 18:44:14.942307 10451 solver.cpp:334]     Train net output #0: loss = 0.218463 (* 1 = 0.218463 loss)
I0814 18:44:14.942312 10451 sgd_solver.cpp:136] Iteration 15700, lr = 0.0754687, m = 0.9
I0814 18:44:16.556831 10451 solver.cpp:312] Iteration 15800 (61.9388 iter/s, 1.6145s/100 iter), loss = 0.198966
I0814 18:44:16.557001 10451 solver.cpp:334]     Train net output #0: loss = 0.198965 (* 1 = 0.198965 loss)
I0814 18:44:16.557025 10451 sgd_solver.cpp:136] Iteration 15800, lr = 0.0753125, m = 0.9
I0814 18:44:18.187975 10451 solver.cpp:312] Iteration 15900 (61.3087 iter/s, 1.63109s/100 iter), loss = 0.139731
I0814 18:44:18.188032 10451 solver.cpp:334]     Train net output #0: loss = 0.139729 (* 1 = 0.139729 loss)
I0814 18:44:18.188050 10451 sgd_solver.cpp:136] Iteration 15900, lr = 0.0751562, m = 0.9
I0814 18:44:19.805476 10451 solver.cpp:509] Iteration 16000, Testing net (#0)
I0814 18:44:20.642119 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.799413
I0814 18:44:20.642137 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.985883
I0814 18:44:20.642141 10451 solver.cpp:594]     Test net output #2: loss = 0.749197 (* 1 = 0.749197 loss)
I0814 18:44:20.642163 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.836662s
I0814 18:44:20.659468 10451 solver.cpp:312] Iteration 16000 (40.4625 iter/s, 2.47142s/100 iter), loss = 0.0290861
I0814 18:44:20.659488 10451 solver.cpp:334]     Train net output #0: loss = 0.0290846 (* 1 = 0.0290846 loss)
I0814 18:44:20.659494 10451 sgd_solver.cpp:136] Iteration 16000, lr = 0.075, m = 0.9
I0814 18:44:22.299613 10451 solver.cpp:312] Iteration 16100 (60.9722 iter/s, 1.64009s/100 iter), loss = 0.33422
I0814 18:44:22.299638 10451 solver.cpp:334]     Train net output #0: loss = 0.334219 (* 1 = 0.334219 loss)
I0814 18:44:22.299644 10451 sgd_solver.cpp:136] Iteration 16100, lr = 0.0748438, m = 0.9
I0814 18:44:23.929388 10451 solver.cpp:312] Iteration 16200 (61.3601 iter/s, 1.62972s/100 iter), loss = 0.200306
I0814 18:44:23.929414 10451 solver.cpp:334]     Train net output #0: loss = 0.200305 (* 1 = 0.200305 loss)
I0814 18:44:23.929421 10451 sgd_solver.cpp:136] Iteration 16200, lr = 0.0746875, m = 0.9
I0814 18:44:25.571362 10451 solver.cpp:312] Iteration 16300 (60.9042 iter/s, 1.64192s/100 iter), loss = 0.0135765
I0814 18:44:25.571388 10451 solver.cpp:334]     Train net output #0: loss = 0.013575 (* 1 = 0.013575 loss)
I0814 18:44:25.571393 10451 sgd_solver.cpp:136] Iteration 16300, lr = 0.0745312, m = 0.9
I0814 18:44:27.183315 10451 solver.cpp:312] Iteration 16400 (62.0385 iter/s, 1.6119s/100 iter), loss = 0.0856932
I0814 18:44:27.183413 10451 solver.cpp:334]     Train net output #0: loss = 0.0856917 (* 1 = 0.0856917 loss)
I0814 18:44:27.183429 10451 sgd_solver.cpp:136] Iteration 16400, lr = 0.074375, m = 0.9
I0814 18:44:28.807698 10451 solver.cpp:312] Iteration 16500 (61.5639 iter/s, 1.62433s/100 iter), loss = 0.0741544
I0814 18:44:28.807745 10451 solver.cpp:334]     Train net output #0: loss = 0.0741529 (* 1 = 0.0741529 loss)
I0814 18:44:28.807760 10451 sgd_solver.cpp:136] Iteration 16500, lr = 0.0742188, m = 0.9
I0814 18:44:30.445211 10451 solver.cpp:312] Iteration 16600 (61.07 iter/s, 1.63746s/100 iter), loss = 0.330168
I0814 18:44:30.445238 10451 solver.cpp:334]     Train net output #0: loss = 0.330166 (* 1 = 0.330166 loss)
I0814 18:44:30.445245 10451 sgd_solver.cpp:136] Iteration 16600, lr = 0.0740625, m = 0.9
I0814 18:44:32.089239 10451 solver.cpp:312] Iteration 16700 (60.8282 iter/s, 1.64397s/100 iter), loss = 0.171333
I0814 18:44:32.089308 10451 solver.cpp:334]     Train net output #0: loss = 0.171331 (* 1 = 0.171331 loss)
I0814 18:44:32.089339 10451 sgd_solver.cpp:136] Iteration 16700, lr = 0.0739063, m = 0.9
I0814 18:44:33.715647 10451 solver.cpp:312] Iteration 16800 (61.4872 iter/s, 1.62636s/100 iter), loss = 0.0531785
I0814 18:44:33.715672 10451 solver.cpp:334]     Train net output #0: loss = 0.0531769 (* 1 = 0.0531769 loss)
I0814 18:44:33.715677 10451 sgd_solver.cpp:136] Iteration 16800, lr = 0.07375, m = 0.9
I0814 18:44:35.338398 10451 solver.cpp:312] Iteration 16900 (61.6257 iter/s, 1.6227s/100 iter), loss = 0.128129
I0814 18:44:35.338446 10451 solver.cpp:334]     Train net output #0: loss = 0.128127 (* 1 = 0.128127 loss)
I0814 18:44:35.338459 10451 sgd_solver.cpp:136] Iteration 16900, lr = 0.0735938, m = 0.9
I0814 18:44:36.930523 10451 solver.cpp:509] Iteration 17000, Testing net (#0)
I0814 18:44:37.750562 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.820295
I0814 18:44:37.750581 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.985588
I0814 18:44:37.750586 10451 solver.cpp:594]     Test net output #2: loss = 0.74981 (* 1 = 0.74981 loss)
I0814 18:44:37.750602 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.820056s
I0814 18:44:37.767980 10451 solver.cpp:312] Iteration 17000 (41.1605 iter/s, 2.42951s/100 iter), loss = 0.143703
I0814 18:44:37.767998 10451 solver.cpp:334]     Train net output #0: loss = 0.143701 (* 1 = 0.143701 loss)
I0814 18:44:37.768003 10451 sgd_solver.cpp:136] Iteration 17000, lr = 0.0734375, m = 0.9
I0814 18:44:39.388905 10451 solver.cpp:312] Iteration 17100 (61.6951 iter/s, 1.62087s/100 iter), loss = 0.112766
I0814 18:44:39.388952 10451 solver.cpp:334]     Train net output #0: loss = 0.112764 (* 1 = 0.112764 loss)
I0814 18:44:39.388968 10451 sgd_solver.cpp:136] Iteration 17100, lr = 0.0732813, m = 0.9
I0814 18:44:41.020293 10451 solver.cpp:312] Iteration 17200 (61.2995 iter/s, 1.63133s/100 iter), loss = 0.0443328
I0814 18:44:41.020339 10451 solver.cpp:334]     Train net output #0: loss = 0.0443313 (* 1 = 0.0443313 loss)
I0814 18:44:41.020354 10451 sgd_solver.cpp:136] Iteration 17200, lr = 0.073125, m = 0.9
I0814 18:44:42.618517 10451 solver.cpp:312] Iteration 17300 (62.5715 iter/s, 1.59817s/100 iter), loss = 0.0679909
I0814 18:44:42.618572 10451 solver.cpp:334]     Train net output #0: loss = 0.0679893 (* 1 = 0.0679893 loss)
I0814 18:44:42.618587 10451 sgd_solver.cpp:136] Iteration 17300, lr = 0.0729688, m = 0.9
I0814 18:44:44.229044 10451 solver.cpp:312] Iteration 17400 (62.0933 iter/s, 1.61048s/100 iter), loss = 0.0466631
I0814 18:44:44.229094 10451 solver.cpp:334]     Train net output #0: loss = 0.0466614 (* 1 = 0.0466614 loss)
I0814 18:44:44.229105 10451 sgd_solver.cpp:136] Iteration 17400, lr = 0.0728125, m = 0.9
I0814 18:44:45.881207 10451 solver.cpp:312] Iteration 17500 (60.5286 iter/s, 1.65211s/100 iter), loss = 0.0399758
I0814 18:44:45.881233 10451 solver.cpp:334]     Train net output #0: loss = 0.0399742 (* 1 = 0.0399742 loss)
I0814 18:44:45.881239 10451 sgd_solver.cpp:136] Iteration 17500, lr = 0.0726563, m = 0.9
I0814 18:44:47.481632 10451 solver.cpp:312] Iteration 17600 (62.4854 iter/s, 1.60037s/100 iter), loss = 0.0310081
I0814 18:44:47.481676 10451 solver.cpp:334]     Train net output #0: loss = 0.0310066 (* 1 = 0.0310066 loss)
I0814 18:44:47.481683 10451 sgd_solver.cpp:136] Iteration 17600, lr = 0.0725, m = 0.9
I0814 18:44:49.104802 10451 solver.cpp:312] Iteration 17700 (61.6099 iter/s, 1.62312s/100 iter), loss = 0.0206702
I0814 18:44:49.104848 10451 solver.cpp:334]     Train net output #0: loss = 0.0206687 (* 1 = 0.0206687 loss)
I0814 18:44:49.104862 10451 sgd_solver.cpp:136] Iteration 17700, lr = 0.0723438, m = 0.9
I0814 18:44:50.704496 10451 solver.cpp:312] Iteration 17800 (62.5139 iter/s, 1.59964s/100 iter), loss = 0.093697
I0814 18:44:50.704524 10451 solver.cpp:334]     Train net output #0: loss = 0.0936956 (* 1 = 0.0936956 loss)
I0814 18:44:50.704530 10451 sgd_solver.cpp:136] Iteration 17800, lr = 0.0721875, m = 0.9
I0814 18:44:52.308497 10451 solver.cpp:312] Iteration 17900 (62.3459 iter/s, 1.60395s/100 iter), loss = 0.223889
I0814 18:44:52.308555 10451 solver.cpp:334]     Train net output #0: loss = 0.223887 (* 1 = 0.223887 loss)
I0814 18:44:52.308570 10451 sgd_solver.cpp:136] Iteration 17900, lr = 0.0720313, m = 0.9
I0814 18:44:53.923688 10451 solver.cpp:509] Iteration 18000, Testing net (#0)
I0814 18:44:54.401392 10438 data_reader.cpp:288] Starting prefetch of epoch 2
I0814 18:44:54.739018 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.805884
I0814 18:44:54.739037 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.986471
I0814 18:44:54.739042 10451 solver.cpp:594]     Test net output #2: loss = 0.756222 (* 1 = 0.756222 loss)
I0814 18:44:54.739058 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.815347s
I0814 18:44:54.754614 10451 solver.cpp:312] Iteration 18000 (40.8824 iter/s, 2.44604s/100 iter), loss = 0.029643
I0814 18:44:54.754631 10451 solver.cpp:334]     Train net output #0: loss = 0.0296416 (* 1 = 0.0296416 loss)
I0814 18:44:54.754637 10451 sgd_solver.cpp:136] Iteration 18000, lr = 0.071875, m = 0.9
I0814 18:44:56.347685 10451 solver.cpp:312] Iteration 18100 (62.7739 iter/s, 1.59302s/100 iter), loss = 0.00368932
I0814 18:44:56.347733 10451 solver.cpp:334]     Train net output #0: loss = 0.00368797 (* 1 = 0.00368797 loss)
I0814 18:44:56.347748 10451 sgd_solver.cpp:136] Iteration 18100, lr = 0.0717188, m = 0.9
I0814 18:44:57.991847 10451 solver.cpp:312] Iteration 18200 (60.8231 iter/s, 1.64411s/100 iter), loss = 0.00725249
I0814 18:44:57.991925 10451 solver.cpp:334]     Train net output #0: loss = 0.00725117 (* 1 = 0.00725117 loss)
I0814 18:44:57.991933 10451 sgd_solver.cpp:136] Iteration 18200, lr = 0.0715625, m = 0.9
I0814 18:44:59.577795 10451 solver.cpp:312] Iteration 18300 (63.0559 iter/s, 1.5859s/100 iter), loss = 0.354245
I0814 18:44:59.577890 10451 solver.cpp:334]     Train net output #0: loss = 0.354244 (* 1 = 0.354244 loss)
I0814 18:44:59.577898 10451 sgd_solver.cpp:136] Iteration 18300, lr = 0.0714063, m = 0.9
I0814 18:45:01.194073 10451 solver.cpp:312] Iteration 18400 (61.8724 iter/s, 1.61623s/100 iter), loss = 0.125627
I0814 18:45:01.194098 10451 solver.cpp:334]     Train net output #0: loss = 0.125626 (* 1 = 0.125626 loss)
I0814 18:45:01.194104 10451 sgd_solver.cpp:136] Iteration 18400, lr = 0.07125, m = 0.9
I0814 18:45:02.806784 10451 solver.cpp:312] Iteration 18500 (62.0093 iter/s, 1.61266s/100 iter), loss = 0.0937057
I0814 18:45:02.806807 10451 solver.cpp:334]     Train net output #0: loss = 0.0937045 (* 1 = 0.0937045 loss)
I0814 18:45:02.806812 10451 sgd_solver.cpp:136] Iteration 18500, lr = 0.0710938, m = 0.9
I0814 18:45:04.404680 10451 solver.cpp:312] Iteration 18600 (62.5843 iter/s, 1.59785s/100 iter), loss = 0.260423
I0814 18:45:04.404703 10451 solver.cpp:334]     Train net output #0: loss = 0.260422 (* 1 = 0.260422 loss)
I0814 18:45:04.404707 10451 sgd_solver.cpp:136] Iteration 18600, lr = 0.0709375, m = 0.9
I0814 18:45:05.986974 10451 solver.cpp:312] Iteration 18700 (63.2014 iter/s, 1.58224s/100 iter), loss = 0.187294
I0814 18:45:05.987001 10451 solver.cpp:334]     Train net output #0: loss = 0.187293 (* 1 = 0.187293 loss)
I0814 18:45:05.987009 10451 sgd_solver.cpp:136] Iteration 18700, lr = 0.0707813, m = 0.9
I0814 18:45:07.631041 10451 solver.cpp:312] Iteration 18800 (60.8268 iter/s, 1.64401s/100 iter), loss = 0.0238274
I0814 18:45:07.631083 10451 solver.cpp:334]     Train net output #0: loss = 0.0238261 (* 1 = 0.0238261 loss)
I0814 18:45:07.631089 10451 sgd_solver.cpp:136] Iteration 18800, lr = 0.070625, m = 0.9
I0814 18:45:09.256136 10451 solver.cpp:312] Iteration 18900 (61.5368 iter/s, 1.62504s/100 iter), loss = 0.162358
I0814 18:45:09.256204 10451 solver.cpp:334]     Train net output #0: loss = 0.162356 (* 1 = 0.162356 loss)
I0814 18:45:09.256234 10451 sgd_solver.cpp:136] Iteration 18900, lr = 0.0704687, m = 0.9
I0814 18:45:10.887142 10451 solver.cpp:509] Iteration 19000, Testing net (#0)
I0814 18:45:11.704962 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.82706
I0814 18:45:11.704978 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.988235
I0814 18:45:11.704983 10451 solver.cpp:594]     Test net output #2: loss = 0.667615 (* 1 = 0.667615 loss)
I0814 18:45:11.705000 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.817835s
I0814 18:45:11.720535 10451 solver.cpp:312] Iteration 19000 (40.579 iter/s, 2.46433s/100 iter), loss = 0.227152
I0814 18:45:11.720554 10451 solver.cpp:334]     Train net output #0: loss = 0.22715 (* 1 = 0.22715 loss)
I0814 18:45:11.720561 10451 sgd_solver.cpp:136] Iteration 19000, lr = 0.0703125, m = 0.9
I0814 18:45:13.368896 10451 solver.cpp:312] Iteration 19100 (60.6683 iter/s, 1.64831s/100 iter), loss = 0.154841
I0814 18:45:13.368944 10451 solver.cpp:334]     Train net output #0: loss = 0.15484 (* 1 = 0.15484 loss)
I0814 18:45:13.368958 10451 sgd_solver.cpp:136] Iteration 19100, lr = 0.0701563, m = 0.9
I0814 18:45:14.991855 10451 solver.cpp:312] Iteration 19200 (61.6178 iter/s, 1.62291s/100 iter), loss = 0.0331433
I0814 18:45:14.991881 10451 solver.cpp:334]     Train net output #0: loss = 0.0331422 (* 1 = 0.0331422 loss)
I0814 18:45:14.991888 10451 sgd_solver.cpp:136] Iteration 19200, lr = 0.07, m = 0.9
I0814 18:45:16.611850 10451 solver.cpp:312] Iteration 19300 (61.7306 iter/s, 1.61994s/100 iter), loss = 0.0327034
I0814 18:45:16.611877 10451 solver.cpp:334]     Train net output #0: loss = 0.0327023 (* 1 = 0.0327023 loss)
I0814 18:45:16.611884 10451 sgd_solver.cpp:136] Iteration 19300, lr = 0.0698438, m = 0.9
I0814 18:45:18.255129 10451 solver.cpp:312] Iteration 19400 (60.8558 iter/s, 1.64323s/100 iter), loss = 0.114478
I0814 18:45:18.255188 10451 solver.cpp:334]     Train net output #0: loss = 0.114476 (* 1 = 0.114476 loss)
I0814 18:45:18.255203 10451 sgd_solver.cpp:136] Iteration 19400, lr = 0.0696875, m = 0.9
I0814 18:45:19.892213 10451 solver.cpp:312] Iteration 19500 (61.0862 iter/s, 1.63703s/100 iter), loss = 0.0220742
I0814 18:45:19.892343 10451 solver.cpp:334]     Train net output #0: loss = 0.0220731 (* 1 = 0.0220731 loss)
I0814 18:45:19.892359 10451 sgd_solver.cpp:136] Iteration 19500, lr = 0.0695313, m = 0.9
I0814 18:45:21.488608 10451 solver.cpp:312] Iteration 19600 (62.6431 iter/s, 1.59634s/100 iter), loss = 0.0620249
I0814 18:45:21.488688 10451 solver.cpp:334]     Train net output #0: loss = 0.0620238 (* 1 = 0.0620238 loss)
I0814 18:45:21.488709 10451 sgd_solver.cpp:136] Iteration 19600, lr = 0.069375, m = 0.9
I0814 18:45:23.120695 10451 solver.cpp:312] Iteration 19700 (61.2732 iter/s, 1.63203s/100 iter), loss = 0.0285975
I0814 18:45:23.120853 10451 solver.cpp:334]     Train net output #0: loss = 0.0285964 (* 1 = 0.0285964 loss)
I0814 18:45:23.120934 10451 sgd_solver.cpp:136] Iteration 19700, lr = 0.0692187, m = 0.9
I0814 18:45:24.780223 10451 solver.cpp:312] Iteration 19800 (60.26 iter/s, 1.65947s/100 iter), loss = 0.154363
I0814 18:45:24.780270 10451 solver.cpp:334]     Train net output #0: loss = 0.154362 (* 1 = 0.154362 loss)
I0814 18:45:24.780282 10451 sgd_solver.cpp:136] Iteration 19800, lr = 0.0690625, m = 0.9
I0814 18:45:26.402451 10451 solver.cpp:312] Iteration 19900 (61.6456 iter/s, 1.62217s/100 iter), loss = 0.125881
I0814 18:45:26.402510 10451 solver.cpp:334]     Train net output #0: loss = 0.125879 (* 1 = 0.125879 loss)
I0814 18:45:26.402526 10451 sgd_solver.cpp:136] Iteration 19900, lr = 0.0689062, m = 0.9
I0814 18:45:28.050727 10451 solver.cpp:639] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/initial/cifar10_jacintonet11v2_iter_20000.caffemodel
I0814 18:45:28.060282 10451 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/initial/cifar10_jacintonet11v2_iter_20000.solverstate
I0814 18:45:28.065045 10451 solver.cpp:509] Iteration 20000, Testing net (#0)
I0814 18:45:28.870872 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.744707
I0814 18:45:28.870890 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.982941
I0814 18:45:28.870896 10451 solver.cpp:594]     Test net output #2: loss = 1.17378 (* 1 = 1.17378 loss)
I0814 18:45:28.870914 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.805846s
I0814 18:45:28.886544 10451 solver.cpp:312] Iteration 20000 (40.2573 iter/s, 2.48402s/100 iter), loss = 0.027179
I0814 18:45:28.886562 10451 solver.cpp:334]     Train net output #0: loss = 0.0271778 (* 1 = 0.0271778 loss)
I0814 18:45:28.886569 10451 sgd_solver.cpp:136] Iteration 20000, lr = 0.06875, m = 0.9
I0814 18:45:30.490424 10451 solver.cpp:312] Iteration 20100 (62.3508 iter/s, 1.60383s/100 iter), loss = 0.0696251
I0814 18:45:30.490447 10451 solver.cpp:334]     Train net output #0: loss = 0.069624 (* 1 = 0.069624 loss)
I0814 18:45:30.490453 10451 sgd_solver.cpp:136] Iteration 20100, lr = 0.0685938, m = 0.9
I0814 18:45:32.135009 10451 solver.cpp:312] Iteration 20200 (60.8075 iter/s, 1.64453s/100 iter), loss = 0.0663001
I0814 18:45:32.135154 10451 solver.cpp:334]     Train net output #0: loss = 0.0662989 (* 1 = 0.0662989 loss)
I0814 18:45:32.135177 10451 sgd_solver.cpp:136] Iteration 20200, lr = 0.0684375, m = 0.9
I0814 18:45:33.779783 10451 solver.cpp:312] Iteration 20300 (60.8006 iter/s, 1.64472s/100 iter), loss = 0.0625814
I0814 18:45:33.779850 10451 solver.cpp:334]     Train net output #0: loss = 0.0625803 (* 1 = 0.0625803 loss)
I0814 18:45:33.779875 10451 sgd_solver.cpp:136] Iteration 20300, lr = 0.0682813, m = 0.9
I0814 18:45:35.394346 10451 solver.cpp:312] Iteration 20400 (61.9383 iter/s, 1.61451s/100 iter), loss = 0.238864
I0814 18:45:35.394409 10451 solver.cpp:334]     Train net output #0: loss = 0.238863 (* 1 = 0.238863 loss)
I0814 18:45:35.394428 10451 sgd_solver.cpp:136] Iteration 20400, lr = 0.068125, m = 0.9
I0814 18:45:37.034440 10451 solver.cpp:312] Iteration 20500 (60.974 iter/s, 1.64004s/100 iter), loss = 0.181434
I0814 18:45:37.034462 10451 solver.cpp:334]     Train net output #0: loss = 0.181433 (* 1 = 0.181433 loss)
I0814 18:45:37.034468 10451 sgd_solver.cpp:136] Iteration 20500, lr = 0.0679687, m = 0.9
I0814 18:45:38.610610 10451 solver.cpp:312] Iteration 20600 (63.447 iter/s, 1.57612s/100 iter), loss = 0.0422956
I0814 18:45:38.610632 10451 solver.cpp:334]     Train net output #0: loss = 0.0422945 (* 1 = 0.0422945 loss)
I0814 18:45:38.610637 10451 sgd_solver.cpp:136] Iteration 20600, lr = 0.0678125, m = 0.9
I0814 18:45:40.215598 10451 solver.cpp:312] Iteration 20700 (62.3077 iter/s, 1.60494s/100 iter), loss = 0.101729
I0814 18:45:40.215667 10451 solver.cpp:334]     Train net output #0: loss = 0.101728 (* 1 = 0.101728 loss)
I0814 18:45:40.215687 10451 sgd_solver.cpp:136] Iteration 20700, lr = 0.0676562, m = 0.9
I0814 18:45:41.886473 10451 solver.cpp:312] Iteration 20800 (59.8507 iter/s, 1.67082s/100 iter), loss = 0.0312345
I0814 18:45:41.886540 10451 solver.cpp:334]     Train net output #0: loss = 0.0312333 (* 1 = 0.0312333 loss)
I0814 18:45:41.886560 10451 sgd_solver.cpp:136] Iteration 20800, lr = 0.0675, m = 0.9
I0814 18:45:43.469056 10451 solver.cpp:312] Iteration 20900 (63.1898 iter/s, 1.58253s/100 iter), loss = 0.0757367
I0814 18:45:43.469105 10451 solver.cpp:334]     Train net output #0: loss = 0.0757354 (* 1 = 0.0757354 loss)
I0814 18:45:43.469118 10451 sgd_solver.cpp:136] Iteration 20900, lr = 0.0673437, m = 0.9
I0814 18:45:45.052381 10451 solver.cpp:509] Iteration 21000, Testing net (#0)
I0814 18:45:45.892338 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.843531
I0814 18:45:45.892356 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.991471
I0814 18:45:45.892361 10451 solver.cpp:594]     Test net output #2: loss = 0.572196 (* 1 = 0.572196 loss)
I0814 18:45:45.892390 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.839985s
I0814 18:45:45.909785 10451 solver.cpp:312] Iteration 21000 (40.9726 iter/s, 2.44066s/100 iter), loss = 0.0723213
I0814 18:45:45.909802 10451 solver.cpp:334]     Train net output #0: loss = 0.07232 (* 1 = 0.07232 loss)
I0814 18:45:45.909808 10451 sgd_solver.cpp:136] Iteration 21000, lr = 0.0671875, m = 0.9
I0814 18:45:47.532778 10451 solver.cpp:312] Iteration 21100 (61.6167 iter/s, 1.62294s/100 iter), loss = 0.0402658
I0814 18:45:47.532827 10451 solver.cpp:334]     Train net output #0: loss = 0.0402645 (* 1 = 0.0402645 loss)
I0814 18:45:47.532847 10451 sgd_solver.cpp:136] Iteration 21100, lr = 0.0670313, m = 0.9
I0814 18:45:49.194260 10451 solver.cpp:312] Iteration 21200 (60.189 iter/s, 1.66143s/100 iter), loss = 0.0827765
I0814 18:45:49.194286 10451 solver.cpp:334]     Train net output #0: loss = 0.0827753 (* 1 = 0.0827753 loss)
I0814 18:45:49.194293 10451 sgd_solver.cpp:136] Iteration 21200, lr = 0.066875, m = 0.9
I0814 18:45:50.815351 10451 solver.cpp:312] Iteration 21300 (61.6888 iter/s, 1.62104s/100 iter), loss = 0.106158
I0814 18:45:50.815376 10451 solver.cpp:334]     Train net output #0: loss = 0.106157 (* 1 = 0.106157 loss)
I0814 18:45:50.815382 10451 sgd_solver.cpp:136] Iteration 21300, lr = 0.0667187, m = 0.9
I0814 18:45:52.391729 10451 solver.cpp:312] Iteration 21400 (63.4385 iter/s, 1.57633s/100 iter), loss = 0.0130171
I0814 18:45:52.391778 10451 solver.cpp:334]     Train net output #0: loss = 0.0130158 (* 1 = 0.0130158 loss)
I0814 18:45:52.391791 10451 sgd_solver.cpp:136] Iteration 21400, lr = 0.0665625, m = 0.9
I0814 18:45:54.011489 10451 solver.cpp:312] Iteration 21500 (61.7395 iter/s, 1.61971s/100 iter), loss = 0.0945474
I0814 18:45:54.011538 10451 solver.cpp:334]     Train net output #0: loss = 0.0945462 (* 1 = 0.0945462 loss)
I0814 18:45:54.011550 10451 sgd_solver.cpp:136] Iteration 21500, lr = 0.0664062, m = 0.9
I0814 18:45:55.636242 10451 solver.cpp:312] Iteration 21600 (61.5498 iter/s, 1.6247s/100 iter), loss = 0.0195708
I0814 18:45:55.636265 10451 solver.cpp:334]     Train net output #0: loss = 0.0195696 (* 1 = 0.0195696 loss)
I0814 18:45:55.636270 10451 sgd_solver.cpp:136] Iteration 21600, lr = 0.06625, m = 0.9
I0814 18:45:57.256575 10451 solver.cpp:312] Iteration 21700 (61.7176 iter/s, 1.62028s/100 iter), loss = 0.14687
I0814 18:45:57.256635 10451 solver.cpp:334]     Train net output #0: loss = 0.146869 (* 1 = 0.146869 loss)
I0814 18:45:57.256655 10451 sgd_solver.cpp:136] Iteration 21700, lr = 0.0660938, m = 0.9
I0814 18:45:58.878281 10451 solver.cpp:312] Iteration 21800 (61.6653 iter/s, 1.62166s/100 iter), loss = 0.147751
I0814 18:45:58.878373 10451 solver.cpp:334]     Train net output #0: loss = 0.14775 (* 1 = 0.14775 loss)
I0814 18:45:58.878381 10451 sgd_solver.cpp:136] Iteration 21800, lr = 0.0659375, m = 0.9
I0814 18:46:00.502902 10451 solver.cpp:312] Iteration 21900 (61.5549 iter/s, 1.62457s/100 iter), loss = 0.231411
I0814 18:46:00.502924 10451 solver.cpp:334]     Train net output #0: loss = 0.231409 (* 1 = 0.231409 loss)
I0814 18:46:00.502930 10451 sgd_solver.cpp:136] Iteration 21900, lr = 0.0657813, m = 0.9
I0814 18:46:02.062724 10451 solver.cpp:509] Iteration 22000, Testing net (#0)
I0814 18:46:02.482765 10438 data_reader.cpp:288] Starting prefetch of epoch 3
I0814 18:46:02.889092 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.819119
I0814 18:46:02.889111 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.987059
I0814 18:46:02.889117 10451 solver.cpp:594]     Test net output #2: loss = 0.704304 (* 1 = 0.704304 loss)
I0814 18:46:02.889132 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.826384s
I0814 18:46:02.907668 10451 solver.cpp:312] Iteration 22000 (41.5853 iter/s, 2.4047s/100 iter), loss = 0.0388929
I0814 18:46:02.907685 10451 solver.cpp:334]     Train net output #0: loss = 0.0388916 (* 1 = 0.0388916 loss)
I0814 18:46:02.907690 10451 sgd_solver.cpp:136] Iteration 22000, lr = 0.065625, m = 0.9
I0814 18:46:04.503993 10451 solver.cpp:312] Iteration 22100 (62.6459 iter/s, 1.59627s/100 iter), loss = 0.139702
I0814 18:46:04.504151 10451 solver.cpp:334]     Train net output #0: loss = 0.139701 (* 1 = 0.139701 loss)
I0814 18:46:04.504179 10451 sgd_solver.cpp:136] Iteration 22100, lr = 0.0654688, m = 0.9
I0814 18:46:06.129202 10451 solver.cpp:312] Iteration 22200 (61.5324 iter/s, 1.62516s/100 iter), loss = 0.171414
I0814 18:46:06.129226 10451 solver.cpp:334]     Train net output #0: loss = 0.171412 (* 1 = 0.171412 loss)
I0814 18:46:06.129232 10451 sgd_solver.cpp:136] Iteration 22200, lr = 0.0653125, m = 0.9
I0814 18:46:07.777119 10451 solver.cpp:312] Iteration 22300 (60.6847 iter/s, 1.64786s/100 iter), loss = 0.0128292
I0814 18:46:07.777170 10451 solver.cpp:334]     Train net output #0: loss = 0.0128279 (* 1 = 0.0128279 loss)
I0814 18:46:07.777184 10451 sgd_solver.cpp:136] Iteration 22300, lr = 0.0651563, m = 0.9
I0814 18:46:09.382447 10451 solver.cpp:312] Iteration 22400 (62.2944 iter/s, 1.60528s/100 iter), loss = 0.0537215
I0814 18:46:09.382494 10451 solver.cpp:334]     Train net output #0: loss = 0.0537203 (* 1 = 0.0537203 loss)
I0814 18:46:09.382506 10451 sgd_solver.cpp:136] Iteration 22400, lr = 0.065, m = 0.9
I0814 18:46:10.955663 10451 solver.cpp:312] Iteration 22500 (63.5661 iter/s, 1.57317s/100 iter), loss = 0.0642078
I0814 18:46:10.955688 10451 solver.cpp:334]     Train net output #0: loss = 0.0642065 (* 1 = 0.0642065 loss)
I0814 18:46:10.955693 10451 sgd_solver.cpp:136] Iteration 22500, lr = 0.0648438, m = 0.9
I0814 18:46:12.596853 10451 solver.cpp:312] Iteration 22600 (60.9332 iter/s, 1.64114s/100 iter), loss = 0.076145
I0814 18:46:12.596879 10451 solver.cpp:334]     Train net output #0: loss = 0.0761438 (* 1 = 0.0761438 loss)
I0814 18:46:12.596885 10451 sgd_solver.cpp:136] Iteration 22600, lr = 0.0646875, m = 0.9
I0814 18:46:14.237812 10451 solver.cpp:312] Iteration 22700 (60.942 iter/s, 1.6409s/100 iter), loss = 0.0630133
I0814 18:46:14.237862 10451 solver.cpp:334]     Train net output #0: loss = 0.0630121 (* 1 = 0.0630121 loss)
I0814 18:46:14.237875 10451 sgd_solver.cpp:136] Iteration 22700, lr = 0.0645313, m = 0.9
I0814 18:46:15.884608 10451 solver.cpp:312] Iteration 22800 (60.7257 iter/s, 1.64675s/100 iter), loss = 0.104703
I0814 18:46:15.884652 10451 solver.cpp:334]     Train net output #0: loss = 0.104702 (* 1 = 0.104702 loss)
I0814 18:46:15.884663 10451 sgd_solver.cpp:136] Iteration 22800, lr = 0.064375, m = 0.9
I0814 18:46:17.485180 10451 solver.cpp:312] Iteration 22900 (62.4796 iter/s, 1.60052s/100 iter), loss = 0.0100016
I0814 18:46:17.485208 10451 solver.cpp:334]     Train net output #0: loss = 0.0100004 (* 1 = 0.0100004 loss)
I0814 18:46:17.485215 10451 sgd_solver.cpp:136] Iteration 22900, lr = 0.0642188, m = 0.9
I0814 18:46:19.081270 10451 solver.cpp:509] Iteration 23000, Testing net (#0)
I0814 18:46:19.904260 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.673235
I0814 18:46:19.904279 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.955883
I0814 18:46:19.904286 10451 solver.cpp:594]     Test net output #2: loss = 1.53669 (* 1 = 1.53669 loss)
I0814 18:46:19.904304 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.823011s
I0814 18:46:19.919862 10451 solver.cpp:312] Iteration 23000 (41.0743 iter/s, 2.43461s/100 iter), loss = 0.222563
I0814 18:46:19.919890 10451 solver.cpp:334]     Train net output #0: loss = 0.222562 (* 1 = 0.222562 loss)
I0814 18:46:19.919901 10451 sgd_solver.cpp:136] Iteration 23000, lr = 0.0640625, m = 0.9
I0814 18:46:21.528087 10451 solver.cpp:312] Iteration 23100 (62.1824 iter/s, 1.60817s/100 iter), loss = 0.0627405
I0814 18:46:21.528111 10451 solver.cpp:334]     Train net output #0: loss = 0.0627393 (* 1 = 0.0627393 loss)
I0814 18:46:21.528117 10451 sgd_solver.cpp:136] Iteration 23100, lr = 0.0639063, m = 0.9
I0814 18:46:23.172240 10451 solver.cpp:312] Iteration 23200 (60.8235 iter/s, 1.6441s/100 iter), loss = 0.0163003
I0814 18:46:23.172266 10451 solver.cpp:334]     Train net output #0: loss = 0.0162992 (* 1 = 0.0162992 loss)
I0814 18:46:23.172271 10451 sgd_solver.cpp:136] Iteration 23200, lr = 0.06375, m = 0.9
I0814 18:46:24.800444 10451 solver.cpp:312] Iteration 23300 (61.4192 iter/s, 1.62816s/100 iter), loss = 0.030798
I0814 18:46:24.800470 10451 solver.cpp:334]     Train net output #0: loss = 0.0307969 (* 1 = 0.0307969 loss)
I0814 18:46:24.800477 10451 sgd_solver.cpp:136] Iteration 23300, lr = 0.0635938, m = 0.9
I0814 18:46:26.464419 10451 solver.cpp:312] Iteration 23400 (60.0989 iter/s, 1.66393s/100 iter), loss = 0.057242
I0814 18:46:26.464489 10451 solver.cpp:334]     Train net output #0: loss = 0.0572409 (* 1 = 0.0572409 loss)
I0814 18:46:26.464509 10451 sgd_solver.cpp:136] Iteration 23400, lr = 0.0634375, m = 0.9
I0814 18:46:28.057186 10451 solver.cpp:312] Iteration 23500 (62.7859 iter/s, 1.59272s/100 iter), loss = 0.0026719
I0814 18:46:28.057212 10451 solver.cpp:334]     Train net output #0: loss = 0.00267075 (* 1 = 0.00267075 loss)
I0814 18:46:28.057219 10451 sgd_solver.cpp:136] Iteration 23500, lr = 0.0632813, m = 0.9
I0814 18:46:29.699753 10451 solver.cpp:312] Iteration 23600 (60.8822 iter/s, 1.64252s/100 iter), loss = 0.0895933
I0814 18:46:29.699857 10451 solver.cpp:334]     Train net output #0: loss = 0.0895921 (* 1 = 0.0895921 loss)
I0814 18:46:29.699870 10451 sgd_solver.cpp:136] Iteration 23600, lr = 0.063125, m = 0.9
I0814 18:46:31.338162 10451 solver.cpp:312] Iteration 23700 (61.0368 iter/s, 1.63836s/100 iter), loss = 0.0393265
I0814 18:46:31.338212 10451 solver.cpp:334]     Train net output #0: loss = 0.0393255 (* 1 = 0.0393255 loss)
I0814 18:46:31.338227 10451 sgd_solver.cpp:136] Iteration 23700, lr = 0.0629688, m = 0.9
I0814 18:46:33.003410 10451 solver.cpp:312] Iteration 23800 (60.0529 iter/s, 1.6652s/100 iter), loss = 0.0941757
I0814 18:46:33.003435 10451 solver.cpp:334]     Train net output #0: loss = 0.0941746 (* 1 = 0.0941746 loss)
I0814 18:46:33.003442 10451 sgd_solver.cpp:136] Iteration 23800, lr = 0.0628125, m = 0.9
I0814 18:46:34.575440 10451 solver.cpp:312] Iteration 23900 (63.6139 iter/s, 1.57198s/100 iter), loss = 0.110839
I0814 18:46:34.575465 10451 solver.cpp:334]     Train net output #0: loss = 0.110838 (* 1 = 0.110838 loss)
I0814 18:46:34.575470 10451 sgd_solver.cpp:136] Iteration 23900, lr = 0.0626562, m = 0.9
I0814 18:46:36.181872 10451 solver.cpp:509] Iteration 24000, Testing net (#0)
I0814 18:46:36.996721 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.801472
I0814 18:46:36.996739 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.987059
I0814 18:46:36.996745 10451 solver.cpp:594]     Test net output #2: loss = 0.761519 (* 1 = 0.761519 loss)
I0814 18:46:36.996767 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.814869s
I0814 18:46:37.015897 10451 solver.cpp:312] Iteration 24000 (40.9772 iter/s, 2.44038s/100 iter), loss = 0.126281
I0814 18:46:37.015928 10451 solver.cpp:334]     Train net output #0: loss = 0.126279 (* 1 = 0.126279 loss)
I0814 18:46:37.015935 10451 sgd_solver.cpp:136] Iteration 24000, lr = 0.0625, m = 0.9
I0814 18:46:38.631508 10451 solver.cpp:312] Iteration 24100 (61.8979 iter/s, 1.61556s/100 iter), loss = 0.0786973
I0814 18:46:38.631750 10451 solver.cpp:334]     Train net output #0: loss = 0.0786962 (* 1 = 0.0786962 loss)
I0814 18:46:38.631757 10451 sgd_solver.cpp:136] Iteration 24100, lr = 0.0623438, m = 0.9
I0814 18:46:40.259683 10451 solver.cpp:312] Iteration 24200 (61.4205 iter/s, 1.62812s/100 iter), loss = 0.050549
I0814 18:46:40.259732 10451 solver.cpp:334]     Train net output #0: loss = 0.0505479 (* 1 = 0.0505479 loss)
I0814 18:46:40.259748 10451 sgd_solver.cpp:136] Iteration 24200, lr = 0.0621875, m = 0.9
I0814 18:46:41.896401 10451 solver.cpp:312] Iteration 24300 (61.0998 iter/s, 1.63667s/100 iter), loss = 0.00538185
I0814 18:46:41.896427 10451 solver.cpp:334]     Train net output #0: loss = 0.00538072 (* 1 = 0.00538072 loss)
I0814 18:46:41.896435 10451 sgd_solver.cpp:136] Iteration 24300, lr = 0.0620313, m = 0.9
I0814 18:46:43.510818 10451 solver.cpp:312] Iteration 24400 (61.9438 iter/s, 1.61437s/100 iter), loss = 0.0184136
I0814 18:46:43.510843 10451 solver.cpp:334]     Train net output #0: loss = 0.0184124 (* 1 = 0.0184124 loss)
I0814 18:46:43.510849 10451 sgd_solver.cpp:136] Iteration 24400, lr = 0.061875, m = 0.9
I0814 18:46:45.117569 10451 solver.cpp:312] Iteration 24500 (62.2393 iter/s, 1.6067s/100 iter), loss = 0.0496733
I0814 18:46:45.117597 10451 solver.cpp:334]     Train net output #0: loss = 0.0496722 (* 1 = 0.0496722 loss)
I0814 18:46:45.117604 10451 sgd_solver.cpp:136] Iteration 24500, lr = 0.0617188, m = 0.9
I0814 18:46:46.776991 10451 solver.cpp:312] Iteration 24600 (60.2638 iter/s, 1.65937s/100 iter), loss = 0.0528936
I0814 18:46:46.777048 10451 solver.cpp:334]     Train net output #0: loss = 0.0528925 (* 1 = 0.0528925 loss)
I0814 18:46:46.777074 10451 sgd_solver.cpp:136] Iteration 24600, lr = 0.0615625, m = 0.9
I0814 18:46:48.391196 10451 solver.cpp:312] Iteration 24700 (61.9519 iter/s, 1.61415s/100 iter), loss = 0.0132825
I0814 18:46:48.391245 10451 solver.cpp:334]     Train net output #0: loss = 0.0132814 (* 1 = 0.0132814 loss)
I0814 18:46:48.391259 10451 sgd_solver.cpp:136] Iteration 24700, lr = 0.0614063, m = 0.9
I0814 18:46:50.040156 10451 solver.cpp:312] Iteration 24800 (60.6461 iter/s, 1.64891s/100 iter), loss = 0.0904861
I0814 18:46:50.040195 10451 solver.cpp:334]     Train net output #0: loss = 0.090485 (* 1 = 0.090485 loss)
I0814 18:46:50.040200 10451 sgd_solver.cpp:136] Iteration 24800, lr = 0.06125, m = 0.9
I0814 18:46:51.633901 10451 solver.cpp:312] Iteration 24900 (62.7473 iter/s, 1.59369s/100 iter), loss = 0.0627828
I0814 18:46:51.633975 10451 solver.cpp:334]     Train net output #0: loss = 0.0627816 (* 1 = 0.0627816 loss)
I0814 18:46:51.633997 10451 sgd_solver.cpp:136] Iteration 24900, lr = 0.0610937, m = 0.9
I0814 18:46:53.251240 10451 solver.cpp:509] Iteration 25000, Testing net (#0)
I0814 18:46:54.068444 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.846178
I0814 18:46:54.068461 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.989412
I0814 18:46:54.068466 10451 solver.cpp:594]     Test net output #2: loss = 0.611982 (* 1 = 0.611982 loss)
I0814 18:46:54.068483 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.817221s
I0814 18:46:54.084005 10451 solver.cpp:312] Iteration 25000 (40.8158 iter/s, 2.45003s/100 iter), loss = 0.0205969
I0814 18:46:54.084022 10451 solver.cpp:334]     Train net output #0: loss = 0.0205957 (* 1 = 0.0205957 loss)
I0814 18:46:54.084025 10451 sgd_solver.cpp:136] Iteration 25000, lr = 0.0609375, m = 0.9
I0814 18:46:55.678484 10451 solver.cpp:312] Iteration 25100 (62.7184 iter/s, 1.59443s/100 iter), loss = 0.041005
I0814 18:46:55.678530 10451 solver.cpp:334]     Train net output #0: loss = 0.0410038 (* 1 = 0.0410038 loss)
I0814 18:46:55.678544 10451 sgd_solver.cpp:136] Iteration 25100, lr = 0.0607813, m = 0.9
I0814 18:46:57.315088 10451 solver.cpp:312] Iteration 25200 (61.1042 iter/s, 1.63655s/100 iter), loss = 0.150859
I0814 18:46:57.315114 10451 solver.cpp:334]     Train net output #0: loss = 0.150858 (* 1 = 0.150858 loss)
I0814 18:46:57.315120 10451 sgd_solver.cpp:136] Iteration 25200, lr = 0.060625, m = 0.9
I0814 18:46:58.934146 10451 solver.cpp:312] Iteration 25300 (61.7661 iter/s, 1.61901s/100 iter), loss = 0.0692633
I0814 18:46:58.934195 10451 solver.cpp:334]     Train net output #0: loss = 0.0692622 (* 1 = 0.0692622 loss)
I0814 18:46:58.934211 10451 sgd_solver.cpp:136] Iteration 25300, lr = 0.0604688, m = 0.9
I0814 18:47:00.514853 10451 solver.cpp:312] Iteration 25400 (63.2647 iter/s, 1.58066s/100 iter), loss = 0.0245713
I0814 18:47:00.515120 10451 solver.cpp:334]     Train net output #0: loss = 0.0245702 (* 1 = 0.0245702 loss)
I0814 18:47:00.515141 10451 sgd_solver.cpp:136] Iteration 25400, lr = 0.0603125, m = 0.9
I0814 18:47:02.112560 10451 solver.cpp:312] Iteration 25500 (62.5917 iter/s, 1.59766s/100 iter), loss = 0.0525974
I0814 18:47:02.112582 10451 solver.cpp:334]     Train net output #0: loss = 0.0525963 (* 1 = 0.0525963 loss)
I0814 18:47:02.112588 10451 sgd_solver.cpp:136] Iteration 25500, lr = 0.0601563, m = 0.9
I0814 18:47:03.742482 10451 solver.cpp:312] Iteration 25600 (61.3546 iter/s, 1.62987s/100 iter), loss = 0.0877739
I0814 18:47:03.742509 10451 solver.cpp:334]     Train net output #0: loss = 0.0877728 (* 1 = 0.0877728 loss)
I0814 18:47:03.742516 10451 sgd_solver.cpp:136] Iteration 25600, lr = 0.06, m = 0.9
I0814 18:47:05.366109 10451 solver.cpp:312] Iteration 25700 (61.5923 iter/s, 1.62358s/100 iter), loss = 0.0297554
I0814 18:47:05.366276 10451 solver.cpp:334]     Train net output #0: loss = 0.0297543 (* 1 = 0.0297543 loss)
I0814 18:47:05.366298 10451 sgd_solver.cpp:136] Iteration 25700, lr = 0.0598437, m = 0.9
I0814 18:47:06.971418 10451 solver.cpp:312] Iteration 25800 (62.2953 iter/s, 1.60526s/100 iter), loss = 0.0321142
I0814 18:47:06.971488 10451 solver.cpp:334]     Train net output #0: loss = 0.032113 (* 1 = 0.032113 loss)
I0814 18:47:06.971508 10451 sgd_solver.cpp:136] Iteration 25800, lr = 0.0596875, m = 0.9
I0814 18:47:08.598374 10451 solver.cpp:312] Iteration 25900 (61.4665 iter/s, 1.6269s/100 iter), loss = 0.0137708
I0814 18:47:08.598440 10451 solver.cpp:334]     Train net output #0: loss = 0.0137696 (* 1 = 0.0137696 loss)
I0814 18:47:08.598460 10451 sgd_solver.cpp:136] Iteration 25900, lr = 0.0595312, m = 0.9
I0814 18:47:10.212738 10451 solver.cpp:509] Iteration 26000, Testing net (#0)
I0814 18:47:11.027925 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.82206
I0814 18:47:11.027940 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.985588
I0814 18:47:11.027945 10451 solver.cpp:594]     Test net output #2: loss = 0.69271 (* 1 = 0.69271 loss)
I0814 18:47:11.027962 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.815202s
I0814 18:47:11.043562 10451 solver.cpp:312] Iteration 26000 (40.8978 iter/s, 2.44512s/100 iter), loss = 0.300729
I0814 18:47:11.043581 10451 solver.cpp:334]     Train net output #0: loss = 0.300728 (* 1 = 0.300728 loss)
I0814 18:47:11.043584 10451 sgd_solver.cpp:136] Iteration 26000, lr = 0.059375, m = 0.9
I0814 18:47:12.684507 10451 solver.cpp:312] Iteration 26100 (60.9424 iter/s, 1.64089s/100 iter), loss = 0.0509249
I0814 18:47:12.684567 10451 solver.cpp:334]     Train net output #0: loss = 0.0509238 (* 1 = 0.0509238 loss)
I0814 18:47:12.684586 10451 sgd_solver.cpp:136] Iteration 26100, lr = 0.0592188, m = 0.9
I0814 18:47:14.333937 10451 solver.cpp:312] Iteration 26200 (60.6289 iter/s, 1.64938s/100 iter), loss = 0.0556359
I0814 18:47:14.333961 10451 solver.cpp:334]     Train net output #0: loss = 0.0556347 (* 1 = 0.0556347 loss)
I0814 18:47:14.333967 10451 sgd_solver.cpp:136] Iteration 26200, lr = 0.0590625, m = 0.9
I0814 18:47:15.973160 10451 solver.cpp:312] Iteration 26300 (61.0064 iter/s, 1.63917s/100 iter), loss = 0.00731394
I0814 18:47:15.973182 10451 solver.cpp:334]     Train net output #0: loss = 0.00731271 (* 1 = 0.00731271 loss)
I0814 18:47:15.973187 10451 sgd_solver.cpp:136] Iteration 26300, lr = 0.0589063, m = 0.9
I0814 18:47:17.579797 10451 solver.cpp:312] Iteration 26400 (62.2437 iter/s, 1.60659s/100 iter), loss = 0.0622092
I0814 18:47:17.579848 10451 solver.cpp:334]     Train net output #0: loss = 0.062208 (* 1 = 0.062208 loss)
I0814 18:47:17.579864 10451 sgd_solver.cpp:136] Iteration 26400, lr = 0.05875, m = 0.9
I0814 18:47:19.215502 10451 solver.cpp:312] Iteration 26500 (61.1376 iter/s, 1.63565s/100 iter), loss = 0.0254935
I0814 18:47:19.215528 10451 solver.cpp:334]     Train net output #0: loss = 0.0254924 (* 1 = 0.0254924 loss)
I0814 18:47:19.215535 10451 sgd_solver.cpp:136] Iteration 26500, lr = 0.0585938, m = 0.9
I0814 18:47:19.414412 10436 data_reader.cpp:288] Starting prefetch of epoch 4
I0814 18:47:20.834434 10451 solver.cpp:312] Iteration 26600 (61.771 iter/s, 1.61888s/100 iter), loss = 0.0740183
I0814 18:47:20.834480 10451 solver.cpp:334]     Train net output #0: loss = 0.0740172 (* 1 = 0.0740172 loss)
I0814 18:47:20.834491 10451 sgd_solver.cpp:136] Iteration 26600, lr = 0.0584375, m = 0.9
I0814 18:47:22.429409 10451 solver.cpp:312] Iteration 26700 (62.6988 iter/s, 1.59493s/100 iter), loss = 0.21666
I0814 18:47:22.429435 10451 solver.cpp:334]     Train net output #0: loss = 0.216659 (* 1 = 0.216659 loss)
I0814 18:47:22.429440 10451 sgd_solver.cpp:136] Iteration 26700, lr = 0.0582813, m = 0.9
I0814 18:47:24.017623 10451 solver.cpp:312] Iteration 26800 (62.9659 iter/s, 1.58816s/100 iter), loss = 0.124589
I0814 18:47:24.017649 10451 solver.cpp:334]     Train net output #0: loss = 0.124587 (* 1 = 0.124587 loss)
I0814 18:47:24.017655 10451 sgd_solver.cpp:136] Iteration 26800, lr = 0.058125, m = 0.9
I0814 18:47:25.630852 10451 solver.cpp:312] Iteration 26900 (61.9894 iter/s, 1.61318s/100 iter), loss = 0.141671
I0814 18:47:25.630877 10451 solver.cpp:334]     Train net output #0: loss = 0.14167 (* 1 = 0.14167 loss)
I0814 18:47:25.630883 10451 sgd_solver.cpp:136] Iteration 26900, lr = 0.0579687, m = 0.9
I0814 18:47:27.265558 10451 solver.cpp:509] Iteration 27000, Testing net (#0)
I0814 18:47:28.101840 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.813825
I0814 18:47:28.101857 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.985883
I0814 18:47:28.101862 10451 solver.cpp:594]     Test net output #2: loss = 0.690739 (* 1 = 0.690739 loss)
I0814 18:47:28.101877 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.836296s
I0814 18:47:28.119418 10451 solver.cpp:312] Iteration 27000 (40.1849 iter/s, 2.4885s/100 iter), loss = 0.0122398
I0814 18:47:28.119436 10451 solver.cpp:334]     Train net output #0: loss = 0.0122387 (* 1 = 0.0122387 loss)
I0814 18:47:28.119441 10451 sgd_solver.cpp:136] Iteration 27000, lr = 0.0578125, m = 0.9
I0814 18:47:29.759593 10451 solver.cpp:312] Iteration 27100 (60.9711 iter/s, 1.64012s/100 iter), loss = 0.0148728
I0814 18:47:29.759657 10451 solver.cpp:334]     Train net output #0: loss = 0.0148718 (* 1 = 0.0148718 loss)
I0814 18:47:29.759677 10451 sgd_solver.cpp:136] Iteration 27100, lr = 0.0576563, m = 0.9
I0814 18:47:31.435333 10451 solver.cpp:312] Iteration 27200 (59.677 iter/s, 1.67569s/100 iter), loss = 0.0304983
I0814 18:47:31.435462 10451 solver.cpp:334]     Train net output #0: loss = 0.0304973 (* 1 = 0.0304973 loss)
I0814 18:47:31.435483 10451 sgd_solver.cpp:136] Iteration 27200, lr = 0.0575, m = 0.9
I0814 18:47:33.044389 10451 solver.cpp:312] Iteration 27300 (62.1503 iter/s, 1.609s/100 iter), loss = 0.0388495
I0814 18:47:33.044453 10451 solver.cpp:334]     Train net output #0: loss = 0.0388484 (* 1 = 0.0388484 loss)
I0814 18:47:33.044473 10451 sgd_solver.cpp:136] Iteration 27300, lr = 0.0573438, m = 0.9
I0814 18:47:34.657492 10451 solver.cpp:312] Iteration 27400 (61.9941 iter/s, 1.61306s/100 iter), loss = 0.0154386
I0814 18:47:34.657539 10451 solver.cpp:334]     Train net output #0: loss = 0.0154375 (* 1 = 0.0154375 loss)
I0814 18:47:34.657552 10451 sgd_solver.cpp:136] Iteration 27400, lr = 0.0571875, m = 0.9
I0814 18:47:36.297762 10451 solver.cpp:312] Iteration 27500 (60.9675 iter/s, 1.64022s/100 iter), loss = 0.0197837
I0814 18:47:36.297812 10451 solver.cpp:334]     Train net output #0: loss = 0.0197826 (* 1 = 0.0197826 loss)
I0814 18:47:36.297827 10451 sgd_solver.cpp:136] Iteration 27500, lr = 0.0570313, m = 0.9
I0814 18:47:37.919636 10451 solver.cpp:312] Iteration 27600 (61.659 iter/s, 1.62182s/100 iter), loss = 0.040675
I0814 18:47:37.919661 10451 solver.cpp:334]     Train net output #0: loss = 0.0406739 (* 1 = 0.0406739 loss)
I0814 18:47:37.919667 10451 sgd_solver.cpp:136] Iteration 27600, lr = 0.056875, m = 0.9
I0814 18:47:39.511689 10451 solver.cpp:312] Iteration 27700 (62.8139 iter/s, 1.592s/100 iter), loss = 0.0184342
I0814 18:47:39.511756 10451 solver.cpp:334]     Train net output #0: loss = 0.018433 (* 1 = 0.018433 loss)
I0814 18:47:39.511776 10451 sgd_solver.cpp:136] Iteration 27700, lr = 0.0567187, m = 0.9
I0814 18:47:41.122467 10451 solver.cpp:312] Iteration 27800 (62.0839 iter/s, 1.61072s/100 iter), loss = 0.0131205
I0814 18:47:41.122490 10451 solver.cpp:334]     Train net output #0: loss = 0.0131193 (* 1 = 0.0131193 loss)
I0814 18:47:41.122496 10451 sgd_solver.cpp:136] Iteration 27800, lr = 0.0565625, m = 0.9
I0814 18:47:42.724033 10451 solver.cpp:312] Iteration 27900 (62.4408 iter/s, 1.60152s/100 iter), loss = 0.0672494
I0814 18:47:42.724079 10451 solver.cpp:334]     Train net output #0: loss = 0.0672481 (* 1 = 0.0672481 loss)
I0814 18:47:42.724094 10451 sgd_solver.cpp:136] Iteration 27900, lr = 0.0564062, m = 0.9
I0814 18:47:44.335402 10451 solver.cpp:509] Iteration 28000, Testing net (#0)
I0814 18:47:45.168401 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.767354
I0814 18:47:45.168418 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.979706
I0814 18:47:45.168426 10451 solver.cpp:594]     Test net output #2: loss = 1.02632 (* 1 = 1.02632 loss)
I0814 18:47:45.168442 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.833017s
I0814 18:47:45.196828 10451 solver.cpp:312] Iteration 28000 (40.4413 iter/s, 2.47272s/100 iter), loss = 0.0260342
I0814 18:47:45.196856 10451 solver.cpp:334]     Train net output #0: loss = 0.026033 (* 1 = 0.026033 loss)
I0814 18:47:45.196861 10451 sgd_solver.cpp:136] Iteration 28000, lr = 0.05625, m = 0.9
I0814 18:47:46.808748 10451 solver.cpp:312] Iteration 28100 (62.0397 iter/s, 1.61187s/100 iter), loss = 0.014554
I0814 18:47:46.808773 10451 solver.cpp:334]     Train net output #0: loss = 0.0145528 (* 1 = 0.0145528 loss)
I0814 18:47:46.808779 10451 sgd_solver.cpp:136] Iteration 28100, lr = 0.0560938, m = 0.9
I0814 18:47:48.438803 10451 solver.cpp:312] Iteration 28200 (61.3495 iter/s, 1.63001s/100 iter), loss = 0.0090445
I0814 18:47:48.438829 10451 solver.cpp:334]     Train net output #0: loss = 0.00904335 (* 1 = 0.00904335 loss)
I0814 18:47:48.438835 10451 sgd_solver.cpp:136] Iteration 28200, lr = 0.0559375, m = 0.9
I0814 18:47:50.030465 10451 solver.cpp:312] Iteration 28300 (62.8293 iter/s, 1.59161s/100 iter), loss = 0.0349209
I0814 18:47:50.030488 10451 solver.cpp:334]     Train net output #0: loss = 0.0349198 (* 1 = 0.0349198 loss)
I0814 18:47:50.030493 10451 sgd_solver.cpp:136] Iteration 28300, lr = 0.0557813, m = 0.9
I0814 18:47:51.664898 10451 solver.cpp:312] Iteration 28400 (61.1852 iter/s, 1.63438s/100 iter), loss = 0.0254241
I0814 18:47:51.664981 10451 solver.cpp:334]     Train net output #0: loss = 0.025423 (* 1 = 0.025423 loss)
I0814 18:47:51.665004 10451 sgd_solver.cpp:136] Iteration 28400, lr = 0.055625, m = 0.9
I0814 18:47:53.289290 10451 solver.cpp:312] Iteration 28500 (61.5634 iter/s, 1.62434s/100 iter), loss = 0.0543113
I0814 18:47:53.289340 10451 solver.cpp:334]     Train net output #0: loss = 0.0543102 (* 1 = 0.0543102 loss)
I0814 18:47:53.289350 10451 sgd_solver.cpp:136] Iteration 28500, lr = 0.0554687, m = 0.9
I0814 18:47:54.934948 10451 solver.cpp:312] Iteration 28600 (60.7679 iter/s, 1.64561s/100 iter), loss = 0.0701881
I0814 18:47:54.934975 10451 solver.cpp:334]     Train net output #0: loss = 0.070187 (* 1 = 0.070187 loss)
I0814 18:47:54.934983 10451 sgd_solver.cpp:136] Iteration 28600, lr = 0.0553125, m = 0.9
I0814 18:47:56.550459 10451 solver.cpp:312] Iteration 28700 (61.9019 iter/s, 1.61546s/100 iter), loss = 0.00852625
I0814 18:47:56.550487 10451 solver.cpp:334]     Train net output #0: loss = 0.00852507 (* 1 = 0.00852507 loss)
I0814 18:47:56.550493 10451 sgd_solver.cpp:136] Iteration 28700, lr = 0.0551562, m = 0.9
I0814 18:47:58.171772 10451 solver.cpp:312] Iteration 28800 (61.6804 iter/s, 1.62126s/100 iter), loss = 0.0221278
I0814 18:47:58.171797 10451 solver.cpp:334]     Train net output #0: loss = 0.0221266 (* 1 = 0.0221266 loss)
I0814 18:47:58.171802 10451 sgd_solver.cpp:136] Iteration 28800, lr = 0.055, m = 0.9
I0814 18:47:59.803843 10451 solver.cpp:312] Iteration 28900 (61.2736 iter/s, 1.63202s/100 iter), loss = 0.122922
I0814 18:47:59.803894 10451 solver.cpp:334]     Train net output #0: loss = 0.122921 (* 1 = 0.122921 loss)
I0814 18:47:59.803908 10451 sgd_solver.cpp:136] Iteration 28900, lr = 0.0548437, m = 0.9
I0814 18:48:01.430172 10451 solver.cpp:509] Iteration 29000, Testing net (#0)
I0814 18:48:02.259057 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.839707
I0814 18:48:02.259125 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.989706
I0814 18:48:02.259135 10451 solver.cpp:594]     Test net output #2: loss = 0.662421 (* 1 = 0.662421 loss)
I0814 18:48:02.259151 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.828956s
I0814 18:48:02.276635 10451 solver.cpp:312] Iteration 29000 (40.4413 iter/s, 2.47272s/100 iter), loss = 0.0165589
I0814 18:48:02.276652 10451 solver.cpp:334]     Train net output #0: loss = 0.0165577 (* 1 = 0.0165577 loss)
I0814 18:48:02.276659 10451 sgd_solver.cpp:136] Iteration 29000, lr = 0.0546875, m = 0.9
I0814 18:48:03.916640 10451 solver.cpp:312] Iteration 29100 (60.9774 iter/s, 1.63995s/100 iter), loss = 0.0485322
I0814 18:48:03.916687 10451 solver.cpp:334]     Train net output #0: loss = 0.048531 (* 1 = 0.048531 loss)
I0814 18:48:03.916694 10451 sgd_solver.cpp:136] Iteration 29100, lr = 0.0545313, m = 0.9
I0814 18:48:05.544513 10451 solver.cpp:312] Iteration 29200 (61.4319 iter/s, 1.62782s/100 iter), loss = 0.0586282
I0814 18:48:05.544615 10451 solver.cpp:334]     Train net output #0: loss = 0.058627 (* 1 = 0.058627 loss)
I0814 18:48:05.544625 10451 sgd_solver.cpp:136] Iteration 29200, lr = 0.054375, m = 0.9
I0814 18:48:07.215697 10451 solver.cpp:312] Iteration 29300 (59.8396 iter/s, 1.67114s/100 iter), loss = 0.0599032
I0814 18:48:07.215744 10451 solver.cpp:334]     Train net output #0: loss = 0.059902 (* 1 = 0.059902 loss)
I0814 18:48:07.215754 10451 sgd_solver.cpp:136] Iteration 29300, lr = 0.0542188, m = 0.9
I0814 18:48:08.868568 10451 solver.cpp:312] Iteration 29400 (60.5027 iter/s, 1.65282s/100 iter), loss = 0.0132989
I0814 18:48:08.868592 10451 solver.cpp:334]     Train net output #0: loss = 0.0132976 (* 1 = 0.0132976 loss)
I0814 18:48:08.868597 10451 sgd_solver.cpp:136] Iteration 29400, lr = 0.0540625, m = 0.9
I0814 18:48:10.472684 10451 solver.cpp:312] Iteration 29500 (62.3416 iter/s, 1.60406s/100 iter), loss = 0.0111242
I0814 18:48:10.472744 10451 solver.cpp:334]     Train net output #0: loss = 0.011123 (* 1 = 0.011123 loss)
I0814 18:48:10.472761 10451 sgd_solver.cpp:136] Iteration 29500, lr = 0.0539063, m = 0.9
I0814 18:48:12.081426 10451 solver.cpp:312] Iteration 29600 (62.1623 iter/s, 1.60869s/100 iter), loss = 0.0608884
I0814 18:48:12.081454 10451 solver.cpp:334]     Train net output #0: loss = 0.0608871 (* 1 = 0.0608871 loss)
I0814 18:48:12.081461 10451 sgd_solver.cpp:136] Iteration 29600, lr = 0.05375, m = 0.9
I0814 18:48:13.688263 10451 solver.cpp:312] Iteration 29700 (62.2361 iter/s, 1.60679s/100 iter), loss = 0.123161
I0814 18:48:13.688325 10451 solver.cpp:334]     Train net output #0: loss = 0.12316 (* 1 = 0.12316 loss)
I0814 18:48:13.688344 10451 sgd_solver.cpp:136] Iteration 29700, lr = 0.0535938, m = 0.9
I0814 18:48:15.361147 10451 solver.cpp:312] Iteration 29800 (59.7788 iter/s, 1.67283s/100 iter), loss = 0.085298
I0814 18:48:15.361197 10451 solver.cpp:334]     Train net output #0: loss = 0.0852969 (* 1 = 0.0852969 loss)
I0814 18:48:15.361212 10451 sgd_solver.cpp:136] Iteration 29800, lr = 0.0534375, m = 0.9
I0814 18:48:16.975670 10451 solver.cpp:312] Iteration 29900 (61.9398 iter/s, 1.61447s/100 iter), loss = 0.106392
I0814 18:48:16.975718 10451 solver.cpp:334]     Train net output #0: loss = 0.106391 (* 1 = 0.106391 loss)
I0814 18:48:16.975729 10451 sgd_solver.cpp:136] Iteration 29900, lr = 0.0532812, m = 0.9
I0814 18:48:18.596055 10451 solver.cpp:639] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/initial/cifar10_jacintonet11v2_iter_30000.caffemodel
I0814 18:48:18.605531 10451 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/initial/cifar10_jacintonet11v2_iter_30000.solverstate
I0814 18:48:18.610255 10451 solver.cpp:509] Iteration 30000, Testing net (#0)
I0814 18:48:19.419006 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.865295
I0814 18:48:19.419025 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.993235
I0814 18:48:19.419030 10451 solver.cpp:594]     Test net output #2: loss = 0.494331 (* 1 = 0.494331 loss)
I0814 18:48:19.419068 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.808791s
I0814 18:48:19.434702 10451 solver.cpp:312] Iteration 30000 (40.6676 iter/s, 2.45896s/100 iter), loss = 0.0279261
I0814 18:48:19.434720 10451 solver.cpp:334]     Train net output #0: loss = 0.027925 (* 1 = 0.027925 loss)
I0814 18:48:19.434725 10451 sgd_solver.cpp:136] Iteration 30000, lr = 0.053125, m = 0.9
I0814 18:48:21.040349 10451 solver.cpp:312] Iteration 30100 (62.2823 iter/s, 1.60559s/100 iter), loss = 0.0567074
I0814 18:48:21.040392 10451 solver.cpp:334]     Train net output #0: loss = 0.0567064 (* 1 = 0.0567064 loss)
I0814 18:48:21.040405 10451 sgd_solver.cpp:136] Iteration 30100, lr = 0.0529688, m = 0.9
I0814 18:48:22.632340 10451 solver.cpp:312] Iteration 30200 (62.8163 iter/s, 1.59194s/100 iter), loss = 0.0150462
I0814 18:48:22.632367 10451 solver.cpp:334]     Train net output #0: loss = 0.0150452 (* 1 = 0.0150452 loss)
I0814 18:48:22.632374 10451 sgd_solver.cpp:136] Iteration 30200, lr = 0.0528125, m = 0.9
I0814 18:48:24.271828 10451 solver.cpp:312] Iteration 30300 (60.9965 iter/s, 1.63944s/100 iter), loss = 0.0230297
I0814 18:48:24.271989 10451 solver.cpp:334]     Train net output #0: loss = 0.0230286 (* 1 = 0.0230286 loss)
I0814 18:48:24.272013 10451 sgd_solver.cpp:136] Iteration 30300, lr = 0.0526563, m = 0.9
I0814 18:48:25.895375 10451 solver.cpp:312] Iteration 30400 (61.5956 iter/s, 1.62349s/100 iter), loss = 0.00905156
I0814 18:48:25.895419 10451 solver.cpp:334]     Train net output #0: loss = 0.00905052 (* 1 = 0.00905052 loss)
I0814 18:48:25.895432 10451 sgd_solver.cpp:136] Iteration 30400, lr = 0.0525, m = 0.9
I0814 18:48:27.500071 10451 solver.cpp:312] Iteration 30500 (62.319 iter/s, 1.60465s/100 iter), loss = 0.030611
I0814 18:48:27.500128 10451 solver.cpp:334]     Train net output #0: loss = 0.0306099 (* 1 = 0.0306099 loss)
I0814 18:48:27.500151 10451 sgd_solver.cpp:136] Iteration 30500, lr = 0.0523438, m = 0.9
I0814 18:48:29.081715 10451 solver.cpp:312] Iteration 30600 (63.2272 iter/s, 1.5816s/100 iter), loss = 0.0848983
I0814 18:48:29.081786 10451 solver.cpp:334]     Train net output #0: loss = 0.0848972 (* 1 = 0.0848972 loss)
I0814 18:48:29.081807 10451 sgd_solver.cpp:136] Iteration 30600, lr = 0.0521875, m = 0.9
I0814 18:48:30.672725 10451 solver.cpp:312] Iteration 30700 (62.8552 iter/s, 1.59096s/100 iter), loss = 0.0894887
I0814 18:48:30.672792 10451 solver.cpp:334]     Train net output #0: loss = 0.0894875 (* 1 = 0.0894875 loss)
I0814 18:48:30.672812 10451 sgd_solver.cpp:136] Iteration 30700, lr = 0.0520312, m = 0.9
I0814 18:48:32.324086 10451 solver.cpp:312] Iteration 30800 (60.558 iter/s, 1.65131s/100 iter), loss = 0.0707794
I0814 18:48:32.324203 10451 solver.cpp:334]     Train net output #0: loss = 0.0707782 (* 1 = 0.0707782 loss)
I0814 18:48:32.324220 10451 sgd_solver.cpp:136] Iteration 30800, lr = 0.051875, m = 0.9
I0814 18:48:33.986016 10451 solver.cpp:312] Iteration 30900 (60.173 iter/s, 1.66188s/100 iter), loss = 0.0251768
I0814 18:48:33.986079 10451 solver.cpp:334]     Train net output #0: loss = 0.0251756 (* 1 = 0.0251756 loss)
I0814 18:48:33.986099 10451 sgd_solver.cpp:136] Iteration 30900, lr = 0.0517187, m = 0.9
I0814 18:48:35.544252 10451 solver.cpp:509] Iteration 31000, Testing net (#0)
I0814 18:48:35.844640 10438 data_reader.cpp:288] Starting prefetch of epoch 4
I0814 18:48:36.365428 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.846472
I0814 18:48:36.365448 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.992647
I0814 18:48:36.365453 10451 solver.cpp:594]     Test net output #2: loss = 0.620303 (* 1 = 0.620303 loss)
I0814 18:48:36.365468 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.821195s
I0814 18:48:36.392905 10451 solver.cpp:312] Iteration 31000 (41.5487 iter/s, 2.40682s/100 iter), loss = 0.0358153
I0814 18:48:36.392940 10451 solver.cpp:334]     Train net output #0: loss = 0.0358142 (* 1 = 0.0358142 loss)
I0814 18:48:36.392951 10451 sgd_solver.cpp:136] Iteration 31000, lr = 0.0515625, m = 0.9
I0814 18:48:38.034559 10451 solver.cpp:312] Iteration 31100 (60.9161 iter/s, 1.6416s/100 iter), loss = 0.0824393
I0814 18:48:38.034621 10451 solver.cpp:334]     Train net output #0: loss = 0.0824382 (* 1 = 0.0824382 loss)
I0814 18:48:38.034638 10451 sgd_solver.cpp:136] Iteration 31100, lr = 0.0514063, m = 0.9
I0814 18:48:39.620373 10451 solver.cpp:312] Iteration 31200 (63.0611 iter/s, 1.58576s/100 iter), loss = 0.0278474
I0814 18:48:39.620395 10451 solver.cpp:334]     Train net output #0: loss = 0.0278463 (* 1 = 0.0278463 loss)
I0814 18:48:39.620400 10451 sgd_solver.cpp:136] Iteration 31200, lr = 0.05125, m = 0.9
I0814 18:48:41.216352 10451 solver.cpp:312] Iteration 31300 (62.6594 iter/s, 1.59593s/100 iter), loss = 0.008993
I0814 18:48:41.216421 10451 solver.cpp:334]     Train net output #0: loss = 0.00899187 (* 1 = 0.00899187 loss)
I0814 18:48:41.216435 10451 sgd_solver.cpp:136] Iteration 31300, lr = 0.0510938, m = 0.9
I0814 18:48:42.824124 10451 solver.cpp:312] Iteration 31400 (62.1998 iter/s, 1.60772s/100 iter), loss = 0.0120592
I0814 18:48:42.824179 10451 solver.cpp:334]     Train net output #0: loss = 0.0120581 (* 1 = 0.0120581 loss)
I0814 18:48:42.824193 10451 sgd_solver.cpp:136] Iteration 31400, lr = 0.0509375, m = 0.9
I0814 18:48:44.410578 10451 solver.cpp:312] Iteration 31500 (63.0358 iter/s, 1.5864s/100 iter), loss = 0.0820099
I0814 18:48:44.410630 10451 solver.cpp:334]     Train net output #0: loss = 0.0820088 (* 1 = 0.0820088 loss)
I0814 18:48:44.410647 10451 sgd_solver.cpp:136] Iteration 31500, lr = 0.0507812, m = 0.9
I0814 18:48:46.032886 10451 solver.cpp:312] Iteration 31600 (61.6425 iter/s, 1.62226s/100 iter), loss = 0.0560098
I0814 18:48:46.032909 10451 solver.cpp:334]     Train net output #0: loss = 0.0560087 (* 1 = 0.0560087 loss)
I0814 18:48:46.032915 10451 sgd_solver.cpp:136] Iteration 31600, lr = 0.050625, m = 0.9
I0814 18:48:47.651834 10451 solver.cpp:312] Iteration 31700 (61.7705 iter/s, 1.6189s/100 iter), loss = 0.0117635
I0814 18:48:47.651895 10451 solver.cpp:334]     Train net output #0: loss = 0.0117624 (* 1 = 0.0117624 loss)
I0814 18:48:47.651913 10451 sgd_solver.cpp:136] Iteration 31700, lr = 0.0504688, m = 0.9
I0814 18:48:49.321336 10451 solver.cpp:312] Iteration 31800 (59.9 iter/s, 1.66945s/100 iter), loss = 0.00448515
I0814 18:48:49.321405 10451 solver.cpp:334]     Train net output #0: loss = 0.00448405 (* 1 = 0.00448405 loss)
I0814 18:48:49.321429 10451 sgd_solver.cpp:136] Iteration 31800, lr = 0.0503125, m = 0.9
I0814 18:48:50.949584 10451 solver.cpp:312] Iteration 31900 (61.4175 iter/s, 1.6282s/100 iter), loss = 0.0477318
I0814 18:48:50.949652 10451 solver.cpp:334]     Train net output #0: loss = 0.0477307 (* 1 = 0.0477307 loss)
I0814 18:48:50.949672 10451 sgd_solver.cpp:136] Iteration 31900, lr = 0.0501562, m = 0.9
I0814 18:48:52.518962 10451 solver.cpp:509] Iteration 32000, Testing net (#0)
I0814 18:48:53.365865 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.832354
I0814 18:48:53.365886 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.988824
I0814 18:48:53.365893 10451 solver.cpp:594]     Test net output #2: loss = 0.695846 (* 1 = 0.695846 loss)
I0814 18:48:53.365919 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.846932s
I0814 18:48:53.384780 10451 solver.cpp:312] Iteration 32000 (41.0656 iter/s, 2.43513s/100 iter), loss = 0.0147003
I0814 18:48:53.384811 10451 solver.cpp:334]     Train net output #0: loss = 0.0146992 (* 1 = 0.0146992 loss)
I0814 18:48:53.384825 10451 sgd_solver.cpp:136] Iteration 32000, lr = 0.05, m = 0.9
I0814 18:48:55.000095 10451 solver.cpp:312] Iteration 32100 (61.9094 iter/s, 1.61526s/100 iter), loss = 0.00240377
I0814 18:48:55.000160 10451 solver.cpp:334]     Train net output #0: loss = 0.00240266 (* 1 = 0.00240266 loss)
I0814 18:48:55.000180 10451 sgd_solver.cpp:136] Iteration 32100, lr = 0.0498438, m = 0.9
I0814 18:48:56.632297 10451 solver.cpp:312] Iteration 32200 (61.2689 iter/s, 1.63215s/100 iter), loss = 0.145529
I0814 18:48:56.632361 10451 solver.cpp:334]     Train net output #0: loss = 0.145528 (* 1 = 0.145528 loss)
I0814 18:48:56.632382 10451 sgd_solver.cpp:136] Iteration 32200, lr = 0.0496875, m = 0.9
I0814 18:48:58.260125 10451 solver.cpp:312] Iteration 32300 (61.4334 iter/s, 1.62778s/100 iter), loss = 0.0562469
I0814 18:48:58.260155 10451 solver.cpp:334]     Train net output #0: loss = 0.0562458 (* 1 = 0.0562458 loss)
I0814 18:48:58.260161 10451 sgd_solver.cpp:136] Iteration 32300, lr = 0.0495313, m = 0.9
I0814 18:48:59.895892 10451 solver.cpp:312] Iteration 32400 (61.1353 iter/s, 1.63572s/100 iter), loss = 0.0730606
I0814 18:48:59.895936 10451 solver.cpp:334]     Train net output #0: loss = 0.0730595 (* 1 = 0.0730595 loss)
I0814 18:48:59.895951 10451 sgd_solver.cpp:136] Iteration 32400, lr = 0.049375, m = 0.9
I0814 18:49:01.503353 10451 solver.cpp:312] Iteration 32500 (62.2118 iter/s, 1.60741s/100 iter), loss = 0.126334
I0814 18:49:01.503381 10451 solver.cpp:334]     Train net output #0: loss = 0.126332 (* 1 = 0.126332 loss)
I0814 18:49:01.503388 10451 sgd_solver.cpp:136] Iteration 32500, lr = 0.0492188, m = 0.9
I0814 18:49:03.103260 10451 solver.cpp:312] Iteration 32600 (62.5056 iter/s, 1.59986s/100 iter), loss = 0.105557
I0814 18:49:03.103354 10451 solver.cpp:334]     Train net output #0: loss = 0.105556 (* 1 = 0.105556 loss)
I0814 18:49:03.103368 10451 sgd_solver.cpp:136] Iteration 32600, lr = 0.0490625, m = 0.9
I0814 18:49:04.709373 10451 solver.cpp:312] Iteration 32700 (62.264 iter/s, 1.60606s/100 iter), loss = 0.0270023
I0814 18:49:04.709424 10451 solver.cpp:334]     Train net output #0: loss = 0.0270013 (* 1 = 0.0270013 loss)
I0814 18:49:04.709437 10451 sgd_solver.cpp:136] Iteration 32700, lr = 0.0489062, m = 0.9
I0814 18:49:06.323611 10451 solver.cpp:312] Iteration 32800 (61.9507 iter/s, 1.61419s/100 iter), loss = 0.114115
I0814 18:49:06.323659 10451 solver.cpp:334]     Train net output #0: loss = 0.114114 (* 1 = 0.114114 loss)
I0814 18:49:06.323673 10451 sgd_solver.cpp:136] Iteration 32800, lr = 0.04875, m = 0.9
I0814 18:49:07.936669 10451 solver.cpp:312] Iteration 32900 (61.9961 iter/s, 1.61301s/100 iter), loss = 0.0109862
I0814 18:49:07.936928 10451 solver.cpp:334]     Train net output #0: loss = 0.0109852 (* 1 = 0.0109852 loss)
I0814 18:49:07.936942 10451 sgd_solver.cpp:136] Iteration 32900, lr = 0.0485937, m = 0.9
I0814 18:49:09.560148 10451 solver.cpp:509] Iteration 33000, Testing net (#0)
I0814 18:49:10.385915 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.837942
I0814 18:49:10.385932 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.992647
I0814 18:49:10.385937 10451 solver.cpp:594]     Test net output #2: loss = 0.615405 (* 1 = 0.615405 loss)
I0814 18:49:10.385959 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.825789s
I0814 18:49:10.401703 10451 solver.cpp:312] Iteration 33000 (40.5686 iter/s, 2.46496s/100 iter), loss = 0.0430765
I0814 18:49:10.401733 10451 solver.cpp:334]     Train net output #0: loss = 0.0430755 (* 1 = 0.0430755 loss)
I0814 18:49:10.401744 10451 sgd_solver.cpp:136] Iteration 33000, lr = 0.0484375, m = 0.9
I0814 18:49:11.988018 10451 solver.cpp:312] Iteration 33100 (63.0412 iter/s, 1.58626s/100 iter), loss = 0.271976
I0814 18:49:11.988044 10451 solver.cpp:334]     Train net output #0: loss = 0.271975 (* 1 = 0.271975 loss)
I0814 18:49:11.988049 10451 sgd_solver.cpp:136] Iteration 33100, lr = 0.0482813, m = 0.9
I0814 18:49:13.667670 10451 solver.cpp:312] Iteration 33200 (59.5379 iter/s, 1.6796s/100 iter), loss = 0.00432047
I0814 18:49:13.667696 10451 solver.cpp:334]     Train net output #0: loss = 0.00431939 (* 1 = 0.00431939 loss)
I0814 18:49:13.667702 10451 sgd_solver.cpp:136] Iteration 33200, lr = 0.048125, m = 0.9
I0814 18:49:15.290233 10451 solver.cpp:312] Iteration 33300 (61.6328 iter/s, 1.62251s/100 iter), loss = 0.1046
I0814 18:49:15.290293 10451 solver.cpp:334]     Train net output #0: loss = 0.104599 (* 1 = 0.104599 loss)
I0814 18:49:15.290311 10451 sgd_solver.cpp:136] Iteration 33300, lr = 0.0479688, m = 0.9
I0814 18:49:16.929900 10451 solver.cpp:312] Iteration 33400 (60.9898 iter/s, 1.63962s/100 iter), loss = 0.0341524
I0814 18:49:16.929965 10451 solver.cpp:334]     Train net output #0: loss = 0.0341514 (* 1 = 0.0341514 loss)
I0814 18:49:16.929986 10451 sgd_solver.cpp:136] Iteration 33400, lr = 0.0478125, m = 0.9
I0814 18:49:18.495329 10451 solver.cpp:312] Iteration 33500 (63.8821 iter/s, 1.56538s/100 iter), loss = 0.136702
I0814 18:49:18.495353 10451 solver.cpp:334]     Train net output #0: loss = 0.136701 (* 1 = 0.136701 loss)
I0814 18:49:18.495358 10451 sgd_solver.cpp:136] Iteration 33500, lr = 0.0476562, m = 0.9
I0814 18:49:20.140719 10451 solver.cpp:312] Iteration 33600 (60.7778 iter/s, 1.64534s/100 iter), loss = 0.0164037
I0814 18:49:20.140902 10451 solver.cpp:334]     Train net output #0: loss = 0.0164027 (* 1 = 0.0164027 loss)
I0814 18:49:20.140964 10451 sgd_solver.cpp:136] Iteration 33600, lr = 0.0475, m = 0.9
I0814 18:49:21.774711 10451 solver.cpp:312] Iteration 33700 (61.2017 iter/s, 1.63394s/100 iter), loss = 0.0105642
I0814 18:49:21.774780 10451 solver.cpp:334]     Train net output #0: loss = 0.0105631 (* 1 = 0.0105631 loss)
I0814 18:49:21.774798 10451 sgd_solver.cpp:136] Iteration 33700, lr = 0.0473437, m = 0.9
I0814 18:49:23.371799 10451 solver.cpp:312] Iteration 33800 (62.6159 iter/s, 1.59704s/100 iter), loss = 0.0359925
I0814 18:49:23.371837 10451 solver.cpp:334]     Train net output #0: loss = 0.0359915 (* 1 = 0.0359915 loss)
I0814 18:49:23.371845 10451 sgd_solver.cpp:136] Iteration 33800, lr = 0.0471875, m = 0.9
I0814 18:49:24.982461 10451 solver.cpp:312] Iteration 33900 (62.0882 iter/s, 1.61061s/100 iter), loss = 0.012779
I0814 18:49:24.982487 10451 solver.cpp:334]     Train net output #0: loss = 0.012778 (* 1 = 0.012778 loss)
I0814 18:49:24.982492 10451 sgd_solver.cpp:136] Iteration 33900, lr = 0.0470312, m = 0.9
I0814 18:49:26.591557 10451 solver.cpp:509] Iteration 34000, Testing net (#0)
I0814 18:49:27.424793 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.849413
I0814 18:49:27.424813 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.993824
I0814 18:49:27.424819 10451 solver.cpp:594]     Test net output #2: loss = 0.621647 (* 1 = 0.621647 loss)
I0814 18:49:27.424836 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.833257s
I0814 18:49:27.445243 10451 solver.cpp:312] Iteration 34000 (40.6057 iter/s, 2.46271s/100 iter), loss = 0.0236849
I0814 18:49:27.445291 10451 solver.cpp:334]     Train net output #0: loss = 0.0236839 (* 1 = 0.0236839 loss)
I0814 18:49:27.445300 10451 sgd_solver.cpp:136] Iteration 34000, lr = 0.046875, m = 0.9
I0814 18:49:29.080417 10451 solver.cpp:312] Iteration 34100 (61.1575 iter/s, 1.63512s/100 iter), loss = 0.0189975
I0814 18:49:29.080440 10451 solver.cpp:334]     Train net output #0: loss = 0.0189965 (* 1 = 0.0189965 loss)
I0814 18:49:29.080446 10451 sgd_solver.cpp:136] Iteration 34100, lr = 0.0467188, m = 0.9
I0814 18:49:30.723062 10451 solver.cpp:312] Iteration 34200 (60.8793 iter/s, 1.6426s/100 iter), loss = 0.021231
I0814 18:49:30.723126 10451 solver.cpp:334]     Train net output #0: loss = 0.0212301 (* 1 = 0.0212301 loss)
I0814 18:49:30.723145 10451 sgd_solver.cpp:136] Iteration 34200, lr = 0.0465625, m = 0.9
I0814 18:49:32.320770 10451 solver.cpp:312] Iteration 34300 (62.5917 iter/s, 1.59766s/100 iter), loss = 0.0233357
I0814 18:49:32.320792 10451 solver.cpp:334]     Train net output #0: loss = 0.0233348 (* 1 = 0.0233348 loss)
I0814 18:49:32.320797 10451 sgd_solver.cpp:136] Iteration 34300, lr = 0.0464063, m = 0.9
I0814 18:49:33.920626 10451 solver.cpp:312] Iteration 34400 (62.5075 iter/s, 1.59981s/100 iter), loss = 0.0839406
I0814 18:49:33.920687 10451 solver.cpp:334]     Train net output #0: loss = 0.0839396 (* 1 = 0.0839396 loss)
I0814 18:49:33.920694 10451 sgd_solver.cpp:136] Iteration 34400, lr = 0.04625, m = 0.9
I0814 18:49:35.562902 10451 solver.cpp:312] Iteration 34500 (60.893 iter/s, 1.64222s/100 iter), loss = 0.0207696
I0814 18:49:35.562965 10451 solver.cpp:334]     Train net output #0: loss = 0.0207687 (* 1 = 0.0207687 loss)
I0814 18:49:35.562983 10451 sgd_solver.cpp:136] Iteration 34500, lr = 0.0460938, m = 0.9
I0814 18:49:37.158835 10451 solver.cpp:312] Iteration 34600 (62.6612 iter/s, 1.59588s/100 iter), loss = 0.0152108
I0814 18:49:37.158859 10451 solver.cpp:334]     Train net output #0: loss = 0.0152098 (* 1 = 0.0152098 loss)
I0814 18:49:37.158862 10451 sgd_solver.cpp:136] Iteration 34600, lr = 0.0459375, m = 0.9
I0814 18:49:38.773162 10451 solver.cpp:312] Iteration 34700 (61.9472 iter/s, 1.61428s/100 iter), loss = 0.00515084
I0814 18:49:38.773213 10451 solver.cpp:334]     Train net output #0: loss = 0.00514984 (* 1 = 0.00514984 loss)
I0814 18:49:38.773227 10451 sgd_solver.cpp:136] Iteration 34700, lr = 0.0457813, m = 0.9
I0814 18:49:40.352954 10451 solver.cpp:312] Iteration 34800 (63.3017 iter/s, 1.57974s/100 iter), loss = 0.0182675
I0814 18:49:40.353178 10451 solver.cpp:334]     Train net output #0: loss = 0.0182665 (* 1 = 0.0182665 loss)
I0814 18:49:40.353257 10451 sgd_solver.cpp:136] Iteration 34800, lr = 0.045625, m = 0.9
I0814 18:49:41.940711 10451 solver.cpp:312] Iteration 34900 (62.9838 iter/s, 1.58771s/100 iter), loss = 0.00600049
I0814 18:49:41.940732 10451 solver.cpp:334]     Train net output #0: loss = 0.00599946 (* 1 = 0.00599946 loss)
I0814 18:49:41.940738 10451 sgd_solver.cpp:136] Iteration 34900, lr = 0.0454687, m = 0.9
I0814 18:49:43.534709 10451 solver.cpp:509] Iteration 35000, Testing net (#0)
I0814 18:49:43.758369 10438 data_reader.cpp:288] Starting prefetch of epoch 5
I0814 18:49:44.349493 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.830884
I0814 18:49:44.349514 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.989706
I0814 18:49:44.349519 10451 solver.cpp:594]     Test net output #2: loss = 0.638632 (* 1 = 0.638632 loss)
I0814 18:49:44.349537 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.814806s
I0814 18:49:44.365080 10451 solver.cpp:312] Iteration 35000 (41.249 iter/s, 2.4243s/100 iter), loss = 0.011998
I0814 18:49:44.365097 10451 solver.cpp:334]     Train net output #0: loss = 0.011997 (* 1 = 0.011997 loss)
I0814 18:49:44.365103 10451 sgd_solver.cpp:136] Iteration 35000, lr = 0.0453125, m = 0.9
I0814 18:49:45.997088 10451 solver.cpp:312] Iteration 35100 (61.2762 iter/s, 1.63196s/100 iter), loss = 0.0718785
I0814 18:49:45.997113 10451 solver.cpp:334]     Train net output #0: loss = 0.0718774 (* 1 = 0.0718774 loss)
I0814 18:49:45.997119 10451 sgd_solver.cpp:136] Iteration 35100, lr = 0.0451563, m = 0.9
I0814 18:49:47.634649 10451 solver.cpp:312] Iteration 35200 (61.0683 iter/s, 1.63751s/100 iter), loss = 0.00875828
I0814 18:49:47.634678 10451 solver.cpp:334]     Train net output #0: loss = 0.00875724 (* 1 = 0.00875724 loss)
I0814 18:49:47.634686 10451 sgd_solver.cpp:136] Iteration 35200, lr = 0.045, m = 0.9
I0814 18:49:49.248739 10451 solver.cpp:312] Iteration 35300 (61.9564 iter/s, 1.61404s/100 iter), loss = 0.00456172
I0814 18:49:49.248764 10451 solver.cpp:334]     Train net output #0: loss = 0.00456071 (* 1 = 0.00456071 loss)
I0814 18:49:49.248769 10451 sgd_solver.cpp:136] Iteration 35300, lr = 0.0448438, m = 0.9
I0814 18:49:50.829383 10451 solver.cpp:312] Iteration 35400 (63.2673 iter/s, 1.5806s/100 iter), loss = 0.0229
I0814 18:49:50.829430 10451 solver.cpp:334]     Train net output #0: loss = 0.0228989 (* 1 = 0.0228989 loss)
I0814 18:49:50.829442 10451 sgd_solver.cpp:136] Iteration 35400, lr = 0.0446875, m = 0.9
I0814 18:49:52.461930 10451 solver.cpp:312] Iteration 35500 (61.2559 iter/s, 1.6325s/100 iter), loss = 0.109765
I0814 18:49:52.461956 10451 solver.cpp:334]     Train net output #0: loss = 0.109764 (* 1 = 0.109764 loss)
I0814 18:49:52.461961 10451 sgd_solver.cpp:136] Iteration 35500, lr = 0.0445313, m = 0.9
I0814 18:49:54.087716 10451 solver.cpp:312] Iteration 35600 (61.5105 iter/s, 1.62574s/100 iter), loss = 0.0853621
I0814 18:49:54.087764 10451 solver.cpp:334]     Train net output #0: loss = 0.0853611 (* 1 = 0.0853611 loss)
I0814 18:49:54.087776 10451 sgd_solver.cpp:136] Iteration 35600, lr = 0.044375, m = 0.9
I0814 18:49:55.684978 10451 solver.cpp:312] Iteration 35700 (62.6091 iter/s, 1.59721s/100 iter), loss = 0.132078
I0814 18:49:55.685004 10451 solver.cpp:334]     Train net output #0: loss = 0.132077 (* 1 = 0.132077 loss)
I0814 18:49:55.685009 10451 sgd_solver.cpp:136] Iteration 35700, lr = 0.0442187, m = 0.9
I0814 18:49:57.292235 10451 solver.cpp:312] Iteration 35800 (62.2198 iter/s, 1.60721s/100 iter), loss = 0.287182
I0814 18:49:57.292259 10451 solver.cpp:334]     Train net output #0: loss = 0.287181 (* 1 = 0.287181 loss)
I0814 18:49:57.292265 10451 sgd_solver.cpp:136] Iteration 35800, lr = 0.0440625, m = 0.9
I0814 18:49:58.874491 10451 solver.cpp:312] Iteration 35900 (63.2028 iter/s, 1.58221s/100 iter), loss = 0.00830345
I0814 18:49:58.874541 10451 solver.cpp:334]     Train net output #0: loss = 0.00830234 (* 1 = 0.00830234 loss)
I0814 18:49:58.874554 10451 sgd_solver.cpp:136] Iteration 35900, lr = 0.0439062, m = 0.9
I0814 18:50:00.469429 10451 solver.cpp:509] Iteration 36000, Testing net (#0)
I0814 18:50:01.285873 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.816766
I0814 18:50:01.285893 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.989412
I0814 18:50:01.285898 10451 solver.cpp:594]     Test net output #2: loss = 0.742305 (* 1 = 0.742305 loss)
I0814 18:50:01.285913 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.816463s
I0814 18:50:01.303599 10451 solver.cpp:312] Iteration 36000 (41.1685 iter/s, 2.42904s/100 iter), loss = 0.0140326
I0814 18:50:01.303618 10451 solver.cpp:334]     Train net output #0: loss = 0.0140314 (* 1 = 0.0140314 loss)
I0814 18:50:01.303624 10451 sgd_solver.cpp:136] Iteration 36000, lr = 0.04375, m = 0.9
I0814 18:50:02.893963 10451 solver.cpp:312] Iteration 36100 (62.8808 iter/s, 1.59031s/100 iter), loss = 0.0218012
I0814 18:50:02.893987 10451 solver.cpp:334]     Train net output #0: loss = 0.0218 (* 1 = 0.0218 loss)
I0814 18:50:02.893992 10451 sgd_solver.cpp:136] Iteration 36100, lr = 0.0435938, m = 0.9
I0814 18:50:04.523744 10451 solver.cpp:312] Iteration 36200 (61.3597 iter/s, 1.62973s/100 iter), loss = 0.0106119
I0814 18:50:04.523846 10451 solver.cpp:334]     Train net output #0: loss = 0.0106108 (* 1 = 0.0106108 loss)
I0814 18:50:04.523859 10451 sgd_solver.cpp:136] Iteration 36200, lr = 0.0434375, m = 0.9
I0814 18:50:06.105769 10451 solver.cpp:312] Iteration 36300 (63.2122 iter/s, 1.58197s/100 iter), loss = 0.0305873
I0814 18:50:06.105794 10451 solver.cpp:334]     Train net output #0: loss = 0.0305862 (* 1 = 0.0305862 loss)
I0814 18:50:06.105799 10451 sgd_solver.cpp:136] Iteration 36300, lr = 0.0432813, m = 0.9
I0814 18:50:07.685899 10451 solver.cpp:312] Iteration 36400 (63.2879 iter/s, 1.58008s/100 iter), loss = 0.0481877
I0814 18:50:07.685961 10451 solver.cpp:334]     Train net output #0: loss = 0.0481866 (* 1 = 0.0481866 loss)
I0814 18:50:07.685981 10451 sgd_solver.cpp:136] Iteration 36400, lr = 0.043125, m = 0.9
I0814 18:50:09.321249 10451 solver.cpp:312] Iteration 36500 (61.151 iter/s, 1.6353s/100 iter), loss = 0.0366159
I0814 18:50:09.321393 10451 solver.cpp:334]     Train net output #0: loss = 0.0366148 (* 1 = 0.0366148 loss)
I0814 18:50:09.321410 10451 sgd_solver.cpp:136] Iteration 36500, lr = 0.0429688, m = 0.9
I0814 18:50:10.960520 10451 solver.cpp:312] Iteration 36600 (61.0045 iter/s, 1.63922s/100 iter), loss = 0.0297357
I0814 18:50:10.960542 10451 solver.cpp:334]     Train net output #0: loss = 0.0297346 (* 1 = 0.0297346 loss)
I0814 18:50:10.960548 10451 sgd_solver.cpp:136] Iteration 36600, lr = 0.0428125, m = 0.9
I0814 18:50:12.532585 10451 solver.cpp:312] Iteration 36700 (63.6125 iter/s, 1.57202s/100 iter), loss = 0.0475045
I0814 18:50:12.532613 10451 solver.cpp:334]     Train net output #0: loss = 0.0475034 (* 1 = 0.0475034 loss)
I0814 18:50:12.532618 10451 sgd_solver.cpp:136] Iteration 36700, lr = 0.0426563, m = 0.9
I0814 18:50:14.164801 10451 solver.cpp:312] Iteration 36800 (61.2684 iter/s, 1.63216s/100 iter), loss = 0.0030108
I0814 18:50:14.164872 10451 solver.cpp:334]     Train net output #0: loss = 0.00300968 (* 1 = 0.00300968 loss)
I0814 18:50:14.164893 10451 sgd_solver.cpp:136] Iteration 36800, lr = 0.0425, m = 0.9
I0814 18:50:15.797813 10451 solver.cpp:312] Iteration 36900 (61.2384 iter/s, 1.63296s/100 iter), loss = 0.164065
I0814 18:50:15.797884 10451 solver.cpp:334]     Train net output #0: loss = 0.164063 (* 1 = 0.164063 loss)
I0814 18:50:15.797907 10451 sgd_solver.cpp:136] Iteration 36900, lr = 0.0423437, m = 0.9
I0814 18:50:17.431097 10451 solver.cpp:509] Iteration 37000, Testing net (#0)
I0814 18:50:18.259825 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.865295
I0814 18:50:18.259845 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.995882
I0814 18:50:18.259850 10451 solver.cpp:594]     Test net output #2: loss = 0.460349 (* 1 = 0.460349 loss)
I0814 18:50:18.259865 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.828745s
I0814 18:50:18.280473 10451 solver.cpp:312] Iteration 37000 (40.2805 iter/s, 2.48259s/100 iter), loss = 0.0130029
I0814 18:50:18.280491 10451 solver.cpp:334]     Train net output #0: loss = 0.0130018 (* 1 = 0.0130018 loss)
I0814 18:50:18.280495 10451 sgd_solver.cpp:136] Iteration 37000, lr = 0.0421875, m = 0.9
I0814 18:50:19.899005 10451 solver.cpp:312] Iteration 37100 (61.7864 iter/s, 1.61848s/100 iter), loss = 0.0284992
I0814 18:50:19.899052 10451 solver.cpp:334]     Train net output #0: loss = 0.0284981 (* 1 = 0.0284981 loss)
I0814 18:50:19.899063 10451 sgd_solver.cpp:136] Iteration 37100, lr = 0.0420313, m = 0.9
I0814 18:50:21.506511 10451 solver.cpp:312] Iteration 37200 (62.21 iter/s, 1.60746s/100 iter), loss = 0.052587
I0814 18:50:21.506541 10451 solver.cpp:334]     Train net output #0: loss = 0.0525859 (* 1 = 0.0525859 loss)
I0814 18:50:21.506546 10451 sgd_solver.cpp:136] Iteration 37200, lr = 0.041875, m = 0.9
I0814 18:50:23.100685 10451 solver.cpp:312] Iteration 37300 (62.7304 iter/s, 1.59412s/100 iter), loss = 0.00367564
I0814 18:50:23.100745 10451 solver.cpp:334]     Train net output #0: loss = 0.00367454 (* 1 = 0.00367454 loss)
I0814 18:50:23.100764 10451 sgd_solver.cpp:136] Iteration 37300, lr = 0.0417188, m = 0.9
I0814 18:50:24.712740 10451 solver.cpp:312] Iteration 37400 (62.0346 iter/s, 1.612s/100 iter), loss = 0.00318111
I0814 18:50:24.712783 10451 solver.cpp:334]     Train net output #0: loss = 0.00318 (* 1 = 0.00318 loss)
I0814 18:50:24.712790 10451 sgd_solver.cpp:136] Iteration 37400, lr = 0.0415625, m = 0.9
I0814 18:50:26.362512 10451 solver.cpp:312] Iteration 37500 (60.6162 iter/s, 1.64972s/100 iter), loss = 0.00733955
I0814 18:50:26.362537 10451 solver.cpp:334]     Train net output #0: loss = 0.00733843 (* 1 = 0.00733843 loss)
I0814 18:50:26.362543 10451 sgd_solver.cpp:136] Iteration 37500, lr = 0.0414063, m = 0.9
I0814 18:50:28.016585 10451 solver.cpp:312] Iteration 37600 (60.4587 iter/s, 1.65402s/100 iter), loss = 0.177557
I0814 18:50:28.016726 10451 solver.cpp:334]     Train net output #0: loss = 0.177556 (* 1 = 0.177556 loss)
I0814 18:50:28.016744 10451 sgd_solver.cpp:136] Iteration 37600, lr = 0.04125, m = 0.9
I0814 18:50:29.622297 10451 solver.cpp:312] Iteration 37700 (62.2797 iter/s, 1.60566s/100 iter), loss = 0.0137741
I0814 18:50:29.622324 10451 solver.cpp:334]     Train net output #0: loss = 0.013773 (* 1 = 0.013773 loss)
I0814 18:50:29.622331 10451 sgd_solver.cpp:136] Iteration 37700, lr = 0.0410937, m = 0.9
I0814 18:50:31.264061 10451 solver.cpp:312] Iteration 37800 (60.912 iter/s, 1.64171s/100 iter), loss = 0.0487533
I0814 18:50:31.264108 10451 solver.cpp:334]     Train net output #0: loss = 0.0487522 (* 1 = 0.0487522 loss)
I0814 18:50:31.264120 10451 sgd_solver.cpp:136] Iteration 37800, lr = 0.0409375, m = 0.9
I0814 18:50:32.894942 10451 solver.cpp:312] Iteration 37900 (61.3183 iter/s, 1.63083s/100 iter), loss = 0.0671668
I0814 18:50:32.894966 10451 solver.cpp:334]     Train net output #0: loss = 0.0671657 (* 1 = 0.0671657 loss)
I0814 18:50:32.894971 10451 sgd_solver.cpp:136] Iteration 37900, lr = 0.0407812, m = 0.9
I0814 18:50:34.543927 10451 solver.cpp:509] Iteration 38000, Testing net (#0)
I0814 18:50:35.358865 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.839707
I0814 18:50:35.358882 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.991765
I0814 18:50:35.358886 10451 solver.cpp:594]     Test net output #2: loss = 0.735563 (* 1 = 0.735563 loss)
I0814 18:50:35.358906 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.814957s
I0814 18:50:35.376727 10451 solver.cpp:312] Iteration 38000 (40.2947 iter/s, 2.48171s/100 iter), loss = 0.0135817
I0814 18:50:35.376745 10451 solver.cpp:334]     Train net output #0: loss = 0.0135805 (* 1 = 0.0135805 loss)
I0814 18:50:35.376751 10451 sgd_solver.cpp:136] Iteration 38000, lr = 0.040625, m = 0.9
I0814 18:50:36.992604 10451 solver.cpp:312] Iteration 38100 (61.8879 iter/s, 1.61583s/100 iter), loss = 0.00928718
I0814 18:50:36.992648 10451 solver.cpp:334]     Train net output #0: loss = 0.00928604 (* 1 = 0.00928604 loss)
I0814 18:50:36.992660 10451 sgd_solver.cpp:136] Iteration 38100, lr = 0.0404688, m = 0.9
I0814 18:50:38.616257 10451 solver.cpp:312] Iteration 38200 (61.5915 iter/s, 1.6236s/100 iter), loss = 0.0153909
I0814 18:50:38.616283 10451 solver.cpp:334]     Train net output #0: loss = 0.0153898 (* 1 = 0.0153898 loss)
I0814 18:50:38.616289 10451 sgd_solver.cpp:136] Iteration 38200, lr = 0.0403125, m = 0.9
I0814 18:50:40.219811 10451 solver.cpp:312] Iteration 38300 (62.3633 iter/s, 1.60351s/100 iter), loss = 0.0146341
I0814 18:50:40.219871 10451 solver.cpp:334]     Train net output #0: loss = 0.0146329 (* 1 = 0.0146329 loss)
I0814 18:50:40.219889 10451 sgd_solver.cpp:136] Iteration 38300, lr = 0.0401563, m = 0.9
I0814 18:50:41.830943 10451 solver.cpp:312] Iteration 38400 (62.0701 iter/s, 1.61108s/100 iter), loss = 0.0283117
I0814 18:50:41.830993 10451 solver.cpp:334]     Train net output #0: loss = 0.0283105 (* 1 = 0.0283105 loss)
I0814 18:50:41.831007 10451 sgd_solver.cpp:136] Iteration 38400, lr = 0.04, m = 0.9
I0814 18:50:43.482955 10451 solver.cpp:312] Iteration 38500 (60.5341 iter/s, 1.65196s/100 iter), loss = 0.0651713
I0814 18:50:43.483006 10451 solver.cpp:334]     Train net output #0: loss = 0.0651702 (* 1 = 0.0651702 loss)
I0814 18:50:43.483019 10451 sgd_solver.cpp:136] Iteration 38500, lr = 0.0398437, m = 0.9
I0814 18:50:45.148651 10451 solver.cpp:312] Iteration 38600 (60.0367 iter/s, 1.66565s/100 iter), loss = 0.0219931
I0814 18:50:45.148699 10451 solver.cpp:334]     Train net output #0: loss = 0.0219919 (* 1 = 0.0219919 loss)
I0814 18:50:45.148712 10451 sgd_solver.cpp:136] Iteration 38600, lr = 0.0396875, m = 0.9
I0814 18:50:46.722004 10451 solver.cpp:312] Iteration 38700 (63.5606 iter/s, 1.5733s/100 iter), loss = 0.0231006
I0814 18:50:46.722028 10451 solver.cpp:334]     Train net output #0: loss = 0.0230994 (* 1 = 0.0230994 loss)
I0814 18:50:46.722033 10451 sgd_solver.cpp:136] Iteration 38700, lr = 0.0395312, m = 0.9
I0814 18:50:48.349359 10451 solver.cpp:312] Iteration 38800 (61.4512 iter/s, 1.62731s/100 iter), loss = 0.00887007
I0814 18:50:48.349382 10451 solver.cpp:334]     Train net output #0: loss = 0.00886893 (* 1 = 0.00886893 loss)
I0814 18:50:48.349386 10451 sgd_solver.cpp:136] Iteration 38800, lr = 0.039375, m = 0.9
I0814 18:50:49.974524 10451 solver.cpp:312] Iteration 38900 (61.5345 iter/s, 1.62511s/100 iter), loss = 0.0196538
I0814 18:50:49.974566 10451 solver.cpp:334]     Train net output #0: loss = 0.0196527 (* 1 = 0.0196527 loss)
I0814 18:50:49.974572 10451 sgd_solver.cpp:136] Iteration 38900, lr = 0.0392187, m = 0.9
I0814 18:50:51.604910 10451 solver.cpp:509] Iteration 39000, Testing net (#0)
I0814 18:50:52.425328 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.843531
I0814 18:50:52.425348 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.992647
I0814 18:50:52.425351 10451 solver.cpp:594]     Test net output #2: loss = 0.684127 (* 1 = 0.684127 loss)
I0814 18:50:52.425365 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.820435s
I0814 18:50:52.442770 10451 solver.cpp:312] Iteration 39000 (40.5156 iter/s, 2.46818s/100 iter), loss = 0.00276099
I0814 18:50:52.442802 10451 solver.cpp:334]     Train net output #0: loss = 0.00275985 (* 1 = 0.00275985 loss)
I0814 18:50:52.442829 10451 sgd_solver.cpp:136] Iteration 39000, lr = 0.0390625, m = 0.9
I0814 18:50:54.074367 10451 solver.cpp:312] Iteration 39100 (61.2917 iter/s, 1.63154s/100 iter), loss = 0.0155792
I0814 18:50:54.074390 10451 solver.cpp:334]     Train net output #0: loss = 0.0155781 (* 1 = 0.0155781 loss)
I0814 18:50:54.074395 10451 sgd_solver.cpp:136] Iteration 39100, lr = 0.0389063, m = 0.9
I0814 18:50:55.682654 10451 solver.cpp:312] Iteration 39200 (62.1799 iter/s, 1.60824s/100 iter), loss = 0.0111963
I0814 18:50:55.682718 10451 solver.cpp:334]     Train net output #0: loss = 0.0111952 (* 1 = 0.0111952 loss)
I0814 18:50:55.682739 10451 sgd_solver.cpp:136] Iteration 39200, lr = 0.03875, m = 0.9
I0814 18:50:57.306162 10451 solver.cpp:312] Iteration 39300 (61.5968 iter/s, 1.62346s/100 iter), loss = 0.00411076
I0814 18:50:57.306228 10451 solver.cpp:334]     Train net output #0: loss = 0.00410958 (* 1 = 0.00410958 loss)
I0814 18:50:57.306249 10451 sgd_solver.cpp:136] Iteration 39300, lr = 0.0385938, m = 0.9
I0814 18:50:58.761765 10436 data_reader.cpp:288] Starting prefetch of epoch 5
I0814 18:50:58.919410 10451 solver.cpp:312] Iteration 39400 (61.9887 iter/s, 1.6132s/100 iter), loss = 0.0460615
I0814 18:50:58.919459 10451 solver.cpp:334]     Train net output #0: loss = 0.0460604 (* 1 = 0.0460604 loss)
I0814 18:50:58.919473 10451 sgd_solver.cpp:136] Iteration 39400, lr = 0.0384375, m = 0.9
I0814 18:51:00.569964 10451 solver.cpp:312] Iteration 39500 (60.5876 iter/s, 1.6505s/100 iter), loss = 0.0373622
I0814 18:51:00.569990 10451 solver.cpp:334]     Train net output #0: loss = 0.0373611 (* 1 = 0.0373611 loss)
I0814 18:51:00.569996 10451 sgd_solver.cpp:136] Iteration 39500, lr = 0.0382813, m = 0.9
I0814 18:51:02.183873 10451 solver.cpp:312] Iteration 39600 (61.9632 iter/s, 1.61386s/100 iter), loss = 0.0260769
I0814 18:51:02.183935 10451 solver.cpp:334]     Train net output #0: loss = 0.0260757 (* 1 = 0.0260757 loss)
I0814 18:51:02.183954 10451 sgd_solver.cpp:136] Iteration 39600, lr = 0.038125, m = 0.9
I0814 18:51:03.811596 10451 solver.cpp:312] Iteration 39700 (61.4373 iter/s, 1.62768s/100 iter), loss = 0.0189345
I0814 18:51:03.811619 10451 solver.cpp:334]     Train net output #0: loss = 0.0189333 (* 1 = 0.0189333 loss)
I0814 18:51:03.811625 10451 sgd_solver.cpp:136] Iteration 39700, lr = 0.0379688, m = 0.9
I0814 18:51:05.411988 10451 solver.cpp:312] Iteration 39800 (62.4866 iter/s, 1.60034s/100 iter), loss = 0.0664255
I0814 18:51:05.412096 10451 solver.cpp:334]     Train net output #0: loss = 0.0664243 (* 1 = 0.0664243 loss)
I0814 18:51:05.412117 10451 sgd_solver.cpp:136] Iteration 39800, lr = 0.0378125, m = 0.9
I0814 18:51:07.032528 10451 solver.cpp:312] Iteration 39900 (61.7098 iter/s, 1.62049s/100 iter), loss = 0.171182
I0814 18:51:07.032593 10451 solver.cpp:334]     Train net output #0: loss = 0.171181 (* 1 = 0.171181 loss)
I0814 18:51:07.032613 10451 sgd_solver.cpp:136] Iteration 39900, lr = 0.0376562, m = 0.9
I0814 18:51:08.613867 10451 solver.cpp:639] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/initial/cifar10_jacintonet11v2_iter_40000.caffemodel
I0814 18:51:08.621873 10451 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/initial/cifar10_jacintonet11v2_iter_40000.solverstate
I0814 18:51:08.625613 10451 solver.cpp:509] Iteration 40000, Testing net (#0)
I0814 18:51:09.457631 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.807942
I0814 18:51:09.457651 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.984412
I0814 18:51:09.457656 10451 solver.cpp:594]     Test net output #2: loss = 0.882284 (* 1 = 0.882284 loss)
I0814 18:51:09.457681 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.832042s
I0814 18:51:09.476699 10451 solver.cpp:312] Iteration 40000 (40.9148 iter/s, 2.4441s/100 iter), loss = 0.0124523
I0814 18:51:09.476717 10451 solver.cpp:334]     Train net output #0: loss = 0.0124512 (* 1 = 0.0124512 loss)
I0814 18:51:09.476723 10451 sgd_solver.cpp:136] Iteration 40000, lr = 0.0375, m = 0.9
I0814 18:51:11.112432 10451 solver.cpp:312] Iteration 40100 (61.1366 iter/s, 1.63568s/100 iter), loss = 0.00379068
I0814 18:51:11.112486 10451 solver.cpp:334]     Train net output #0: loss = 0.00378953 (* 1 = 0.00378953 loss)
I0814 18:51:11.112504 10451 sgd_solver.cpp:136] Iteration 40100, lr = 0.0373438, m = 0.9
I0814 18:51:12.714201 10451 solver.cpp:312] Iteration 40200 (62.433 iter/s, 1.60172s/100 iter), loss = 0.00168164
I0814 18:51:12.714253 10451 solver.cpp:334]     Train net output #0: loss = 0.00168047 (* 1 = 0.00168047 loss)
I0814 18:51:12.714267 10451 sgd_solver.cpp:136] Iteration 40200, lr = 0.0371875, m = 0.9
I0814 18:51:14.352242 10451 solver.cpp:312] Iteration 40300 (61.0503 iter/s, 1.63799s/100 iter), loss = 0.0571777
I0814 18:51:14.352267 10451 solver.cpp:334]     Train net output #0: loss = 0.0571765 (* 1 = 0.0571765 loss)
I0814 18:51:14.352272 10451 sgd_solver.cpp:136] Iteration 40300, lr = 0.0370313, m = 0.9
I0814 18:51:15.978581 10451 solver.cpp:312] Iteration 40400 (61.4898 iter/s, 1.62629s/100 iter), loss = 0.044027
I0814 18:51:15.978605 10451 solver.cpp:334]     Train net output #0: loss = 0.0440259 (* 1 = 0.0440259 loss)
I0814 18:51:15.978612 10451 sgd_solver.cpp:136] Iteration 40400, lr = 0.036875, m = 0.9
I0814 18:51:17.604154 10451 solver.cpp:312] Iteration 40500 (61.5186 iter/s, 1.62552s/100 iter), loss = 0.0101699
I0814 18:51:17.604182 10451 solver.cpp:334]     Train net output #0: loss = 0.0101687 (* 1 = 0.0101687 loss)
I0814 18:51:17.604188 10451 sgd_solver.cpp:136] Iteration 40500, lr = 0.0367188, m = 0.9
I0814 18:51:19.185962 10451 solver.cpp:312] Iteration 40600 (63.2207 iter/s, 1.58176s/100 iter), loss = 0.000730814
I0814 18:51:19.185987 10451 solver.cpp:334]     Train net output #0: loss = 0.000729586 (* 1 = 0.000729586 loss)
I0814 18:51:19.185993 10451 sgd_solver.cpp:136] Iteration 40600, lr = 0.0365625, m = 0.9
I0814 18:51:20.790719 10451 solver.cpp:312] Iteration 40700 (62.3166 iter/s, 1.60471s/100 iter), loss = 0.00220906
I0814 18:51:20.790743 10451 solver.cpp:334]     Train net output #0: loss = 0.00220781 (* 1 = 0.00220781 loss)
I0814 18:51:20.790748 10451 sgd_solver.cpp:136] Iteration 40700, lr = 0.0364062, m = 0.9
I0814 18:51:22.374222 10451 solver.cpp:312] Iteration 40800 (63.1532 iter/s, 1.58345s/100 iter), loss = 0.00279215
I0814 18:51:22.374269 10451 solver.cpp:334]     Train net output #0: loss = 0.0027909 (* 1 = 0.0027909 loss)
I0814 18:51:22.374280 10451 sgd_solver.cpp:136] Iteration 40800, lr = 0.03625, m = 0.9
I0814 18:51:23.962272 10451 solver.cpp:312] Iteration 40900 (62.9722 iter/s, 1.588s/100 iter), loss = 0.00667532
I0814 18:51:23.962296 10451 solver.cpp:334]     Train net output #0: loss = 0.00667411 (* 1 = 0.00667411 loss)
I0814 18:51:23.962301 10451 sgd_solver.cpp:136] Iteration 40900, lr = 0.0360937, m = 0.9
I0814 18:51:25.556411 10451 solver.cpp:509] Iteration 41000, Testing net (#0)
I0814 18:51:26.391418 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.881766
I0814 18:51:26.391438 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.991177
I0814 18:51:26.391443 10451 solver.cpp:594]     Test net output #2: loss = 0.49656 (* 1 = 0.49656 loss)
I0814 18:51:26.391458 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.835026s
I0814 18:51:26.408761 10451 solver.cpp:312] Iteration 41000 (40.876 iter/s, 2.44642s/100 iter), loss = 0.0294485
I0814 18:51:26.408778 10451 solver.cpp:334]     Train net output #0: loss = 0.0294473 (* 1 = 0.0294473 loss)
I0814 18:51:26.408784 10451 sgd_solver.cpp:136] Iteration 41000, lr = 0.0359375, m = 0.9
I0814 18:51:28.001758 10451 solver.cpp:312] Iteration 41100 (62.7767 iter/s, 1.59295s/100 iter), loss = 0.0179635
I0814 18:51:28.001782 10451 solver.cpp:334]     Train net output #0: loss = 0.0179623 (* 1 = 0.0179623 loss)
I0814 18:51:28.001788 10451 sgd_solver.cpp:136] Iteration 41100, lr = 0.0357813, m = 0.9
I0814 18:51:29.602717 10451 solver.cpp:312] Iteration 41200 (62.4645 iter/s, 1.60091s/100 iter), loss = 0.00240601
I0814 18:51:29.602741 10451 solver.cpp:334]     Train net output #0: loss = 0.00240479 (* 1 = 0.00240479 loss)
I0814 18:51:29.602744 10451 sgd_solver.cpp:136] Iteration 41200, lr = 0.035625, m = 0.9
I0814 18:51:31.231551 10451 solver.cpp:312] Iteration 41300 (61.3955 iter/s, 1.62878s/100 iter), loss = 0.0119284
I0814 18:51:31.231575 10451 solver.cpp:334]     Train net output #0: loss = 0.0119271 (* 1 = 0.0119271 loss)
I0814 18:51:31.231580 10451 sgd_solver.cpp:136] Iteration 41300, lr = 0.0354688, m = 0.9
I0814 18:51:32.837158 10451 solver.cpp:312] Iteration 41400 (62.2836 iter/s, 1.60556s/100 iter), loss = 0.16754
I0814 18:51:32.837182 10451 solver.cpp:334]     Train net output #0: loss = 0.167539 (* 1 = 0.167539 loss)
I0814 18:51:32.837188 10451 sgd_solver.cpp:136] Iteration 41400, lr = 0.0353125, m = 0.9
I0814 18:51:34.456197 10451 solver.cpp:312] Iteration 41500 (61.7669 iter/s, 1.61899s/100 iter), loss = 0.0748028
I0814 18:51:34.456220 10451 solver.cpp:334]     Train net output #0: loss = 0.0748016 (* 1 = 0.0748016 loss)
I0814 18:51:34.456224 10451 sgd_solver.cpp:136] Iteration 41500, lr = 0.0351562, m = 0.9
I0814 18:51:36.056588 10451 solver.cpp:312] Iteration 41600 (62.4866 iter/s, 1.60034s/100 iter), loss = 0.0687077
I0814 18:51:36.056694 10451 solver.cpp:334]     Train net output #0: loss = 0.0687065 (* 1 = 0.0687065 loss)
I0814 18:51:36.056715 10451 sgd_solver.cpp:136] Iteration 41600, lr = 0.035, m = 0.9
I0814 18:51:37.683518 10451 solver.cpp:312] Iteration 41700 (61.4675 iter/s, 1.62688s/100 iter), loss = 0.00337201
I0814 18:51:37.683570 10451 solver.cpp:334]     Train net output #0: loss = 0.00337079 (* 1 = 0.00337079 loss)
I0814 18:51:37.683583 10451 sgd_solver.cpp:136] Iteration 41700, lr = 0.0348438, m = 0.9
I0814 18:51:39.281250 10451 solver.cpp:312] Iteration 41800 (62.5905 iter/s, 1.59769s/100 iter), loss = 0.0311508
I0814 18:51:39.281275 10451 solver.cpp:334]     Train net output #0: loss = 0.0311495 (* 1 = 0.0311495 loss)
I0814 18:51:39.281281 10451 sgd_solver.cpp:136] Iteration 41800, lr = 0.0346875, m = 0.9
I0814 18:51:40.863584 10451 solver.cpp:312] Iteration 41900 (63.1999 iter/s, 1.58228s/100 iter), loss = 0.00378588
I0814 18:51:40.863608 10451 solver.cpp:334]     Train net output #0: loss = 0.00378466 (* 1 = 0.00378466 loss)
I0814 18:51:40.863613 10451 sgd_solver.cpp:136] Iteration 41900, lr = 0.0345312, m = 0.9
I0814 18:51:42.471477 10451 solver.cpp:509] Iteration 42000, Testing net (#0)
I0814 18:51:43.292425 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.875884
I0814 18:51:43.292445 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.993235
I0814 18:51:43.292453 10451 solver.cpp:594]     Test net output #2: loss = 0.516559 (* 1 = 0.516559 loss)
I0814 18:51:43.292469 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.820969s
I0814 18:51:43.308943 10451 solver.cpp:312] Iteration 42000 (40.8949 iter/s, 2.44529s/100 iter), loss = 0.0140624
I0814 18:51:43.308959 10451 solver.cpp:334]     Train net output #0: loss = 0.0140612 (* 1 = 0.0140612 loss)
I0814 18:51:43.308965 10451 sgd_solver.cpp:136] Iteration 42000, lr = 0.034375, m = 0.9
I0814 18:51:44.935335 10451 solver.cpp:312] Iteration 42100 (61.4877 iter/s, 1.62634s/100 iter), loss = 0.00130629
I0814 18:51:44.935398 10451 solver.cpp:334]     Train net output #0: loss = 0.00130508 (* 1 = 0.00130508 loss)
I0814 18:51:44.935416 10451 sgd_solver.cpp:136] Iteration 42100, lr = 0.0342188, m = 0.9
I0814 18:51:46.603922 10451 solver.cpp:312] Iteration 42200 (59.9327 iter/s, 1.66854s/100 iter), loss = 0.0121697
I0814 18:51:46.603947 10451 solver.cpp:334]     Train net output #0: loss = 0.0121685 (* 1 = 0.0121685 loss)
I0814 18:51:46.603953 10451 sgd_solver.cpp:136] Iteration 42200, lr = 0.0340625, m = 0.9
I0814 18:51:48.228363 10451 solver.cpp:312] Iteration 42300 (61.5616 iter/s, 1.62439s/100 iter), loss = 0.00853712
I0814 18:51:48.228411 10451 solver.cpp:334]     Train net output #0: loss = 0.00853589 (* 1 = 0.00853589 loss)
I0814 18:51:48.228426 10451 sgd_solver.cpp:136] Iteration 42300, lr = 0.0339063, m = 0.9
I0814 18:51:49.841279 10451 solver.cpp:312] Iteration 42400 (62.0015 iter/s, 1.61286s/100 iter), loss = 0.0219785
I0814 18:51:49.841424 10451 solver.cpp:334]     Train net output #0: loss = 0.0219773 (* 1 = 0.0219773 loss)
I0814 18:51:49.841442 10451 sgd_solver.cpp:136] Iteration 42400, lr = 0.03375, m = 0.9
I0814 18:51:51.462061 10451 solver.cpp:312] Iteration 42500 (61.7004 iter/s, 1.62074s/100 iter), loss = 0.0180231
I0814 18:51:51.462124 10451 solver.cpp:334]     Train net output #0: loss = 0.0180219 (* 1 = 0.0180219 loss)
I0814 18:51:51.462142 10451 sgd_solver.cpp:136] Iteration 42500, lr = 0.0335938, m = 0.9
I0814 18:51:53.085363 10451 solver.cpp:312] Iteration 42600 (61.6048 iter/s, 1.62325s/100 iter), loss = 0.0046968
I0814 18:51:53.085412 10451 solver.cpp:334]     Train net output #0: loss = 0.00469558 (* 1 = 0.00469558 loss)
I0814 18:51:53.085427 10451 sgd_solver.cpp:136] Iteration 42600, lr = 0.0334375, m = 0.9
I0814 18:51:54.716687 10451 solver.cpp:312] Iteration 42700 (61.3018 iter/s, 1.63127s/100 iter), loss = 0.0192307
I0814 18:51:54.716733 10451 solver.cpp:334]     Train net output #0: loss = 0.0192295 (* 1 = 0.0192295 loss)
I0814 18:51:54.716753 10451 sgd_solver.cpp:136] Iteration 42700, lr = 0.0332812, m = 0.9
I0814 18:51:56.334280 10451 solver.cpp:312] Iteration 42800 (61.8222 iter/s, 1.61754s/100 iter), loss = 0.00405898
I0814 18:51:56.334321 10451 solver.cpp:334]     Train net output #0: loss = 0.00405776 (* 1 = 0.00405776 loss)
I0814 18:51:56.334327 10451 sgd_solver.cpp:136] Iteration 42800, lr = 0.033125, m = 0.9
I0814 18:51:57.978305 10451 solver.cpp:312] Iteration 42900 (60.8281 iter/s, 1.64398s/100 iter), loss = 0.0852655
I0814 18:51:57.978368 10451 solver.cpp:334]     Train net output #0: loss = 0.0852642 (* 1 = 0.0852642 loss)
I0814 18:51:57.978385 10451 sgd_solver.cpp:136] Iteration 42900, lr = 0.0329687, m = 0.9
I0814 18:51:59.581404 10451 solver.cpp:509] Iteration 43000, Testing net (#0)
I0814 18:52:00.398563 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.902942
I0814 18:52:00.398584 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.992647
I0814 18:52:00.398591 10451 solver.cpp:594]     Test net output #2: loss = 0.394826 (* 1 = 0.394826 loss)
I0814 18:52:00.398607 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.817181s
I0814 18:52:00.417124 10451 solver.cpp:312] Iteration 43000 (41.0046 iter/s, 2.43875s/100 iter), loss = 0.0366942
I0814 18:52:00.417143 10451 solver.cpp:334]     Train net output #0: loss = 0.036693 (* 1 = 0.036693 loss)
I0814 18:52:00.417148 10451 sgd_solver.cpp:136] Iteration 43000, lr = 0.0328125, m = 0.9
I0814 18:52:02.028239 10451 solver.cpp:312] Iteration 43100 (62.0709 iter/s, 1.61106s/100 iter), loss = 0.00117044
I0814 18:52:02.028286 10451 solver.cpp:334]     Train net output #0: loss = 0.00116922 (* 1 = 0.00116922 loss)
I0814 18:52:02.028301 10451 sgd_solver.cpp:136] Iteration 43100, lr = 0.0326563, m = 0.9
I0814 18:52:03.656743 10451 solver.cpp:312] Iteration 43200 (61.4079 iter/s, 1.62845s/100 iter), loss = 0.0132958
I0814 18:52:03.656765 10451 solver.cpp:334]     Train net output #0: loss = 0.0132946 (* 1 = 0.0132946 loss)
I0814 18:52:03.656769 10451 sgd_solver.cpp:136] Iteration 43200, lr = 0.0325, m = 0.9
I0814 18:52:05.275022 10451 solver.cpp:312] Iteration 43300 (61.7959 iter/s, 1.61823s/100 iter), loss = 0.0137503
I0814 18:52:05.275048 10451 solver.cpp:334]     Train net output #0: loss = 0.0137491 (* 1 = 0.0137491 loss)
I0814 18:52:05.275054 10451 sgd_solver.cpp:136] Iteration 43300, lr = 0.0323438, m = 0.9
I0814 18:52:06.887450 10451 solver.cpp:312] Iteration 43400 (62.0201 iter/s, 1.61238s/100 iter), loss = 0.039078
I0814 18:52:06.887677 10451 solver.cpp:334]     Train net output #0: loss = 0.0390768 (* 1 = 0.0390768 loss)
I0814 18:52:06.887688 10451 sgd_solver.cpp:136] Iteration 43400, lr = 0.0321875, m = 0.9
I0814 18:52:08.522092 10451 solver.cpp:312] Iteration 43500 (61.1774 iter/s, 1.63459s/100 iter), loss = 0.00291157
I0814 18:52:08.522159 10451 solver.cpp:334]     Train net output #0: loss = 0.00291035 (* 1 = 0.00291035 loss)
I0814 18:52:08.522178 10451 sgd_solver.cpp:136] Iteration 43500, lr = 0.0320312, m = 0.9
I0814 18:52:10.165441 10451 solver.cpp:312] Iteration 43600 (60.8533 iter/s, 1.6433s/100 iter), loss = 0.0510304
I0814 18:52:10.165508 10451 solver.cpp:334]     Train net output #0: loss = 0.0510292 (* 1 = 0.0510292 loss)
I0814 18:52:10.165527 10451 sgd_solver.cpp:136] Iteration 43600, lr = 0.031875, m = 0.9
I0814 18:52:11.788556 10451 solver.cpp:312] Iteration 43700 (61.6118 iter/s, 1.62307s/100 iter), loss = 0.00586816
I0814 18:52:11.788579 10451 solver.cpp:334]     Train net output #0: loss = 0.00586692 (* 1 = 0.00586692 loss)
I0814 18:52:11.788585 10451 sgd_solver.cpp:136] Iteration 43700, lr = 0.0317187, m = 0.9
I0814 18:52:13.368582 10451 solver.cpp:312] Iteration 43800 (63.292 iter/s, 1.57998s/100 iter), loss = 0.0241371
I0814 18:52:13.368607 10451 solver.cpp:334]     Train net output #0: loss = 0.0241359 (* 1 = 0.0241359 loss)
I0814 18:52:13.368612 10451 sgd_solver.cpp:136] Iteration 43800, lr = 0.0315625, m = 0.9
I0814 18:52:15.009043 10451 solver.cpp:312] Iteration 43900 (60.9604 iter/s, 1.64041s/100 iter), loss = 0.0037756
I0814 18:52:15.009099 10451 solver.cpp:334]     Train net output #0: loss = 0.00377437 (* 1 = 0.00377437 loss)
I0814 18:52:15.009114 10451 sgd_solver.cpp:136] Iteration 43900, lr = 0.0314062, m = 0.9
I0814 18:52:15.577735 10436 data_reader.cpp:288] Starting prefetch of epoch 6
I0814 18:52:16.627359 10451 solver.cpp:509] Iteration 44000, Testing net (#0)
I0814 18:52:17.456171 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.899413
I0814 18:52:17.456190 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.992647
I0814 18:52:17.456195 10451 solver.cpp:594]     Test net output #2: loss = 0.417456 (* 1 = 0.417456 loss)
I0814 18:52:17.456210 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.828829s
I0814 18:52:17.471879 10451 solver.cpp:312] Iteration 44000 (40.6048 iter/s, 2.46276s/100 iter), loss = 0.0263823
I0814 18:52:17.471895 10451 solver.cpp:334]     Train net output #0: loss = 0.0263811 (* 1 = 0.0263811 loss)
I0814 18:52:17.471900 10451 sgd_solver.cpp:136] Iteration 44000, lr = 0.03125, m = 0.9
I0814 18:52:19.136248 10451 solver.cpp:312] Iteration 44100 (60.0846 iter/s, 1.66432s/100 iter), loss = 0.00904561
I0814 18:52:19.136382 10451 solver.cpp:334]     Train net output #0: loss = 0.00904439 (* 1 = 0.00904439 loss)
I0814 18:52:19.136401 10451 sgd_solver.cpp:136] Iteration 44100, lr = 0.0310938, m = 0.9
I0814 18:52:20.752770 10451 solver.cpp:312] Iteration 44200 (61.8632 iter/s, 1.61647s/100 iter), loss = 0.00138242
I0814 18:52:20.752818 10451 solver.cpp:334]     Train net output #0: loss = 0.0013812 (* 1 = 0.0013812 loss)
I0814 18:52:20.752831 10451 sgd_solver.cpp:136] Iteration 44200, lr = 0.0309375, m = 0.9
I0814 18:52:22.396009 10451 solver.cpp:312] Iteration 44300 (60.8573 iter/s, 1.64319s/100 iter), loss = 0.001634
I0814 18:52:22.396039 10451 solver.cpp:334]     Train net output #0: loss = 0.00163278 (* 1 = 0.00163278 loss)
I0814 18:52:22.396046 10451 sgd_solver.cpp:136] Iteration 44300, lr = 0.0307813, m = 0.9
I0814 18:52:24.014899 10451 solver.cpp:312] Iteration 44400 (61.7726 iter/s, 1.61884s/100 iter), loss = 0.00267269
I0814 18:52:24.014968 10451 solver.cpp:334]     Train net output #0: loss = 0.00267146 (* 1 = 0.00267146 loss)
I0814 18:52:24.014991 10451 sgd_solver.cpp:136] Iteration 44400, lr = 0.030625, m = 0.9
I0814 18:52:25.662688 10451 solver.cpp:312] Iteration 44500 (60.6893 iter/s, 1.64774s/100 iter), loss = 0.00531626
I0814 18:52:25.662713 10451 solver.cpp:334]     Train net output #0: loss = 0.00531503 (* 1 = 0.00531503 loss)
I0814 18:52:25.662719 10451 sgd_solver.cpp:136] Iteration 44500, lr = 0.0304688, m = 0.9
I0814 18:52:27.310803 10451 solver.cpp:312] Iteration 44600 (60.6772 iter/s, 1.64807s/100 iter), loss = 0.0118297
I0814 18:52:27.310858 10451 solver.cpp:334]     Train net output #0: loss = 0.0118285 (* 1 = 0.0118285 loss)
I0814 18:52:27.310873 10451 sgd_solver.cpp:136] Iteration 44600, lr = 0.0303125, m = 0.9
I0814 18:52:28.942615 10451 solver.cpp:312] Iteration 44700 (61.2834 iter/s, 1.63176s/100 iter), loss = 0.00679046
I0814 18:52:28.942641 10451 solver.cpp:334]     Train net output #0: loss = 0.00678924 (* 1 = 0.00678924 loss)
I0814 18:52:28.942646 10451 sgd_solver.cpp:136] Iteration 44700, lr = 0.0301562, m = 0.9
I0814 18:52:30.543246 10451 solver.cpp:312] Iteration 44800 (62.4772 iter/s, 1.60058s/100 iter), loss = 0.00202586
I0814 18:52:30.543293 10451 solver.cpp:334]     Train net output #0: loss = 0.00202464 (* 1 = 0.00202464 loss)
I0814 18:52:30.543306 10451 sgd_solver.cpp:136] Iteration 44800, lr = 0.03, m = 0.9
I0814 18:52:32.160542 10451 solver.cpp:312] Iteration 44900 (61.8336 iter/s, 1.61724s/100 iter), loss = 0.0124467
I0814 18:52:32.160567 10451 solver.cpp:334]     Train net output #0: loss = 0.0124455 (* 1 = 0.0124455 loss)
I0814 18:52:32.160573 10451 sgd_solver.cpp:136] Iteration 44900, lr = 0.0298437, m = 0.9
I0814 18:52:33.750669 10451 solver.cpp:509] Iteration 45000, Testing net (#0)
I0814 18:52:34.567961 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.909119
I0814 18:52:34.567981 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.997059
I0814 18:52:34.567986 10451 solver.cpp:594]     Test net output #2: loss = 0.365954 (* 1 = 0.365954 loss)
I0814 18:52:34.568004 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.817311s
I0814 18:52:34.583636 10451 solver.cpp:312] Iteration 45000 (41.2707 iter/s, 2.42302s/100 iter), loss = 0.000105146
I0814 18:52:34.583665 10451 solver.cpp:334]     Train net output #0: loss = 0.000103918 (* 1 = 0.000103918 loss)
I0814 18:52:34.583676 10451 sgd_solver.cpp:136] Iteration 45000, lr = 0.0296875, m = 0.9
I0814 18:52:36.220041 10451 solver.cpp:312] Iteration 45100 (61.1114 iter/s, 1.63636s/100 iter), loss = 0.00087603
I0814 18:52:36.220064 10451 solver.cpp:334]     Train net output #0: loss = 0.000874811 (* 1 = 0.000874811 loss)
I0814 18:52:36.220072 10451 sgd_solver.cpp:136] Iteration 45100, lr = 0.0295313, m = 0.9
I0814 18:52:37.868669 10451 solver.cpp:312] Iteration 45200 (60.6585 iter/s, 1.64857s/100 iter), loss = 0.000562392
I0814 18:52:37.868780 10451 solver.cpp:334]     Train net output #0: loss = 0.000561175 (* 1 = 0.000561175 loss)
I0814 18:52:37.868798 10451 sgd_solver.cpp:136] Iteration 45200, lr = 0.029375, m = 0.9
I0814 18:52:39.503159 10451 solver.cpp:312] Iteration 45300 (61.183 iter/s, 1.63444s/100 iter), loss = 0.000995024
I0814 18:52:39.503252 10451 solver.cpp:334]     Train net output #0: loss = 0.000993808 (* 1 = 0.000993808 loss)
I0814 18:52:39.503260 10451 sgd_solver.cpp:136] Iteration 45300, lr = 0.0292188, m = 0.9
I0814 18:52:41.121129 10451 solver.cpp:312] Iteration 45400 (61.8077 iter/s, 1.61792s/100 iter), loss = 0.013548
I0814 18:52:41.121152 10451 solver.cpp:334]     Train net output #0: loss = 0.0135468 (* 1 = 0.0135468 loss)
I0814 18:52:41.121158 10451 sgd_solver.cpp:136] Iteration 45400, lr = 0.0290625, m = 0.9
I0814 18:52:42.730648 10451 solver.cpp:312] Iteration 45500 (62.1323 iter/s, 1.60947s/100 iter), loss = 0.00162457
I0814 18:52:42.730672 10451 solver.cpp:334]     Train net output #0: loss = 0.00162335 (* 1 = 0.00162335 loss)
I0814 18:52:42.730679 10451 sgd_solver.cpp:136] Iteration 45500, lr = 0.0289063, m = 0.9
I0814 18:52:44.376734 10451 solver.cpp:312] Iteration 45600 (60.752 iter/s, 1.64604s/100 iter), loss = 0.00594894
I0814 18:52:44.376760 10451 solver.cpp:334]     Train net output #0: loss = 0.00594772 (* 1 = 0.00594772 loss)
I0814 18:52:44.376766 10451 sgd_solver.cpp:136] Iteration 45600, lr = 0.02875, m = 0.9
I0814 18:52:45.999230 10451 solver.cpp:312] Iteration 45700 (61.6353 iter/s, 1.62245s/100 iter), loss = 0.00241306
I0814 18:52:45.999258 10451 solver.cpp:334]     Train net output #0: loss = 0.00241183 (* 1 = 0.00241183 loss)
I0814 18:52:45.999264 10451 sgd_solver.cpp:136] Iteration 45700, lr = 0.0285937, m = 0.9
I0814 18:52:47.624460 10451 solver.cpp:312] Iteration 45800 (61.5316 iter/s, 1.62518s/100 iter), loss = 0.00164167
I0814 18:52:47.624485 10451 solver.cpp:334]     Train net output #0: loss = 0.00164045 (* 1 = 0.00164045 loss)
I0814 18:52:47.624490 10451 sgd_solver.cpp:136] Iteration 45800, lr = 0.0284375, m = 0.9
I0814 18:52:49.233278 10451 solver.cpp:312] Iteration 45900 (62.1594 iter/s, 1.60877s/100 iter), loss = 0.0202958
I0814 18:52:49.233304 10451 solver.cpp:334]     Train net output #0: loss = 0.0202946 (* 1 = 0.0202946 loss)
I0814 18:52:49.233309 10451 sgd_solver.cpp:136] Iteration 45900, lr = 0.0282812, m = 0.9
I0814 18:52:50.843459 10451 solver.cpp:509] Iteration 46000, Testing net (#0)
I0814 18:52:51.672091 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.915295
I0814 18:52:51.672111 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.997647
I0814 18:52:51.672116 10451 solver.cpp:594]     Test net output #2: loss = 0.311863 (* 1 = 0.311863 loss)
I0814 18:52:51.672138 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.828652s
I0814 18:52:51.687741 10451 solver.cpp:312] Iteration 46000 (40.7433 iter/s, 2.45439s/100 iter), loss = 0.00736032
I0814 18:52:51.687757 10451 solver.cpp:334]     Train net output #0: loss = 0.00735909 (* 1 = 0.00735909 loss)
I0814 18:52:51.687762 10451 sgd_solver.cpp:136] Iteration 46000, lr = 0.028125, m = 0.9
I0814 18:52:53.345029 10451 solver.cpp:312] Iteration 46100 (60.3415 iter/s, 1.65723s/100 iter), loss = 0.00109126
I0814 18:52:53.345098 10451 solver.cpp:334]     Train net output #0: loss = 0.00109003 (* 1 = 0.00109003 loss)
I0814 18:52:53.345118 10451 sgd_solver.cpp:136] Iteration 46100, lr = 0.0279688, m = 0.9
I0814 18:52:54.959347 10451 solver.cpp:312] Iteration 46200 (61.9474 iter/s, 1.61427s/100 iter), loss = 0.00144412
I0814 18:52:54.959409 10451 solver.cpp:334]     Train net output #0: loss = 0.00144289 (* 1 = 0.00144289 loss)
I0814 18:52:54.959429 10451 sgd_solver.cpp:136] Iteration 46200, lr = 0.0278125, m = 0.9
I0814 18:52:56.540159 10451 solver.cpp:312] Iteration 46300 (63.2607 iter/s, 1.58076s/100 iter), loss = 0.000453224
I0814 18:52:56.540226 10451 solver.cpp:334]     Train net output #0: loss = 0.000451996 (* 1 = 0.000451996 loss)
I0814 18:52:56.540246 10451 sgd_solver.cpp:136] Iteration 46300, lr = 0.0276563, m = 0.9
I0814 18:52:58.195893 10451 solver.cpp:312] Iteration 46400 (60.398 iter/s, 1.65568s/100 iter), loss = 0.00120206
I0814 18:52:58.195958 10451 solver.cpp:334]     Train net output #0: loss = 0.00120083 (* 1 = 0.00120083 loss)
I0814 18:52:58.195978 10451 sgd_solver.cpp:136] Iteration 46400, lr = 0.0275, m = 0.9
I0814 18:52:59.824237 10451 solver.cpp:312] Iteration 46500 (61.414 iter/s, 1.62829s/100 iter), loss = 0.0010247
I0814 18:52:59.824298 10451 solver.cpp:334]     Train net output #0: loss = 0.00102348 (* 1 = 0.00102348 loss)
I0814 18:52:59.824316 10451 sgd_solver.cpp:136] Iteration 46500, lr = 0.0273438, m = 0.9
I0814 18:53:01.425729 10451 solver.cpp:312] Iteration 46600 (62.4436 iter/s, 1.60144s/100 iter), loss = 0.000866297
I0814 18:53:01.425788 10451 solver.cpp:334]     Train net output #0: loss = 0.000865067 (* 1 = 0.000865067 loss)
I0814 18:53:01.425807 10451 sgd_solver.cpp:136] Iteration 46600, lr = 0.0271875, m = 0.9
I0814 18:53:03.009379 10451 solver.cpp:312] Iteration 46700 (63.1473 iter/s, 1.5836s/100 iter), loss = 0.00257616
I0814 18:53:03.009523 10451 solver.cpp:334]     Train net output #0: loss = 0.00257493 (* 1 = 0.00257493 loss)
I0814 18:53:03.009542 10451 sgd_solver.cpp:136] Iteration 46700, lr = 0.0270312, m = 0.9
I0814 18:53:04.633821 10451 solver.cpp:312] Iteration 46800 (61.5615 iter/s, 1.62439s/100 iter), loss = 0.000689873
I0814 18:53:04.633868 10451 solver.cpp:334]     Train net output #0: loss = 0.000688642 (* 1 = 0.000688642 loss)
I0814 18:53:04.633880 10451 sgd_solver.cpp:136] Iteration 46800, lr = 0.026875, m = 0.9
I0814 18:53:06.256296 10451 solver.cpp:312] Iteration 46900 (61.636 iter/s, 1.62243s/100 iter), loss = 0.000566735
I0814 18:53:06.256362 10451 solver.cpp:334]     Train net output #0: loss = 0.000565504 (* 1 = 0.000565504 loss)
I0814 18:53:06.256381 10451 sgd_solver.cpp:136] Iteration 46900, lr = 0.0267187, m = 0.9
I0814 18:53:07.883736 10451 solver.cpp:509] Iteration 47000, Testing net (#0)
I0814 18:53:08.708876 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.91706
I0814 18:53:08.708895 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.997941
I0814 18:53:08.708900 10451 solver.cpp:594]     Test net output #2: loss = 0.318635 (* 1 = 0.318635 loss)
I0814 18:53:08.708915 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.825158s
I0814 18:53:08.724726 10451 solver.cpp:312] Iteration 47000 (40.5127 iter/s, 2.46836s/100 iter), loss = 0.00420694
I0814 18:53:08.724745 10451 solver.cpp:334]     Train net output #0: loss = 0.00420571 (* 1 = 0.00420571 loss)
I0814 18:53:08.724750 10451 sgd_solver.cpp:136] Iteration 47000, lr = 0.0265625, m = 0.9
I0814 18:53:10.326845 10451 solver.cpp:312] Iteration 47100 (62.4193 iter/s, 1.60207s/100 iter), loss = 0.0022052
I0814 18:53:10.326917 10451 solver.cpp:334]     Train net output #0: loss = 0.00220397 (* 1 = 0.00220397 loss)
I0814 18:53:10.326938 10451 sgd_solver.cpp:136] Iteration 47100, lr = 0.0264063, m = 0.9
I0814 18:53:11.907449 10451 solver.cpp:312] Iteration 47200 (63.2689 iter/s, 1.58055s/100 iter), loss = 0.000568174
I0814 18:53:11.907502 10451 solver.cpp:334]     Train net output #0: loss = 0.000566938 (* 1 = 0.000566938 loss)
I0814 18:53:11.907515 10451 sgd_solver.cpp:136] Iteration 47200, lr = 0.02625, m = 0.9
I0814 18:53:13.527763 10451 solver.cpp:312] Iteration 47300 (61.7183 iter/s, 1.62026s/100 iter), loss = 0.00090965
I0814 18:53:13.527812 10451 solver.cpp:334]     Train net output #0: loss = 0.000908414 (* 1 = 0.000908414 loss)
I0814 18:53:13.527827 10451 sgd_solver.cpp:136] Iteration 47300, lr = 0.0260938, m = 0.9
I0814 18:53:15.164391 10451 solver.cpp:312] Iteration 47400 (61.1031 iter/s, 1.63658s/100 iter), loss = 0.000767824
I0814 18:53:15.164450 10451 solver.cpp:334]     Train net output #0: loss = 0.000766588 (* 1 = 0.000766588 loss)
I0814 18:53:15.164469 10451 sgd_solver.cpp:136] Iteration 47400, lr = 0.0259375, m = 0.9
I0814 18:53:16.777034 10451 solver.cpp:312] Iteration 47500 (62.012 iter/s, 1.61259s/100 iter), loss = 0.00259016
I0814 18:53:16.777107 10451 solver.cpp:334]     Train net output #0: loss = 0.00258892 (* 1 = 0.00258892 loss)
I0814 18:53:16.777129 10451 sgd_solver.cpp:136] Iteration 47500, lr = 0.0257812, m = 0.9
I0814 18:53:18.404006 10451 solver.cpp:312] Iteration 47600 (61.4657 iter/s, 1.62692s/100 iter), loss = 0.000281997
I0814 18:53:18.404050 10451 solver.cpp:334]     Train net output #0: loss = 0.000280759 (* 1 = 0.000280759 loss)
I0814 18:53:18.404062 10451 sgd_solver.cpp:136] Iteration 47600, lr = 0.025625, m = 0.9
I0814 18:53:20.032513 10451 solver.cpp:312] Iteration 47700 (61.4079 iter/s, 1.62845s/100 iter), loss = 0.00115148
I0814 18:53:20.032537 10451 solver.cpp:334]     Train net output #0: loss = 0.00115025 (* 1 = 0.00115025 loss)
I0814 18:53:20.032543 10451 sgd_solver.cpp:136] Iteration 47700, lr = 0.0254687, m = 0.9
I0814 18:53:21.641963 10451 solver.cpp:312] Iteration 47800 (62.1349 iter/s, 1.6094s/100 iter), loss = 0.000972823
I0814 18:53:21.642030 10451 solver.cpp:334]     Train net output #0: loss = 0.000971587 (* 1 = 0.000971587 loss)
I0814 18:53:21.642050 10451 sgd_solver.cpp:136] Iteration 47800, lr = 0.0253125, m = 0.9
I0814 18:53:23.290139 10451 solver.cpp:312] Iteration 47900 (60.675 iter/s, 1.64812s/100 iter), loss = 0.000272515
I0814 18:53:23.290164 10451 solver.cpp:334]     Train net output #0: loss = 0.00027128 (* 1 = 0.00027128 loss)
I0814 18:53:23.290170 10451 sgd_solver.cpp:136] Iteration 47900, lr = 0.0251562, m = 0.9
I0814 18:53:24.851459 10451 solver.cpp:509] Iteration 48000, Testing net (#0)
I0814 18:53:24.882599 10438 data_reader.cpp:288] Starting prefetch of epoch 6
I0814 18:53:25.688210 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.919118
I0814 18:53:25.688230 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.997059
I0814 18:53:25.688235 10451 solver.cpp:594]     Test net output #2: loss = 0.298945 (* 1 = 0.298945 loss)
I0814 18:53:25.688251 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.83677s
I0814 18:53:25.709908 10451 solver.cpp:312] Iteration 48000 (41.3274 iter/s, 2.4197s/100 iter), loss = 0.000495195
I0814 18:53:25.709936 10451 solver.cpp:334]     Train net output #0: loss = 0.000493957 (* 1 = 0.000493957 loss)
I0814 18:53:25.709941 10451 sgd_solver.cpp:136] Iteration 48000, lr = 0.025, m = 0.9
I0814 18:53:27.340843 10451 solver.cpp:312] Iteration 48100 (61.3164 iter/s, 1.63088s/100 iter), loss = 0.00406636
I0814 18:53:27.340867 10451 solver.cpp:334]     Train net output #0: loss = 0.00406512 (* 1 = 0.00406512 loss)
I0814 18:53:27.340873 10451 sgd_solver.cpp:136] Iteration 48100, lr = 0.0248438, m = 0.9
I0814 18:53:28.928972 10451 solver.cpp:312] Iteration 48200 (62.9691 iter/s, 1.58808s/100 iter), loss = 0.00129514
I0814 18:53:28.928997 10451 solver.cpp:334]     Train net output #0: loss = 0.00129391 (* 1 = 0.00129391 loss)
I0814 18:53:28.929003 10451 sgd_solver.cpp:136] Iteration 48200, lr = 0.0246875, m = 0.9
I0814 18:53:30.544404 10451 solver.cpp:312] Iteration 48300 (61.9049 iter/s, 1.61538s/100 iter), loss = 0.00145908
I0814 18:53:30.544466 10451 solver.cpp:334]     Train net output #0: loss = 0.00145784 (* 1 = 0.00145784 loss)
I0814 18:53:30.544493 10451 sgd_solver.cpp:136] Iteration 48300, lr = 0.0245313, m = 0.9
I0814 18:53:32.158380 10451 solver.cpp:312] Iteration 48400 (61.9607 iter/s, 1.61393s/100 iter), loss = 0.00140065
I0814 18:53:32.158401 10451 solver.cpp:334]     Train net output #0: loss = 0.00139941 (* 1 = 0.00139941 loss)
I0814 18:53:32.158407 10451 sgd_solver.cpp:136] Iteration 48400, lr = 0.024375, m = 0.9
I0814 18:53:33.756410 10451 solver.cpp:312] Iteration 48500 (62.5789 iter/s, 1.59798s/100 iter), loss = 0.000401453
I0814 18:53:33.756435 10451 solver.cpp:334]     Train net output #0: loss = 0.000400218 (* 1 = 0.000400218 loss)
I0814 18:53:33.756441 10451 sgd_solver.cpp:136] Iteration 48500, lr = 0.0242188, m = 0.9
I0814 18:53:35.365556 10451 solver.cpp:312] Iteration 48600 (62.1467 iter/s, 1.6091s/100 iter), loss = 0.00178565
I0814 18:53:35.365603 10451 solver.cpp:334]     Train net output #0: loss = 0.00178441 (* 1 = 0.00178441 loss)
I0814 18:53:35.365615 10451 sgd_solver.cpp:136] Iteration 48600, lr = 0.0240625, m = 0.9
I0814 18:53:36.968639 10451 solver.cpp:312] Iteration 48700 (62.3817 iter/s, 1.60303s/100 iter), loss = 0.000970848
I0814 18:53:36.968665 10451 solver.cpp:334]     Train net output #0: loss = 0.000969612 (* 1 = 0.000969612 loss)
I0814 18:53:36.968673 10451 sgd_solver.cpp:136] Iteration 48700, lr = 0.0239062, m = 0.9
I0814 18:53:38.575392 10451 solver.cpp:312] Iteration 48800 (62.2393 iter/s, 1.6067s/100 iter), loss = 0.000798375
I0814 18:53:38.575515 10451 solver.cpp:334]     Train net output #0: loss = 0.000797139 (* 1 = 0.000797139 loss)
I0814 18:53:38.575534 10451 sgd_solver.cpp:136] Iteration 48800, lr = 0.02375, m = 0.9
I0814 18:53:40.149404 10451 solver.cpp:312] Iteration 48900 (63.534 iter/s, 1.57396s/100 iter), loss = 0.00106245
I0814 18:53:40.149453 10451 solver.cpp:334]     Train net output #0: loss = 0.00106121 (* 1 = 0.00106121 loss)
I0814 18:53:40.149466 10451 sgd_solver.cpp:136] Iteration 48900, lr = 0.0235937, m = 0.9
I0814 18:53:41.719640 10451 solver.cpp:509] Iteration 49000, Testing net (#0)
I0814 18:53:42.541822 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.919707
I0814 18:53:42.541842 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.996765
I0814 18:53:42.541847 10451 solver.cpp:594]     Test net output #2: loss = 0.297661 (* 1 = 0.297661 loss)
I0814 18:53:42.541862 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.822199s
I0814 18:53:42.557442 10451 solver.cpp:312] Iteration 49000 (41.5287 iter/s, 2.40797s/100 iter), loss = 0.00294959
I0814 18:53:42.557461 10451 solver.cpp:334]     Train net output #0: loss = 0.00294835 (* 1 = 0.00294835 loss)
I0814 18:53:42.557466 10451 sgd_solver.cpp:136] Iteration 49000, lr = 0.0234375, m = 0.9
I0814 18:53:44.120275 10451 solver.cpp:312] Iteration 49100 (63.9884 iter/s, 1.56278s/100 iter), loss = 0.00307807
I0814 18:53:44.120334 10451 solver.cpp:334]     Train net output #0: loss = 0.00307684 (* 1 = 0.00307684 loss)
I0814 18:53:44.120352 10451 sgd_solver.cpp:136] Iteration 49100, lr = 0.0232813, m = 0.9
I0814 18:53:45.758668 10451 solver.cpp:312] Iteration 49200 (61.0373 iter/s, 1.63834s/100 iter), loss = 0.00102918
I0814 18:53:45.758694 10451 solver.cpp:334]     Train net output #0: loss = 0.00102795 (* 1 = 0.00102795 loss)
I0814 18:53:45.758700 10451 sgd_solver.cpp:136] Iteration 49200, lr = 0.023125, m = 0.9
I0814 18:53:47.380723 10451 solver.cpp:312] Iteration 49300 (61.6522 iter/s, 1.622s/100 iter), loss = 0.000471866
I0814 18:53:47.380748 10451 solver.cpp:334]     Train net output #0: loss = 0.000470632 (* 1 = 0.000470632 loss)
I0814 18:53:47.380753 10451 sgd_solver.cpp:136] Iteration 49300, lr = 0.0229688, m = 0.9
I0814 18:53:49.016607 10451 solver.cpp:312] Iteration 49400 (61.1309 iter/s, 1.63583s/100 iter), loss = 0.000497134
I0814 18:53:49.016680 10451 solver.cpp:334]     Train net output #0: loss = 0.0004959 (* 1 = 0.0004959 loss)
I0814 18:53:49.016700 10451 sgd_solver.cpp:136] Iteration 49400, lr = 0.0228125, m = 0.9
I0814 18:53:50.624868 10451 solver.cpp:312] Iteration 49500 (62.1808 iter/s, 1.60821s/100 iter), loss = 0.00160473
I0814 18:53:50.625030 10451 solver.cpp:334]     Train net output #0: loss = 0.0016035 (* 1 = 0.0016035 loss)
I0814 18:53:50.625051 10451 sgd_solver.cpp:136] Iteration 49500, lr = 0.0226563, m = 0.9
I0814 18:53:52.252451 10451 solver.cpp:312] Iteration 49600 (61.4427 iter/s, 1.62753s/100 iter), loss = 0.000892904
I0814 18:53:52.252514 10451 solver.cpp:334]     Train net output #0: loss = 0.00089167 (* 1 = 0.00089167 loss)
I0814 18:53:52.252532 10451 sgd_solver.cpp:136] Iteration 49600, lr = 0.0225, m = 0.9
I0814 18:53:53.842883 10451 solver.cpp:312] Iteration 49700 (62.878 iter/s, 1.59038s/100 iter), loss = 0.000289856
I0814 18:53:53.842907 10451 solver.cpp:334]     Train net output #0: loss = 0.000288621 (* 1 = 0.000288621 loss)
I0814 18:53:53.842913 10451 sgd_solver.cpp:136] Iteration 49700, lr = 0.0223437, m = 0.9
I0814 18:53:55.486316 10451 solver.cpp:312] Iteration 49800 (60.85 iter/s, 1.64338s/100 iter), loss = 0.000511818
I0814 18:53:55.486366 10451 solver.cpp:334]     Train net output #0: loss = 0.000510583 (* 1 = 0.000510583 loss)
I0814 18:53:55.486378 10451 sgd_solver.cpp:136] Iteration 49800, lr = 0.0221875, m = 0.9
I0814 18:53:57.075842 10451 solver.cpp:312] Iteration 49900 (62.9139 iter/s, 1.58947s/100 iter), loss = 0.000839467
I0814 18:53:57.075866 10451 solver.cpp:334]     Train net output #0: loss = 0.000838232 (* 1 = 0.000838232 loss)
I0814 18:53:57.075872 10451 sgd_solver.cpp:136] Iteration 49900, lr = 0.0220312, m = 0.9
I0814 18:53:58.675328 10451 solver.cpp:639] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/initial/cifar10_jacintonet11v2_iter_50000.caffemodel
I0814 18:53:58.683293 10451 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/initial/cifar10_jacintonet11v2_iter_50000.solverstate
I0814 18:53:58.686866 10451 solver.cpp:509] Iteration 50000, Testing net (#0)
I0814 18:53:59.486847 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.917354
I0814 18:53:59.486876 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.997059
I0814 18:53:59.486884 10451 solver.cpp:594]     Test net output #2: loss = 0.310996 (* 1 = 0.310996 loss)
I0814 18:53:59.486907 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.800017s
I0814 18:53:59.509707 10451 solver.cpp:312] Iteration 50000 (41.0881 iter/s, 2.43379s/100 iter), loss = 0.00032694
I0814 18:53:59.509734 10451 solver.cpp:334]     Train net output #0: loss = 0.000325705 (* 1 = 0.000325705 loss)
I0814 18:53:59.509739 10451 sgd_solver.cpp:136] Iteration 50000, lr = 0.021875, m = 0.9
I0814 18:54:01.136447 10451 solver.cpp:312] Iteration 50100 (61.4745 iter/s, 1.62669s/100 iter), loss = 0.000703579
I0814 18:54:01.136473 10451 solver.cpp:334]     Train net output #0: loss = 0.000702344 (* 1 = 0.000702344 loss)
I0814 18:54:01.136481 10451 sgd_solver.cpp:136] Iteration 50100, lr = 0.0217188, m = 0.9
I0814 18:54:02.759368 10451 solver.cpp:312] Iteration 50200 (61.6191 iter/s, 1.62287s/100 iter), loss = 0.00170066
I0814 18:54:02.759393 10451 solver.cpp:334]     Train net output #0: loss = 0.00169943 (* 1 = 0.00169943 loss)
I0814 18:54:02.759399 10451 sgd_solver.cpp:136] Iteration 50200, lr = 0.0215625, m = 0.9
I0814 18:54:04.390023 10451 solver.cpp:312] Iteration 50300 (61.327 iter/s, 1.6306s/100 iter), loss = 0.000491016
I0814 18:54:04.390085 10451 solver.cpp:334]     Train net output #0: loss = 0.000489781 (* 1 = 0.000489781 loss)
I0814 18:54:04.390103 10451 sgd_solver.cpp:136] Iteration 50300, lr = 0.0214063, m = 0.9
I0814 18:54:06.020542 10451 solver.cpp:312] Iteration 50400 (61.332 iter/s, 1.63047s/100 iter), loss = 0.000467951
I0814 18:54:06.020568 10451 solver.cpp:334]     Train net output #0: loss = 0.000466717 (* 1 = 0.000466717 loss)
I0814 18:54:06.020573 10451 sgd_solver.cpp:136] Iteration 50400, lr = 0.02125, m = 0.9
I0814 18:54:07.625085 10451 solver.cpp:312] Iteration 50500 (62.3248 iter/s, 1.6045s/100 iter), loss = 0.00106298
I0814 18:54:07.625232 10451 solver.cpp:334]     Train net output #0: loss = 0.00106174 (* 1 = 0.00106174 loss)
I0814 18:54:07.625260 10451 sgd_solver.cpp:136] Iteration 50500, lr = 0.0210938, m = 0.9
I0814 18:54:09.233101 10451 solver.cpp:312] Iteration 50600 (62.1903 iter/s, 1.60797s/100 iter), loss = 0.00110135
I0814 18:54:09.233206 10451 solver.cpp:334]     Train net output #0: loss = 0.00110012 (* 1 = 0.00110012 loss)
I0814 18:54:09.233219 10451 sgd_solver.cpp:136] Iteration 50600, lr = 0.0209375, m = 0.9
I0814 18:54:10.852448 10451 solver.cpp:312] Iteration 50700 (61.7552 iter/s, 1.6193s/100 iter), loss = 0.00217056
I0814 18:54:10.852473 10451 solver.cpp:334]     Train net output #0: loss = 0.00216933 (* 1 = 0.00216933 loss)
I0814 18:54:10.852479 10451 sgd_solver.cpp:136] Iteration 50700, lr = 0.0207812, m = 0.9
I0814 18:54:12.447604 10451 solver.cpp:312] Iteration 50800 (62.6916 iter/s, 1.59511s/100 iter), loss = 0.000804358
I0814 18:54:12.447634 10451 solver.cpp:334]     Train net output #0: loss = 0.000803124 (* 1 = 0.000803124 loss)
I0814 18:54:12.447640 10451 sgd_solver.cpp:136] Iteration 50800, lr = 0.020625, m = 0.9
I0814 18:54:14.082401 10451 solver.cpp:312] Iteration 50900 (61.1715 iter/s, 1.63475s/100 iter), loss = 0.000998344
I0814 18:54:14.082546 10451 solver.cpp:334]     Train net output #0: loss = 0.000997111 (* 1 = 0.000997111 loss)
I0814 18:54:14.082571 10451 sgd_solver.cpp:136] Iteration 50900, lr = 0.0204687, m = 0.9
I0814 18:54:15.717260 10451 solver.cpp:509] Iteration 51000, Testing net (#0)
I0814 18:54:16.546891 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.912354
I0814 18:54:16.546911 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.997059
I0814 18:54:16.546916 10451 solver.cpp:594]     Test net output #2: loss = 0.321833 (* 1 = 0.321833 loss)
I0814 18:54:16.546929 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.829648s
I0814 18:54:16.567836 10451 solver.cpp:312] Iteration 51000 (40.2356 iter/s, 2.48536s/100 iter), loss = 0.00075457
I0814 18:54:16.567853 10451 solver.cpp:334]     Train net output #0: loss = 0.000753338 (* 1 = 0.000753338 loss)
I0814 18:54:16.567857 10451 sgd_solver.cpp:136] Iteration 51000, lr = 0.0203125, m = 0.9
I0814 18:54:18.231674 10451 solver.cpp:312] Iteration 51100 (60.1038 iter/s, 1.66379s/100 iter), loss = 0.000562066
I0814 18:54:18.231698 10451 solver.cpp:334]     Train net output #0: loss = 0.000560835 (* 1 = 0.000560835 loss)
I0814 18:54:18.231703 10451 sgd_solver.cpp:136] Iteration 51100, lr = 0.0201563, m = 0.9
I0814 18:54:19.863257 10451 solver.cpp:312] Iteration 51200 (61.292 iter/s, 1.63153s/100 iter), loss = 0.000749945
I0814 18:54:19.863304 10451 solver.cpp:334]     Train net output #0: loss = 0.000748714 (* 1 = 0.000748714 loss)
I0814 18:54:19.863317 10451 sgd_solver.cpp:136] Iteration 51200, lr = 0.02, m = 0.9
I0814 18:54:21.466930 10451 solver.cpp:312] Iteration 51300 (62.3588 iter/s, 1.60362s/100 iter), loss = 0.00117396
I0814 18:54:21.466956 10451 solver.cpp:334]     Train net output #0: loss = 0.00117273 (* 1 = 0.00117273 loss)
I0814 18:54:21.466962 10451 sgd_solver.cpp:136] Iteration 51300, lr = 0.0198438, m = 0.9
I0814 18:54:23.077049 10451 solver.cpp:312] Iteration 51400 (62.1092 iter/s, 1.61007s/100 iter), loss = 0.00267232
I0814 18:54:23.077096 10451 solver.cpp:334]     Train net output #0: loss = 0.00267109 (* 1 = 0.00267109 loss)
I0814 18:54:23.077111 10451 sgd_solver.cpp:136] Iteration 51400, lr = 0.0196875, m = 0.9
I0814 18:54:24.701618 10451 solver.cpp:312] Iteration 51500 (61.5566 iter/s, 1.62452s/100 iter), loss = 0.000394848
I0814 18:54:24.701644 10451 solver.cpp:334]     Train net output #0: loss = 0.000393617 (* 1 = 0.000393617 loss)
I0814 18:54:24.701650 10451 sgd_solver.cpp:136] Iteration 51500, lr = 0.0195312, m = 0.9
I0814 18:54:26.305460 10451 solver.cpp:312] Iteration 51600 (62.3521 iter/s, 1.60379s/100 iter), loss = 0.00115834
I0814 18:54:26.305483 10451 solver.cpp:334]     Train net output #0: loss = 0.00115711 (* 1 = 0.00115711 loss)
I0814 18:54:26.305487 10451 sgd_solver.cpp:136] Iteration 51600, lr = 0.019375, m = 0.9
I0814 18:54:27.940460 10451 solver.cpp:312] Iteration 51700 (61.1639 iter/s, 1.63495s/100 iter), loss = 0.000353252
I0814 18:54:27.940488 10451 solver.cpp:334]     Train net output #0: loss = 0.000352022 (* 1 = 0.000352022 loss)
I0814 18:54:27.940495 10451 sgd_solver.cpp:136] Iteration 51700, lr = 0.0192187, m = 0.9
I0814 18:54:29.568994 10451 solver.cpp:312] Iteration 51800 (61.4069 iter/s, 1.62848s/100 iter), loss = 0.00143266
I0814 18:54:29.569056 10451 solver.cpp:334]     Train net output #0: loss = 0.00143143 (* 1 = 0.00143143 loss)
I0814 18:54:29.569075 10451 sgd_solver.cpp:136] Iteration 51800, lr = 0.0190625, m = 0.9
I0814 18:54:31.187793 10451 solver.cpp:312] Iteration 51900 (61.7761 iter/s, 1.61875s/100 iter), loss = 0.000557461
I0814 18:54:31.187816 10451 solver.cpp:334]     Train net output #0: loss = 0.00055623 (* 1 = 0.00055623 loss)
I0814 18:54:31.187824 10451 sgd_solver.cpp:136] Iteration 51900, lr = 0.0189062, m = 0.9
I0814 18:54:32.806725 10451 solver.cpp:509] Iteration 52000, Testing net (#0)
I0814 18:54:33.531756 10438 data_reader.cpp:288] Starting prefetch of epoch 7
I0814 18:54:33.622151 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.911177
I0814 18:54:33.622174 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.996177
I0814 18:54:33.622181 10451 solver.cpp:594]     Test net output #2: loss = 0.317098 (* 1 = 0.317098 loss)
I0814 18:54:33.622198 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.81545s
I0814 18:54:33.663556 10451 solver.cpp:312] Iteration 52000 (40.3927 iter/s, 2.47569s/100 iter), loss = 0.000271434
I0814 18:54:33.663605 10451 solver.cpp:334]     Train net output #0: loss = 0.000270203 (* 1 = 0.000270203 loss)
I0814 18:54:33.663616 10451 sgd_solver.cpp:136] Iteration 52000, lr = 0.01875, m = 0.9
I0814 18:54:35.259913 10451 solver.cpp:312] Iteration 52100 (62.6446 iter/s, 1.59631s/100 iter), loss = 0.00146658
I0814 18:54:35.259938 10451 solver.cpp:334]     Train net output #0: loss = 0.00146535 (* 1 = 0.00146535 loss)
I0814 18:54:35.259945 10451 sgd_solver.cpp:136] Iteration 52100, lr = 0.0185938, m = 0.9
I0814 18:54:36.881520 10451 solver.cpp:312] Iteration 52200 (61.6692 iter/s, 1.62156s/100 iter), loss = 0.000917433
I0814 18:54:36.881567 10451 solver.cpp:334]     Train net output #0: loss = 0.000916202 (* 1 = 0.000916202 loss)
I0814 18:54:36.881578 10451 sgd_solver.cpp:136] Iteration 52200, lr = 0.0184375, m = 0.9
I0814 18:54:38.533223 10451 solver.cpp:312] Iteration 52300 (60.5453 iter/s, 1.65165s/100 iter), loss = 0.00238159
I0814 18:54:38.533291 10451 solver.cpp:334]     Train net output #0: loss = 0.00238036 (* 1 = 0.00238036 loss)
I0814 18:54:38.533311 10451 sgd_solver.cpp:136] Iteration 52300, lr = 0.0182813, m = 0.9
I0814 18:54:40.144783 10451 solver.cpp:312] Iteration 52400 (62.0536 iter/s, 1.61151s/100 iter), loss = 0.00113295
I0814 18:54:40.144865 10451 solver.cpp:334]     Train net output #0: loss = 0.00113172 (* 1 = 0.00113172 loss)
I0814 18:54:40.144871 10451 sgd_solver.cpp:136] Iteration 52400, lr = 0.018125, m = 0.9
I0814 18:54:41.766054 10451 solver.cpp:312] Iteration 52500 (61.6819 iter/s, 1.62122s/100 iter), loss = 0.000821069
I0814 18:54:41.766104 10451 solver.cpp:334]     Train net output #0: loss = 0.000819838 (* 1 = 0.000819838 loss)
I0814 18:54:41.766119 10451 sgd_solver.cpp:136] Iteration 52500, lr = 0.0179687, m = 0.9
I0814 18:54:43.402146 10451 solver.cpp:312] Iteration 52600 (61.1231 iter/s, 1.63604s/100 iter), loss = 0.000957264
I0814 18:54:43.402196 10451 solver.cpp:334]     Train net output #0: loss = 0.000956032 (* 1 = 0.000956032 loss)
I0814 18:54:43.402209 10451 sgd_solver.cpp:136] Iteration 52600, lr = 0.0178125, m = 0.9
I0814 18:54:45.011947 10451 solver.cpp:312] Iteration 52700 (62.1213 iter/s, 1.60975s/100 iter), loss = 0.000501108
I0814 18:54:45.011992 10451 solver.cpp:334]     Train net output #0: loss = 0.000499876 (* 1 = 0.000499876 loss)
I0814 18:54:45.012006 10451 sgd_solver.cpp:136] Iteration 52700, lr = 0.0176562, m = 0.9
I0814 18:54:46.603376 10451 solver.cpp:312] Iteration 52800 (62.8386 iter/s, 1.59138s/100 iter), loss = 0.000739691
I0814 18:54:46.603433 10451 solver.cpp:334]     Train net output #0: loss = 0.000738459 (* 1 = 0.000738459 loss)
I0814 18:54:46.603447 10451 sgd_solver.cpp:136] Iteration 52800, lr = 0.0175, m = 0.9
I0814 18:54:48.205332 10451 solver.cpp:312] Iteration 52900 (62.4258 iter/s, 1.6019s/100 iter), loss = 0.000399633
I0814 18:54:48.205366 10451 solver.cpp:334]     Train net output #0: loss = 0.000398402 (* 1 = 0.000398402 loss)
I0814 18:54:48.205374 10451 sgd_solver.cpp:136] Iteration 52900, lr = 0.0173437, m = 0.9
I0814 18:54:49.824395 10451 solver.cpp:509] Iteration 53000, Testing net (#0)
I0814 18:54:50.642603 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.915295
I0814 18:54:50.642626 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.995882
I0814 18:54:50.642632 10451 solver.cpp:594]     Test net output #2: loss = 0.312248 (* 1 = 0.312248 loss)
I0814 18:54:50.642671 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.818254s
I0814 18:54:50.658247 10451 solver.cpp:312] Iteration 53000 (40.7689 iter/s, 2.45285s/100 iter), loss = 0.000322833
I0814 18:54:50.658263 10451 solver.cpp:334]     Train net output #0: loss = 0.000321601 (* 1 = 0.000321601 loss)
I0814 18:54:50.658268 10451 sgd_solver.cpp:136] Iteration 53000, lr = 0.0171875, m = 0.9
I0814 18:54:52.281255 10451 solver.cpp:312] Iteration 53100 (61.6159 iter/s, 1.62296s/100 iter), loss = 0.000510215
I0814 18:54:52.281299 10451 solver.cpp:334]     Train net output #0: loss = 0.000508984 (* 1 = 0.000508984 loss)
I0814 18:54:52.281313 10451 sgd_solver.cpp:136] Iteration 53100, lr = 0.0170313, m = 0.9
I0814 18:54:53.911402 10451 solver.cpp:312] Iteration 53200 (61.346 iter/s, 1.6301s/100 iter), loss = 0.000336807
I0814 18:54:53.911427 10451 solver.cpp:334]     Train net output #0: loss = 0.000335576 (* 1 = 0.000335576 loss)
I0814 18:54:53.911433 10451 sgd_solver.cpp:136] Iteration 53200, lr = 0.016875, m = 0.9
I0814 18:54:55.533953 10451 solver.cpp:312] Iteration 53300 (61.6332 iter/s, 1.6225s/100 iter), loss = 0.00118072
I0814 18:54:55.533977 10451 solver.cpp:334]     Train net output #0: loss = 0.00117949 (* 1 = 0.00117949 loss)
I0814 18:54:55.533983 10451 sgd_solver.cpp:136] Iteration 53300, lr = 0.0167188, m = 0.9
I0814 18:54:57.160763 10451 solver.cpp:312] Iteration 53400 (61.4718 iter/s, 1.62676s/100 iter), loss = 0.000591931
I0814 18:54:57.160789 10451 solver.cpp:334]     Train net output #0: loss = 0.000590699 (* 1 = 0.000590699 loss)
I0814 18:54:57.160794 10451 sgd_solver.cpp:136] Iteration 53400, lr = 0.0165625, m = 0.9
I0814 18:54:58.783751 10451 solver.cpp:312] Iteration 53500 (61.6167 iter/s, 1.62294s/100 iter), loss = 0.00239152
I0814 18:54:58.783776 10451 solver.cpp:334]     Train net output #0: loss = 0.00239029 (* 1 = 0.00239029 loss)
I0814 18:54:58.783782 10451 sgd_solver.cpp:136] Iteration 53500, lr = 0.0164063, m = 0.9
I0814 18:55:00.420122 10451 solver.cpp:312] Iteration 53600 (61.1126 iter/s, 1.63632s/100 iter), loss = 0.00101008
I0814 18:55:00.420171 10451 solver.cpp:334]     Train net output #0: loss = 0.00100885 (* 1 = 0.00100885 loss)
I0814 18:55:00.420186 10451 sgd_solver.cpp:136] Iteration 53600, lr = 0.01625, m = 0.9
I0814 18:55:02.008635 10451 solver.cpp:312] Iteration 53700 (62.954 iter/s, 1.58846s/100 iter), loss = 0.000510479
I0814 18:55:02.008689 10451 solver.cpp:334]     Train net output #0: loss = 0.000509247 (* 1 = 0.000509247 loss)
I0814 18:55:02.008708 10451 sgd_solver.cpp:136] Iteration 53700, lr = 0.0160937, m = 0.9
I0814 18:55:03.611337 10451 solver.cpp:312] Iteration 53800 (62.3965 iter/s, 1.60265s/100 iter), loss = 0.000755453
I0814 18:55:03.611383 10451 solver.cpp:334]     Train net output #0: loss = 0.000754221 (* 1 = 0.000754221 loss)
I0814 18:55:03.611397 10451 sgd_solver.cpp:136] Iteration 53800, lr = 0.0159375, m = 0.9
I0814 18:55:05.244680 10451 solver.cpp:312] Iteration 53900 (61.2259 iter/s, 1.6333s/100 iter), loss = 0.00269955
I0814 18:55:05.244735 10451 solver.cpp:334]     Train net output #0: loss = 0.00269832 (* 1 = 0.00269832 loss)
I0814 18:55:05.244750 10451 sgd_solver.cpp:136] Iteration 53900, lr = 0.0157812, m = 0.9
I0814 18:55:06.820300 10451 solver.cpp:509] Iteration 54000, Testing net (#0)
I0814 18:55:07.632517 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.917354
I0814 18:55:07.632535 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.996765
I0814 18:55:07.632542 10451 solver.cpp:594]     Test net output #2: loss = 0.286956 (* 1 = 0.286956 loss)
I0814 18:55:07.632560 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.812427s
I0814 18:55:07.648859 10451 solver.cpp:312] Iteration 54000 (41.5954 iter/s, 2.40411s/100 iter), loss = 0.000950624
I0814 18:55:07.648890 10451 solver.cpp:334]     Train net output #0: loss = 0.000949391 (* 1 = 0.000949391 loss)
I0814 18:55:07.648900 10451 sgd_solver.cpp:136] Iteration 54000, lr = 0.015625, m = 0.9
I0814 18:55:09.285346 10451 solver.cpp:312] Iteration 54100 (61.1085 iter/s, 1.63643s/100 iter), loss = 0.000910629
I0814 18:55:09.285464 10451 solver.cpp:334]     Train net output #0: loss = 0.000909396 (* 1 = 0.000909396 loss)
I0814 18:55:09.285480 10451 sgd_solver.cpp:136] Iteration 54100, lr = 0.0154688, m = 0.9
I0814 18:55:10.884905 10451 solver.cpp:312] Iteration 54200 (62.5191 iter/s, 1.59951s/100 iter), loss = 0.00130849
I0814 18:55:10.885026 10451 solver.cpp:334]     Train net output #0: loss = 0.00130726 (* 1 = 0.00130726 loss)
I0814 18:55:10.885044 10451 sgd_solver.cpp:136] Iteration 54200, lr = 0.0153125, m = 0.9
I0814 18:55:12.490061 10451 solver.cpp:312] Iteration 54300 (62.3011 iter/s, 1.60511s/100 iter), loss = 0.00361174
I0814 18:55:12.490084 10451 solver.cpp:334]     Train net output #0: loss = 0.00361051 (* 1 = 0.00361051 loss)
I0814 18:55:12.490090 10451 sgd_solver.cpp:136] Iteration 54300, lr = 0.0151563, m = 0.9
I0814 18:55:14.134016 10451 solver.cpp:312] Iteration 54400 (60.8308 iter/s, 1.64391s/100 iter), loss = 0.000510048
I0814 18:55:14.134042 10451 solver.cpp:334]     Train net output #0: loss = 0.000508817 (* 1 = 0.000508817 loss)
I0814 18:55:14.134047 10451 sgd_solver.cpp:136] Iteration 54400, lr = 0.015, m = 0.9
I0814 18:55:15.799777 10451 solver.cpp:312] Iteration 54500 (60.0345 iter/s, 1.66571s/100 iter), loss = 0.00109913
I0814 18:55:15.799803 10451 solver.cpp:334]     Train net output #0: loss = 0.0010979 (* 1 = 0.0010979 loss)
I0814 18:55:15.799808 10451 sgd_solver.cpp:136] Iteration 54500, lr = 0.0148437, m = 0.9
I0814 18:55:17.430318 10451 solver.cpp:312] Iteration 54600 (61.3311 iter/s, 1.63049s/100 iter), loss = 0.000547417
I0814 18:55:17.430363 10451 solver.cpp:334]     Train net output #0: loss = 0.000546185 (* 1 = 0.000546185 loss)
I0814 18:55:17.430371 10451 sgd_solver.cpp:136] Iteration 54600, lr = 0.0146875, m = 0.9
I0814 18:55:18.996803 10451 solver.cpp:312] Iteration 54700 (63.8392 iter/s, 1.56644s/100 iter), loss = 0.00375039
I0814 18:55:18.996830 10451 solver.cpp:334]     Train net output #0: loss = 0.00374916 (* 1 = 0.00374916 loss)
I0814 18:55:18.996836 10451 sgd_solver.cpp:136] Iteration 54700, lr = 0.0145312, m = 0.9
I0814 18:55:20.652500 10451 solver.cpp:312] Iteration 54800 (60.3993 iter/s, 1.65565s/100 iter), loss = 0.00116787
I0814 18:55:20.652547 10451 solver.cpp:334]     Train net output #0: loss = 0.00116664 (* 1 = 0.00116664 loss)
I0814 18:55:20.652559 10451 sgd_solver.cpp:136] Iteration 54800, lr = 0.014375, m = 0.9
I0814 18:55:22.294411 10451 solver.cpp:312] Iteration 54900 (60.9065 iter/s, 1.64186s/100 iter), loss = 0.000564652
I0814 18:55:22.294456 10451 solver.cpp:334]     Train net output #0: loss = 0.00056342 (* 1 = 0.00056342 loss)
I0814 18:55:22.294468 10451 sgd_solver.cpp:136] Iteration 54900, lr = 0.0142187, m = 0.9
I0814 18:55:23.896700 10451 solver.cpp:509] Iteration 55000, Testing net (#0)
I0814 18:55:24.711472 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.924707
I0814 18:55:24.711494 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.997059
I0814 18:55:24.711499 10451 solver.cpp:594]     Test net output #2: loss = 0.259994 (* 1 = 0.259994 loss)
I0814 18:55:24.711524 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.814802s
I0814 18:55:24.729013 10451 solver.cpp:312] Iteration 55000 (41.0756 iter/s, 2.43453s/100 iter), loss = 0.00134337
I0814 18:55:24.729049 10451 solver.cpp:334]     Train net output #0: loss = 0.00134214 (* 1 = 0.00134214 loss)
I0814 18:55:24.729063 10451 sgd_solver.cpp:136] Iteration 55000, lr = 0.0140625, m = 0.9
I0814 18:55:26.363684 10451 solver.cpp:312] Iteration 55100 (61.1764 iter/s, 1.63462s/100 iter), loss = 0.00159734
I0814 18:55:26.363732 10451 solver.cpp:334]     Train net output #0: loss = 0.00159611 (* 1 = 0.00159611 loss)
I0814 18:55:26.363746 10451 sgd_solver.cpp:136] Iteration 55100, lr = 0.0139063, m = 0.9
I0814 18:55:27.986346 10451 solver.cpp:312] Iteration 55200 (61.6291 iter/s, 1.62261s/100 iter), loss = 0.00182078
I0814 18:55:27.986394 10451 solver.cpp:334]     Train net output #0: loss = 0.00181955 (* 1 = 0.00181955 loss)
I0814 18:55:27.986407 10451 sgd_solver.cpp:136] Iteration 55200, lr = 0.01375, m = 0.9
I0814 18:55:29.567176 10451 solver.cpp:312] Iteration 55300 (63.2597 iter/s, 1.58078s/100 iter), loss = 0.000906301
I0814 18:55:29.567200 10451 solver.cpp:334]     Train net output #0: loss = 0.000905069 (* 1 = 0.000905069 loss)
I0814 18:55:29.567205 10451 sgd_solver.cpp:136] Iteration 55300, lr = 0.0135938, m = 0.9
I0814 18:55:31.204169 10451 solver.cpp:312] Iteration 55400 (61.0896 iter/s, 1.63694s/100 iter), loss = 0.000625996
I0814 18:55:31.204216 10451 solver.cpp:334]     Train net output #0: loss = 0.000624764 (* 1 = 0.000624764 loss)
I0814 18:55:31.204228 10451 sgd_solver.cpp:136] Iteration 55400, lr = 0.0134375, m = 0.9
I0814 18:55:32.852048 10451 solver.cpp:312] Iteration 55500 (60.6858 iter/s, 1.64783s/100 iter), loss = 0.000557931
I0814 18:55:32.852193 10451 solver.cpp:334]     Train net output #0: loss = 0.000556698 (* 1 = 0.000556698 loss)
I0814 18:55:32.852210 10451 sgd_solver.cpp:136] Iteration 55500, lr = 0.0132813, m = 0.9
I0814 18:55:34.465461 10451 solver.cpp:312] Iteration 55600 (61.9824 iter/s, 1.61336s/100 iter), loss = 0.000669917
I0814 18:55:34.465492 10451 solver.cpp:334]     Train net output #0: loss = 0.000668685 (* 1 = 0.000668685 loss)
I0814 18:55:34.465499 10451 sgd_solver.cpp:136] Iteration 55600, lr = 0.013125, m = 0.9
I0814 18:55:36.097889 10451 solver.cpp:312] Iteration 55700 (61.2604 iter/s, 1.63238s/100 iter), loss = 0.000473318
I0814 18:55:36.097936 10451 solver.cpp:334]     Train net output #0: loss = 0.000472087 (* 1 = 0.000472087 loss)
I0814 18:55:36.097950 10451 sgd_solver.cpp:136] Iteration 55700, lr = 0.0129687, m = 0.9
I0814 18:55:37.770625 10451 solver.cpp:312] Iteration 55800 (59.7841 iter/s, 1.67269s/100 iter), loss = 0.00122252
I0814 18:55:37.770674 10451 solver.cpp:334]     Train net output #0: loss = 0.00122129 (* 1 = 0.00122129 loss)
I0814 18:55:37.770686 10451 sgd_solver.cpp:136] Iteration 55800, lr = 0.0128125, m = 0.9
I0814 18:55:39.423409 10451 solver.cpp:312] Iteration 55900 (60.5058 iter/s, 1.65273s/100 iter), loss = 0.00107546
I0814 18:55:39.423436 10451 solver.cpp:334]     Train net output #0: loss = 0.00107423 (* 1 = 0.00107423 loss)
I0814 18:55:39.423444 10451 sgd_solver.cpp:136] Iteration 55900, lr = 0.0126562, m = 0.9
I0814 18:55:41.064301 10451 solver.cpp:509] Iteration 56000, Testing net (#0)
I0814 18:55:41.886852 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.927354
I0814 18:55:41.886871 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.997059
I0814 18:55:41.886876 10451 solver.cpp:594]     Test net output #2: loss = 0.258227 (* 1 = 0.258227 loss)
I0814 18:55:41.886891 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.822568s
I0814 18:55:41.904646 10451 solver.cpp:312] Iteration 56000 (40.3036 iter/s, 2.48117s/100 iter), loss = 0.000564412
I0814 18:55:41.904664 10451 solver.cpp:334]     Train net output #0: loss = 0.00056318 (* 1 = 0.00056318 loss)
I0814 18:55:41.904670 10451 sgd_solver.cpp:136] Iteration 56000, lr = 0.0125, m = 0.9
I0814 18:55:42.812085 10436 data_reader.cpp:288] Starting prefetch of epoch 7
I0814 18:55:43.531683 10451 solver.cpp:312] Iteration 56100 (61.4634 iter/s, 1.62699s/100 iter), loss = 0.00166363
I0814 18:55:43.531740 10451 solver.cpp:334]     Train net output #0: loss = 0.0016624 (* 1 = 0.0016624 loss)
I0814 18:55:43.531754 10451 sgd_solver.cpp:136] Iteration 56100, lr = 0.0123438, m = 0.9
I0814 18:55:45.116880 10451 solver.cpp:312] Iteration 56200 (63.0856 iter/s, 1.58515s/100 iter), loss = 0.000565143
I0814 18:55:45.116904 10451 solver.cpp:334]     Train net output #0: loss = 0.000563911 (* 1 = 0.000563911 loss)
I0814 18:55:45.116907 10451 sgd_solver.cpp:136] Iteration 56200, lr = 0.0121875, m = 0.9
I0814 18:55:46.757547 10451 solver.cpp:312] Iteration 56300 (60.9527 iter/s, 1.64062s/100 iter), loss = 0.00117087
I0814 18:55:46.757571 10451 solver.cpp:334]     Train net output #0: loss = 0.00116963 (* 1 = 0.00116963 loss)
I0814 18:55:46.757577 10451 sgd_solver.cpp:136] Iteration 56300, lr = 0.0120313, m = 0.9
I0814 18:55:48.397936 10451 solver.cpp:312] Iteration 56400 (60.9629 iter/s, 1.64034s/100 iter), loss = 0.00128762
I0814 18:55:48.397985 10451 solver.cpp:334]     Train net output #0: loss = 0.00128639 (* 1 = 0.00128639 loss)
I0814 18:55:48.398000 10451 sgd_solver.cpp:136] Iteration 56400, lr = 0.011875, m = 0.9
I0814 18:55:49.990844 10451 solver.cpp:312] Iteration 56500 (62.7802 iter/s, 1.59286s/100 iter), loss = 0.000556568
I0814 18:55:49.990917 10451 solver.cpp:334]     Train net output #0: loss = 0.000555336 (* 1 = 0.000555336 loss)
I0814 18:55:49.990942 10451 sgd_solver.cpp:136] Iteration 56500, lr = 0.0117188, m = 0.9
I0814 18:55:51.601828 10451 solver.cpp:312] Iteration 56600 (62.0758 iter/s, 1.61093s/100 iter), loss = 0.00181939
I0814 18:55:51.601897 10451 solver.cpp:334]     Train net output #0: loss = 0.00181815 (* 1 = 0.00181815 loss)
I0814 18:55:51.601917 10451 sgd_solver.cpp:136] Iteration 56600, lr = 0.0115625, m = 0.9
I0814 18:55:53.270568 10451 solver.cpp:312] Iteration 56700 (59.9273 iter/s, 1.66869s/100 iter), loss = 0.000480917
I0814 18:55:53.270632 10451 solver.cpp:334]     Train net output #0: loss = 0.000479686 (* 1 = 0.000479686 loss)
I0814 18:55:53.270653 10451 sgd_solver.cpp:136] Iteration 56700, lr = 0.0114062, m = 0.9
I0814 18:55:54.895768 10451 solver.cpp:312] Iteration 56800 (61.5327 iter/s, 1.62515s/100 iter), loss = 0.000449994
I0814 18:55:54.895794 10451 solver.cpp:334]     Train net output #0: loss = 0.000448763 (* 1 = 0.000448763 loss)
I0814 18:55:54.895800 10451 sgd_solver.cpp:136] Iteration 56800, lr = 0.01125, m = 0.9
I0814 18:55:56.554152 10451 solver.cpp:312] Iteration 56900 (60.3017 iter/s, 1.65833s/100 iter), loss = 0.00108461
I0814 18:55:56.554177 10451 solver.cpp:334]     Train net output #0: loss = 0.00108338 (* 1 = 0.00108338 loss)
I0814 18:55:56.554183 10451 sgd_solver.cpp:136] Iteration 56900, lr = 0.0110937, m = 0.9
I0814 18:55:58.171747 10451 solver.cpp:509] Iteration 57000, Testing net (#0)
I0814 18:55:58.996601 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.924118
I0814 18:55:58.996620 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.996471
I0814 18:55:58.996626 10451 solver.cpp:594]     Test net output #2: loss = 0.25858 (* 1 = 0.25858 loss)
I0814 18:55:58.996640 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.824873s
I0814 18:55:59.020314 10451 solver.cpp:312] Iteration 57000 (40.5499 iter/s, 2.4661s/100 iter), loss = 0.00314952
I0814 18:55:59.020356 10451 solver.cpp:334]     Train net output #0: loss = 0.00314829 (* 1 = 0.00314829 loss)
I0814 18:55:59.020364 10451 sgd_solver.cpp:136] Iteration 57000, lr = 0.0109375, m = 0.9
I0814 18:56:00.634039 10451 solver.cpp:312] Iteration 57100 (61.9704 iter/s, 1.61367s/100 iter), loss = 0.000750812
I0814 18:56:00.634093 10451 solver.cpp:334]     Train net output #0: loss = 0.00074958 (* 1 = 0.00074958 loss)
I0814 18:56:00.634109 10451 sgd_solver.cpp:136] Iteration 57100, lr = 0.0107813, m = 0.9
I0814 18:56:02.210853 10451 solver.cpp:312] Iteration 57200 (63.4209 iter/s, 1.57677s/100 iter), loss = 0.00177745
I0814 18:56:02.210922 10451 solver.cpp:334]     Train net output #0: loss = 0.00177621 (* 1 = 0.00177621 loss)
I0814 18:56:02.210948 10451 sgd_solver.cpp:136] Iteration 57200, lr = 0.010625, m = 0.9
I0814 18:56:03.805660 10451 solver.cpp:312] Iteration 57300 (62.7054 iter/s, 1.59476s/100 iter), loss = 0.00195043
I0814 18:56:03.805685 10451 solver.cpp:334]     Train net output #0: loss = 0.0019492 (* 1 = 0.0019492 loss)
I0814 18:56:03.805691 10451 sgd_solver.cpp:136] Iteration 57300, lr = 0.0104688, m = 0.9
I0814 18:56:05.430621 10451 solver.cpp:312] Iteration 57400 (61.5418 iter/s, 1.62491s/100 iter), loss = 0.00105527
I0814 18:56:05.430667 10451 solver.cpp:334]     Train net output #0: loss = 0.00105404 (* 1 = 0.00105404 loss)
I0814 18:56:05.430678 10451 sgd_solver.cpp:136] Iteration 57400, lr = 0.0103125, m = 0.9
I0814 18:56:07.086958 10451 solver.cpp:312] Iteration 57500 (60.376 iter/s, 1.65629s/100 iter), loss = 0.00108823
I0814 18:56:07.087023 10451 solver.cpp:334]     Train net output #0: loss = 0.00108699 (* 1 = 0.00108699 loss)
I0814 18:56:07.087041 10451 sgd_solver.cpp:136] Iteration 57500, lr = 0.0101563, m = 0.9
I0814 18:56:08.686594 10451 solver.cpp:312] Iteration 57600 (62.5162 iter/s, 1.59959s/100 iter), loss = 0.000894665
I0814 18:56:08.686652 10451 solver.cpp:334]     Train net output #0: loss = 0.000893434 (* 1 = 0.000893434 loss)
I0814 18:56:08.686671 10451 sgd_solver.cpp:136] Iteration 57600, lr = 0.01, m = 0.9
I0814 18:56:10.320752 10451 solver.cpp:312] Iteration 57700 (61.1954 iter/s, 1.63411s/100 iter), loss = 0.00124147
I0814 18:56:10.320797 10451 solver.cpp:334]     Train net output #0: loss = 0.00124024 (* 1 = 0.00124024 loss)
I0814 18:56:10.320811 10451 sgd_solver.cpp:136] Iteration 57700, lr = 0.00984375, m = 0.9
I0814 18:56:11.951863 10451 solver.cpp:312] Iteration 57800 (61.3099 iter/s, 1.63106s/100 iter), loss = 0.00169928
I0814 18:56:11.951969 10451 solver.cpp:334]     Train net output #0: loss = 0.00169805 (* 1 = 0.00169805 loss)
I0814 18:56:11.951984 10451 sgd_solver.cpp:136] Iteration 57800, lr = 0.0096875, m = 0.9
I0814 18:56:13.576314 10451 solver.cpp:312] Iteration 57900 (61.561 iter/s, 1.6244s/100 iter), loss = 0.00106803
I0814 18:56:13.576341 10451 solver.cpp:334]     Train net output #0: loss = 0.0010668 (* 1 = 0.0010668 loss)
I0814 18:56:13.576347 10451 sgd_solver.cpp:136] Iteration 57900, lr = 0.00953125, m = 0.9
I0814 18:56:15.164325 10451 solver.cpp:509] Iteration 58000, Testing net (#0)
I0814 18:56:15.992182 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.918824
I0814 18:56:15.992202 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.997353
I0814 18:56:15.992207 10451 solver.cpp:594]     Test net output #2: loss = 0.277742 (* 1 = 0.277742 loss)
I0814 18:56:15.992223 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.827875s
I0814 18:56:16.007686 10451 solver.cpp:312] Iteration 58000 (41.1302 iter/s, 2.4313s/100 iter), loss = 0.00234378
I0814 18:56:16.007705 10451 solver.cpp:334]     Train net output #0: loss = 0.00234254 (* 1 = 0.00234254 loss)
I0814 18:56:16.007711 10451 sgd_solver.cpp:136] Iteration 58000, lr = 0.009375, m = 0.9
I0814 18:56:17.582916 10451 solver.cpp:312] Iteration 58100 (63.485 iter/s, 1.57518s/100 iter), loss = 0.0032052
I0814 18:56:17.582944 10451 solver.cpp:334]     Train net output #0: loss = 0.00320397 (* 1 = 0.00320397 loss)
I0814 18:56:17.582949 10451 sgd_solver.cpp:136] Iteration 58100, lr = 0.00921875, m = 0.9
I0814 18:56:19.205978 10451 solver.cpp:312] Iteration 58200 (61.6138 iter/s, 1.62301s/100 iter), loss = 0.000705798
I0814 18:56:19.206041 10451 solver.cpp:334]     Train net output #0: loss = 0.000704566 (* 1 = 0.000704566 loss)
I0814 18:56:19.206060 10451 sgd_solver.cpp:136] Iteration 58200, lr = 0.0090625, m = 0.9
I0814 18:56:20.825124 10451 solver.cpp:312] Iteration 58300 (61.7628 iter/s, 1.6191s/100 iter), loss = 0.00125104
I0814 18:56:20.825148 10451 solver.cpp:334]     Train net output #0: loss = 0.00124981 (* 1 = 0.00124981 loss)
I0814 18:56:20.825155 10451 sgd_solver.cpp:136] Iteration 58300, lr = 0.00890625, m = 0.9
I0814 18:56:22.462705 10451 solver.cpp:312] Iteration 58400 (61.0676 iter/s, 1.63753s/100 iter), loss = 0.000794407
I0814 18:56:22.462729 10451 solver.cpp:334]     Train net output #0: loss = 0.000793176 (* 1 = 0.000793176 loss)
I0814 18:56:22.462735 10451 sgd_solver.cpp:136] Iteration 58400, lr = 0.00875, m = 0.9
I0814 18:56:24.072718 10451 solver.cpp:312] Iteration 58500 (62.1131 iter/s, 1.60997s/100 iter), loss = 0.00209288
I0814 18:56:24.072796 10451 solver.cpp:334]     Train net output #0: loss = 0.00209165 (* 1 = 0.00209165 loss)
I0814 18:56:24.072818 10451 sgd_solver.cpp:136] Iteration 58500, lr = 0.00859375, m = 0.9
I0814 18:56:25.645290 10451 solver.cpp:312] Iteration 58600 (63.5921 iter/s, 1.57252s/100 iter), loss = 0.000244313
I0814 18:56:25.645354 10451 solver.cpp:334]     Train net output #0: loss = 0.000243081 (* 1 = 0.000243081 loss)
I0814 18:56:25.645372 10451 sgd_solver.cpp:136] Iteration 58600, lr = 0.0084375, m = 0.9
I0814 18:56:27.266263 10451 solver.cpp:312] Iteration 58700 (61.6932 iter/s, 1.62092s/100 iter), loss = 0.00109152
I0814 18:56:27.266311 10451 solver.cpp:334]     Train net output #0: loss = 0.00109029 (* 1 = 0.00109029 loss)
I0814 18:56:27.266325 10451 sgd_solver.cpp:136] Iteration 58700, lr = 0.00828125, m = 0.9
I0814 18:56:28.886451 10451 solver.cpp:312] Iteration 58800 (61.7231 iter/s, 1.62014s/100 iter), loss = 0.00117142
I0814 18:56:28.886473 10451 solver.cpp:334]     Train net output #0: loss = 0.00117019 (* 1 = 0.00117019 loss)
I0814 18:56:28.886479 10451 sgd_solver.cpp:136] Iteration 58800, lr = 0.008125, m = 0.9
I0814 18:56:30.462716 10451 solver.cpp:312] Iteration 58900 (63.443 iter/s, 1.57622s/100 iter), loss = 0.000894161
I0814 18:56:30.462777 10451 solver.cpp:334]     Train net output #0: loss = 0.000892929 (* 1 = 0.000892929 loss)
I0814 18:56:30.462795 10451 sgd_solver.cpp:136] Iteration 58900, lr = 0.00796875, m = 0.9
I0814 18:56:32.051406 10451 solver.cpp:509] Iteration 59000, Testing net (#0)
I0814 18:56:32.877914 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.922648
I0814 18:56:32.877935 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.997647
I0814 18:56:32.877940 10451 solver.cpp:594]     Test net output #2: loss = 0.273025 (* 1 = 0.273025 loss)
I0814 18:56:32.877956 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.826527s
I0814 18:56:32.893761 10451 solver.cpp:312] Iteration 59000 (41.1357 iter/s, 2.43098s/100 iter), loss = 0.000754704
I0814 18:56:32.893780 10451 solver.cpp:334]     Train net output #0: loss = 0.000753471 (* 1 = 0.000753471 loss)
I0814 18:56:32.893786 10451 sgd_solver.cpp:136] Iteration 59000, lr = 0.0078125, m = 0.9
I0814 18:56:34.493808 10451 solver.cpp:312] Iteration 59100 (62.5001 iter/s, 1.6s/100 iter), loss = 0.00126008
I0814 18:56:34.493871 10451 solver.cpp:334]     Train net output #0: loss = 0.00125885 (* 1 = 0.00125885 loss)
I0814 18:56:34.493891 10451 sgd_solver.cpp:136] Iteration 59100, lr = 0.00765625, m = 0.9
I0814 18:56:36.111426 10451 solver.cpp:312] Iteration 59200 (61.8212 iter/s, 1.61757s/100 iter), loss = 0.000922871
I0814 18:56:36.111449 10451 solver.cpp:334]     Train net output #0: loss = 0.000921639 (* 1 = 0.000921639 loss)
I0814 18:56:36.111455 10451 sgd_solver.cpp:136] Iteration 59200, lr = 0.0075, m = 0.9
I0814 18:56:37.768780 10451 solver.cpp:312] Iteration 59300 (60.339 iter/s, 1.6573s/100 iter), loss = 0.000581206
I0814 18:56:37.768806 10451 solver.cpp:334]     Train net output #0: loss = 0.000579973 (* 1 = 0.000579973 loss)
I0814 18:56:37.768812 10451 sgd_solver.cpp:136] Iteration 59300, lr = 0.00734375, m = 0.9
I0814 18:56:39.379773 10451 solver.cpp:312] Iteration 59400 (62.0755 iter/s, 1.61094s/100 iter), loss = 0.00216083
I0814 18:56:39.379796 10451 solver.cpp:334]     Train net output #0: loss = 0.00215959 (* 1 = 0.00215959 loss)
I0814 18:56:39.379801 10451 sgd_solver.cpp:136] Iteration 59400, lr = 0.0071875, m = 0.9
I0814 18:56:40.977162 10451 solver.cpp:312] Iteration 59500 (62.604 iter/s, 1.59734s/100 iter), loss = 0.000483285
I0814 18:56:40.977210 10451 solver.cpp:334]     Train net output #0: loss = 0.000482052 (* 1 = 0.000482052 loss)
I0814 18:56:40.977221 10451 sgd_solver.cpp:136] Iteration 59500, lr = 0.00703125, m = 0.9
I0814 18:56:42.627460 10451 solver.cpp:312] Iteration 59600 (60.597 iter/s, 1.65025s/100 iter), loss = 0.00109495
I0814 18:56:42.627581 10451 solver.cpp:334]     Train net output #0: loss = 0.00109371 (* 1 = 0.00109371 loss)
I0814 18:56:42.627599 10451 sgd_solver.cpp:136] Iteration 59600, lr = 0.006875, m = 0.9
I0814 18:56:44.263106 10451 solver.cpp:312] Iteration 59700 (61.1398 iter/s, 1.6356s/100 iter), loss = 0.00246691
I0814 18:56:44.263167 10451 solver.cpp:334]     Train net output #0: loss = 0.00246567 (* 1 = 0.00246567 loss)
I0814 18:56:44.263186 10451 sgd_solver.cpp:136] Iteration 59700, lr = 0.00671875, m = 0.9
I0814 18:56:45.923985 10451 solver.cpp:312] Iteration 59800 (60.2109 iter/s, 1.66083s/100 iter), loss = 0.00158699
I0814 18:56:45.924010 10451 solver.cpp:334]     Train net output #0: loss = 0.00158575 (* 1 = 0.00158575 loss)
I0814 18:56:45.924015 10451 sgd_solver.cpp:136] Iteration 59800, lr = 0.0065625, m = 0.9
I0814 18:56:47.527837 10451 solver.cpp:312] Iteration 59900 (62.3517 iter/s, 1.6038s/100 iter), loss = 0.0006376
I0814 18:56:47.527884 10451 solver.cpp:334]     Train net output #0: loss = 0.000636366 (* 1 = 0.000636366 loss)
I0814 18:56:47.527896 10451 sgd_solver.cpp:136] Iteration 59900, lr = 0.00640625, m = 0.9
I0814 18:56:49.135640 10451 solver.cpp:639] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/initial/cifar10_jacintonet11v2_iter_60000.caffemodel
I0814 18:56:49.143610 10451 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/initial/cifar10_jacintonet11v2_iter_60000.solverstate
I0814 18:56:49.147171 10451 solver.cpp:509] Iteration 60000, Testing net (#0)
I0814 18:56:49.948936 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.921177
I0814 18:56:49.948956 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.996765
I0814 18:56:49.948961 10451 solver.cpp:594]     Test net output #2: loss = 0.282779 (* 1 = 0.282779 loss)
I0814 18:56:49.948982 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.801787s
I0814 18:56:49.968080 10451 solver.cpp:312] Iteration 60000 (40.9807 iter/s, 2.44017s/100 iter), loss = 0.00285988
I0814 18:56:49.968107 10451 solver.cpp:334]     Train net output #0: loss = 0.00285865 (* 1 = 0.00285865 loss)
I0814 18:56:49.968112 10451 sgd_solver.cpp:136] Iteration 60000, lr = 0.00625, m = 0.9
I0814 18:56:51.593371 10451 solver.cpp:312] Iteration 60100 (61.5293 iter/s, 1.62524s/100 iter), loss = 0.00131081
I0814 18:56:51.593395 10451 solver.cpp:334]     Train net output #0: loss = 0.00130958 (* 1 = 0.00130958 loss)
I0814 18:56:51.593400 10451 sgd_solver.cpp:136] Iteration 60100, lr = 0.00609375, m = 0.9
I0814 18:56:53.183264 10451 solver.cpp:312] Iteration 60200 (62.8993 iter/s, 1.58984s/100 iter), loss = 0.000997263
I0814 18:56:53.183323 10451 solver.cpp:334]     Train net output #0: loss = 0.00099603 (* 1 = 0.00099603 loss)
I0814 18:56:53.183341 10451 sgd_solver.cpp:136] Iteration 60200, lr = 0.0059375, m = 0.9
I0814 18:56:54.812763 10451 solver.cpp:312] Iteration 60300 (61.3704 iter/s, 1.62945s/100 iter), loss = 0.00188993
I0814 18:56:54.812788 10451 solver.cpp:334]     Train net output #0: loss = 0.0018887 (* 1 = 0.0018887 loss)
I0814 18:56:54.812794 10451 sgd_solver.cpp:136] Iteration 60300, lr = 0.00578125, m = 0.9
I0814 18:56:56.428689 10451 solver.cpp:312] Iteration 60400 (61.886 iter/s, 1.61588s/100 iter), loss = 0.000784928
I0814 18:56:56.428771 10451 solver.cpp:334]     Train net output #0: loss = 0.000783694 (* 1 = 0.000783694 loss)
I0814 18:56:56.428797 10451 sgd_solver.cpp:136] Iteration 60400, lr = 0.005625, m = 0.9
I0814 18:56:58.044888 10451 solver.cpp:312] Iteration 60500 (61.8753 iter/s, 1.61615s/100 iter), loss = 0.00123573
I0814 18:56:58.044910 10451 solver.cpp:334]     Train net output #0: loss = 0.0012345 (* 1 = 0.0012345 loss)
I0814 18:56:58.044916 10451 sgd_solver.cpp:136] Iteration 60500, lr = 0.00546875, m = 0.9
I0814 18:56:59.644196 10451 solver.cpp:312] Iteration 60600 (62.5289 iter/s, 1.59926s/100 iter), loss = 0.00208535
I0814 18:56:59.644265 10451 solver.cpp:334]     Train net output #0: loss = 0.00208411 (* 1 = 0.00208411 loss)
I0814 18:56:59.644300 10451 sgd_solver.cpp:136] Iteration 60600, lr = 0.0053125, m = 0.9
I0814 18:56:59.696897 10436 data_reader.cpp:288] Starting prefetch of epoch 8
I0814 18:57:01.246330 10451 solver.cpp:312] Iteration 60700 (62.4188 iter/s, 1.60208s/100 iter), loss = 0.000623473
I0814 18:57:01.246376 10451 solver.cpp:334]     Train net output #0: loss = 0.00062224 (* 1 = 0.00062224 loss)
I0814 18:57:01.246388 10451 sgd_solver.cpp:136] Iteration 60700, lr = 0.00515625, m = 0.9
I0814 18:57:02.826195 10451 solver.cpp:312] Iteration 60800 (63.2985 iter/s, 1.57982s/100 iter), loss = 0.004545
I0814 18:57:02.826220 10451 solver.cpp:334]     Train net output #0: loss = 0.00454377 (* 1 = 0.00454377 loss)
I0814 18:57:02.826225 10451 sgd_solver.cpp:136] Iteration 60800, lr = 0.005, m = 0.9
I0814 18:57:04.451730 10451 solver.cpp:312] Iteration 60900 (61.52 iter/s, 1.62549s/100 iter), loss = 0.00166931
I0814 18:57:04.451752 10451 solver.cpp:334]     Train net output #0: loss = 0.00166808 (* 1 = 0.00166808 loss)
I0814 18:57:04.451756 10451 sgd_solver.cpp:136] Iteration 60900, lr = 0.00484375, m = 0.9
I0814 18:57:06.023166 10451 solver.cpp:509] Iteration 61000, Testing net (#0)
I0814 18:57:06.838989 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.917648
I0814 18:57:06.839011 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.997059
I0814 18:57:06.839016 10451 solver.cpp:594]     Test net output #2: loss = 0.295314 (* 1 = 0.295314 loss)
I0814 18:57:06.839046 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.815856s
I0814 18:57:06.854648 10451 solver.cpp:312] Iteration 61000 (41.6172 iter/s, 2.40285s/100 iter), loss = 0.00107245
I0814 18:57:06.854678 10451 solver.cpp:334]     Train net output #0: loss = 0.00107122 (* 1 = 0.00107122 loss)
I0814 18:57:06.854689 10451 sgd_solver.cpp:136] Iteration 61000, lr = 0.0046875, m = 0.9
I0814 18:57:08.531898 10451 solver.cpp:312] Iteration 61100 (59.6232 iter/s, 1.6772s/100 iter), loss = 0.00103812
I0814 18:57:08.531985 10451 solver.cpp:334]     Train net output #0: loss = 0.00103689 (* 1 = 0.00103689 loss)
I0814 18:57:08.531993 10451 sgd_solver.cpp:136] Iteration 61100, lr = 0.00453125, m = 0.9
I0814 18:57:10.144480 10451 solver.cpp:312] Iteration 61200 (62.0144 iter/s, 1.61253s/100 iter), loss = 0.000756713
I0814 18:57:10.144508 10451 solver.cpp:334]     Train net output #0: loss = 0.000755479 (* 1 = 0.000755479 loss)
I0814 18:57:10.144515 10451 sgd_solver.cpp:136] Iteration 61200, lr = 0.004375, m = 0.9
I0814 18:57:11.748689 10451 solver.cpp:312] Iteration 61300 (62.3378 iter/s, 1.60416s/100 iter), loss = 0.000556967
I0814 18:57:11.748713 10451 solver.cpp:334]     Train net output #0: loss = 0.000555734 (* 1 = 0.000555734 loss)
I0814 18:57:11.748716 10451 sgd_solver.cpp:136] Iteration 61300, lr = 0.00421875, m = 0.9
I0814 18:57:13.339221 10451 solver.cpp:312] Iteration 61400 (62.8741 iter/s, 1.59048s/100 iter), loss = 0.00132137
I0814 18:57:13.339329 10451 solver.cpp:334]     Train net output #0: loss = 0.00132014 (* 1 = 0.00132014 loss)
I0814 18:57:13.339347 10451 sgd_solver.cpp:136] Iteration 61400, lr = 0.0040625, m = 0.9
I0814 18:57:14.979758 10451 solver.cpp:312] Iteration 61500 (60.9574 iter/s, 1.64049s/100 iter), loss = 0.00348396
I0814 18:57:14.979782 10451 solver.cpp:334]     Train net output #0: loss = 0.00348273 (* 1 = 0.00348273 loss)
I0814 18:57:14.979789 10451 sgd_solver.cpp:136] Iteration 61500, lr = 0.00390625, m = 0.9
I0814 18:57:16.604085 10451 solver.cpp:312] Iteration 61600 (61.5658 iter/s, 1.62428s/100 iter), loss = 0.00147628
I0814 18:57:16.604110 10451 solver.cpp:334]     Train net output #0: loss = 0.00147505 (* 1 = 0.00147505 loss)
I0814 18:57:16.604116 10451 sgd_solver.cpp:136] Iteration 61600, lr = 0.00375, m = 0.9
I0814 18:57:18.232282 10451 solver.cpp:312] Iteration 61700 (61.4195 iter/s, 1.62815s/100 iter), loss = 0.000346502
I0814 18:57:18.232306 10451 solver.cpp:334]     Train net output #0: loss = 0.000345268 (* 1 = 0.000345268 loss)
I0814 18:57:18.232312 10451 sgd_solver.cpp:136] Iteration 61700, lr = 0.00359375, m = 0.9
I0814 18:57:19.853334 10451 solver.cpp:312] Iteration 61800 (61.6903 iter/s, 1.621s/100 iter), loss = 0.00034867
I0814 18:57:19.853361 10451 solver.cpp:334]     Train net output #0: loss = 0.000347436 (* 1 = 0.000347436 loss)
I0814 18:57:19.853369 10451 sgd_solver.cpp:136] Iteration 61800, lr = 0.0034375, m = 0.9
I0814 18:57:21.479785 10451 solver.cpp:312] Iteration 61900 (61.4854 iter/s, 1.6264s/100 iter), loss = 0.00107245
I0814 18:57:21.479852 10451 solver.cpp:334]     Train net output #0: loss = 0.00107122 (* 1 = 0.00107122 loss)
I0814 18:57:21.479874 10451 sgd_solver.cpp:136] Iteration 61900, lr = 0.00328125, m = 0.9
I0814 18:57:23.051357 10451 solver.cpp:509] Iteration 62000, Testing net (#0)
I0814 18:57:23.883425 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.924413
I0814 18:57:23.883443 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.996765
I0814 18:57:23.883447 10451 solver.cpp:594]     Test net output #2: loss = 0.285738 (* 1 = 0.285738 loss)
I0814 18:57:23.883463 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.832085s
I0814 18:57:23.898879 10451 solver.cpp:312] Iteration 62000 (41.339 iter/s, 2.41902s/100 iter), loss = 0.00153246
I0814 18:57:23.898895 10451 solver.cpp:334]     Train net output #0: loss = 0.00153122 (* 1 = 0.00153122 loss)
I0814 18:57:23.898901 10451 sgd_solver.cpp:136] Iteration 62000, lr = 0.003125, m = 0.9
I0814 18:57:25.521047 10451 solver.cpp:312] Iteration 62100 (61.6479 iter/s, 1.62212s/100 iter), loss = 0.000606953
I0814 18:57:25.521071 10451 solver.cpp:334]     Train net output #0: loss = 0.000605718 (* 1 = 0.000605718 loss)
I0814 18:57:25.521076 10451 sgd_solver.cpp:136] Iteration 62100, lr = 0.00296875, m = 0.9
I0814 18:57:27.171756 10451 solver.cpp:312] Iteration 62200 (60.5819 iter/s, 1.65066s/100 iter), loss = 0.000650115
I0814 18:57:27.171782 10451 solver.cpp:334]     Train net output #0: loss = 0.00064888 (* 1 = 0.00064888 loss)
I0814 18:57:27.171787 10451 sgd_solver.cpp:136] Iteration 62200, lr = 0.0028125, m = 0.9
I0814 18:57:28.783681 10451 solver.cpp:312] Iteration 62300 (62.0394 iter/s, 1.61188s/100 iter), loss = 0.00155333
I0814 18:57:28.783710 10451 solver.cpp:334]     Train net output #0: loss = 0.00155209 (* 1 = 0.00155209 loss)
I0814 18:57:28.783715 10451 sgd_solver.cpp:136] Iteration 62300, lr = 0.00265625, m = 0.9
I0814 18:57:30.386093 10451 solver.cpp:312] Iteration 62400 (62.4079 iter/s, 1.60236s/100 iter), loss = 0.000725817
I0814 18:57:30.386167 10451 solver.cpp:334]     Train net output #0: loss = 0.000724582 (* 1 = 0.000724582 loss)
I0814 18:57:30.386184 10451 sgd_solver.cpp:136] Iteration 62400, lr = 0.0025, m = 0.9
I0814 18:57:31.995882 10451 solver.cpp:312] Iteration 62500 (62.1218 iter/s, 1.60974s/100 iter), loss = 0.000801346
I0814 18:57:31.995932 10451 solver.cpp:334]     Train net output #0: loss = 0.000800111 (* 1 = 0.000800111 loss)
I0814 18:57:31.995949 10451 sgd_solver.cpp:136] Iteration 62500, lr = 0.00234375, m = 0.9
I0814 18:57:33.621520 10451 solver.cpp:312] Iteration 62600 (61.5162 iter/s, 1.62559s/100 iter), loss = 0.00141416
I0814 18:57:33.621546 10451 solver.cpp:334]     Train net output #0: loss = 0.00141293 (* 1 = 0.00141293 loss)
I0814 18:57:33.621552 10451 sgd_solver.cpp:136] Iteration 62600, lr = 0.0021875, m = 0.9
I0814 18:57:35.206928 10451 solver.cpp:312] Iteration 62700 (63.0772 iter/s, 1.58536s/100 iter), loss = 0.00109758
I0814 18:57:35.206976 10451 solver.cpp:334]     Train net output #0: loss = 0.00109634 (* 1 = 0.00109634 loss)
I0814 18:57:35.206987 10451 sgd_solver.cpp:136] Iteration 62700, lr = 0.00203125, m = 0.9
I0814 18:57:36.841001 10451 solver.cpp:312] Iteration 62800 (61.1986 iter/s, 1.63403s/100 iter), loss = 0.00219834
I0814 18:57:36.841025 10451 solver.cpp:334]     Train net output #0: loss = 0.0021971 (* 1 = 0.0021971 loss)
I0814 18:57:36.841030 10451 sgd_solver.cpp:136] Iteration 62800, lr = 0.001875, m = 0.9
I0814 18:57:38.473928 10451 solver.cpp:312] Iteration 62900 (61.2416 iter/s, 1.63288s/100 iter), loss = 0.000779434
I0814 18:57:38.474017 10451 solver.cpp:334]     Train net output #0: loss = 0.000778199 (* 1 = 0.000778199 loss)
I0814 18:57:38.474026 10451 sgd_solver.cpp:136] Iteration 62900, lr = 0.00171875, m = 0.9
I0814 18:57:40.071972 10451 solver.cpp:509] Iteration 63000, Testing net (#0)
I0814 18:57:40.887034 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.920883
I0814 18:57:40.887053 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.996471
I0814 18:57:40.887058 10451 solver.cpp:594]     Test net output #2: loss = 0.297442 (* 1 = 0.297442 loss)
I0814 18:57:40.887073 10451 solver.cpp:264] [MultiGPU] Tests completed in 0.81508s
I0814 18:57:40.902688 10451 solver.cpp:312] Iteration 63000 (41.1744 iter/s, 2.42869s/100 iter), loss = 0.000700657
I0814 18:57:40.902704 10451 solver.cpp:334]     Train net output #0: loss = 0.000699421 (* 1 = 0.000699421 loss)
I0814 18:57:40.902710 10451 sgd_solver.cpp:136] Iteration 63000, lr = 0.0015625, m = 0.9
I0814 18:57:42.499683 10451 solver.cpp:312] Iteration 63100 (62.6196 iter/s, 1.59694s/100 iter), loss = 0.00127757
I0814 18:57:42.499727 10451 solver.cpp:334]     Train net output #0: loss = 0.00127633 (* 1 = 0.00127633 loss)
I0814 18:57:42.499740 10451 sgd_solver.cpp:136] Iteration 63100, lr = 0.00140625, m = 0.9
I0814 18:57:44.164033 10451 solver.cpp:312] Iteration 63200 (60.0854 iter/s, 1.6643s/100 iter), loss = 0.00167401
I0814 18:57:44.164119 10451 solver.cpp:334]     Train net output #0: loss = 0.00167277 (* 1 = 0.00167277 loss)
I0814 18:57:44.164127 10451 sgd_solver.cpp:136] Iteration 63200, lr = 0.00125, m = 0.9
I0814 18:57:45.743232 10451 solver.cpp:312] Iteration 63300 (63.325 iter/s, 1.57915s/100 iter), loss = 0.00170525
I0814 18:57:45.743257 10451 solver.cpp:334]     Train net output #0: loss = 0.00170402 (* 1 = 0.00170402 loss)
I0814 18:57:45.743263 10451 sgd_solver.cpp:136] Iteration 63300, lr = 0.00109375, m = 0.9
I0814 18:57:47.361192 10451 solver.cpp:312] Iteration 63400 (61.8082 iter/s, 1.61791s/100 iter), loss = 0.000515989
I0814 18:57:47.361217 10451 solver.cpp:334]     Train net output #0: loss = 0.000514755 (* 1 = 0.000514755 loss)
I0814 18:57:47.361222 10451 sgd_solver.cpp:136] Iteration 63400, lr = 0.000937498, m = 0.9
I0814 18:57:48.979198 10451 solver.cpp:312] Iteration 63500 (61.8063 iter/s, 1.61796s/100 iter), loss = 0.000633863
I0814 18:57:48.979254 10451 solver.cpp:334]     Train net output #0: loss = 0.000632628 (* 1 = 0.000632628 loss)
I0814 18:57:48.979269 10451 sgd_solver.cpp:136] Iteration 63500, lr = 0.00078125, m = 0.9
I0814 18:57:50.587890 10451 solver.cpp:312] Iteration 63600 (62.1642 iter/s, 1.60864s/100 iter), loss = 0.00161503
I0814 18:57:50.587918 10451 solver.cpp:334]     Train net output #0: loss = 0.0016138 (* 1 = 0.0016138 loss)
I0814 18:57:50.587924 10451 sgd_solver.cpp:136] Iteration 63600, lr = 0.000625002, m = 0.9
I0814 18:57:52.151053 10451 solver.cpp:312] Iteration 63700 (63.9749 iter/s, 1.56311s/100 iter), loss = 0.00182812
I0814 18:57:52.151077 10451 solver.cpp:334]     Train net output #0: loss = 0.00182689 (* 1 = 0.00182689 loss)
I0814 18:57:52.151083 10451 sgd_solver.cpp:136] Iteration 63700, lr = 0.000468749, m = 0.9
I0814 18:57:53.803895 10451 solver.cpp:312] Iteration 63800 (60.5037 iter/s, 1.65279s/100 iter), loss = 0.00115639
I0814 18:57:53.803923 10451 solver.cpp:334]     Train net output #0: loss = 0.00115516 (* 1 = 0.00115516 loss)
I0814 18:57:53.803930 10451 sgd_solver.cpp:136] Iteration 63800, lr = 0.000312501, m = 0.9
I0814 18:57:55.416045 10451 solver.cpp:312] Iteration 63900 (62.0309 iter/s, 1.6121s/100 iter), loss = 0.00106957
I0814 18:57:55.416261 10451 solver.cpp:334]     Train net output #0: loss = 0.00106833 (* 1 = 0.00106833 loss)
I0814 18:57:55.416268 10451 sgd_solver.cpp:136] Iteration 63900, lr = 0.000156248, m = 0.9
I0814 18:57:57.030429 10451 solver.cpp:312] Iteration 63999 (61.3255 iter/s, 1.61434s/99 iter), loss = 0.00052641
I0814 18:57:57.030472 10451 solver.cpp:334]     Train net output #0: loss = 0.000525176 (* 1 = 0.000525176 loss)
I0814 18:57:57.030827 10451 solver.cpp:639] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/initial/cifar10_jacintonet11v2_iter_64000.caffemodel
I0814 18:57:57.040349 10451 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/initial/cifar10_jacintonet11v2_iter_64000.solverstate
I0814 18:57:57.050317 10451 solver.cpp:486] Iteration 64000, loss = 0.000863708
I0814 18:57:57.050343 10451 solver.cpp:509] Iteration 64000, Testing net (#0)
I0814 18:57:57.854610 10451 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.915001
I0814 18:57:57.854629 10451 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.995882
I0814 18:57:57.854635 10451 solver.cpp:594]     Test net output #2: loss = 0.311565 (* 1 = 0.311565 loss)
I0814 18:57:57.857556 10396 parallel.cpp:71] Root Solver performance on device 0: 58.97 * 22 = 1297 img/sec (64000 itr in 1085 sec)
I0814 18:57:57.857568 10396 parallel.cpp:76]      Solver performance on device 1: 58.97 * 22 = 1297 img/sec (64000 itr in 1085 sec)
I0814 18:57:57.857573 10396 parallel.cpp:76]      Solver performance on device 2: 58.97 * 22 = 1297 img/sec (64000 itr in 1085 sec)
I0814 18:57:57.857578 10396 parallel.cpp:79] Overall multi-GPU performance: 3892.15 img/sec
I0814 18:57:57.935192 10396 caffe.cpp:247] Optimization Done in 18m 8s
