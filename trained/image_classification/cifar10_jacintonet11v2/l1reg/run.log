I0814 18:57:58.809798   556 caffe.cpp:608] This is NVCaffe 0.16.3 started at Mon Aug 14 18:57:58 2017
I0814 18:57:58.809919   556 caffe.cpp:611] CuDNN version: 6021
I0814 18:57:58.809923   556 caffe.cpp:612] CuBLAS version: 8000
I0814 18:57:58.809926   556 caffe.cpp:613] CUDA version: 8000
I0814 18:57:58.809927   556 caffe.cpp:614] CUDA driver version: 8000
I0814 18:57:59.060483   556 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0814 18:57:59.061066   556 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8278441984, dev_info[0]: total=8506769408 free=8278441984
I0814 18:57:59.061597   556 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8278441984, dev_info[1]: total=8508145664 free=8379236352
I0814 18:57:59.062113   556 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8278441984, dev_info[2]: total=8508145664 free=8379236352
I0814 18:57:59.062120   556 caffe.cpp:208] Using GPUs 0, 1, 2
I0814 18:57:59.062443   556 caffe.cpp:213] GPU 0: GeForce GTX 1080
I0814 18:57:59.062764   556 caffe.cpp:213] GPU 1: GeForce GTX 1080
I0814 18:57:59.063086   556 caffe.cpp:213] GPU 2: GeForce GTX 1080
I0814 18:57:59.063123   556 solver.cpp:42] Solver data type: FLOAT
I0814 18:57:59.063151   556 solver.cpp:45] Initializing solver from parameters: 
train_net: "training/cifar10_jacintonet11v2_2017-08-14_18-39-46/l1reg/train.prototxt"
test_net: "training/cifar10_jacintonet11v2_2017-08-14_18-39-46/l1reg/test.prototxt"
test_iter: 200
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 64000
lr_policy: "poly"
gamma: 0.1
power: 1
momentum: 0.9
weight_decay: 1e-05
snapshot: 10000
snapshot_prefix: "training/cifar10_jacintonet11v2_2017-08-14_18-39-46/l1reg/cifar10_jacintonet11v2"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
snapshot_after_train: true
regularization_type: "L1"
test_initialization: true
iter_size: 1
type: "SGD"
I0814 18:57:59.069975   556 solver.cpp:77] Creating training net from train_net file: training/cifar10_jacintonet11v2_2017-08-14_18-39-46/l1reg/train.prototxt
I0814 18:57:59.070391   556 net.cpp:443] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top1
I0814 18:57:59.070399   556 net.cpp:443] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top5
W0814 18:57:59.070420   556 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 64 to 66
I0814 18:57:59.070603   556 net.cpp:72] Initializing net from parameters: 
name: "jacintonet11v2_train"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: true
    crop_size: 32
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/cifar10_train_lmdb"
    batch_size: 22
    backend: LMDB
    threads: 1
    parser_threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc10"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc10"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
I0814 18:57:59.070704   556 net.cpp:104] Using FLOAT as default forward math type
I0814 18:57:59.070708   556 net.cpp:110] Using FLOAT as default backward math type
I0814 18:57:59.070711   556 layer_factory.hpp:136] Creating layer 'data' of type 'Data'
I0814 18:57:59.070714   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.070757   556 net.cpp:184] Created Layer data (0)
I0814 18:57:59.070762   556 net.cpp:530] data -> data
I0814 18:57:59.070771   556 net.cpp:530] data -> label
I0814 18:57:59.070791   556 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 22
I0814 18:57:59.070809   556 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0814 18:57:59.071651   592 db_lmdb.cpp:24] Opened lmdb ./data/cifar10_train_lmdb
I0814 18:57:59.072685   556 data_layer.cpp:185] [0] ReshapePrefetch 22, 3, 32, 32
I0814 18:57:59.072747   556 data_layer.cpp:209] [0] Output data size: 22, 3, 32, 32
I0814 18:57:59.072752   556 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0814 18:57:59.072770   556 net.cpp:245] Setting up data
I0814 18:57:59.072777   556 net.cpp:252] TRAIN Top shape for layer 0 'data' 22 3 32 32 (67584)
I0814 18:57:59.072782   556 net.cpp:252] TRAIN Top shape for layer 0 'data' 22 (22)
I0814 18:57:59.072788   556 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0814 18:57:59.072793   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.072803   556 net.cpp:184] Created Layer data/bias (1)
I0814 18:57:59.072808   556 net.cpp:561] data/bias <- data
I0814 18:57:59.072814   556 net.cpp:530] data/bias -> data/bias
I0814 18:57:59.074765   556 net.cpp:245] Setting up data/bias
I0814 18:57:59.074775   556 net.cpp:252] TRAIN Top shape for layer 1 'data/bias' 22 3 32 32 (67584)
I0814 18:57:59.074784   556 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0814 18:57:59.074787   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.074800   556 net.cpp:184] Created Layer conv1a (2)
I0814 18:57:59.074805   556 net.cpp:561] conv1a <- data/bias
I0814 18:57:59.074806   556 net.cpp:530] conv1a -> conv1a
I0814 18:57:59.363154   556 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.01G/1 1 0 3  (limit 8.15G, req 0G)
I0814 18:57:59.363173   556 net.cpp:245] Setting up conv1a
I0814 18:57:59.363179   556 net.cpp:252] TRAIN Top shape for layer 2 'conv1a' 22 32 32 32 (720896)
I0814 18:57:59.363188   556 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0814 18:57:59.363193   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.363204   556 net.cpp:184] Created Layer conv1a/bn (3)
I0814 18:57:59.363206   556 net.cpp:561] conv1a/bn <- conv1a
I0814 18:57:59.363210   556 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0814 18:57:59.363850   556 net.cpp:245] Setting up conv1a/bn
I0814 18:57:59.363858   556 net.cpp:252] TRAIN Top shape for layer 3 'conv1a/bn' 22 32 32 32 (720896)
I0814 18:57:59.363867   556 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0814 18:57:59.363869   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.363874   556 net.cpp:184] Created Layer conv1a/relu (4)
I0814 18:57:59.363876   556 net.cpp:561] conv1a/relu <- conv1a
I0814 18:57:59.363878   556 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0814 18:57:59.363891   556 net.cpp:245] Setting up conv1a/relu
I0814 18:57:59.363895   556 net.cpp:252] TRAIN Top shape for layer 4 'conv1a/relu' 22 32 32 32 (720896)
I0814 18:57:59.363898   556 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0814 18:57:59.363899   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.363906   556 net.cpp:184] Created Layer conv1b (5)
I0814 18:57:59.363909   556 net.cpp:561] conv1b <- conv1a
I0814 18:57:59.363910   556 net.cpp:530] conv1b -> conv1b
I0814 18:57:59.370620   556 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 8.13G, req 0G)
I0814 18:57:59.370630   556 net.cpp:245] Setting up conv1b
I0814 18:57:59.370635   556 net.cpp:252] TRAIN Top shape for layer 5 'conv1b' 22 32 32 32 (720896)
I0814 18:57:59.370641   556 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0814 18:57:59.370645   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.370651   556 net.cpp:184] Created Layer conv1b/bn (6)
I0814 18:57:59.370653   556 net.cpp:561] conv1b/bn <- conv1b
I0814 18:57:59.370664   556 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0814 18:57:59.371253   556 net.cpp:245] Setting up conv1b/bn
I0814 18:57:59.371263   556 net.cpp:252] TRAIN Top shape for layer 6 'conv1b/bn' 22 32 32 32 (720896)
I0814 18:57:59.371269   556 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0814 18:57:59.371273   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.371276   556 net.cpp:184] Created Layer conv1b/relu (7)
I0814 18:57:59.371279   556 net.cpp:561] conv1b/relu <- conv1b
I0814 18:57:59.371281   556 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0814 18:57:59.371285   556 net.cpp:245] Setting up conv1b/relu
I0814 18:57:59.371289   556 net.cpp:252] TRAIN Top shape for layer 7 'conv1b/relu' 22 32 32 32 (720896)
I0814 18:57:59.371291   556 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0814 18:57:59.371294   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.371300   556 net.cpp:184] Created Layer pool1 (8)
I0814 18:57:59.371302   556 net.cpp:561] pool1 <- conv1b
I0814 18:57:59.371305   556 net.cpp:530] pool1 -> pool1
I0814 18:57:59.371378   556 net.cpp:245] Setting up pool1
I0814 18:57:59.371382   556 net.cpp:252] TRAIN Top shape for layer 8 'pool1' 22 32 32 32 (720896)
I0814 18:57:59.371386   556 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0814 18:57:59.371388   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.371397   556 net.cpp:184] Created Layer res2a_branch2a (9)
I0814 18:57:59.371400   556 net.cpp:561] res2a_branch2a <- pool1
I0814 18:57:59.371403   556 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0814 18:57:59.380489   556 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 8.11G, req 0G)
I0814 18:57:59.380501   556 net.cpp:245] Setting up res2a_branch2a
I0814 18:57:59.380506   556 net.cpp:252] TRAIN Top shape for layer 9 'res2a_branch2a' 22 64 32 32 (1441792)
I0814 18:57:59.380513   556 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0814 18:57:59.380517   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.380522   556 net.cpp:184] Created Layer res2a_branch2a/bn (10)
I0814 18:57:59.380523   556 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0814 18:57:59.380527   556 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0814 18:57:59.381132   556 net.cpp:245] Setting up res2a_branch2a/bn
I0814 18:57:59.381140   556 net.cpp:252] TRAIN Top shape for layer 10 'res2a_branch2a/bn' 22 64 32 32 (1441792)
I0814 18:57:59.381145   556 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0814 18:57:59.381148   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.381151   556 net.cpp:184] Created Layer res2a_branch2a/relu (11)
I0814 18:57:59.381155   556 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0814 18:57:59.381156   556 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0814 18:57:59.381160   556 net.cpp:245] Setting up res2a_branch2a/relu
I0814 18:57:59.381162   556 net.cpp:252] TRAIN Top shape for layer 11 'res2a_branch2a/relu' 22 64 32 32 (1441792)
I0814 18:57:59.381165   556 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0814 18:57:59.381166   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.381175   556 net.cpp:184] Created Layer res2a_branch2b (12)
I0814 18:57:59.381177   556 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0814 18:57:59.381181   556 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0814 18:57:59.387694   556 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 8.1G, req 0G)
I0814 18:57:59.387706   556 net.cpp:245] Setting up res2a_branch2b
I0814 18:57:59.387718   556 net.cpp:252] TRAIN Top shape for layer 12 'res2a_branch2b' 22 64 32 32 (1441792)
I0814 18:57:59.387723   556 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0814 18:57:59.387727   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.387732   556 net.cpp:184] Created Layer res2a_branch2b/bn (13)
I0814 18:57:59.387735   556 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0814 18:57:59.387737   556 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0814 18:57:59.388346   556 net.cpp:245] Setting up res2a_branch2b/bn
I0814 18:57:59.388353   556 net.cpp:252] TRAIN Top shape for layer 13 'res2a_branch2b/bn' 22 64 32 32 (1441792)
I0814 18:57:59.388360   556 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0814 18:57:59.388363   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.388367   556 net.cpp:184] Created Layer res2a_branch2b/relu (14)
I0814 18:57:59.388370   556 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0814 18:57:59.388373   556 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0814 18:57:59.388377   556 net.cpp:245] Setting up res2a_branch2b/relu
I0814 18:57:59.388381   556 net.cpp:252] TRAIN Top shape for layer 14 'res2a_branch2b/relu' 22 64 32 32 (1441792)
I0814 18:57:59.388382   556 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0814 18:57:59.388386   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.388389   556 net.cpp:184] Created Layer pool2 (15)
I0814 18:57:59.388392   556 net.cpp:561] pool2 <- res2a_branch2b
I0814 18:57:59.388394   556 net.cpp:530] pool2 -> pool2
I0814 18:57:59.388453   556 net.cpp:245] Setting up pool2
I0814 18:57:59.388456   556 net.cpp:252] TRAIN Top shape for layer 15 'pool2' 22 64 16 16 (360448)
I0814 18:57:59.388459   556 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0814 18:57:59.388463   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.388470   556 net.cpp:184] Created Layer res3a_branch2a (16)
I0814 18:57:59.388473   556 net.cpp:561] res3a_branch2a <- pool2
I0814 18:57:59.388476   556 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0814 18:57:59.399266   556 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 3  (limit 8.09G, req 0G)
I0814 18:57:59.399308   556 net.cpp:245] Setting up res3a_branch2a
I0814 18:57:59.399317   556 net.cpp:252] TRAIN Top shape for layer 16 'res3a_branch2a' 22 128 16 16 (720896)
I0814 18:57:59.399327   556 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0814 18:57:59.399334   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.399350   556 net.cpp:184] Created Layer res3a_branch2a/bn (17)
I0814 18:57:59.399355   556 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0814 18:57:59.399363   556 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0814 18:57:59.400300   556 net.cpp:245] Setting up res3a_branch2a/bn
I0814 18:57:59.400329   556 net.cpp:252] TRAIN Top shape for layer 17 'res3a_branch2a/bn' 22 128 16 16 (720896)
I0814 18:57:59.400348   556 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0814 18:57:59.403084   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.403108   556 net.cpp:184] Created Layer res3a_branch2a/relu (18)
I0814 18:57:59.403115   556 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0814 18:57:59.403126   556 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0814 18:57:59.403139   556 net.cpp:245] Setting up res3a_branch2a/relu
I0814 18:57:59.403147   556 net.cpp:252] TRAIN Top shape for layer 18 'res3a_branch2a/relu' 22 128 16 16 (720896)
I0814 18:57:59.403154   556 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0814 18:57:59.403172   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.403189   556 net.cpp:184] Created Layer res3a_branch2b (19)
I0814 18:57:59.403194   556 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0814 18:57:59.403198   556 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0814 18:57:59.408903   556 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 8.08G, req 0G)
I0814 18:57:59.408927   556 net.cpp:245] Setting up res3a_branch2b
I0814 18:57:59.408936   556 net.cpp:252] TRAIN Top shape for layer 19 'res3a_branch2b' 22 128 16 16 (720896)
I0814 18:57:59.408947   556 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0814 18:57:59.408952   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.408964   556 net.cpp:184] Created Layer res3a_branch2b/bn (20)
I0814 18:57:59.408967   556 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0814 18:57:59.408972   556 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0814 18:57:59.409687   556 net.cpp:245] Setting up res3a_branch2b/bn
I0814 18:57:59.409696   556 net.cpp:252] TRAIN Top shape for layer 20 'res3a_branch2b/bn' 22 128 16 16 (720896)
I0814 18:57:59.409703   556 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0814 18:57:59.409706   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.409713   556 net.cpp:184] Created Layer res3a_branch2b/relu (21)
I0814 18:57:59.409716   556 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0814 18:57:59.409719   556 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0814 18:57:59.409724   556 net.cpp:245] Setting up res3a_branch2b/relu
I0814 18:57:59.409729   556 net.cpp:252] TRAIN Top shape for layer 21 'res3a_branch2b/relu' 22 128 16 16 (720896)
I0814 18:57:59.409731   556 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0814 18:57:59.409734   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.409739   556 net.cpp:184] Created Layer pool3 (22)
I0814 18:57:59.409740   556 net.cpp:561] pool3 <- res3a_branch2b
I0814 18:57:59.409742   556 net.cpp:530] pool3 -> pool3
I0814 18:57:59.409803   556 net.cpp:245] Setting up pool3
I0814 18:57:59.409808   556 net.cpp:252] TRAIN Top shape for layer 22 'pool3' 22 128 16 16 (720896)
I0814 18:57:59.409811   556 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0814 18:57:59.409813   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.409822   556 net.cpp:184] Created Layer res4a_branch2a (23)
I0814 18:57:59.409826   556 net.cpp:561] res4a_branch2a <- pool3
I0814 18:57:59.409827   556 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0814 18:57:59.428618   556 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 8.05G, req 0G)
I0814 18:57:59.428637   556 net.cpp:245] Setting up res4a_branch2a
I0814 18:57:59.428642   556 net.cpp:252] TRAIN Top shape for layer 23 'res4a_branch2a' 22 256 16 16 (1441792)
I0814 18:57:59.428648   556 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0814 18:57:59.428653   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.428660   556 net.cpp:184] Created Layer res4a_branch2a/bn (24)
I0814 18:57:59.428663   556 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0814 18:57:59.428668   556 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0814 18:57:59.429316   556 net.cpp:245] Setting up res4a_branch2a/bn
I0814 18:57:59.429322   556 net.cpp:252] TRAIN Top shape for layer 24 'res4a_branch2a/bn' 22 256 16 16 (1441792)
I0814 18:57:59.429328   556 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0814 18:57:59.429342   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.429345   556 net.cpp:184] Created Layer res4a_branch2a/relu (25)
I0814 18:57:59.429347   556 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0814 18:57:59.429349   556 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0814 18:57:59.429353   556 net.cpp:245] Setting up res4a_branch2a/relu
I0814 18:57:59.429356   556 net.cpp:252] TRAIN Top shape for layer 25 'res4a_branch2a/relu' 22 256 16 16 (1441792)
I0814 18:57:59.429358   556 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0814 18:57:59.429363   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.429373   556 net.cpp:184] Created Layer res4a_branch2b (26)
I0814 18:57:59.429374   556 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0814 18:57:59.429378   556 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0814 18:57:59.437366   556 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 8.04G, req 0G)
I0814 18:57:59.437377   556 net.cpp:245] Setting up res4a_branch2b
I0814 18:57:59.437381   556 net.cpp:252] TRAIN Top shape for layer 26 'res4a_branch2b' 22 256 16 16 (1441792)
I0814 18:57:59.437386   556 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0814 18:57:59.437389   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.437394   556 net.cpp:184] Created Layer res4a_branch2b/bn (27)
I0814 18:57:59.437397   556 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0814 18:57:59.437399   556 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0814 18:57:59.438014   556 net.cpp:245] Setting up res4a_branch2b/bn
I0814 18:57:59.438021   556 net.cpp:252] TRAIN Top shape for layer 27 'res4a_branch2b/bn' 22 256 16 16 (1441792)
I0814 18:57:59.438030   556 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0814 18:57:59.438032   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.438035   556 net.cpp:184] Created Layer res4a_branch2b/relu (28)
I0814 18:57:59.438037   556 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0814 18:57:59.438040   556 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0814 18:57:59.438043   556 net.cpp:245] Setting up res4a_branch2b/relu
I0814 18:57:59.438045   556 net.cpp:252] TRAIN Top shape for layer 28 'res4a_branch2b/relu' 22 256 16 16 (1441792)
I0814 18:57:59.438047   556 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0814 18:57:59.438050   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.438053   556 net.cpp:184] Created Layer pool4 (29)
I0814 18:57:59.438055   556 net.cpp:561] pool4 <- res4a_branch2b
I0814 18:57:59.438057   556 net.cpp:530] pool4 -> pool4
I0814 18:57:59.438120   556 net.cpp:245] Setting up pool4
I0814 18:57:59.438125   556 net.cpp:252] TRAIN Top shape for layer 29 'pool4' 22 256 8 8 (360448)
I0814 18:57:59.438127   556 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0814 18:57:59.438129   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.438134   556 net.cpp:184] Created Layer res5a_branch2a (30)
I0814 18:57:59.438138   556 net.cpp:561] res5a_branch2a <- pool4
I0814 18:57:59.438139   556 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0814 18:57:59.479249   556 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 1  (limit 8.02G, req 0.01G)
I0814 18:57:59.479266   556 net.cpp:245] Setting up res5a_branch2a
I0814 18:57:59.479272   556 net.cpp:252] TRAIN Top shape for layer 30 'res5a_branch2a' 22 512 8 8 (720896)
I0814 18:57:59.479277   556 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0814 18:57:59.479281   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.479302   556 net.cpp:184] Created Layer res5a_branch2a/bn (31)
I0814 18:57:59.479305   556 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0814 18:57:59.479310   556 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0814 18:57:59.479945   556 net.cpp:245] Setting up res5a_branch2a/bn
I0814 18:57:59.479954   556 net.cpp:252] TRAIN Top shape for layer 31 'res5a_branch2a/bn' 22 512 8 8 (720896)
I0814 18:57:59.479959   556 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0814 18:57:59.479961   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.479966   556 net.cpp:184] Created Layer res5a_branch2a/relu (32)
I0814 18:57:59.479969   556 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0814 18:57:59.479970   556 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0814 18:57:59.479974   556 net.cpp:245] Setting up res5a_branch2a/relu
I0814 18:57:59.479977   556 net.cpp:252] TRAIN Top shape for layer 32 'res5a_branch2a/relu' 22 512 8 8 (720896)
I0814 18:57:59.479979   556 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0814 18:57:59.479981   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.479988   556 net.cpp:184] Created Layer res5a_branch2b (33)
I0814 18:57:59.479990   556 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0814 18:57:59.479993   556 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0814 18:57:59.498662   556 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 5  (limit 8G, req 0.01G)
I0814 18:57:59.498679   556 net.cpp:245] Setting up res5a_branch2b
I0814 18:57:59.498684   556 net.cpp:252] TRAIN Top shape for layer 33 'res5a_branch2b' 22 512 8 8 (720896)
I0814 18:57:59.498693   556 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0814 18:57:59.498697   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.498703   556 net.cpp:184] Created Layer res5a_branch2b/bn (34)
I0814 18:57:59.498706   556 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0814 18:57:59.498709   556 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0814 18:57:59.499342   556 net.cpp:245] Setting up res5a_branch2b/bn
I0814 18:57:59.499349   556 net.cpp:252] TRAIN Top shape for layer 34 'res5a_branch2b/bn' 22 512 8 8 (720896)
I0814 18:57:59.499356   556 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0814 18:57:59.499357   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.499361   556 net.cpp:184] Created Layer res5a_branch2b/relu (35)
I0814 18:57:59.499363   556 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0814 18:57:59.499366   556 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0814 18:57:59.499369   556 net.cpp:245] Setting up res5a_branch2b/relu
I0814 18:57:59.499372   556 net.cpp:252] TRAIN Top shape for layer 35 'res5a_branch2b/relu' 22 512 8 8 (720896)
I0814 18:57:59.499373   556 layer_factory.hpp:136] Creating layer 'pool5' of type 'Pooling'
I0814 18:57:59.499377   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.499379   556 net.cpp:184] Created Layer pool5 (36)
I0814 18:57:59.499382   556 net.cpp:561] pool5 <- res5a_branch2b
I0814 18:57:59.499384   556 net.cpp:530] pool5 -> pool5
I0814 18:57:59.499413   556 net.cpp:245] Setting up pool5
I0814 18:57:59.499418   556 net.cpp:252] TRAIN Top shape for layer 36 'pool5' 22 512 1 1 (11264)
I0814 18:57:59.499420   556 layer_factory.hpp:136] Creating layer 'fc10' of type 'InnerProduct'
I0814 18:57:59.499423   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.499428   556 net.cpp:184] Created Layer fc10 (37)
I0814 18:57:59.499429   556 net.cpp:561] fc10 <- pool5
I0814 18:57:59.499440   556 net.cpp:530] fc10 -> fc10
I0814 18:57:59.499701   556 net.cpp:245] Setting up fc10
I0814 18:57:59.499707   556 net.cpp:252] TRAIN Top shape for layer 37 'fc10' 22 10 (220)
I0814 18:57:59.499711   556 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0814 18:57:59.499713   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.499725   556 net.cpp:184] Created Layer loss (38)
I0814 18:57:59.499727   556 net.cpp:561] loss <- fc10
I0814 18:57:59.499730   556 net.cpp:561] loss <- label
I0814 18:57:59.499734   556 net.cpp:530] loss -> loss
I0814 18:57:59.499877   556 net.cpp:245] Setting up loss
I0814 18:57:59.499883   556 net.cpp:252] TRAIN Top shape for layer 38 'loss' (1)
I0814 18:57:59.499886   556 net.cpp:256]     with loss weight 1
I0814 18:57:59.499889   556 net.cpp:323] loss needs backward computation.
I0814 18:57:59.499891   556 net.cpp:323] fc10 needs backward computation.
I0814 18:57:59.499893   556 net.cpp:323] pool5 needs backward computation.
I0814 18:57:59.499896   556 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0814 18:57:59.499897   556 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0814 18:57:59.499898   556 net.cpp:323] res5a_branch2b needs backward computation.
I0814 18:57:59.499900   556 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0814 18:57:59.499903   556 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0814 18:57:59.499907   556 net.cpp:323] res5a_branch2a needs backward computation.
I0814 18:57:59.499910   556 net.cpp:323] pool4 needs backward computation.
I0814 18:57:59.499913   556 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0814 18:57:59.499917   556 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0814 18:57:59.499920   556 net.cpp:323] res4a_branch2b needs backward computation.
I0814 18:57:59.499923   556 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0814 18:57:59.499927   556 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0814 18:57:59.499929   556 net.cpp:323] res4a_branch2a needs backward computation.
I0814 18:57:59.499933   556 net.cpp:323] pool3 needs backward computation.
I0814 18:57:59.499935   556 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0814 18:57:59.499939   556 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0814 18:57:59.499941   556 net.cpp:323] res3a_branch2b needs backward computation.
I0814 18:57:59.499945   556 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0814 18:57:59.499948   556 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0814 18:57:59.499950   556 net.cpp:323] res3a_branch2a needs backward computation.
I0814 18:57:59.499954   556 net.cpp:323] pool2 needs backward computation.
I0814 18:57:59.499958   556 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0814 18:57:59.499961   556 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0814 18:57:59.499964   556 net.cpp:323] res2a_branch2b needs backward computation.
I0814 18:57:59.499967   556 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0814 18:57:59.499971   556 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0814 18:57:59.499974   556 net.cpp:323] res2a_branch2a needs backward computation.
I0814 18:57:59.499977   556 net.cpp:323] pool1 needs backward computation.
I0814 18:57:59.499980   556 net.cpp:323] conv1b/relu needs backward computation.
I0814 18:57:59.499984   556 net.cpp:323] conv1b/bn needs backward computation.
I0814 18:57:59.499986   556 net.cpp:323] conv1b needs backward computation.
I0814 18:57:59.499990   556 net.cpp:323] conv1a/relu needs backward computation.
I0814 18:57:59.499994   556 net.cpp:323] conv1a/bn needs backward computation.
I0814 18:57:59.499996   556 net.cpp:323] conv1a needs backward computation.
I0814 18:57:59.500000   556 net.cpp:325] data/bias does not need backward computation.
I0814 18:57:59.500005   556 net.cpp:325] data does not need backward computation.
I0814 18:57:59.500006   556 net.cpp:367] This network produces output loss
I0814 18:57:59.500041   556 net.cpp:389] Top memory (TRAIN) required for data: 121110528 diff: 121110536
I0814 18:57:59.500044   556 net.cpp:392] Bottom memory (TRAIN) required for data: 121110528 diff: 121110528
I0814 18:57:59.500046   556 net.cpp:395] Shared (in-place) memory (TRAIN) by data: 80740352 diff: 80740352
I0814 18:57:59.500049   556 net.cpp:398] Parameters memory (TRAIN) required for data: 9450960 diff: 9450960
I0814 18:57:59.500052   556 net.cpp:401] Parameters shared memory (TRAIN) by data: 0 diff: 0
I0814 18:57:59.500056   556 net.cpp:407] Network initialization done.
I0814 18:57:59.500416   556 solver.cpp:176] Creating test net (#0) specified by test_net file: training/cifar10_jacintonet11v2_2017-08-14_18-39-46/l1reg/test.prototxt
W0814 18:57:59.500460   556 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 50 to 51
I0814 18:57:59.500581   556 net.cpp:72] Initializing net from parameters: 
name: "jacintonet11v2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  transform_param {
    mirror: false
    crop_size: 32
    mean_value: 0
    mean_value: 0
    mean_value: 0
  }
  data_param {
    source: "./data/cifar10_test_lmdb"
    batch_size: 17
    backend: LMDB
    threads: 1
    parser_threads: 1
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5a_branch2b"
  top: "pool5"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "fc10"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc10"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "fc10"
  bottom: "label"
  top: "accuracy/top1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "fc10"
  bottom: "label"
  top: "accuracy/top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0814 18:57:59.500689   556 net.cpp:104] Using FLOAT as default forward math type
I0814 18:57:59.500694   556 net.cpp:110] Using FLOAT as default backward math type
I0814 18:57:59.500696   556 layer_factory.hpp:136] Creating layer 'data' of type 'Data'
I0814 18:57:59.500699   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.500711   556 net.cpp:184] Created Layer data (0)
I0814 18:57:59.500715   556 net.cpp:530] data -> data
I0814 18:57:59.500718   556 net.cpp:530] data -> label
I0814 18:57:59.500726   556 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 17
I0814 18:57:59.500735   556 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0814 18:57:59.501469   611 db_lmdb.cpp:24] Opened lmdb ./data/cifar10_test_lmdb
I0814 18:57:59.501526   556 data_layer.cpp:185] (0) ReshapePrefetch 17, 3, 32, 32
I0814 18:57:59.501590   556 data_layer.cpp:209] (0) Output data size: 17, 3, 32, 32
I0814 18:57:59.501593   556 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0814 18:57:59.501605   556 net.cpp:245] Setting up data
I0814 18:57:59.501610   556 net.cpp:252] TEST Top shape for layer 0 'data' 17 3 32 32 (52224)
I0814 18:57:59.501611   556 net.cpp:252] TEST Top shape for layer 0 'data' 17 (17)
I0814 18:57:59.501615   556 layer_factory.hpp:136] Creating layer 'label_data_1_split' of type 'Split'
I0814 18:57:59.501616   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.501621   556 net.cpp:184] Created Layer label_data_1_split (1)
I0814 18:57:59.501622   556 net.cpp:561] label_data_1_split <- label
I0814 18:57:59.501626   556 net.cpp:530] label_data_1_split -> label_data_1_split_0
I0814 18:57:59.501636   556 net.cpp:530] label_data_1_split -> label_data_1_split_1
I0814 18:57:59.501638   556 net.cpp:530] label_data_1_split -> label_data_1_split_2
I0814 18:57:59.501698   556 net.cpp:245] Setting up label_data_1_split
I0814 18:57:59.501701   556 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 17 (17)
I0814 18:57:59.501704   556 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 17 (17)
I0814 18:57:59.501708   556 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 17 (17)
I0814 18:57:59.501709   556 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0814 18:57:59.501713   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.501716   556 net.cpp:184] Created Layer data/bias (2)
I0814 18:57:59.501720   556 net.cpp:561] data/bias <- data
I0814 18:57:59.501724   556 net.cpp:530] data/bias -> data/bias
I0814 18:57:59.501852   556 net.cpp:245] Setting up data/bias
I0814 18:57:59.501858   556 net.cpp:252] TEST Top shape for layer 2 'data/bias' 17 3 32 32 (52224)
I0814 18:57:59.501865   556 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0814 18:57:59.501869   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.501879   556 net.cpp:184] Created Layer conv1a (3)
I0814 18:57:59.501883   556 net.cpp:561] conv1a <- data/bias
I0814 18:57:59.501888   556 net.cpp:530] conv1a -> conv1a
I0814 18:57:59.502287   612 data_layer.cpp:97] (0) Parser threads: 1
I0814 18:57:59.502295   612 data_layer.cpp:99] (0) Transformer threads: 1
I0814 18:57:59.504931   556 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 8G, req 0.01G)
I0814 18:57:59.504942   556 net.cpp:245] Setting up conv1a
I0814 18:57:59.504948   556 net.cpp:252] TEST Top shape for layer 3 'conv1a' 17 32 32 32 (557056)
I0814 18:57:59.504957   556 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0814 18:57:59.504961   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.504969   556 net.cpp:184] Created Layer conv1a/bn (4)
I0814 18:57:59.504972   556 net.cpp:561] conv1a/bn <- conv1a
I0814 18:57:59.504976   556 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0814 18:57:59.505594   556 net.cpp:245] Setting up conv1a/bn
I0814 18:57:59.505601   556 net.cpp:252] TEST Top shape for layer 4 'conv1a/bn' 17 32 32 32 (557056)
I0814 18:57:59.505611   556 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0814 18:57:59.505615   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.505620   556 net.cpp:184] Created Layer conv1a/relu (5)
I0814 18:57:59.505625   556 net.cpp:561] conv1a/relu <- conv1a
I0814 18:57:59.505628   556 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0814 18:57:59.505635   556 net.cpp:245] Setting up conv1a/relu
I0814 18:57:59.505640   556 net.cpp:252] TEST Top shape for layer 5 'conv1a/relu' 17 32 32 32 (557056)
I0814 18:57:59.505643   556 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0814 18:57:59.505647   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.505655   556 net.cpp:184] Created Layer conv1b (6)
I0814 18:57:59.505658   556 net.cpp:561] conv1b <- conv1a
I0814 18:57:59.505661   556 net.cpp:530] conv1b -> conv1b
I0814 18:57:59.508611   556 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'conv1b' with space 0.02G/2 1  (limit 8G, req 0.01G)
I0814 18:57:59.508621   556 net.cpp:245] Setting up conv1b
I0814 18:57:59.508627   556 net.cpp:252] TEST Top shape for layer 6 'conv1b' 17 32 32 32 (557056)
I0814 18:57:59.508636   556 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0814 18:57:59.508641   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.508647   556 net.cpp:184] Created Layer conv1b/bn (7)
I0814 18:57:59.508656   556 net.cpp:561] conv1b/bn <- conv1b
I0814 18:57:59.508661   556 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0814 18:57:59.509280   556 net.cpp:245] Setting up conv1b/bn
I0814 18:57:59.509287   556 net.cpp:252] TEST Top shape for layer 7 'conv1b/bn' 17 32 32 32 (557056)
I0814 18:57:59.509296   556 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0814 18:57:59.509300   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.509305   556 net.cpp:184] Created Layer conv1b/relu (8)
I0814 18:57:59.509310   556 net.cpp:561] conv1b/relu <- conv1b
I0814 18:57:59.509315   556 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0814 18:57:59.509320   556 net.cpp:245] Setting up conv1b/relu
I0814 18:57:59.509325   556 net.cpp:252] TEST Top shape for layer 8 'conv1b/relu' 17 32 32 32 (557056)
I0814 18:57:59.509328   556 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0814 18:57:59.509332   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.509337   556 net.cpp:184] Created Layer pool1 (9)
I0814 18:57:59.509341   556 net.cpp:561] pool1 <- conv1b
I0814 18:57:59.509344   556 net.cpp:530] pool1 -> pool1
I0814 18:57:59.509405   556 net.cpp:245] Setting up pool1
I0814 18:57:59.509412   556 net.cpp:252] TEST Top shape for layer 9 'pool1' 17 32 32 32 (557056)
I0814 18:57:59.509415   556 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0814 18:57:59.509419   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.509428   556 net.cpp:184] Created Layer res2a_branch2a (10)
I0814 18:57:59.509431   556 net.cpp:561] res2a_branch2a <- pool1
I0814 18:57:59.509435   556 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0814 18:57:59.512919   556 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.99G, req 0.01G)
I0814 18:57:59.512930   556 net.cpp:245] Setting up res2a_branch2a
I0814 18:57:59.512936   556 net.cpp:252] TEST Top shape for layer 10 'res2a_branch2a' 17 64 32 32 (1114112)
I0814 18:57:59.512944   556 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0814 18:57:59.512949   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.512955   556 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0814 18:57:59.512959   556 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0814 18:57:59.512964   556 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0814 18:57:59.513597   556 net.cpp:245] Setting up res2a_branch2a/bn
I0814 18:57:59.513604   556 net.cpp:252] TEST Top shape for layer 11 'res2a_branch2a/bn' 17 64 32 32 (1114112)
I0814 18:57:59.513612   556 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0814 18:57:59.513625   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.513630   556 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0814 18:57:59.513639   556 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0814 18:57:59.513645   556 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0814 18:57:59.513659   556 net.cpp:245] Setting up res2a_branch2a/relu
I0814 18:57:59.513664   556 net.cpp:252] TEST Top shape for layer 12 'res2a_branch2a/relu' 17 64 32 32 (1114112)
I0814 18:57:59.513671   556 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0814 18:57:59.513676   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.513689   556 net.cpp:184] Created Layer res2a_branch2b (13)
I0814 18:57:59.513692   556 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0814 18:57:59.513696   556 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0814 18:57:59.516703   556 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.98G, req 0.01G)
I0814 18:57:59.516716   556 net.cpp:245] Setting up res2a_branch2b
I0814 18:57:59.516731   556 net.cpp:252] TEST Top shape for layer 13 'res2a_branch2b' 17 64 32 32 (1114112)
I0814 18:57:59.516736   556 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0814 18:57:59.516739   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.516746   556 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0814 18:57:59.516747   556 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0814 18:57:59.516752   556 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0814 18:57:59.517403   556 net.cpp:245] Setting up res2a_branch2b/bn
I0814 18:57:59.517410   556 net.cpp:252] TEST Top shape for layer 14 'res2a_branch2b/bn' 17 64 32 32 (1114112)
I0814 18:57:59.517416   556 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0814 18:57:59.517418   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.517421   556 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0814 18:57:59.517423   556 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0814 18:57:59.517426   556 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0814 18:57:59.517429   556 net.cpp:245] Setting up res2a_branch2b/relu
I0814 18:57:59.517432   556 net.cpp:252] TEST Top shape for layer 15 'res2a_branch2b/relu' 17 64 32 32 (1114112)
I0814 18:57:59.517434   556 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0814 18:57:59.517436   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.517441   556 net.cpp:184] Created Layer pool2 (16)
I0814 18:57:59.517443   556 net.cpp:561] pool2 <- res2a_branch2b
I0814 18:57:59.517448   556 net.cpp:530] pool2 -> pool2
I0814 18:57:59.517524   556 net.cpp:245] Setting up pool2
I0814 18:57:59.517529   556 net.cpp:252] TEST Top shape for layer 16 'pool2' 17 64 16 16 (278528)
I0814 18:57:59.517534   556 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0814 18:57:59.517542   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.517554   556 net.cpp:184] Created Layer res3a_branch2a (17)
I0814 18:57:59.517563   556 net.cpp:561] res3a_branch2a <- pool2
I0814 18:57:59.517570   556 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0814 18:57:59.523484   556 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.97G, req 0.01G)
I0814 18:57:59.523495   556 net.cpp:245] Setting up res3a_branch2a
I0814 18:57:59.523500   556 net.cpp:252] TEST Top shape for layer 17 'res3a_branch2a' 17 128 16 16 (557056)
I0814 18:57:59.523506   556 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0814 18:57:59.523512   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.523520   556 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0814 18:57:59.523524   556 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0814 18:57:59.523530   556 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0814 18:57:59.524165   556 net.cpp:245] Setting up res3a_branch2a/bn
I0814 18:57:59.524173   556 net.cpp:252] TEST Top shape for layer 18 'res3a_branch2a/bn' 17 128 16 16 (557056)
I0814 18:57:59.524181   556 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0814 18:57:59.524183   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.524186   556 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0814 18:57:59.524188   556 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0814 18:57:59.524191   556 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0814 18:57:59.524195   556 net.cpp:245] Setting up res3a_branch2a/relu
I0814 18:57:59.524197   556 net.cpp:252] TEST Top shape for layer 19 'res3a_branch2a/relu' 17 128 16 16 (557056)
I0814 18:57:59.524199   556 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0814 18:57:59.524214   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.524224   556 net.cpp:184] Created Layer res3a_branch2b (20)
I0814 18:57:59.524229   556 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0814 18:57:59.524231   556 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0814 18:57:59.527416   556 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.97G, req 0.01G)
I0814 18:57:59.527426   556 net.cpp:245] Setting up res3a_branch2b
I0814 18:57:59.527431   556 net.cpp:252] TEST Top shape for layer 20 'res3a_branch2b' 17 128 16 16 (557056)
I0814 18:57:59.527437   556 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0814 18:57:59.527442   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.527449   556 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0814 18:57:59.527454   556 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0814 18:57:59.527459   556 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0814 18:57:59.528077   556 net.cpp:245] Setting up res3a_branch2b/bn
I0814 18:57:59.528085   556 net.cpp:252] TEST Top shape for layer 21 'res3a_branch2b/bn' 17 128 16 16 (557056)
I0814 18:57:59.528095   556 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0814 18:57:59.528098   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.528103   556 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0814 18:57:59.528108   556 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0814 18:57:59.528112   556 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0814 18:57:59.528120   556 net.cpp:245] Setting up res3a_branch2b/relu
I0814 18:57:59.528125   556 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b/relu' 17 128 16 16 (557056)
I0814 18:57:59.528128   556 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0814 18:57:59.528138   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.528144   556 net.cpp:184] Created Layer pool3 (23)
I0814 18:57:59.528146   556 net.cpp:561] pool3 <- res3a_branch2b
I0814 18:57:59.528149   556 net.cpp:530] pool3 -> pool3
I0814 18:57:59.528216   556 net.cpp:245] Setting up pool3
I0814 18:57:59.528221   556 net.cpp:252] TEST Top shape for layer 23 'pool3' 17 128 16 16 (557056)
I0814 18:57:59.528226   556 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0814 18:57:59.528231   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.528240   556 net.cpp:184] Created Layer res4a_branch2a (24)
I0814 18:57:59.528244   556 net.cpp:561] res4a_branch2a <- pool3
I0814 18:57:59.528247   556 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0814 18:57:59.538830   556 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.96G, req 0.01G)
I0814 18:57:59.538838   556 net.cpp:245] Setting up res4a_branch2a
I0814 18:57:59.538842   556 net.cpp:252] TEST Top shape for layer 24 'res4a_branch2a' 17 256 16 16 (1114112)
I0814 18:57:59.538846   556 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0814 18:57:59.538849   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.538853   556 net.cpp:184] Created Layer res4a_branch2a/bn (25)
I0814 18:57:59.538856   556 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0814 18:57:59.538858   556 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0814 18:57:59.539486   556 net.cpp:245] Setting up res4a_branch2a/bn
I0814 18:57:59.539494   556 net.cpp:252] TEST Top shape for layer 25 'res4a_branch2a/bn' 17 256 16 16 (1114112)
I0814 18:57:59.539499   556 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0814 18:57:59.539501   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.539510   556 net.cpp:184] Created Layer res4a_branch2a/relu (26)
I0814 18:57:59.539513   556 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0814 18:57:59.539515   556 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0814 18:57:59.539520   556 net.cpp:245] Setting up res4a_branch2a/relu
I0814 18:57:59.539522   556 net.cpp:252] TEST Top shape for layer 26 'res4a_branch2a/relu' 17 256 16 16 (1114112)
I0814 18:57:59.539525   556 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0814 18:57:59.539528   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.539539   556 net.cpp:184] Created Layer res4a_branch2b (27)
I0814 18:57:59.539544   556 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0814 18:57:59.539547   556 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0814 18:57:59.545004   556 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.95G, req 0.01G)
I0814 18:57:59.545017   556 net.cpp:245] Setting up res4a_branch2b
I0814 18:57:59.545022   556 net.cpp:252] TEST Top shape for layer 27 'res4a_branch2b' 17 256 16 16 (1114112)
I0814 18:57:59.545029   556 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0814 18:57:59.545034   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.545044   556 net.cpp:184] Created Layer res4a_branch2b/bn (28)
I0814 18:57:59.545050   556 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0814 18:57:59.545053   556 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0814 18:57:59.545740   556 net.cpp:245] Setting up res4a_branch2b/bn
I0814 18:57:59.545747   556 net.cpp:252] TEST Top shape for layer 28 'res4a_branch2b/bn' 17 256 16 16 (1114112)
I0814 18:57:59.545756   556 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0814 18:57:59.545763   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.545766   556 net.cpp:184] Created Layer res4a_branch2b/relu (29)
I0814 18:57:59.545770   556 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0814 18:57:59.545775   556 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0814 18:57:59.545783   556 net.cpp:245] Setting up res4a_branch2b/relu
I0814 18:57:59.545788   556 net.cpp:252] TEST Top shape for layer 29 'res4a_branch2b/relu' 17 256 16 16 (1114112)
I0814 18:57:59.545791   556 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0814 18:57:59.545796   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.545804   556 net.cpp:184] Created Layer pool4 (30)
I0814 18:57:59.545809   556 net.cpp:561] pool4 <- res4a_branch2b
I0814 18:57:59.545814   556 net.cpp:530] pool4 -> pool4
I0814 18:57:59.545882   556 net.cpp:245] Setting up pool4
I0814 18:57:59.545887   556 net.cpp:252] TEST Top shape for layer 30 'pool4' 17 256 8 8 (278528)
I0814 18:57:59.545892   556 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0814 18:57:59.545895   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.545905   556 net.cpp:184] Created Layer res5a_branch2a (31)
I0814 18:57:59.545909   556 net.cpp:561] res5a_branch2a <- pool4
I0814 18:57:59.545912   556 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0814 18:57:59.576697   556 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.94G, req 0.01G)
I0814 18:57:59.576719   556 net.cpp:245] Setting up res5a_branch2a
I0814 18:57:59.576726   556 net.cpp:252] TEST Top shape for layer 31 'res5a_branch2a' 17 512 8 8 (557056)
I0814 18:57:59.576735   556 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0814 18:57:59.576741   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.576767   556 net.cpp:184] Created Layer res5a_branch2a/bn (32)
I0814 18:57:59.576772   556 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0814 18:57:59.576777   556 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0814 18:57:59.577735   556 net.cpp:245] Setting up res5a_branch2a/bn
I0814 18:57:59.577745   556 net.cpp:252] TEST Top shape for layer 32 'res5a_branch2a/bn' 17 512 8 8 (557056)
I0814 18:57:59.577754   556 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0814 18:57:59.577759   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.577764   556 net.cpp:184] Created Layer res5a_branch2a/relu (33)
I0814 18:57:59.577767   556 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0814 18:57:59.577771   556 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0814 18:57:59.577778   556 net.cpp:245] Setting up res5a_branch2a/relu
I0814 18:57:59.577782   556 net.cpp:252] TEST Top shape for layer 33 'res5a_branch2a/relu' 17 512 8 8 (557056)
I0814 18:57:59.577786   556 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0814 18:57:59.577790   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.577800   556 net.cpp:184] Created Layer res5a_branch2b (34)
I0814 18:57:59.577805   556 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0814 18:57:59.577808   556 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0814 18:57:59.596637   556 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.93G, req 0.01G)
I0814 18:57:59.596652   556 net.cpp:245] Setting up res5a_branch2b
I0814 18:57:59.596657   556 net.cpp:252] TEST Top shape for layer 34 'res5a_branch2b' 17 512 8 8 (557056)
I0814 18:57:59.596665   556 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0814 18:57:59.596669   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.596676   556 net.cpp:184] Created Layer res5a_branch2b/bn (35)
I0814 18:57:59.596678   556 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0814 18:57:59.596683   556 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0814 18:57:59.597337   556 net.cpp:245] Setting up res5a_branch2b/bn
I0814 18:57:59.597344   556 net.cpp:252] TEST Top shape for layer 35 'res5a_branch2b/bn' 17 512 8 8 (557056)
I0814 18:57:59.597349   556 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0814 18:57:59.597352   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.597357   556 net.cpp:184] Created Layer res5a_branch2b/relu (36)
I0814 18:57:59.597358   556 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0814 18:57:59.597362   556 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0814 18:57:59.597364   556 net.cpp:245] Setting up res5a_branch2b/relu
I0814 18:57:59.597368   556 net.cpp:252] TEST Top shape for layer 36 'res5a_branch2b/relu' 17 512 8 8 (557056)
I0814 18:57:59.597369   556 layer_factory.hpp:136] Creating layer 'pool5' of type 'Pooling'
I0814 18:57:59.597371   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.597376   556 net.cpp:184] Created Layer pool5 (37)
I0814 18:57:59.597378   556 net.cpp:561] pool5 <- res5a_branch2b
I0814 18:57:59.597381   556 net.cpp:530] pool5 -> pool5
I0814 18:57:59.597409   556 net.cpp:245] Setting up pool5
I0814 18:57:59.597412   556 net.cpp:252] TEST Top shape for layer 37 'pool5' 17 512 1 1 (8704)
I0814 18:57:59.597415   556 layer_factory.hpp:136] Creating layer 'fc10' of type 'InnerProduct'
I0814 18:57:59.597417   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.597421   556 net.cpp:184] Created Layer fc10 (38)
I0814 18:57:59.597424   556 net.cpp:561] fc10 <- pool5
I0814 18:57:59.597425   556 net.cpp:530] fc10 -> fc10
I0814 18:57:59.597683   556 net.cpp:245] Setting up fc10
I0814 18:57:59.597698   556 net.cpp:252] TEST Top shape for layer 38 'fc10' 17 10 (170)
I0814 18:57:59.597702   556 layer_factory.hpp:136] Creating layer 'fc10_fc10_0_split' of type 'Split'
I0814 18:57:59.597704   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.597707   556 net.cpp:184] Created Layer fc10_fc10_0_split (39)
I0814 18:57:59.597709   556 net.cpp:561] fc10_fc10_0_split <- fc10
I0814 18:57:59.597712   556 net.cpp:530] fc10_fc10_0_split -> fc10_fc10_0_split_0
I0814 18:57:59.597715   556 net.cpp:530] fc10_fc10_0_split -> fc10_fc10_0_split_1
I0814 18:57:59.597718   556 net.cpp:530] fc10_fc10_0_split -> fc10_fc10_0_split_2
I0814 18:57:59.597779   556 net.cpp:245] Setting up fc10_fc10_0_split
I0814 18:57:59.597784   556 net.cpp:252] TEST Top shape for layer 39 'fc10_fc10_0_split' 17 10 (170)
I0814 18:57:59.597786   556 net.cpp:252] TEST Top shape for layer 39 'fc10_fc10_0_split' 17 10 (170)
I0814 18:57:59.597789   556 net.cpp:252] TEST Top shape for layer 39 'fc10_fc10_0_split' 17 10 (170)
I0814 18:57:59.597790   556 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0814 18:57:59.597792   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.597797   556 net.cpp:184] Created Layer loss (40)
I0814 18:57:59.597800   556 net.cpp:561] loss <- fc10_fc10_0_split_0
I0814 18:57:59.597801   556 net.cpp:561] loss <- label_data_1_split_0
I0814 18:57:59.597805   556 net.cpp:530] loss -> loss
I0814 18:57:59.597936   556 net.cpp:245] Setting up loss
I0814 18:57:59.597942   556 net.cpp:252] TEST Top shape for layer 40 'loss' (1)
I0814 18:57:59.597944   556 net.cpp:256]     with loss weight 1
I0814 18:57:59.597947   556 layer_factory.hpp:136] Creating layer 'accuracy/top1' of type 'Accuracy'
I0814 18:57:59.597950   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.597956   556 net.cpp:184] Created Layer accuracy/top1 (41)
I0814 18:57:59.597959   556 net.cpp:561] accuracy/top1 <- fc10_fc10_0_split_1
I0814 18:57:59.597960   556 net.cpp:561] accuracy/top1 <- label_data_1_split_1
I0814 18:57:59.597964   556 net.cpp:530] accuracy/top1 -> accuracy/top1
I0814 18:57:59.597967   556 net.cpp:245] Setting up accuracy/top1
I0814 18:57:59.597970   556 net.cpp:252] TEST Top shape for layer 41 'accuracy/top1' (1)
I0814 18:57:59.597971   556 layer_factory.hpp:136] Creating layer 'accuracy/top5' of type 'Accuracy'
I0814 18:57:59.597973   556 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0814 18:57:59.597976   556 net.cpp:184] Created Layer accuracy/top5 (42)
I0814 18:57:59.597980   556 net.cpp:561] accuracy/top5 <- fc10_fc10_0_split_2
I0814 18:57:59.597981   556 net.cpp:561] accuracy/top5 <- label_data_1_split_2
I0814 18:57:59.597985   556 net.cpp:530] accuracy/top5 -> accuracy/top5
I0814 18:57:59.597988   556 net.cpp:245] Setting up accuracy/top5
I0814 18:57:59.597990   556 net.cpp:252] TEST Top shape for layer 42 'accuracy/top5' (1)
I0814 18:57:59.597993   556 net.cpp:325] accuracy/top5 does not need backward computation.
I0814 18:57:59.597996   556 net.cpp:325] accuracy/top1 does not need backward computation.
I0814 18:57:59.597998   556 net.cpp:323] loss needs backward computation.
I0814 18:57:59.598001   556 net.cpp:323] fc10_fc10_0_split needs backward computation.
I0814 18:57:59.598002   556 net.cpp:323] fc10 needs backward computation.
I0814 18:57:59.598004   556 net.cpp:323] pool5 needs backward computation.
I0814 18:57:59.598007   556 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0814 18:57:59.598008   556 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0814 18:57:59.598011   556 net.cpp:323] res5a_branch2b needs backward computation.
I0814 18:57:59.598012   556 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0814 18:57:59.598016   556 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0814 18:57:59.598016   556 net.cpp:323] res5a_branch2a needs backward computation.
I0814 18:57:59.598026   556 net.cpp:323] pool4 needs backward computation.
I0814 18:57:59.598029   556 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0814 18:57:59.598031   556 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0814 18:57:59.598033   556 net.cpp:323] res4a_branch2b needs backward computation.
I0814 18:57:59.598036   556 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0814 18:57:59.598037   556 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0814 18:57:59.598039   556 net.cpp:323] res4a_branch2a needs backward computation.
I0814 18:57:59.598042   556 net.cpp:323] pool3 needs backward computation.
I0814 18:57:59.598044   556 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0814 18:57:59.598047   556 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0814 18:57:59.598048   556 net.cpp:323] res3a_branch2b needs backward computation.
I0814 18:57:59.598050   556 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0814 18:57:59.598052   556 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0814 18:57:59.598055   556 net.cpp:323] res3a_branch2a needs backward computation.
I0814 18:57:59.598057   556 net.cpp:323] pool2 needs backward computation.
I0814 18:57:59.598058   556 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0814 18:57:59.598062   556 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0814 18:57:59.598063   556 net.cpp:323] res2a_branch2b needs backward computation.
I0814 18:57:59.598065   556 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0814 18:57:59.598067   556 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0814 18:57:59.598069   556 net.cpp:323] res2a_branch2a needs backward computation.
I0814 18:57:59.598071   556 net.cpp:323] pool1 needs backward computation.
I0814 18:57:59.598074   556 net.cpp:323] conv1b/relu needs backward computation.
I0814 18:57:59.598076   556 net.cpp:323] conv1b/bn needs backward computation.
I0814 18:57:59.598078   556 net.cpp:323] conv1b needs backward computation.
I0814 18:57:59.598080   556 net.cpp:323] conv1a/relu needs backward computation.
I0814 18:57:59.598083   556 net.cpp:323] conv1a/bn needs backward computation.
I0814 18:57:59.598085   556 net.cpp:323] conv1a needs backward computation.
I0814 18:57:59.598088   556 net.cpp:325] data/bias does not need backward computation.
I0814 18:57:59.598090   556 net.cpp:325] label_data_1_split does not need backward computation.
I0814 18:57:59.598093   556 net.cpp:325] data does not need backward computation.
I0814 18:57:59.598096   556 net.cpp:367] This network produces output accuracy/top1
I0814 18:57:59.598098   556 net.cpp:367] This network produces output accuracy/top5
I0814 18:57:59.598101   556 net.cpp:367] This network produces output loss
I0814 18:57:59.598126   556 net.cpp:389] Top memory (TEST) required for data: 93585408 diff: 8
I0814 18:57:59.598129   556 net.cpp:392] Bottom memory (TEST) required for data: 93585408 diff: 93585408
I0814 18:57:59.598131   556 net.cpp:395] Shared (in-place) memory (TEST) by data: 62390272 diff: 62390272
I0814 18:57:59.598134   556 net.cpp:398] Parameters memory (TEST) required for data: 9450960 diff: 9450960
I0814 18:57:59.598135   556 net.cpp:401] Parameters shared memory (TEST) by data: 0 diff: 0
I0814 18:57:59.598137   556 net.cpp:407] Network initialization done.
I0814 18:57:59.598188   556 solver.cpp:56] Solver scaffolding done.
I0814 18:57:59.602416   556 caffe.cpp:137] Finetuning from training/cifar10_jacintonet11v2_2017-08-14_18-39-46/initial/cifar10_jacintonet11v2_iter_64000.caffemodel
I0814 18:57:59.607378   556 net.cpp:1095] Copying source layer data Type:Data #blobs=0
I0814 18:57:59.607405   556 net.cpp:1095] Copying source layer data/bias Type:Bias #blobs=1
I0814 18:57:59.607445   556 net.cpp:1095] Copying source layer conv1a Type:Convolution #blobs=2
I0814 18:57:59.607460   556 net.cpp:1095] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0814 18:57:59.607775   556 net.cpp:1095] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0814 18:57:59.607794   556 net.cpp:1095] Copying source layer conv1b Type:Convolution #blobs=2
I0814 18:57:59.607806   556 net.cpp:1095] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0814 18:57:59.608001   556 net.cpp:1095] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0814 18:57:59.608008   556 net.cpp:1095] Copying source layer pool1 Type:Pooling #blobs=0
I0814 18:57:59.608012   556 net.cpp:1095] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0814 18:57:59.608031   556 net.cpp:1095] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0814 18:57:59.608229   556 net.cpp:1095] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0814 18:57:59.608237   556 net.cpp:1095] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0814 18:57:59.608252   556 net.cpp:1095] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0814 18:57:59.608434   556 net.cpp:1095] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0814 18:57:59.608440   556 net.cpp:1095] Copying source layer pool2 Type:Pooling #blobs=0
I0814 18:57:59.608444   556 net.cpp:1095] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0814 18:57:59.608487   556 net.cpp:1095] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0814 18:57:59.608656   556 net.cpp:1095] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0814 18:57:59.608662   556 net.cpp:1095] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0814 18:57:59.608690   556 net.cpp:1095] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0814 18:57:59.608844   556 net.cpp:1095] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0814 18:57:59.608850   556 net.cpp:1095] Copying source layer pool3 Type:Pooling #blobs=0
I0814 18:57:59.608855   556 net.cpp:1095] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0814 18:57:59.608976   556 net.cpp:1095] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0814 18:57:59.609136   556 net.cpp:1095] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0814 18:57:59.609143   556 net.cpp:1095] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0814 18:57:59.609212   556 net.cpp:1095] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0814 18:57:59.609370   556 net.cpp:1095] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0814 18:57:59.609376   556 net.cpp:1095] Copying source layer pool4 Type:Pooling #blobs=0
I0814 18:57:59.609380   556 net.cpp:1095] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0814 18:57:59.609763   556 net.cpp:1095] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0814 18:57:59.609933   556 net.cpp:1095] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0814 18:57:59.609941   556 net.cpp:1095] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0814 18:57:59.610136   556 net.cpp:1095] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0814 18:57:59.610299   556 net.cpp:1095] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0814 18:57:59.610306   556 net.cpp:1095] Copying source layer pool5 Type:Pooling #blobs=0
I0814 18:57:59.610309   556 net.cpp:1095] Copying source layer fc10 Type:InnerProduct #blobs=2
I0814 18:57:59.610322   556 net.cpp:1095] Copying source layer loss Type:SoftmaxWithLoss #blobs=0
I0814 18:57:59.613785   556 net.cpp:1095] Copying source layer data Type:Data #blobs=0
I0814 18:57:59.613813   556 net.cpp:1095] Copying source layer data/bias Type:Bias #blobs=1
I0814 18:57:59.613847   556 net.cpp:1095] Copying source layer conv1a Type:Convolution #blobs=2
I0814 18:57:59.613863   556 net.cpp:1095] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0814 18:57:59.614171   556 net.cpp:1095] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0814 18:57:59.614177   556 net.cpp:1095] Copying source layer conv1b Type:Convolution #blobs=2
I0814 18:57:59.614188   556 net.cpp:1095] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0814 18:57:59.614394   556 net.cpp:1095] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0814 18:57:59.614401   556 net.cpp:1095] Copying source layer pool1 Type:Pooling #blobs=0
I0814 18:57:59.614405   556 net.cpp:1095] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0814 18:57:59.614423   556 net.cpp:1095] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0814 18:57:59.614622   556 net.cpp:1095] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0814 18:57:59.614629   556 net.cpp:1095] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0814 18:57:59.614644   556 net.cpp:1095] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0814 18:57:59.614827   556 net.cpp:1095] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0814 18:57:59.614835   556 net.cpp:1095] Copying source layer pool2 Type:Pooling #blobs=0
I0814 18:57:59.614837   556 net.cpp:1095] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0814 18:57:59.614909   556 net.cpp:1095] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0814 18:57:59.615118   556 net.cpp:1095] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0814 18:57:59.615124   556 net.cpp:1095] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0814 18:57:59.615164   556 net.cpp:1095] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0814 18:57:59.615350   556 net.cpp:1095] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0814 18:57:59.615356   556 net.cpp:1095] Copying source layer pool3 Type:Pooling #blobs=0
I0814 18:57:59.615361   556 net.cpp:1095] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0814 18:57:59.615578   556 net.cpp:1095] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0814 18:57:59.615769   556 net.cpp:1095] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0814 18:57:59.615777   556 net.cpp:1095] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0814 18:57:59.615892   556 net.cpp:1095] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0814 18:57:59.616052   556 net.cpp:1095] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0814 18:57:59.616060   556 net.cpp:1095] Copying source layer pool4 Type:Pooling #blobs=0
I0814 18:57:59.616063   556 net.cpp:1095] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0814 18:57:59.616472   556 net.cpp:1095] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0814 18:57:59.616606   556 net.cpp:1095] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0814 18:57:59.616611   556 net.cpp:1095] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0814 18:57:59.616791   556 net.cpp:1095] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0814 18:57:59.616914   556 net.cpp:1095] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0814 18:57:59.616919   556 net.cpp:1095] Copying source layer pool5 Type:Pooling #blobs=0
I0814 18:57:59.616920   556 net.cpp:1095] Copying source layer fc10 Type:InnerProduct #blobs=2
I0814 18:57:59.616931   556 net.cpp:1095] Copying source layer loss Type:SoftmaxWithLoss #blobs=0
I0814 18:57:59.617017   556 parallel.cpp:106] [0 - 0] P2pSync adding callback
I0814 18:57:59.617022   556 parallel.cpp:106] [1 - 1] P2pSync adding callback
I0814 18:57:59.617025   556 parallel.cpp:106] [2 - 2] P2pSync adding callback
I0814 18:57:59.617027   556 parallel.cpp:59] Starting Optimization
I0814 18:57:59.617030   556 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0814 18:57:59.617063   556 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0814 18:57:59.617081   556 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0814 18:57:59.617736   613 device_alternate.hpp:116] NVML initialized on thread 139686397118208
I0814 18:57:59.630224   613 common.cpp:583] NVML succeeded to set CPU affinity on device 0
I0814 18:57:59.630278   614 device_alternate.hpp:116] NVML initialized on thread 139686388725504
I0814 18:57:59.631216   614 common.cpp:583] NVML succeeded to set CPU affinity on device 1
I0814 18:57:59.631230   615 device_alternate.hpp:116] NVML initialized on thread 139686380332800
I0814 18:57:59.631891   615 common.cpp:583] NVML succeeded to set CPU affinity on device 2
I0814 18:57:59.635761   614 solver.cpp:42] Solver data type: FLOAT
W0814 18:57:59.636374   614 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 64 to 66
I0814 18:57:59.636497   614 net.cpp:104] Using FLOAT as default forward math type
I0814 18:57:59.636505   614 net.cpp:110] Using FLOAT as default backward math type
I0814 18:57:59.636553   614 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 22
I0814 18:57:59.636569   614 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0814 18:57:59.639961   615 solver.cpp:42] Solver data type: FLOAT
W0814 18:57:59.640400   615 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 64 to 66
I0814 18:57:59.640487   615 net.cpp:104] Using FLOAT as default forward math type
I0814 18:57:59.640494   615 net.cpp:110] Using FLOAT as default backward math type
I0814 18:57:59.640525   615 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 22
I0814 18:57:59.640537   615 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0814 18:57:59.640677   616 db_lmdb.cpp:24] Opened lmdb ./data/cifar10_train_lmdb
I0814 18:57:59.641551   617 db_lmdb.cpp:24] Opened lmdb ./data/cifar10_train_lmdb
I0814 18:57:59.641700   614 data_layer.cpp:185] [1] ReshapePrefetch 22, 3, 32, 32
I0814 18:57:59.642566   615 data_layer.cpp:185] [2] ReshapePrefetch 22, 3, 32, 32
I0814 18:57:59.642638   614 data_layer.cpp:209] [1] Output data size: 22, 3, 32, 32
I0814 18:57:59.642647   614 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0814 18:57:59.642693   615 data_layer.cpp:209] [2] Output data size: 22, 3, 32, 32
I0814 18:57:59.642711   615 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0814 18:58:00.106839   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.01G/1 1 0 3  (limit 8.25G, req 0G)
I0814 18:58:00.128237   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 8.23G, req 0G)
I0814 18:58:00.130591   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'conv1a' with space 0.01G/1 1 0 3  (limit 8.25G, req 0G)
I0814 18:58:00.139853   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 8.21G, req 0G)
I0814 18:58:00.140468   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 8.23G, req 0G)
I0814 18:58:00.150177   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 8.19G, req 0G)
I0814 18:58:00.154572   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 8.21G, req 0G)
I0814 18:58:00.163355   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 8.19G, req 0G)
I0814 18:58:00.164436   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 8.18G, req 0.01G)
I0814 18:58:00.172821   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 8.17G, req 0.01G)
I0814 18:58:00.177237   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 8.18G, req 0.01G)
I0814 18:58:00.184353   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 8.17G, req 0.01G)
I0814 18:58:00.197270   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 8.15G, req 0.01G)
I0814 18:58:00.207002   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 8.15G, req 0.01G)
I0814 18:58:00.207504   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 8.14G, req 0.01G)
I0814 18:58:00.215893   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 8.14G, req 0.01G)
I0814 18:58:00.252426   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 1  (limit 8.11G, req 0.01G)
I0814 18:58:00.259016   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 1  (limit 8.11G, req 0.01G)
I0814 18:58:00.272644   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 5  (limit 8.1G, req 0.01G)
I0814 18:58:00.274224   614 solver.cpp:176] Creating test net (#0) specified by test_net file: training/cifar10_jacintonet11v2_2017-08-14_18-39-46/l1reg/test.prototxt
W0814 18:58:00.274274   614 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 50 to 51
I0814 18:58:00.274351   614 net.cpp:104] Using FLOAT as default forward math type
I0814 18:58:00.274356   614 net.cpp:110] Using FLOAT as default backward math type
I0814 18:58:00.274374   614 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 17
I0814 18:58:00.274380   614 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0814 18:58:00.275141   620 db_lmdb.cpp:24] Opened lmdb ./data/cifar10_test_lmdb
I0814 18:58:00.275256   614 data_layer.cpp:185] (1) ReshapePrefetch 17, 3, 32, 32
I0814 18:58:00.275410   614 data_layer.cpp:209] (1) Output data size: 17, 3, 32, 32
I0814 18:58:00.275418   614 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0814 18:58:00.276432   621 data_layer.cpp:97] (1) Parser threads: 1
I0814 18:58:00.276439   621 data_layer.cpp:99] (1) Transformer threads: 1
I0814 18:58:00.280073   614 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 8.1G, req 0.01G)
I0814 18:58:00.282663   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 5  (limit 8.1G, req 0.01G)
I0814 18:58:00.284327   615 solver.cpp:176] Creating test net (#0) specified by test_net file: training/cifar10_jacintonet11v2_2017-08-14_18-39-46/l1reg/test.prototxt
W0814 18:58:00.284374   615 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 50 to 51
I0814 18:58:00.284453   615 net.cpp:104] Using FLOAT as default forward math type
I0814 18:58:00.284457   615 net.cpp:110] Using FLOAT as default backward math type
I0814 18:58:00.284472   615 data_reader.cpp:52] Data Reader threads: 1, out queues: 1, depth: 17
I0814 18:58:00.284479   615 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0814 18:58:00.284564   614 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'conv1b' with space 0.02G/2 1  (limit 8.09G, req 0.01G)
I0814 18:58:00.285249   622 db_lmdb.cpp:24] Opened lmdb ./data/cifar10_test_lmdb
I0814 18:58:00.285310   615 data_layer.cpp:185] (2) ReshapePrefetch 17, 3, 32, 32
I0814 18:58:00.285444   615 data_layer.cpp:209] (2) Output data size: 17, 3, 32, 32
I0814 18:58:00.285449   615 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0814 18:58:00.286301   623 data_layer.cpp:97] (2) Parser threads: 1
I0814 18:58:00.286310   623 data_layer.cpp:99] (2) Transformer threads: 1
I0814 18:58:00.289921   615 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 8.1G, req 0.01G)
I0814 18:58:00.290402   614 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 8.08G, req 0.01G)
I0814 18:58:00.294618   615 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'conv1b' with space 0.02G/2 1  (limit 8.09G, req 0.01G)
I0814 18:58:00.295430   614 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 8.08G, req 0.01G)
I0814 18:58:00.299952   615 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 8.08G, req 0.01G)
I0814 18:58:00.303792   614 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 8.07G, req 0.01G)
I0814 18:58:00.305091   615 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 8.08G, req 0.01G)
I0814 18:58:00.308926   614 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 8.06G, req 0.01G)
I0814 18:58:00.330965   615 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 8.07G, req 0.01G)
I0814 18:58:00.349627   614 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 8.05G, req 0.01G)
I0814 18:58:00.350803   615 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 8.06G, req 0.01G)
I0814 18:58:00.356366   614 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 8.05G, req 0.01G)
I0814 18:58:00.364092   615 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 8.05G, req 0.01G)
I0814 18:58:00.370630   615 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 8.05G, req 0.01G)
I0814 18:58:00.389578   614 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 8.03G, req 0.01G)
I0814 18:58:00.405167   615 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 8.03G, req 0.01G)
I0814 18:58:00.409523   614 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 8.02G, req 0.01G)
I0814 18:58:00.411995   614 solver.cpp:56] Solver scaffolding done.
I0814 18:58:00.428007   615 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 8.02G, req 0.01G)
I0814 18:58:00.429550   615 solver.cpp:56] Solver scaffolding done.
I0814 18:58:00.474635   614 parallel.cpp:161] [1 - 1] P2pSync adding callback
I0814 18:58:00.474660   615 parallel.cpp:161] [2 - 2] P2pSync adding callback
I0814 18:58:00.474660   613 parallel.cpp:161] [0 - 0] P2pSync adding callback
I0814 18:58:00.655833   615 solver.cpp:438] Solving jacintonet11v2_train
I0814 18:58:00.655853   615 solver.cpp:439] Learning Rate Policy: poly
I0814 18:58:00.655860   613 solver.cpp:438] Solving jacintonet11v2_train
I0814 18:58:00.655869   613 solver.cpp:439] Learning Rate Policy: poly
I0814 18:58:00.655889   614 solver.cpp:438] Solving jacintonet11v2_train
I0814 18:58:00.655897   614 solver.cpp:439] Learning Rate Policy: poly
I0814 18:58:00.662636   614 solver.cpp:227] Starting Optimization on GPU 1
I0814 18:58:00.662642   615 solver.cpp:227] Starting Optimization on GPU 2
I0814 18:58:00.662672   613 solver.cpp:227] Starting Optimization on GPU 0
I0814 18:58:00.662794   613 solver.cpp:509] Iteration 0, Testing net (#0)
I0814 18:58:00.662796   640 device_alternate.hpp:116] NVML initialized on thread 139685616518912
I0814 18:58:00.662834   640 common.cpp:583] NVML succeeded to set CPU affinity on device 2
I0814 18:58:00.663596   641 device_alternate.hpp:116] NVML initialized on thread 139685624911616
I0814 18:58:00.663611   641 common.cpp:583] NVML succeeded to set CPU affinity on device 1
I0814 18:58:00.663621   642 device_alternate.hpp:116] NVML initialized on thread 139685608126208
I0814 18:58:00.663642   642 common.cpp:583] NVML succeeded to set CPU affinity on device 0
I0814 18:58:00.672150   614 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 7.99G, req 0.01G)
I0814 18:58:00.672612   615 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'conv1a' with space 0.02G/1 1  (limit 7.99G, req 0.01G)
I0814 18:58:00.677130   614 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'conv1b' with space 0.02G/2 1  (limit 7.98G, req 0.01G)
I0814 18:58:00.677780   615 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'conv1b' with space 0.02G/2 1  (limit 7.98G, req 0.01G)
I0814 18:58:00.680330   613 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'conv1a' with space 0.01G/1 1  (limit 7.92G, req 0G)
I0814 18:58:00.684980   614 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.97G, req 0.01G)
I0814 18:58:00.686468   615 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.97G, req 0.01G)
I0814 18:58:00.689206   613 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'conv1b' with space 0.02G/2 1  (limit 7.9G, req 0G)
I0814 18:58:00.690688   614 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.96G, req 0.01G)
I0814 18:58:00.691998   615 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.96G, req 0.01G)
I0814 18:58:00.697806   613 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res2a_branch2a' with space 0.02G/1 6  (limit 7.89G, req 0G)
I0814 18:58:00.698791   614 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.94G, req 0.01G)
I0814 18:58:00.699388   615 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.94G, req 0.01G)
I0814 18:58:00.704150   613 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res2a_branch2b' with space 0.02G/2 6  (limit 7.88G, req 0G)
I0814 18:58:00.705171   614 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.94G, req 0.01G)
I0814 18:58:00.705519   615 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.94G, req 0.01G)
I0814 18:58:00.711588   613 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res3a_branch2a' with space 0.02G/1 6  (limit 7.86G, req 0G)
I0814 18:58:00.714012   614 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.92G, req 0.01G)
I0814 18:58:00.714648   615 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.92G, req 0.01G)
I0814 18:58:00.716493   613 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res3a_branch2b' with space 0.02G/2 6  (limit 7.85G, req 0G)
I0814 18:58:00.721395   614 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.91G, req 0.01G)
I0814 18:58:00.721773   615 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.91G, req 0.01G)
I0814 18:58:00.724592   613 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res4a_branch2a' with space 0.02G/1 6  (limit 7.84G, req 0G)
I0814 18:58:00.729332   613 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res4a_branch2b' with space 0.02G/2 6  (limit 7.83G, req 0G)
I0814 18:58:00.732103   614 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.9G, req 0.01G)
I0814 18:58:00.732488   615 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.9G, req 0.01G)
I0814 18:58:00.736973   613 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res5a_branch2a' with space 0.02G/1 1  (limit 7.81G, req 0G)
I0814 18:58:00.737758   614 cudnn_conv_layer.cpp:1010] (1) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.89G, req 0.01G)
I0814 18:58:00.738447   615 cudnn_conv_layer.cpp:1010] (2) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.89G, req 0.01G)
I0814 18:58:00.743052   613 cudnn_conv_layer.cpp:1010] (0) Conv Algo (F): 'res5a_branch2b' with space 0.02G/2 6  (limit 7.8G, req 0G)
I0814 18:58:00.745635   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 1
I0814 18:58:00.745646   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 1
I0814 18:58:00.745651   613 solver.cpp:594]     Test net output #2: loss = 0.0157617 (* 1 = 0.0157617 loss)
I0814 18:58:00.745656   613 solver.cpp:254] [MultiGPU] Initial Test completed
I0814 18:58:00.745671   613 blocking_queue.cpp:40] Data layer prefetch queue empty
I0814 18:58:00.755549   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 3  (limit 7.88G, req 0.01G)
I0814 18:58:00.755846   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 3  (limit 7.88G, req 0.01G)
I0814 18:58:00.756314   613 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.02G/1 1 0 3  (limit 7.8G, req 0G)
I0814 18:58:00.764144   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 7.87G, req 0.01G)
I0814 18:58:00.765630   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 7.87G, req 0.01G)
I0814 18:58:00.766041   613 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'conv1b' with space 0.02G/2 1 1 3  (limit 7.79G, req 0G)
I0814 18:58:00.774771   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 7.86G, req 0.01G)
I0814 18:58:00.776578   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 7.86G, req 0.01G)
I0814 18:58:00.777418   613 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 0.02G/1 6 4 3  (limit 7.77G, req 0G)
I0814 18:58:00.783592   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 7.85G, req 0.01G)
I0814 18:58:00.785780   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 7.85G, req 0.01G)
I0814 18:58:00.786193   613 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 0.02G/2 6 4 3  (limit 7.76G, req 0G)
I0814 18:58:00.794153   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 7.83G, req 0.01G)
I0814 18:58:00.797289   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 7.83G, req 0.01G)
I0814 18:58:00.797729   613 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 0.02G/1 6 4 5  (limit 7.75G, req 0.01G)
I0814 18:58:00.800206   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 7.82G, req 0.01G)
I0814 18:58:00.804668   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 7.82G, req 0.01G)
I0814 18:58:00.804935   613 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 0.02G/2 6 4 3  (limit 7.74G, req 0.01G)
I0814 18:58:00.814416   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 7.81G, req 0.01G)
I0814 18:58:00.819767   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 7.81G, req 0.01G)
I0814 18:58:00.820945   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 7.8G, req 0.01G)
I0814 18:58:00.821667   613 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 0.02G/1 6 4 1  (limit 7.72G, req 0.01G)
I0814 18:58:00.827654   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 7.8G, req 0.01G)
I0814 18:58:00.829885   613 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 0.02G/2 6 4 3  (limit 7.71G, req 0.01G)
I0814 18:58:00.840168   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 1  (limit 7.78G, req 0.01G)
I0814 18:58:00.845576   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 1  (limit 7.78G, req 0.01G)
I0814 18:58:00.848228   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 5  (limit 7.77G, req 0.01G)
I0814 18:58:00.848793   613 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 0.02G/1 6 4 1  (limit 7.69G, req 0.01G)
I0814 18:58:00.853555   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 5  (limit 7.77G, req 0.01G)
I0814 18:58:00.856276   613 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 0.02G/2 6 4 5  (limit 7.68G, req 0.01G)
I0814 18:58:00.886109   618 data_layer.cpp:97] [1] Parser threads: 1
I0814 18:58:00.886127   618 data_layer.cpp:99] [1] Transformer threads: 1
I0814 18:58:00.895926   619 data_layer.cpp:97] [2] Parser threads: 1
I0814 18:58:00.895938   619 data_layer.cpp:99] [2] Transformer threads: 1
I0814 18:58:00.899823   595 data_layer.cpp:97] [0] Parser threads: 1
I0814 18:58:00.899838   595 data_layer.cpp:99] [0] Transformer threads: 1
I0814 18:58:00.905618   613 solver.cpp:317] Iteration 0 (0.159937 s), loss = 0.000548466
I0814 18:58:00.905635   613 solver.cpp:334]     Train net output #0: loss = 0.000548466 (* 1 = 0.000548466 loss)
I0814 18:58:00.905642   613 sgd_solver.cpp:136] Iteration 0, lr = 0.01, m = 0.9
I0814 18:58:00.934574   613 solver.cpp:317] Iteration 1 (0.0289444 s), loss = 0.00309271
I0814 18:58:00.934600   613 solver.cpp:334]     Train net output #0: loss = 0.00309271 (* 1 = 0.00309271 loss)
I0814 18:58:00.950670   613 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'conv1a' with space 0.64G/1 1 0 3  (limit 6.98G, req 0.01G)
I0814 18:58:00.951123   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'conv1a' with space 0.64G/1 1 0 3  (limit 7.07G, req 0.01G)
I0814 18:58:00.951709   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'conv1a' with space 0.64G/1 1 0 3  (limit 7.07G, req 0.01G)
I0814 18:58:00.959046   613 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'conv1b' with space 1.29G/2 1 1 3  (limit 6.34G, req 0.01G)
I0814 18:58:00.962069   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'conv1b' with space 1.29G/2 1 1 3  (limit 6.43G, req 0.01G)
I0814 18:58:00.962230   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'conv1b' with space 1.29G/2 1 1 3  (limit 6.43G, req 0.01G)
I0814 18:58:00.971765   613 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 1.29G/1 6 4 1  (limit 6.34G, req 0.01G)
I0814 18:58:00.976080   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 1.29G/1 6 4 3  (limit 6.43G, req 0.01G)
I0814 18:58:00.976320   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 1.29G/1 6 4 3  (limit 6.43G, req 0.01G)
I0814 18:58:00.978543   613 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 1.29G/2 6 4 3  (limit 6.34G, req 0.01G)
I0814 18:58:00.983597   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 1.29G/2 6 4 3  (limit 6.43G, req 0.01G)
I0814 18:58:00.984035   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 1.29G/2 6 4 3  (limit 6.43G, req 0.01G)
I0814 18:58:00.987265   613 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 1.29G/1 6 4 5  (limit 6.34G, req 0.01G)
I0814 18:58:00.991374   613 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 1.29G/2 6 4 3  (limit 6.34G, req 0.01G)
I0814 18:58:00.993340   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 1.29G/1 6 4 5  (limit 6.43G, req 0.01G)
I0814 18:58:00.993840   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 1.29G/1 6 4 5  (limit 6.43G, req 0.01G)
I0814 18:58:00.998183   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 1.29G/2 6 4 3  (limit 6.43G, req 0.01G)
I0814 18:58:00.998622   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 1.29G/2 6 4 3  (limit 6.43G, req 0.01G)
I0814 18:58:01.013521   613 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 1.29G/1 6 4 5  (limit 6.34G, req 0.02G)
I0814 18:58:01.020581   613 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 1.29G/2 6 4 3  (limit 6.34G, req 0.02G)
I0814 18:58:01.022765   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 1.29G/1 6 4 5  (limit 6.43G, req 0.02G)
I0814 18:58:01.023008   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 1.29G/1 6 4 5  (limit 6.43G, req 0.02G)
I0814 18:58:01.030165   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 1.29G/2 6 4 3  (limit 6.43G, req 0.02G)
I0814 18:58:01.031278   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 1.29G/2 6 4 3  (limit 6.43G, req 0.02G)
I0814 18:58:01.054518   613 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 1.29G/1 7 5 5  (limit 6.34G, req 0.03G)
I0814 18:58:01.062980   613 cudnn_conv_layer.cpp:1010] [0] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 1.29G/2 6 4 5  (limit 6.34G, req 0.03G)
I0814 18:58:01.066308   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 1.29G/1 7 5 5  (limit 6.43G, req 0.03G)
I0814 18:58:01.070242   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res5a_branch2a' with space 1.29G/1 7 5 5  (limit 6.43G, req 0.03G)
I0814 18:58:01.076056   614 cudnn_conv_layer.cpp:1010] [1] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 1.29G/2 6 4 5  (limit 6.43G, req 0.03G)
I0814 18:58:01.078339   615 cudnn_conv_layer.cpp:1010] [2] Conv Algos (F,BD,BF): 'res5a_branch2b' with space 1.29G/2 6 4 5  (limit 6.43G, req 0.03G)
I0814 18:58:01.091893   613 solver.cpp:317] Iteration 2 (0.15731 s), loss = 0.00064818
I0814 18:58:01.091922   613 solver.cpp:334]     Train net output #0: loss = 0.00064818 (* 1 = 0.00064818 loss)
I0814 18:58:01.091962   613 cudnn_conv_layer.cpp:292] [0] Layer 'conv1a' reallocating workspace: 1.29G -> 0.07G
I0814 18:58:01.091964   614 cudnn_conv_layer.cpp:292] [1] Layer 'conv1a' reallocating workspace: 1.29G -> 0.07G
I0814 18:58:01.092200   615 cudnn_conv_layer.cpp:292] [2] Layer 'conv1a' reallocating workspace: 1.29G -> 0.07G
I0814 18:58:02.694392   613 solver.cpp:312] Iteration 100 (61.1564 iter/s, 1.60245s/98 iter), loss = 0.00096959
I0814 18:58:02.694568   613 solver.cpp:334]     Train net output #0: loss = 0.00096959 (* 1 = 0.00096959 loss)
I0814 18:58:02.694641   613 sgd_solver.cpp:136] Iteration 100, lr = 0.00998437, m = 0.9
I0814 18:58:04.294579   613 solver.cpp:312] Iteration 200 (62.4946 iter/s, 1.60014s/100 iter), loss = 0.00222569
I0814 18:58:04.294603   613 solver.cpp:334]     Train net output #0: loss = 0.00222569 (* 1 = 0.00222569 loss)
I0814 18:58:04.294608   613 sgd_solver.cpp:136] Iteration 200, lr = 0.00996875, m = 0.9
I0814 18:58:05.923637   613 solver.cpp:312] Iteration 300 (61.3869 iter/s, 1.62901s/100 iter), loss = 0.000549344
I0814 18:58:05.923661   613 solver.cpp:334]     Train net output #0: loss = 0.000549344 (* 1 = 0.000549344 loss)
I0814 18:58:05.923667   613 sgd_solver.cpp:136] Iteration 300, lr = 0.00995312, m = 0.9
I0814 18:58:07.560977   613 solver.cpp:312] Iteration 400 (61.0766 iter/s, 1.63729s/100 iter), loss = 0.000610687
I0814 18:58:07.561024   613 solver.cpp:334]     Train net output #0: loss = 0.000610687 (* 1 = 0.000610687 loss)
I0814 18:58:07.561036   613 sgd_solver.cpp:136] Iteration 400, lr = 0.0099375, m = 0.9
I0814 18:58:09.142563   613 solver.cpp:312] Iteration 500 (63.2297 iter/s, 1.58154s/100 iter), loss = 0.00207446
I0814 18:58:09.142587   613 solver.cpp:334]     Train net output #0: loss = 0.00207446 (* 1 = 0.00207446 loss)
I0814 18:58:09.142593   613 sgd_solver.cpp:136] Iteration 500, lr = 0.00992187, m = 0.9
I0814 18:58:10.761804   613 solver.cpp:312] Iteration 600 (61.7591 iter/s, 1.61919s/100 iter), loss = 0.00105794
I0814 18:58:10.761828   613 solver.cpp:334]     Train net output #0: loss = 0.00105794 (* 1 = 0.00105794 loss)
I0814 18:58:10.761834   613 sgd_solver.cpp:136] Iteration 600, lr = 0.00990625, m = 0.9
I0814 18:58:12.366839   613 solver.cpp:312] Iteration 700 (62.3059 iter/s, 1.60498s/100 iter), loss = 0.000622428
I0814 18:58:12.366897   613 solver.cpp:334]     Train net output #0: loss = 0.000622429 (* 1 = 0.000622429 loss)
I0814 18:58:12.366922   613 sgd_solver.cpp:136] Iteration 700, lr = 0.00989062, m = 0.9
I0814 18:58:13.231541   592 data_reader.cpp:288] Starting prefetch of epoch 1
I0814 18:58:13.976851   613 solver.cpp:312] Iteration 800 (62.1132 iter/s, 1.60996s/100 iter), loss = 0.00091661
I0814 18:58:13.976914   613 solver.cpp:334]     Train net output #0: loss = 0.000916611 (* 1 = 0.000916611 loss)
I0814 18:58:13.976933   613 sgd_solver.cpp:136] Iteration 800, lr = 0.009875, m = 0.9
I0814 18:58:15.602308   613 solver.cpp:312] Iteration 900 (61.523 iter/s, 1.62541s/100 iter), loss = 0.000823716
I0814 18:58:15.602355   613 solver.cpp:334]     Train net output #0: loss = 0.000823718 (* 1 = 0.000823718 loss)
I0814 18:58:15.602366   613 sgd_solver.cpp:136] Iteration 900, lr = 0.00985937, m = 0.9
I0814 18:58:17.208395   613 solver.cpp:509] Iteration 1000, Testing net (#0)
I0814 18:58:18.045778   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.914413
I0814 18:58:18.045796   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.996471
I0814 18:58:18.045804   613 solver.cpp:594]     Test net output #2: loss = 0.307134 (* 1 = 0.307134 loss)
I0814 18:58:18.045822   613 solver.cpp:264] [MultiGPU] Tests completed in 0.837406s
I0814 18:58:18.061470   613 solver.cpp:312] Iteration 1000 (40.6654 iter/s, 2.45909s/100 iter), loss = 0.00108904
I0814 18:58:18.061487   613 solver.cpp:334]     Train net output #0: loss = 0.00108904 (* 1 = 0.00108904 loss)
I0814 18:58:18.061493   613 sgd_solver.cpp:136] Iteration 1000, lr = 0.00984375, m = 0.9
I0814 18:58:19.709295   613 solver.cpp:312] Iteration 1100 (60.6879 iter/s, 1.64777s/100 iter), loss = 0.000795235
I0814 18:58:19.709342   613 solver.cpp:334]     Train net output #0: loss = 0.000795236 (* 1 = 0.000795236 loss)
I0814 18:58:19.709354   613 sgd_solver.cpp:136] Iteration 1100, lr = 0.00982813, m = 0.9
I0814 18:58:21.293243   613 solver.cpp:312] Iteration 1200 (63.1353 iter/s, 1.5839s/100 iter), loss = 0.00101821
I0814 18:58:21.293269   613 solver.cpp:334]     Train net output #0: loss = 0.00101821 (* 1 = 0.00101821 loss)
I0814 18:58:21.293275   613 sgd_solver.cpp:136] Iteration 1200, lr = 0.0098125, m = 0.9
I0814 18:58:22.885113   613 solver.cpp:312] Iteration 1300 (62.8211 iter/s, 1.59182s/100 iter), loss = 0.00055598
I0814 18:58:22.885295   613 solver.cpp:334]     Train net output #0: loss = 0.000555982 (* 1 = 0.000555982 loss)
I0814 18:58:22.885390   613 sgd_solver.cpp:136] Iteration 1300, lr = 0.00979687, m = 0.9
I0814 18:58:24.511551   613 solver.cpp:312] Iteration 1400 (61.4859 iter/s, 1.62639s/100 iter), loss = 0.00180588
I0814 18:58:24.511597   613 solver.cpp:334]     Train net output #0: loss = 0.00180588 (* 1 = 0.00180588 loss)
I0814 18:58:24.511610   613 sgd_solver.cpp:136] Iteration 1400, lr = 0.00978125, m = 0.9
I0814 18:58:26.133632   613 solver.cpp:312] Iteration 1500 (61.6511 iter/s, 1.62203s/100 iter), loss = 0.00105548
I0814 18:58:26.133657   613 solver.cpp:334]     Train net output #0: loss = 0.00105548 (* 1 = 0.00105548 loss)
I0814 18:58:26.133662   613 sgd_solver.cpp:136] Iteration 1500, lr = 0.00976562, m = 0.9
I0814 18:58:27.763067   613 solver.cpp:312] Iteration 1600 (61.3728 iter/s, 1.62939s/100 iter), loss = 0.000856867
I0814 18:58:27.763092   613 solver.cpp:334]     Train net output #0: loss = 0.000856868 (* 1 = 0.000856868 loss)
I0814 18:58:27.763098   613 sgd_solver.cpp:136] Iteration 1600, lr = 0.00975, m = 0.9
I0814 18:58:29.404562   613 solver.cpp:312] Iteration 1700 (60.9219 iter/s, 1.64145s/100 iter), loss = 0.000658037
I0814 18:58:29.404639   613 solver.cpp:334]     Train net output #0: loss = 0.000658039 (* 1 = 0.000658039 loss)
I0814 18:58:29.404651   613 sgd_solver.cpp:136] Iteration 1700, lr = 0.00973437, m = 0.9
I0814 18:58:30.991829   613 solver.cpp:312] Iteration 1800 (63.0033 iter/s, 1.58722s/100 iter), loss = 0.00117118
I0814 18:58:30.991876   613 solver.cpp:334]     Train net output #0: loss = 0.00117118 (* 1 = 0.00117118 loss)
I0814 18:58:30.991888   613 sgd_solver.cpp:136] Iteration 1800, lr = 0.00971875, m = 0.9
I0814 18:58:32.586118   613 solver.cpp:312] Iteration 1900 (62.7258 iter/s, 1.59424s/100 iter), loss = 0.00158526
I0814 18:58:32.586168   613 solver.cpp:334]     Train net output #0: loss = 0.00158526 (* 1 = 0.00158526 loss)
I0814 18:58:32.586180   613 sgd_solver.cpp:136] Iteration 1900, lr = 0.00970312, m = 0.9
I0814 18:58:34.226788   613 solver.cpp:509] Iteration 2000, Testing net (#0)
I0814 18:58:35.040240   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.91206
I0814 18:58:35.040256   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.996765
I0814 18:58:35.040263   613 solver.cpp:594]     Test net output #2: loss = 0.306596 (* 1 = 0.306596 loss)
I0814 18:58:35.040282   613 solver.cpp:264] [MultiGPU] Tests completed in 0.813471s
I0814 18:58:35.055939   613 solver.cpp:312] Iteration 2000 (40.4899 iter/s, 2.46975s/100 iter), loss = 0.000787644
I0814 18:58:35.055956   613 solver.cpp:334]     Train net output #0: loss = 0.000787645 (* 1 = 0.000787645 loss)
I0814 18:58:35.055963   613 sgd_solver.cpp:136] Iteration 2000, lr = 0.0096875, m = 0.9
I0814 18:58:36.668682   613 solver.cpp:312] Iteration 2100 (62.0081 iter/s, 1.61269s/100 iter), loss = 0.00090322
I0814 18:58:36.668706   613 solver.cpp:334]     Train net output #0: loss = 0.000903221 (* 1 = 0.000903221 loss)
I0814 18:58:36.668711   613 sgd_solver.cpp:136] Iteration 2100, lr = 0.00967188, m = 0.9
I0814 18:58:38.286005   613 solver.cpp:312] Iteration 2200 (61.8324 iter/s, 1.61727s/100 iter), loss = 0.000534815
I0814 18:58:38.286069   613 solver.cpp:334]     Train net output #0: loss = 0.000534816 (* 1 = 0.000534816 loss)
I0814 18:58:38.286089   613 sgd_solver.cpp:136] Iteration 2200, lr = 0.00965625, m = 0.9
I0814 18:58:39.902894   613 solver.cpp:312] Iteration 2300 (61.849 iter/s, 1.61684s/100 iter), loss = 0.00118112
I0814 18:58:39.902920   613 solver.cpp:334]     Train net output #0: loss = 0.00118112 (* 1 = 0.00118112 loss)
I0814 18:58:39.902928   613 sgd_solver.cpp:136] Iteration 2300, lr = 0.00964062, m = 0.9
I0814 18:58:41.535922   613 solver.cpp:312] Iteration 2400 (61.238 iter/s, 1.63297s/100 iter), loss = 0.00106256
I0814 18:58:41.536255   613 solver.cpp:334]     Train net output #0: loss = 0.00106256 (* 1 = 0.00106256 loss)
I0814 18:58:41.536273   613 sgd_solver.cpp:136] Iteration 2400, lr = 0.009625, m = 0.9
I0814 18:58:43.173405   613 solver.cpp:312] Iteration 2500 (61.0712 iter/s, 1.63743s/100 iter), loss = 0.000910575
I0814 18:58:43.173430   613 solver.cpp:334]     Train net output #0: loss = 0.000910576 (* 1 = 0.000910576 loss)
I0814 18:58:43.173436   613 sgd_solver.cpp:136] Iteration 2500, lr = 0.00960938, m = 0.9
I0814 18:58:44.829327   613 solver.cpp:312] Iteration 2600 (60.3911 iter/s, 1.65587s/100 iter), loss = 0.00105894
I0814 18:58:44.829352   613 solver.cpp:334]     Train net output #0: loss = 0.00105894 (* 1 = 0.00105894 loss)
I0814 18:58:44.829358   613 sgd_solver.cpp:136] Iteration 2600, lr = 0.00959375, m = 0.9
I0814 18:58:46.421227   613 solver.cpp:312] Iteration 2700 (62.82 iter/s, 1.59185s/100 iter), loss = 0.000250533
I0814 18:58:46.421291   613 solver.cpp:334]     Train net output #0: loss = 0.000250535 (* 1 = 0.000250535 loss)
I0814 18:58:46.421310   613 sgd_solver.cpp:136] Iteration 2700, lr = 0.00957812, m = 0.9
I0814 18:58:48.067821   613 solver.cpp:312] Iteration 2800 (60.7332 iter/s, 1.64655s/100 iter), loss = 0.00105618
I0814 18:58:48.067845   613 solver.cpp:334]     Train net output #0: loss = 0.00105618 (* 1 = 0.00105618 loss)
I0814 18:58:48.067850   613 sgd_solver.cpp:136] Iteration 2800, lr = 0.0095625, m = 0.9
I0814 18:58:49.724416   613 solver.cpp:312] Iteration 2900 (60.3667 iter/s, 1.65654s/100 iter), loss = 0.000324261
I0814 18:58:49.724474   613 solver.cpp:334]     Train net output #0: loss = 0.000324263 (* 1 = 0.000324263 loss)
I0814 18:58:49.724493   613 sgd_solver.cpp:136] Iteration 2900, lr = 0.00954687, m = 0.9
I0814 18:58:51.330724   613 solver.cpp:509] Iteration 3000, Testing net (#0)
I0814 18:58:52.141471   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.914119
I0814 18:58:52.141490   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.996177
I0814 18:58:52.141497   613 solver.cpp:594]     Test net output #2: loss = 0.301904 (* 1 = 0.301904 loss)
I0814 18:58:52.141515   613 solver.cpp:264] [MultiGPU] Tests completed in 0.810769s
I0814 18:58:52.157130   613 solver.cpp:312] Iteration 3000 (41.1075 iter/s, 2.43265s/100 iter), loss = 0.000712715
I0814 18:58:52.157160   613 solver.cpp:334]     Train net output #0: loss = 0.000712717 (* 1 = 0.000712717 loss)
I0814 18:58:52.157172   613 sgd_solver.cpp:136] Iteration 3000, lr = 0.00953125, m = 0.9
I0814 18:58:53.792516   613 solver.cpp:312] Iteration 3100 (61.1496 iter/s, 1.63533s/100 iter), loss = 0.000373582
I0814 18:58:53.792542   613 solver.cpp:334]     Train net output #0: loss = 0.000373585 (* 1 = 0.000373585 loss)
I0814 18:58:53.792548   613 sgd_solver.cpp:136] Iteration 3100, lr = 0.00951563, m = 0.9
I0814 18:58:55.432726   613 solver.cpp:312] Iteration 3200 (60.9697 iter/s, 1.64016s/100 iter), loss = 0.000884733
I0814 18:58:55.432754   613 solver.cpp:334]     Train net output #0: loss = 0.000884735 (* 1 = 0.000884735 loss)
I0814 18:58:55.432761   613 sgd_solver.cpp:136] Iteration 3200, lr = 0.0095, m = 0.9
I0814 18:58:57.039791   613 solver.cpp:312] Iteration 3300 (62.2272 iter/s, 1.60702s/100 iter), loss = 0.000937286
I0814 18:58:57.039841   613 solver.cpp:334]     Train net output #0: loss = 0.000937289 (* 1 = 0.000937289 loss)
I0814 18:58:57.039855   613 sgd_solver.cpp:136] Iteration 3300, lr = 0.00948437, m = 0.9
I0814 18:58:58.696647   613 solver.cpp:312] Iteration 3400 (60.357 iter/s, 1.65681s/100 iter), loss = 0.000920437
I0814 18:58:58.696696   613 solver.cpp:334]     Train net output #0: loss = 0.000920439 (* 1 = 0.000920439 loss)
I0814 18:58:58.696710   613 sgd_solver.cpp:136] Iteration 3400, lr = 0.00946875, m = 0.9
I0814 18:59:00.363884   613 solver.cpp:312] Iteration 3500 (59.9813 iter/s, 1.66719s/100 iter), loss = 0.00241712
I0814 18:59:00.363986   613 solver.cpp:334]     Train net output #0: loss = 0.00241713 (* 1 = 0.00241713 loss)
I0814 18:59:00.363992   613 sgd_solver.cpp:136] Iteration 3500, lr = 0.00945312, m = 0.9
I0814 18:59:02.020522   613 solver.cpp:312] Iteration 3600 (60.3651 iter/s, 1.65659s/100 iter), loss = 0.00146104
I0814 18:59:02.020550   613 solver.cpp:334]     Train net output #0: loss = 0.00146105 (* 1 = 0.00146105 loss)
I0814 18:59:02.020555   613 sgd_solver.cpp:136] Iteration 3600, lr = 0.0094375, m = 0.9
I0814 18:59:03.623626   613 solver.cpp:312] Iteration 3700 (62.3809 iter/s, 1.60305s/100 iter), loss = 0.00051913
I0814 18:59:03.623693   613 solver.cpp:334]     Train net output #0: loss = 0.000519133 (* 1 = 0.000519133 loss)
I0814 18:59:03.623715   613 sgd_solver.cpp:136] Iteration 3700, lr = 0.00942187, m = 0.9
I0814 18:59:05.234933   613 solver.cpp:312] Iteration 3800 (62.0632 iter/s, 1.61126s/100 iter), loss = 0.00115885
I0814 18:59:05.234958   613 solver.cpp:334]     Train net output #0: loss = 0.00115885 (* 1 = 0.00115885 loss)
I0814 18:59:05.234964   613 sgd_solver.cpp:136] Iteration 3800, lr = 0.00940625, m = 0.9
I0814 18:59:06.874492   613 solver.cpp:312] Iteration 3900 (60.9939 iter/s, 1.63951s/100 iter), loss = 0.00281817
I0814 18:59:06.874517   613 solver.cpp:334]     Train net output #0: loss = 0.00281817 (* 1 = 0.00281817 loss)
I0814 18:59:06.874523   613 sgd_solver.cpp:136] Iteration 3900, lr = 0.00939062, m = 0.9
I0814 18:59:08.492553   613 solver.cpp:509] Iteration 4000, Testing net (#0)
I0814 18:59:09.310694   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.919118
I0814 18:59:09.310714   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.996471
I0814 18:59:09.310719   613 solver.cpp:594]     Test net output #2: loss = 0.285206 (* 1 = 0.285206 loss)
I0814 18:59:09.310732   613 solver.cpp:264] [MultiGPU] Tests completed in 0.81816s
I0814 18:59:09.332589   613 solver.cpp:312] Iteration 4000 (40.683 iter/s, 2.45803s/100 iter), loss = 0.000766689
I0814 18:59:09.332607   613 solver.cpp:334]     Train net output #0: loss = 0.000766691 (* 1 = 0.000766691 loss)
I0814 18:59:09.332612   613 sgd_solver.cpp:136] Iteration 4000, lr = 0.009375, m = 0.9
I0814 18:59:10.934617   613 solver.cpp:312] Iteration 4100 (62.4228 iter/s, 1.60198s/100 iter), loss = 0.000855702
I0814 18:59:10.934682   613 solver.cpp:334]     Train net output #0: loss = 0.000855704 (* 1 = 0.000855704 loss)
I0814 18:59:10.934701   613 sgd_solver.cpp:136] Iteration 4100, lr = 0.00935937, m = 0.9
I0814 18:59:12.590566   613 solver.cpp:312] Iteration 4200 (60.3902 iter/s, 1.6559s/100 iter), loss = 0.000800785
I0814 18:59:12.590613   613 solver.cpp:334]     Train net output #0: loss = 0.000800788 (* 1 = 0.000800788 loss)
I0814 18:59:12.590626   613 sgd_solver.cpp:136] Iteration 4200, lr = 0.00934375, m = 0.9
I0814 18:59:14.180943   613 solver.cpp:312] Iteration 4300 (62.8801 iter/s, 1.59033s/100 iter), loss = 0.00231759
I0814 18:59:14.180969   613 solver.cpp:334]     Train net output #0: loss = 0.00231759 (* 1 = 0.00231759 loss)
I0814 18:59:14.180974   613 sgd_solver.cpp:136] Iteration 4300, lr = 0.00932813, m = 0.9
I0814 18:59:15.820266   613 solver.cpp:312] Iteration 4400 (61.0027 iter/s, 1.63927s/100 iter), loss = 0.000542646
I0814 18:59:15.820333   613 solver.cpp:334]     Train net output #0: loss = 0.000542649 (* 1 = 0.000542649 loss)
I0814 18:59:15.820353   613 sgd_solver.cpp:136] Iteration 4400, lr = 0.0093125, m = 0.9
I0814 18:59:17.466584   613 solver.cpp:312] Iteration 4500 (60.7435 iter/s, 1.64627s/100 iter), loss = 0.000854967
I0814 18:59:17.466631   613 solver.cpp:334]     Train net output #0: loss = 0.00085497 (* 1 = 0.00085497 loss)
I0814 18:59:17.466644   613 sgd_solver.cpp:136] Iteration 4500, lr = 0.00929687, m = 0.9
I0814 18:59:19.120606   613 solver.cpp:312] Iteration 4600 (60.4604 iter/s, 1.65398s/100 iter), loss = 0.000815887
I0814 18:59:19.120631   613 solver.cpp:334]     Train net output #0: loss = 0.00081589 (* 1 = 0.00081589 loss)
I0814 18:59:19.120637   613 sgd_solver.cpp:136] Iteration 4600, lr = 0.00928125, m = 0.9
I0814 18:59:20.732702   613 solver.cpp:312] Iteration 4700 (62.033 iter/s, 1.61205s/100 iter), loss = 0.00404256
I0814 18:59:20.732725   613 solver.cpp:334]     Train net output #0: loss = 0.00404256 (* 1 = 0.00404256 loss)
I0814 18:59:20.732729   613 sgd_solver.cpp:136] Iteration 4700, lr = 0.00926562, m = 0.9
I0814 18:59:22.367946   613 solver.cpp:312] Iteration 4800 (61.1548 iter/s, 1.6352s/100 iter), loss = 0.00112103
I0814 18:59:22.368017   613 solver.cpp:334]     Train net output #0: loss = 0.00112103 (* 1 = 0.00112103 loss)
I0814 18:59:22.368037   613 sgd_solver.cpp:136] Iteration 4800, lr = 0.00925, m = 0.9
I0814 18:59:23.989509   613 solver.cpp:312] Iteration 4900 (61.6709 iter/s, 1.62151s/100 iter), loss = 0.00161254
I0814 18:59:23.989533   613 solver.cpp:334]     Train net output #0: loss = 0.00161254 (* 1 = 0.00161254 loss)
I0814 18:59:23.989539   613 sgd_solver.cpp:136] Iteration 4900, lr = 0.00923437, m = 0.9
I0814 18:59:25.600283   613 solver.cpp:509] Iteration 5000, Testing net (#0)
I0814 18:59:26.272680   611 data_reader.cpp:288] Starting prefetch of epoch 1
I0814 18:59:26.409451   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.925295
I0814 18:59:26.409471   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.997647
I0814 18:59:26.409476   613 solver.cpp:594]     Test net output #2: loss = 0.258845 (* 1 = 0.258845 loss)
I0814 18:59:26.409490   613 solver.cpp:264] [MultiGPU] Tests completed in 0.809186s
I0814 18:59:26.425143   613 solver.cpp:312] Iteration 5000 (41.0582 iter/s, 2.43557s/100 iter), loss = 0.00130248
I0814 18:59:26.425158   613 solver.cpp:334]     Train net output #0: loss = 0.00130249 (* 1 = 0.00130249 loss)
I0814 18:59:26.425163   613 sgd_solver.cpp:136] Iteration 5000, lr = 0.00921875, m = 0.9
I0814 18:59:28.022670   613 solver.cpp:312] Iteration 5100 (62.5987 iter/s, 1.59748s/100 iter), loss = 0.00145321
I0814 18:59:28.022734   613 solver.cpp:334]     Train net output #0: loss = 0.00145322 (* 1 = 0.00145322 loss)
I0814 18:59:28.022755   613 sgd_solver.cpp:136] Iteration 5100, lr = 0.00920312, m = 0.9
I0814 18:59:29.635462   613 solver.cpp:312] Iteration 5200 (62.0063 iter/s, 1.61274s/100 iter), loss = 0.00149784
I0814 18:59:29.635489   613 solver.cpp:334]     Train net output #0: loss = 0.00149785 (* 1 = 0.00149785 loss)
I0814 18:59:29.635496   613 sgd_solver.cpp:136] Iteration 5200, lr = 0.0091875, m = 0.9
I0814 18:59:31.265836   613 solver.cpp:312] Iteration 5300 (61.3374 iter/s, 1.63033s/100 iter), loss = 0.00119783
I0814 18:59:31.265918   613 solver.cpp:334]     Train net output #0: loss = 0.00119784 (* 1 = 0.00119784 loss)
I0814 18:59:31.265924   613 sgd_solver.cpp:136] Iteration 5300, lr = 0.00917188, m = 0.9
I0814 18:59:32.920838   613 solver.cpp:312] Iteration 5400 (60.4247 iter/s, 1.65495s/100 iter), loss = 0.000558035
I0814 18:59:32.920897   613 solver.cpp:334]     Train net output #0: loss = 0.000558037 (* 1 = 0.000558037 loss)
I0814 18:59:32.920917   613 sgd_solver.cpp:136] Iteration 5400, lr = 0.00915625, m = 0.9
I0814 18:59:34.554991   613 solver.cpp:312] Iteration 5500 (61.1958 iter/s, 1.6341s/100 iter), loss = 0.000801629
I0814 18:59:34.555038   613 solver.cpp:334]     Train net output #0: loss = 0.000801631 (* 1 = 0.000801631 loss)
I0814 18:59:34.555053   613 sgd_solver.cpp:136] Iteration 5500, lr = 0.00914062, m = 0.9
I0814 18:59:36.168826   613 solver.cpp:312] Iteration 5600 (61.9662 iter/s, 1.61378s/100 iter), loss = 0.000841402
I0814 18:59:36.168850   613 solver.cpp:334]     Train net output #0: loss = 0.000841404 (* 1 = 0.000841404 loss)
I0814 18:59:36.168854   613 sgd_solver.cpp:136] Iteration 5600, lr = 0.009125, m = 0.9
I0814 18:59:37.786312   613 solver.cpp:312] Iteration 5700 (61.8261 iter/s, 1.61744s/100 iter), loss = 0.000567414
I0814 18:59:37.786337   613 solver.cpp:334]     Train net output #0: loss = 0.000567416 (* 1 = 0.000567416 loss)
I0814 18:59:37.786342   613 sgd_solver.cpp:136] Iteration 5700, lr = 0.00910938, m = 0.9
I0814 18:59:39.411339   613 solver.cpp:312] Iteration 5800 (61.5394 iter/s, 1.62498s/100 iter), loss = 0.000803597
I0814 18:59:39.411363   613 solver.cpp:334]     Train net output #0: loss = 0.0008036 (* 1 = 0.0008036 loss)
I0814 18:59:39.411370   613 sgd_solver.cpp:136] Iteration 5800, lr = 0.00909375, m = 0.9
I0814 18:59:41.038350   613 solver.cpp:312] Iteration 5900 (61.4641 iter/s, 1.62697s/100 iter), loss = 0.00183941
I0814 18:59:41.038375   613 solver.cpp:334]     Train net output #0: loss = 0.00183941 (* 1 = 0.00183941 loss)
I0814 18:59:41.038381   613 sgd_solver.cpp:136] Iteration 5900, lr = 0.00907812, m = 0.9
I0814 18:59:42.631839   613 solver.cpp:509] Iteration 6000, Testing net (#0)
I0814 18:59:43.448930   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.928236
I0814 18:59:43.448949   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.997647
I0814 18:59:43.448954   613 solver.cpp:594]     Test net output #2: loss = 0.25561 (* 1 = 0.25561 loss)
I0814 18:59:43.448971   613 solver.cpp:264] [MultiGPU] Tests completed in 0.81711s
I0814 18:59:43.464515   613 solver.cpp:312] Iteration 6000 (41.2185 iter/s, 2.42609s/100 iter), loss = 0.000732102
I0814 18:59:43.464534   613 solver.cpp:334]     Train net output #0: loss = 0.000732104 (* 1 = 0.000732104 loss)
I0814 18:59:43.464540   613 sgd_solver.cpp:136] Iteration 6000, lr = 0.0090625, m = 0.9
I0814 18:59:45.100119   613 solver.cpp:312] Iteration 6100 (61.1413 iter/s, 1.63555s/100 iter), loss = 0.00225511
I0814 18:59:45.100172   613 solver.cpp:334]     Train net output #0: loss = 0.00225511 (* 1 = 0.00225511 loss)
I0814 18:59:45.100184   613 sgd_solver.cpp:136] Iteration 6100, lr = 0.00904687, m = 0.9
I0814 18:59:46.694612   613 solver.cpp:312] Iteration 6200 (62.7177 iter/s, 1.59445s/100 iter), loss = 0.000762816
I0814 18:59:46.694636   613 solver.cpp:334]     Train net output #0: loss = 0.000762818 (* 1 = 0.000762818 loss)
I0814 18:59:46.694641   613 sgd_solver.cpp:136] Iteration 6200, lr = 0.00903125, m = 0.9
I0814 18:59:48.315784   613 solver.cpp:312] Iteration 6300 (61.6858 iter/s, 1.62112s/100 iter), loss = 0.000955307
I0814 18:59:48.315834   613 solver.cpp:334]     Train net output #0: loss = 0.000955309 (* 1 = 0.000955309 loss)
I0814 18:59:48.315855   613 sgd_solver.cpp:136] Iteration 6300, lr = 0.00901563, m = 0.9
I0814 18:59:49.928176   613 solver.cpp:312] Iteration 6400 (62.0214 iter/s, 1.61235s/100 iter), loss = 0.00260718
I0814 18:59:49.928237   613 solver.cpp:334]     Train net output #0: loss = 0.00260719 (* 1 = 0.00260719 loss)
I0814 18:59:49.928256   613 sgd_solver.cpp:136] Iteration 6400, lr = 0.009, m = 0.9
I0814 18:59:51.541084   613 solver.cpp:312] Iteration 6500 (62.0019 iter/s, 1.61285s/100 iter), loss = 0.00083582
I0814 18:59:51.541108   613 solver.cpp:334]     Train net output #0: loss = 0.000835823 (* 1 = 0.000835823 loss)
I0814 18:59:51.541115   613 sgd_solver.cpp:136] Iteration 6500, lr = 0.00898437, m = 0.9
I0814 18:59:53.110280   613 solver.cpp:312] Iteration 6600 (63.7289 iter/s, 1.56915s/100 iter), loss = 0.00268273
I0814 18:59:53.110340   613 solver.cpp:334]     Train net output #0: loss = 0.00268274 (* 1 = 0.00268274 loss)
I0814 18:59:53.110359   613 sgd_solver.cpp:136] Iteration 6600, lr = 0.00896875, m = 0.9
I0814 18:59:54.720000   613 solver.cpp:312] Iteration 6700 (62.1244 iter/s, 1.60967s/100 iter), loss = 0.00100576
I0814 18:59:54.720043   613 solver.cpp:334]     Train net output #0: loss = 0.00100577 (* 1 = 0.00100577 loss)
I0814 18:59:54.720054   613 sgd_solver.cpp:136] Iteration 6700, lr = 0.00895312, m = 0.9
I0814 18:59:56.327491   613 solver.cpp:312] Iteration 6800 (62.2107 iter/s, 1.60744s/100 iter), loss = 0.00122988
I0814 18:59:56.327515   613 solver.cpp:334]     Train net output #0: loss = 0.00122988 (* 1 = 0.00122988 loss)
I0814 18:59:56.327522   613 sgd_solver.cpp:136] Iteration 6800, lr = 0.0089375, m = 0.9
I0814 18:59:57.915350   613 solver.cpp:312] Iteration 6900 (62.9797 iter/s, 1.58781s/100 iter), loss = 0.000633278
I0814 18:59:57.915411   613 solver.cpp:334]     Train net output #0: loss = 0.000633281 (* 1 = 0.000633281 loss)
I0814 18:59:57.915429   613 sgd_solver.cpp:136] Iteration 6900, lr = 0.00892187, m = 0.9
I0814 18:59:59.496975   613 solver.cpp:509] Iteration 7000, Testing net (#0)
I0814 19:00:00.318768   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.92853
I0814 19:00:00.318786   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.997647
I0814 19:00:00.318794   613 solver.cpp:594]     Test net output #2: loss = 0.259493 (* 1 = 0.259493 loss)
I0814 19:00:00.318811   613 solver.cpp:264] [MultiGPU] Tests completed in 0.821812s
I0814 19:00:00.334638   613 solver.cpp:312] Iteration 7000 (41.3356 iter/s, 2.41922s/100 iter), loss = 0.00120422
I0814 19:00:00.334657   613 solver.cpp:334]     Train net output #0: loss = 0.00120423 (* 1 = 0.00120423 loss)
I0814 19:00:00.334662   613 sgd_solver.cpp:136] Iteration 7000, lr = 0.00890625, m = 0.9
I0814 19:00:01.932751   613 solver.cpp:312] Iteration 7100 (62.5758 iter/s, 1.59806s/100 iter), loss = 0.000656834
I0814 19:00:01.932831   613 solver.cpp:334]     Train net output #0: loss = 0.000656837 (* 1 = 0.000656837 loss)
I0814 19:00:01.932838   613 sgd_solver.cpp:136] Iteration 7100, lr = 0.00889063, m = 0.9
I0814 19:00:03.559361   613 solver.cpp:312] Iteration 7200 (61.4794 iter/s, 1.62656s/100 iter), loss = 0.00135278
I0814 19:00:03.559384   613 solver.cpp:334]     Train net output #0: loss = 0.00135279 (* 1 = 0.00135279 loss)
I0814 19:00:03.559391   613 sgd_solver.cpp:136] Iteration 7200, lr = 0.008875, m = 0.9
I0814 19:00:05.222133   613 solver.cpp:312] Iteration 7300 (60.1424 iter/s, 1.66272s/100 iter), loss = 0.00144445
I0814 19:00:05.222182   613 solver.cpp:334]     Train net output #0: loss = 0.00144445 (* 1 = 0.00144445 loss)
I0814 19:00:05.222193   613 sgd_solver.cpp:136] Iteration 7300, lr = 0.00885937, m = 0.9
I0814 19:00:06.819478   613 solver.cpp:312] Iteration 7400 (62.6059 iter/s, 1.59729s/100 iter), loss = 0.000636561
I0814 19:00:06.819524   613 solver.cpp:334]     Train net output #0: loss = 0.000636564 (* 1 = 0.000636564 loss)
I0814 19:00:06.819536   613 sgd_solver.cpp:136] Iteration 7400, lr = 0.00884375, m = 0.9
I0814 19:00:08.423743   613 solver.cpp:312] Iteration 7500 (62.3357 iter/s, 1.60422s/100 iter), loss = 0.0004935
I0814 19:00:08.423810   613 solver.cpp:334]     Train net output #0: loss = 0.000493504 (* 1 = 0.000493504 loss)
I0814 19:00:08.423828   613 sgd_solver.cpp:136] Iteration 7500, lr = 0.00882812, m = 0.9
I0814 19:00:10.040758   613 solver.cpp:312] Iteration 7600 (61.8443 iter/s, 1.61696s/100 iter), loss = 0.00115649
I0814 19:00:10.040807   613 solver.cpp:334]     Train net output #0: loss = 0.00115649 (* 1 = 0.00115649 loss)
I0814 19:00:10.040946   613 sgd_solver.cpp:136] Iteration 7600, lr = 0.0088125, m = 0.9
I0814 19:00:11.665786   613 solver.cpp:312] Iteration 7700 (61.5393 iter/s, 1.62498s/100 iter), loss = 0.000344601
I0814 19:00:11.665845   613 solver.cpp:334]     Train net output #0: loss = 0.000344605 (* 1 = 0.000344605 loss)
I0814 19:00:11.665863   613 sgd_solver.cpp:136] Iteration 7700, lr = 0.00879687, m = 0.9
I0814 19:00:13.334347   613 solver.cpp:312] Iteration 7800 (59.9337 iter/s, 1.66851s/100 iter), loss = 0.00147152
I0814 19:00:13.334391   613 solver.cpp:334]     Train net output #0: loss = 0.00147152 (* 1 = 0.00147152 loss)
I0814 19:00:13.334403   613 sgd_solver.cpp:136] Iteration 7800, lr = 0.00878125, m = 0.9
I0814 19:00:14.916340   613 solver.cpp:312] Iteration 7900 (63.2133 iter/s, 1.58195s/100 iter), loss = 0.00125078
I0814 19:00:14.916368   613 solver.cpp:334]     Train net output #0: loss = 0.00125079 (* 1 = 0.00125079 loss)
I0814 19:00:14.916375   613 sgd_solver.cpp:136] Iteration 7900, lr = 0.00876562, m = 0.9
I0814 19:00:16.519829   613 solver.cpp:509] Iteration 8000, Testing net (#0)
I0814 19:00:17.332904   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.920001
I0814 19:00:17.332924   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.997059
I0814 19:00:17.332929   613 solver.cpp:594]     Test net output #2: loss = 0.280132 (* 1 = 0.280132 loss)
I0814 19:00:17.332947   613 solver.cpp:264] [MultiGPU] Tests completed in 0.813096s
I0814 19:00:17.348517   613 solver.cpp:312] Iteration 8000 (41.1166 iter/s, 2.43211s/100 iter), loss = 0.00241033
I0814 19:00:17.348536   613 solver.cpp:334]     Train net output #0: loss = 0.00241033 (* 1 = 0.00241033 loss)
I0814 19:00:17.348543   613 sgd_solver.cpp:136] Iteration 8000, lr = 0.00875, m = 0.9
I0814 19:00:18.940136   613 solver.cpp:312] Iteration 8100 (62.8313 iter/s, 1.59156s/100 iter), loss = 0.00254658
I0814 19:00:18.940182   613 solver.cpp:334]     Train net output #0: loss = 0.00254658 (* 1 = 0.00254658 loss)
I0814 19:00:18.940193   613 sgd_solver.cpp:136] Iteration 8100, lr = 0.00873438, m = 0.9
I0814 19:00:20.604782   613 solver.cpp:312] Iteration 8200 (60.0746 iter/s, 1.6646s/100 iter), loss = 0.000689749
I0814 19:00:20.604938   613 solver.cpp:334]     Train net output #0: loss = 0.000689751 (* 1 = 0.000689751 loss)
I0814 19:00:20.605029   613 sgd_solver.cpp:136] Iteration 8200, lr = 0.00871875, m = 0.9
I0814 19:00:22.213068   613 solver.cpp:312] Iteration 8300 (62.1799 iter/s, 1.60824s/100 iter), loss = 0.00152416
I0814 19:00:22.213093   613 solver.cpp:334]     Train net output #0: loss = 0.00152416 (* 1 = 0.00152416 loss)
I0814 19:00:22.213101   613 sgd_solver.cpp:136] Iteration 8300, lr = 0.00870312, m = 0.9
I0814 19:00:23.856964   613 solver.cpp:312] Iteration 8400 (60.8329 iter/s, 1.64385s/100 iter), loss = 0.00169297
I0814 19:00:23.856988   613 solver.cpp:334]     Train net output #0: loss = 0.00169297 (* 1 = 0.00169297 loss)
I0814 19:00:23.856994   613 sgd_solver.cpp:136] Iteration 8400, lr = 0.0086875, m = 0.9
I0814 19:00:25.446161   613 solver.cpp:312] Iteration 8500 (62.9268 iter/s, 1.58915s/100 iter), loss = 0.00153697
I0814 19:00:25.446188   613 solver.cpp:334]     Train net output #0: loss = 0.00153697 (* 1 = 0.00153697 loss)
I0814 19:00:25.446194   613 sgd_solver.cpp:136] Iteration 8500, lr = 0.00867188, m = 0.9
I0814 19:00:27.056836   613 solver.cpp:312] Iteration 8600 (62.0877 iter/s, 1.61063s/100 iter), loss = 0.000643072
I0814 19:00:27.056860   613 solver.cpp:334]     Train net output #0: loss = 0.000643074 (* 1 = 0.000643074 loss)
I0814 19:00:27.056865   613 sgd_solver.cpp:136] Iteration 8600, lr = 0.00865625, m = 0.9
I0814 19:00:28.691506   613 solver.cpp:312] Iteration 8700 (61.1762 iter/s, 1.63462s/100 iter), loss = 0.00097274
I0814 19:00:28.691534   613 solver.cpp:334]     Train net output #0: loss = 0.000972742 (* 1 = 0.000972742 loss)
I0814 19:00:28.691540   613 sgd_solver.cpp:136] Iteration 8700, lr = 0.00864062, m = 0.9
I0814 19:00:30.338904   613 solver.cpp:312] Iteration 8800 (60.7037 iter/s, 1.64735s/100 iter), loss = 0.002728
I0814 19:00:30.338929   613 solver.cpp:334]     Train net output #0: loss = 0.002728 (* 1 = 0.002728 loss)
I0814 19:00:30.338935   613 sgd_solver.cpp:136] Iteration 8800, lr = 0.008625, m = 0.9
I0814 19:00:31.950960   613 solver.cpp:312] Iteration 8900 (62.0345 iter/s, 1.61201s/100 iter), loss = 0.0010851
I0814 19:00:31.951051   613 solver.cpp:334]     Train net output #0: loss = 0.00108511 (* 1 = 0.00108511 loss)
I0814 19:00:31.951068   613 sgd_solver.cpp:136] Iteration 8900, lr = 0.00860937, m = 0.9
I0814 19:00:33.545852   613 solver.cpp:509] Iteration 9000, Testing net (#0)
I0814 19:00:34.355777   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.920001
I0814 19:00:34.355795   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.995882
I0814 19:00:34.355799   613 solver.cpp:594]     Test net output #2: loss = 0.275584 (* 1 = 0.275584 loss)
I0814 19:00:34.355814   613 solver.cpp:264] [MultiGPU] Tests completed in 0.809941s
I0814 19:00:34.371256   613 solver.cpp:312] Iteration 9000 (41.3184 iter/s, 2.42023s/100 iter), loss = 0.0010081
I0814 19:00:34.371274   613 solver.cpp:334]     Train net output #0: loss = 0.0010081 (* 1 = 0.0010081 loss)
I0814 19:00:34.371279   613 sgd_solver.cpp:136] Iteration 9000, lr = 0.00859375, m = 0.9
I0814 19:00:35.772261   592 data_reader.cpp:288] Starting prefetch of epoch 2
I0814 19:00:35.974222   613 solver.cpp:312] Iteration 9100 (62.3864 iter/s, 1.60291s/100 iter), loss = 0.00175818
I0814 19:00:35.974268   613 solver.cpp:334]     Train net output #0: loss = 0.00175818 (* 1 = 0.00175818 loss)
I0814 19:00:35.974280   613 sgd_solver.cpp:136] Iteration 9100, lr = 0.00857813, m = 0.9
I0814 19:00:37.564599   613 solver.cpp:312] Iteration 9200 (62.8801 iter/s, 1.59033s/100 iter), loss = 0.00146192
I0814 19:00:37.564652   613 solver.cpp:334]     Train net output #0: loss = 0.00146192 (* 1 = 0.00146192 loss)
I0814 19:00:37.564666   613 sgd_solver.cpp:136] Iteration 9200, lr = 0.0085625, m = 0.9
I0814 19:00:39.182272   613 solver.cpp:312] Iteration 9300 (61.8191 iter/s, 1.61762s/100 iter), loss = 0.000442209
I0814 19:00:39.182297   613 solver.cpp:334]     Train net output #0: loss = 0.00044221 (* 1 = 0.00044221 loss)
I0814 19:00:39.182303   613 sgd_solver.cpp:136] Iteration 9300, lr = 0.00854687, m = 0.9
I0814 19:00:40.806073   613 solver.cpp:312] Iteration 9400 (61.5858 iter/s, 1.62375s/100 iter), loss = 0.00222224
I0814 19:00:40.806100   613 solver.cpp:334]     Train net output #0: loss = 0.00222224 (* 1 = 0.00222224 loss)
I0814 19:00:40.806107   613 sgd_solver.cpp:136] Iteration 9400, lr = 0.00853125, m = 0.9
I0814 19:00:42.422749   613 solver.cpp:312] Iteration 9500 (61.8572 iter/s, 1.61663s/100 iter), loss = 0.000476131
I0814 19:00:42.422775   613 solver.cpp:334]     Train net output #0: loss = 0.000476132 (* 1 = 0.000476132 loss)
I0814 19:00:42.422781   613 sgd_solver.cpp:136] Iteration 9500, lr = 0.00851563, m = 0.9
I0814 19:00:44.072320   613 solver.cpp:312] Iteration 9600 (60.6237 iter/s, 1.64952s/100 iter), loss = 0.00124401
I0814 19:00:44.072347   613 solver.cpp:334]     Train net output #0: loss = 0.00124401 (* 1 = 0.00124401 loss)
I0814 19:00:44.072355   613 sgd_solver.cpp:136] Iteration 9600, lr = 0.0085, m = 0.9
I0814 19:00:45.709556   613 solver.cpp:312] Iteration 9700 (61.0804 iter/s, 1.63719s/100 iter), loss = 0.00352153
I0814 19:00:45.709602   613 solver.cpp:334]     Train net output #0: loss = 0.00352153 (* 1 = 0.00352153 loss)
I0814 19:00:45.709614   613 sgd_solver.cpp:136] Iteration 9700, lr = 0.00848437, m = 0.9
I0814 19:00:47.320477   613 solver.cpp:312] Iteration 9800 (62.0782 iter/s, 1.61087s/100 iter), loss = 0.00116342
I0814 19:00:47.320502   613 solver.cpp:334]     Train net output #0: loss = 0.00116342 (* 1 = 0.00116342 loss)
I0814 19:00:47.320508   613 sgd_solver.cpp:136] Iteration 9800, lr = 0.00846875, m = 0.9
I0814 19:00:48.951493   613 solver.cpp:312] Iteration 9900 (61.3133 iter/s, 1.63097s/100 iter), loss = 0.000878821
I0814 19:00:48.951557   613 solver.cpp:334]     Train net output #0: loss = 0.000878822 (* 1 = 0.000878822 loss)
I0814 19:00:48.951576   613 sgd_solver.cpp:136] Iteration 9900, lr = 0.00845312, m = 0.9
I0814 19:00:50.558339   613 solver.cpp:639] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/l1reg/cifar10_jacintonet11v2_iter_10000.caffemodel
I0814 19:00:50.573385   613 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/l1reg/cifar10_jacintonet11v2_iter_10000.solverstate
I0814 19:00:50.579520   613 solver.cpp:509] Iteration 10000, Testing net (#0)
I0814 19:00:51.388346   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.920295
I0814 19:00:51.388365   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.997647
I0814 19:00:51.388370   613 solver.cpp:594]     Test net output #2: loss = 0.28255 (* 1 = 0.28255 loss)
I0814 19:00:51.388386   613 solver.cpp:264] [MultiGPU] Tests completed in 0.808842s
I0814 19:00:51.407680   613 solver.cpp:312] Iteration 10000 (40.7147 iter/s, 2.45612s/100 iter), loss = 0.0023508
I0814 19:00:51.407698   613 solver.cpp:334]     Train net output #0: loss = 0.0023508 (* 1 = 0.0023508 loss)
I0814 19:00:51.407704   613 sgd_solver.cpp:136] Iteration 10000, lr = 0.0084375, m = 0.9
I0814 19:00:53.005925   613 solver.cpp:312] Iteration 10100 (62.5706 iter/s, 1.59819s/100 iter), loss = 0.00207654
I0814 19:00:53.005949   613 solver.cpp:334]     Train net output #0: loss = 0.00207654 (* 1 = 0.00207654 loss)
I0814 19:00:53.005954   613 sgd_solver.cpp:136] Iteration 10100, lr = 0.00842187, m = 0.9
I0814 19:00:54.655638   613 solver.cpp:312] Iteration 10200 (60.6184 iter/s, 1.64966s/100 iter), loss = 0.00217249
I0814 19:00:54.655663   613 solver.cpp:334]     Train net output #0: loss = 0.00217249 (* 1 = 0.00217249 loss)
I0814 19:00:54.655668   613 sgd_solver.cpp:136] Iteration 10200, lr = 0.00840625, m = 0.9
I0814 19:00:56.284055   613 solver.cpp:312] Iteration 10300 (61.4113 iter/s, 1.62837s/100 iter), loss = 0.00213185
I0814 19:00:56.284126   613 solver.cpp:334]     Train net output #0: loss = 0.00213185 (* 1 = 0.00213185 loss)
I0814 19:00:56.284155   613 sgd_solver.cpp:136] Iteration 10300, lr = 0.00839063, m = 0.9
I0814 19:00:57.873436   613 solver.cpp:312] Iteration 10400 (62.9194 iter/s, 1.58934s/100 iter), loss = 0.00123549
I0814 19:00:57.873503   613 solver.cpp:334]     Train net output #0: loss = 0.00123549 (* 1 = 0.00123549 loss)
I0814 19:00:57.873523   613 sgd_solver.cpp:136] Iteration 10400, lr = 0.008375, m = 0.9
I0814 19:00:59.523696   613 solver.cpp:312] Iteration 10500 (60.5984 iter/s, 1.65021s/100 iter), loss = 0.00176174
I0814 19:00:59.523721   613 solver.cpp:334]     Train net output #0: loss = 0.00176174 (* 1 = 0.00176174 loss)
I0814 19:00:59.523727   613 sgd_solver.cpp:136] Iteration 10500, lr = 0.00835937, m = 0.9
I0814 19:01:01.150777   613 solver.cpp:312] Iteration 10600 (61.4615 iter/s, 1.62703s/100 iter), loss = 0.00185199
I0814 19:01:01.150835   613 solver.cpp:334]     Train net output #0: loss = 0.00185199 (* 1 = 0.00185199 loss)
I0814 19:01:01.150853   613 sgd_solver.cpp:136] Iteration 10600, lr = 0.00834375, m = 0.9
I0814 19:01:02.766182   613 solver.cpp:312] Iteration 10700 (61.9058 iter/s, 1.61536s/100 iter), loss = 0.00171822
I0814 19:01:02.766286   613 solver.cpp:334]     Train net output #0: loss = 0.00171823 (* 1 = 0.00171823 loss)
I0814 19:01:02.766304   613 sgd_solver.cpp:136] Iteration 10700, lr = 0.00832812, m = 0.9
I0814 19:01:04.369999   613 solver.cpp:312] Iteration 10800 (62.3532 iter/s, 1.60377s/100 iter), loss = 0.00409551
I0814 19:01:04.370070   613 solver.cpp:334]     Train net output #0: loss = 0.00409552 (* 1 = 0.00409552 loss)
I0814 19:01:04.370101   613 sgd_solver.cpp:136] Iteration 10800, lr = 0.0083125, m = 0.9
I0814 19:01:05.980542   613 solver.cpp:312] Iteration 10900 (62.0928 iter/s, 1.61049s/100 iter), loss = 0.00212342
I0814 19:01:05.980568   613 solver.cpp:334]     Train net output #0: loss = 0.00212343 (* 1 = 0.00212343 loss)
I0814 19:01:05.980574   613 sgd_solver.cpp:136] Iteration 10900, lr = 0.00829687, m = 0.9
I0814 19:01:07.593227   613 solver.cpp:509] Iteration 11000, Testing net (#0)
I0814 19:01:08.422883   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.916177
I0814 19:01:08.422902   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.995882
I0814 19:01:08.422907   613 solver.cpp:594]     Test net output #2: loss = 0.296183 (* 1 = 0.296183 loss)
I0814 19:01:08.422924   613 solver.cpp:264] [MultiGPU] Tests completed in 0.829684s
I0814 19:01:08.440649   613 solver.cpp:312] Iteration 11000 (40.6498 iter/s, 2.46004s/100 iter), loss = 0.00128561
I0814 19:01:08.440681   613 solver.cpp:334]     Train net output #0: loss = 0.00128562 (* 1 = 0.00128562 loss)
I0814 19:01:08.440696   613 sgd_solver.cpp:136] Iteration 11000, lr = 0.00828125, m = 0.9
I0814 19:01:10.035934   613 solver.cpp:312] Iteration 11100 (62.6867 iter/s, 1.59524s/100 iter), loss = 0.00254285
I0814 19:01:10.035981   613 solver.cpp:334]     Train net output #0: loss = 0.00254286 (* 1 = 0.00254286 loss)
I0814 19:01:10.035993   613 sgd_solver.cpp:136] Iteration 11100, lr = 0.00826562, m = 0.9
I0814 19:01:11.685240   613 solver.cpp:312] Iteration 11200 (60.6334 iter/s, 1.64926s/100 iter), loss = 0.000756026
I0814 19:01:11.685266   613 solver.cpp:334]     Train net output #0: loss = 0.000756032 (* 1 = 0.000756032 loss)
I0814 19:01:11.685274   613 sgd_solver.cpp:136] Iteration 11200, lr = 0.00825, m = 0.9
I0814 19:01:13.280048   613 solver.cpp:312] Iteration 11300 (62.7055 iter/s, 1.59476s/100 iter), loss = 0.000932795
I0814 19:01:13.280077   613 solver.cpp:334]     Train net output #0: loss = 0.000932802 (* 1 = 0.000932802 loss)
I0814 19:01:13.280083   613 sgd_solver.cpp:136] Iteration 11300, lr = 0.00823438, m = 0.9
I0814 19:01:14.921511   613 solver.cpp:312] Iteration 11400 (60.9232 iter/s, 1.64141s/100 iter), loss = 0.0019065
I0814 19:01:14.921579   613 solver.cpp:334]     Train net output #0: loss = 0.00190651 (* 1 = 0.00190651 loss)
I0814 19:01:14.921599   613 sgd_solver.cpp:136] Iteration 11400, lr = 0.00821875, m = 0.9
I0814 19:01:16.534878   613 solver.cpp:312] Iteration 11500 (61.9841 iter/s, 1.61332s/100 iter), loss = 0.00301876
I0814 19:01:16.534940   613 solver.cpp:334]     Train net output #0: loss = 0.00301876 (* 1 = 0.00301876 loss)
I0814 19:01:16.534958   613 sgd_solver.cpp:136] Iteration 11500, lr = 0.00820312, m = 0.9
I0814 19:01:18.156390   613 solver.cpp:312] Iteration 11600 (61.6727 iter/s, 1.62146s/100 iter), loss = 0.00316448
I0814 19:01:18.156437   613 solver.cpp:334]     Train net output #0: loss = 0.00316449 (* 1 = 0.00316449 loss)
I0814 19:01:18.156450   613 sgd_solver.cpp:136] Iteration 11600, lr = 0.0081875, m = 0.9
I0814 19:01:19.756758   613 solver.cpp:312] Iteration 11700 (62.4876 iter/s, 1.60032s/100 iter), loss = 0.000728933
I0814 19:01:19.756811   613 solver.cpp:334]     Train net output #0: loss = 0.00072894 (* 1 = 0.00072894 loss)
I0814 19:01:19.756829   613 sgd_solver.cpp:136] Iteration 11700, lr = 0.00817188, m = 0.9
I0814 19:01:21.369840   613 solver.cpp:312] Iteration 11800 (61.995 iter/s, 1.61303s/100 iter), loss = 0.000616483
I0814 19:01:21.369894   613 solver.cpp:334]     Train net output #0: loss = 0.000616489 (* 1 = 0.000616489 loss)
I0814 19:01:21.369907   613 sgd_solver.cpp:136] Iteration 11800, lr = 0.00815625, m = 0.9
I0814 19:01:23.010448   613 solver.cpp:312] Iteration 11900 (60.9548 iter/s, 1.64056s/100 iter), loss = 0.000982335
I0814 19:01:23.010545   613 solver.cpp:334]     Train net output #0: loss = 0.000982341 (* 1 = 0.000982341 loss)
I0814 19:01:23.010553   613 sgd_solver.cpp:136] Iteration 11900, lr = 0.00814062, m = 0.9
I0814 19:01:24.632519   613 solver.cpp:509] Iteration 12000, Testing net (#0)
I0814 19:01:25.447366   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.919413
I0814 19:01:25.447386   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.995588
I0814 19:01:25.447391   613 solver.cpp:594]     Test net output #2: loss = 0.286347 (* 1 = 0.286347 loss)
I0814 19:01:25.447405   613 solver.cpp:264] [MultiGPU] Tests completed in 0.814867s
I0814 19:01:25.462883   613 solver.cpp:312] Iteration 12000 (40.777 iter/s, 2.45236s/100 iter), loss = 0.000947756
I0814 19:01:25.462899   613 solver.cpp:334]     Train net output #0: loss = 0.000947762 (* 1 = 0.000947762 loss)
I0814 19:01:25.462903   613 sgd_solver.cpp:136] Iteration 12000, lr = 0.008125, m = 0.9
I0814 19:01:27.072866   613 solver.cpp:312] Iteration 12100 (62.1144 iter/s, 1.60993s/100 iter), loss = 0.000586014
I0814 19:01:27.072895   613 solver.cpp:334]     Train net output #0: loss = 0.00058602 (* 1 = 0.00058602 loss)
I0814 19:01:27.072901   613 sgd_solver.cpp:136] Iteration 12100, lr = 0.00810937, m = 0.9
I0814 19:01:28.684233   613 solver.cpp:312] Iteration 12200 (62.0611 iter/s, 1.61132s/100 iter), loss = 0.000906608
I0814 19:01:28.684259   613 solver.cpp:334]     Train net output #0: loss = 0.000906614 (* 1 = 0.000906614 loss)
I0814 19:01:28.684267   613 sgd_solver.cpp:136] Iteration 12200, lr = 0.00809375, m = 0.9
I0814 19:01:30.263794   613 solver.cpp:312] Iteration 12300 (63.3106 iter/s, 1.57951s/100 iter), loss = 0.00084128
I0814 19:01:30.263819   613 solver.cpp:334]     Train net output #0: loss = 0.000841287 (* 1 = 0.000841287 loss)
I0814 19:01:30.263825   613 sgd_solver.cpp:136] Iteration 12300, lr = 0.00807813, m = 0.9
I0814 19:01:31.923334   613 solver.cpp:312] Iteration 12400 (60.2595 iter/s, 1.65949s/100 iter), loss = 0.000783493
I0814 19:01:31.923358   613 solver.cpp:334]     Train net output #0: loss = 0.000783501 (* 1 = 0.000783501 loss)
I0814 19:01:31.923364   613 sgd_solver.cpp:136] Iteration 12400, lr = 0.0080625, m = 0.9
I0814 19:01:33.538316   613 solver.cpp:312] Iteration 12500 (61.922 iter/s, 1.61493s/100 iter), loss = 0.000894408
I0814 19:01:33.538401   613 solver.cpp:334]     Train net output #0: loss = 0.000894416 (* 1 = 0.000894416 loss)
I0814 19:01:33.538408   613 sgd_solver.cpp:136] Iteration 12500, lr = 0.00804687, m = 0.9
I0814 19:01:35.144990   613 solver.cpp:312] Iteration 12600 (62.2423 iter/s, 1.60662s/100 iter), loss = 0.00241254
I0814 19:01:35.145015   613 solver.cpp:334]     Train net output #0: loss = 0.00241255 (* 1 = 0.00241255 loss)
I0814 19:01:35.145020   613 sgd_solver.cpp:136] Iteration 12600, lr = 0.00803125, m = 0.9
I0814 19:01:36.746534   613 solver.cpp:312] Iteration 12700 (62.4417 iter/s, 1.6015s/100 iter), loss = 0.00268598
I0814 19:01:36.746558   613 solver.cpp:334]     Train net output #0: loss = 0.00268598 (* 1 = 0.00268598 loss)
I0814 19:01:36.746564   613 sgd_solver.cpp:136] Iteration 12700, lr = 0.00801562, m = 0.9
I0814 19:01:38.410475   613 solver.cpp:312] Iteration 12800 (60.1002 iter/s, 1.66389s/100 iter), loss = 0.00307565
I0814 19:01:38.410544   613 solver.cpp:334]     Train net output #0: loss = 0.00307566 (* 1 = 0.00307566 loss)
I0814 19:01:38.410567   613 sgd_solver.cpp:136] Iteration 12800, lr = 0.008, m = 0.9
I0814 19:01:40.081960   613 solver.cpp:312] Iteration 12900 (59.8288 iter/s, 1.67144s/100 iter), loss = 0.00121009
I0814 19:01:40.081989   613 solver.cpp:334]     Train net output #0: loss = 0.0012101 (* 1 = 0.0012101 loss)
I0814 19:01:40.081995   613 sgd_solver.cpp:136] Iteration 12900, lr = 0.00798437, m = 0.9
I0814 19:01:41.684594   613 solver.cpp:509] Iteration 13000, Testing net (#0)
I0814 19:01:42.509568   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.914707
I0814 19:01:42.509588   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.994412
I0814 19:01:42.509593   613 solver.cpp:594]     Test net output #2: loss = 0.300487 (* 1 = 0.300487 loss)
I0814 19:01:42.509611   613 solver.cpp:264] [MultiGPU] Tests completed in 0.824994s
I0814 19:01:42.526510   613 solver.cpp:312] Iteration 13000 (40.9085 iter/s, 2.44448s/100 iter), loss = 0.00118577
I0814 19:01:42.526530   613 solver.cpp:334]     Train net output #0: loss = 0.00118578 (* 1 = 0.00118578 loss)
I0814 19:01:42.526536   613 sgd_solver.cpp:136] Iteration 13000, lr = 0.00796875, m = 0.9
I0814 19:01:44.131896   613 solver.cpp:312] Iteration 13100 (62.2922 iter/s, 1.60534s/100 iter), loss = 0.00265075
I0814 19:01:44.131920   613 solver.cpp:334]     Train net output #0: loss = 0.00265076 (* 1 = 0.00265076 loss)
I0814 19:01:44.131925   613 sgd_solver.cpp:136] Iteration 13100, lr = 0.00795313, m = 0.9
I0814 19:01:45.766261   613 solver.cpp:312] Iteration 13200 (61.1877 iter/s, 1.63432s/100 iter), loss = 0.00332237
I0814 19:01:45.766309   613 solver.cpp:334]     Train net output #0: loss = 0.00332238 (* 1 = 0.00332238 loss)
I0814 19:01:45.766320   613 sgd_solver.cpp:136] Iteration 13200, lr = 0.0079375, m = 0.9
I0814 19:01:47.361692   613 solver.cpp:312] Iteration 13300 (62.681 iter/s, 1.59538s/100 iter), loss = 0.00146
I0814 19:01:47.361717   613 solver.cpp:334]     Train net output #0: loss = 0.00146001 (* 1 = 0.00146001 loss)
I0814 19:01:47.361722   613 sgd_solver.cpp:136] Iteration 13300, lr = 0.00792187, m = 0.9
I0814 19:01:48.973592   613 solver.cpp:312] Iteration 13400 (62.0404 iter/s, 1.61185s/100 iter), loss = 0.000782068
I0814 19:01:48.973619   613 solver.cpp:334]     Train net output #0: loss = 0.000782077 (* 1 = 0.000782077 loss)
I0814 19:01:48.973626   613 sgd_solver.cpp:136] Iteration 13400, lr = 0.00790625, m = 0.9
I0814 19:01:50.612776   613 solver.cpp:312] Iteration 13500 (61.0079 iter/s, 1.63913s/100 iter), loss = 0.00214357
I0814 19:01:50.612803   613 solver.cpp:334]     Train net output #0: loss = 0.00214358 (* 1 = 0.00214358 loss)
I0814 19:01:50.612810   613 sgd_solver.cpp:136] Iteration 13500, lr = 0.00789062, m = 0.9
I0814 19:01:52.240870   613 solver.cpp:312] Iteration 13600 (61.4235 iter/s, 1.62804s/100 iter), loss = 0.00199094
I0814 19:01:52.240900   613 solver.cpp:334]     Train net output #0: loss = 0.00199095 (* 1 = 0.00199095 loss)
I0814 19:01:52.240906   613 sgd_solver.cpp:136] Iteration 13600, lr = 0.007875, m = 0.9
I0814 19:01:52.774317   592 data_reader.cpp:288] Starting prefetch of epoch 3
I0814 19:01:53.828558   613 solver.cpp:312] Iteration 13700 (62.9866 iter/s, 1.58764s/100 iter), loss = 0.0016825
I0814 19:01:53.828583   613 solver.cpp:334]     Train net output #0: loss = 0.00168251 (* 1 = 0.00168251 loss)
I0814 19:01:53.828590   613 sgd_solver.cpp:136] Iteration 13700, lr = 0.00785937, m = 0.9
I0814 19:01:55.437085   613 solver.cpp:312] Iteration 13800 (62.1705 iter/s, 1.60848s/100 iter), loss = 0.00191537
I0814 19:01:55.437110   613 solver.cpp:334]     Train net output #0: loss = 0.00191538 (* 1 = 0.00191538 loss)
I0814 19:01:55.437116   613 sgd_solver.cpp:136] Iteration 13800, lr = 0.00784375, m = 0.9
I0814 19:01:57.056506   613 solver.cpp:312] Iteration 13900 (61.7523 iter/s, 1.61937s/100 iter), loss = 0.00177273
I0814 19:01:57.056532   613 solver.cpp:334]     Train net output #0: loss = 0.00177274 (* 1 = 0.00177274 loss)
I0814 19:01:57.056537   613 sgd_solver.cpp:136] Iteration 13900, lr = 0.00782812, m = 0.9
I0814 19:01:58.669126   613 solver.cpp:509] Iteration 14000, Testing net (#0)
I0814 19:01:59.487828   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.910295
I0814 19:01:59.487848   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.995
I0814 19:01:59.487853   613 solver.cpp:594]     Test net output #2: loss = 0.322272 (* 1 = 0.322272 loss)
I0814 19:01:59.487867   613 solver.cpp:264] [MultiGPU] Tests completed in 0.818723s
I0814 19:01:59.505007   613 solver.cpp:312] Iteration 14000 (40.8424 iter/s, 2.44843s/100 iter), loss = 0.00211855
I0814 19:01:59.505201   613 solver.cpp:334]     Train net output #0: loss = 0.00211856 (* 1 = 0.00211856 loss)
I0814 19:01:59.505208   613 sgd_solver.cpp:136] Iteration 14000, lr = 0.0078125, m = 0.9
I0814 19:02:01.122784   613 solver.cpp:312] Iteration 14100 (61.8152 iter/s, 1.61772s/100 iter), loss = 0.00135588
I0814 19:02:01.122807   613 solver.cpp:334]     Train net output #0: loss = 0.00135589 (* 1 = 0.00135589 loss)
I0814 19:02:01.122812   613 sgd_solver.cpp:136] Iteration 14100, lr = 0.00779688, m = 0.9
I0814 19:02:02.722257   613 solver.cpp:312] Iteration 14200 (62.5225 iter/s, 1.59942s/100 iter), loss = 0.00100908
I0814 19:02:02.722282   613 solver.cpp:334]     Train net output #0: loss = 0.00100909 (* 1 = 0.00100909 loss)
I0814 19:02:02.722288   613 sgd_solver.cpp:136] Iteration 14200, lr = 0.00778125, m = 0.9
I0814 19:02:04.365736   613 solver.cpp:312] Iteration 14300 (60.8483 iter/s, 1.64343s/100 iter), loss = 0.00267836
I0814 19:02:04.365875   613 solver.cpp:334]     Train net output #0: loss = 0.00267837 (* 1 = 0.00267837 loss)
I0814 19:02:04.365885   613 sgd_solver.cpp:136] Iteration 14300, lr = 0.00776563, m = 0.9
I0814 19:02:06.014319   613 solver.cpp:312] Iteration 14400 (60.66 iter/s, 1.64853s/100 iter), loss = 0.00425318
I0814 19:02:06.014380   613 solver.cpp:334]     Train net output #0: loss = 0.00425319 (* 1 = 0.00425319 loss)
I0814 19:02:06.014398   613 sgd_solver.cpp:136] Iteration 14400, lr = 0.00775, m = 0.9
I0814 19:02:07.665529   613 solver.cpp:312] Iteration 14500 (60.5637 iter/s, 1.65115s/100 iter), loss = 0.000804562
I0814 19:02:07.665555   613 solver.cpp:334]     Train net output #0: loss = 0.00080457 (* 1 = 0.00080457 loss)
I0814 19:02:07.665561   613 sgd_solver.cpp:136] Iteration 14500, lr = 0.00773437, m = 0.9
I0814 19:02:09.242305   613 solver.cpp:312] Iteration 14600 (63.4224 iter/s, 1.57673s/100 iter), loss = 0.0016726
I0814 19:02:09.242332   613 solver.cpp:334]     Train net output #0: loss = 0.00167261 (* 1 = 0.00167261 loss)
I0814 19:02:09.242338   613 sgd_solver.cpp:136] Iteration 14600, lr = 0.00771875, m = 0.9
I0814 19:02:10.906086   613 solver.cpp:312] Iteration 14700 (60.1059 iter/s, 1.66373s/100 iter), loss = 0.0019093
I0814 19:02:10.906134   613 solver.cpp:334]     Train net output #0: loss = 0.00190931 (* 1 = 0.00190931 loss)
I0814 19:02:10.906147   613 sgd_solver.cpp:136] Iteration 14700, lr = 0.00770312, m = 0.9
I0814 19:02:12.545008   613 solver.cpp:312] Iteration 14800 (61.0177 iter/s, 1.63887s/100 iter), loss = 0.00179903
I0814 19:02:12.545037   613 solver.cpp:334]     Train net output #0: loss = 0.00179904 (* 1 = 0.00179904 loss)
I0814 19:02:12.545043   613 sgd_solver.cpp:136] Iteration 14800, lr = 0.0076875, m = 0.9
I0814 19:02:14.181891   613 solver.cpp:312] Iteration 14900 (61.0936 iter/s, 1.63683s/100 iter), loss = 0.00176115
I0814 19:02:14.181916   613 solver.cpp:334]     Train net output #0: loss = 0.00176116 (* 1 = 0.00176116 loss)
I0814 19:02:14.181922   613 sgd_solver.cpp:136] Iteration 14900, lr = 0.00767187, m = 0.9
I0814 19:02:15.753820   613 solver.cpp:509] Iteration 15000, Testing net (#0)
I0814 19:02:16.578467   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.909119
I0814 19:02:16.578485   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.995
I0814 19:02:16.578490   613 solver.cpp:594]     Test net output #2: loss = 0.314472 (* 1 = 0.314472 loss)
I0814 19:02:16.578507   613 solver.cpp:264] [MultiGPU] Tests completed in 0.824664s
I0814 19:02:16.594023   613 solver.cpp:312] Iteration 15000 (41.4583 iter/s, 2.41206s/100 iter), loss = 0.000777235
I0814 19:02:16.594041   613 solver.cpp:334]     Train net output #0: loss = 0.00077724 (* 1 = 0.00077724 loss)
I0814 19:02:16.594046   613 sgd_solver.cpp:136] Iteration 15000, lr = 0.00765625, m = 0.9
I0814 19:02:18.199842   613 solver.cpp:312] Iteration 15100 (62.2755 iter/s, 1.60577s/100 iter), loss = 0.00185174
I0814 19:02:18.199867   613 solver.cpp:334]     Train net output #0: loss = 0.00185174 (* 1 = 0.00185174 loss)
I0814 19:02:18.199872   613 sgd_solver.cpp:136] Iteration 15100, lr = 0.00764062, m = 0.9
I0814 19:02:19.796512   613 solver.cpp:312] Iteration 15200 (62.6324 iter/s, 1.59662s/100 iter), loss = 0.000854524
I0814 19:02:19.796561   613 solver.cpp:334]     Train net output #0: loss = 0.000854529 (* 1 = 0.000854529 loss)
I0814 19:02:19.796574   613 sgd_solver.cpp:136] Iteration 15200, lr = 0.007625, m = 0.9
I0814 19:02:21.439632   613 solver.cpp:312] Iteration 15300 (60.8617 iter/s, 1.64307s/100 iter), loss = 0.00110343
I0814 19:02:21.439680   613 solver.cpp:334]     Train net output #0: loss = 0.00110343 (* 1 = 0.00110343 loss)
I0814 19:02:21.439692   613 sgd_solver.cpp:136] Iteration 15300, lr = 0.00760937, m = 0.9
I0814 19:02:23.060503   613 solver.cpp:312] Iteration 15400 (61.6971 iter/s, 1.62082s/100 iter), loss = 0.00551649
I0814 19:02:23.060576   613 solver.cpp:334]     Train net output #0: loss = 0.0055165 (* 1 = 0.0055165 loss)
I0814 19:02:23.060600   613 sgd_solver.cpp:136] Iteration 15400, lr = 0.00759375, m = 0.9
I0814 19:02:24.678741   613 solver.cpp:312] Iteration 15500 (61.7976 iter/s, 1.61819s/100 iter), loss = 0.00109347
I0814 19:02:24.678774   613 solver.cpp:334]     Train net output #0: loss = 0.00109347 (* 1 = 0.00109347 loss)
I0814 19:02:24.678782   613 sgd_solver.cpp:136] Iteration 15500, lr = 0.00757812, m = 0.9
I0814 19:02:26.284601   613 solver.cpp:312] Iteration 15600 (62.2738 iter/s, 1.60581s/100 iter), loss = 0.00153432
I0814 19:02:26.284626   613 solver.cpp:334]     Train net output #0: loss = 0.00153432 (* 1 = 0.00153432 loss)
I0814 19:02:26.284632   613 sgd_solver.cpp:136] Iteration 15600, lr = 0.0075625, m = 0.9
I0814 19:02:27.918694   613 solver.cpp:312] Iteration 15700 (61.1979 iter/s, 1.63404s/100 iter), loss = 0.00775528
I0814 19:02:27.918718   613 solver.cpp:334]     Train net output #0: loss = 0.00775528 (* 1 = 0.00775528 loss)
I0814 19:02:27.918725   613 sgd_solver.cpp:136] Iteration 15700, lr = 0.00754687, m = 0.9
I0814 19:02:29.571770   613 solver.cpp:312] Iteration 15800 (60.4951 iter/s, 1.65303s/100 iter), loss = 0.00118675
I0814 19:02:29.571837   613 solver.cpp:334]     Train net output #0: loss = 0.00118675 (* 1 = 0.00118675 loss)
I0814 19:02:29.571856   613 sgd_solver.cpp:136] Iteration 15800, lr = 0.00753125, m = 0.9
I0814 19:02:31.235224   613 solver.cpp:312] Iteration 15900 (60.1177 iter/s, 1.6634s/100 iter), loss = 0.00723424
I0814 19:02:31.235251   613 solver.cpp:334]     Train net output #0: loss = 0.00723424 (* 1 = 0.00723424 loss)
I0814 19:02:31.235257   613 sgd_solver.cpp:136] Iteration 15900, lr = 0.00751562, m = 0.9
I0814 19:02:32.830828   613 solver.cpp:509] Iteration 16000, Testing net (#0)
I0814 19:02:33.646445   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.910295
I0814 19:02:33.646464   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.995588
I0814 19:02:33.646469   613 solver.cpp:594]     Test net output #2: loss = 0.309762 (* 1 = 0.309762 loss)
I0814 19:02:33.646483   613 solver.cpp:264] [MultiGPU] Tests completed in 0.815633s
I0814 19:02:33.662111   613 solver.cpp:312] Iteration 16000 (41.2062 iter/s, 2.42682s/100 iter), loss = 0.0019195
I0814 19:02:33.662129   613 solver.cpp:334]     Train net output #0: loss = 0.0019195 (* 1 = 0.0019195 loss)
I0814 19:02:33.662135   613 sgd_solver.cpp:136] Iteration 16000, lr = 0.0075, m = 0.9
I0814 19:02:35.252976   613 solver.cpp:312] Iteration 16100 (62.861 iter/s, 1.59081s/100 iter), loss = 0.00118147
I0814 19:02:35.253023   613 solver.cpp:334]     Train net output #0: loss = 0.00118147 (* 1 = 0.00118147 loss)
I0814 19:02:35.253029   613 sgd_solver.cpp:136] Iteration 16100, lr = 0.00748438, m = 0.9
I0814 19:02:36.864543   613 solver.cpp:312] Iteration 16200 (62.0533 iter/s, 1.61152s/100 iter), loss = 0.00292831
I0814 19:02:36.864588   613 solver.cpp:334]     Train net output #0: loss = 0.00292831 (* 1 = 0.00292831 loss)
I0814 19:02:36.864599   613 sgd_solver.cpp:136] Iteration 16200, lr = 0.00746875, m = 0.9
I0814 19:02:38.505540   613 solver.cpp:312] Iteration 16300 (60.9404 iter/s, 1.64095s/100 iter), loss = 0.00397588
I0814 19:02:38.505587   613 solver.cpp:334]     Train net output #0: loss = 0.00397588 (* 1 = 0.00397588 loss)
I0814 19:02:38.505599   613 sgd_solver.cpp:136] Iteration 16300, lr = 0.00745312, m = 0.9
I0814 19:02:40.167719   613 solver.cpp:312] Iteration 16400 (60.1638 iter/s, 1.66213s/100 iter), loss = 0.00162321
I0814 19:02:40.167800   613 solver.cpp:334]     Train net output #0: loss = 0.00162321 (* 1 = 0.00162321 loss)
I0814 19:02:40.167807   613 sgd_solver.cpp:136] Iteration 16400, lr = 0.0074375, m = 0.9
I0814 19:02:41.788164   613 solver.cpp:312] Iteration 16500 (61.7133 iter/s, 1.6204s/100 iter), loss = 0.0013623
I0814 19:02:41.788192   613 solver.cpp:334]     Train net output #0: loss = 0.0013623 (* 1 = 0.0013623 loss)
I0814 19:02:41.788199   613 sgd_solver.cpp:136] Iteration 16500, lr = 0.00742187, m = 0.9
I0814 19:02:43.392880   613 solver.cpp:312] Iteration 16600 (62.3183 iter/s, 1.60467s/100 iter), loss = 0.00175429
I0814 19:02:43.392931   613 solver.cpp:334]     Train net output #0: loss = 0.00175429 (* 1 = 0.00175429 loss)
I0814 19:02:43.392946   613 sgd_solver.cpp:136] Iteration 16600, lr = 0.00740625, m = 0.9
I0814 19:02:45.049950   613 solver.cpp:312] Iteration 16700 (60.3494 iter/s, 1.65702s/100 iter), loss = 0.00445534
I0814 19:02:45.049999   613 solver.cpp:334]     Train net output #0: loss = 0.00445534 (* 1 = 0.00445534 loss)
I0814 19:02:45.050012   613 sgd_solver.cpp:136] Iteration 16700, lr = 0.00739062, m = 0.9
I0814 19:02:46.685770   613 solver.cpp:312] Iteration 16800 (61.1332 iter/s, 1.63577s/100 iter), loss = 0.00359188
I0814 19:02:46.685820   613 solver.cpp:334]     Train net output #0: loss = 0.00359188 (* 1 = 0.00359188 loss)
I0814 19:02:46.685832   613 sgd_solver.cpp:136] Iteration 16800, lr = 0.007375, m = 0.9
I0814 19:02:48.291832   613 solver.cpp:312] Iteration 16900 (62.2662 iter/s, 1.60601s/100 iter), loss = 0.00337016
I0814 19:02:48.291862   613 solver.cpp:334]     Train net output #0: loss = 0.00337016 (* 1 = 0.00337016 loss)
I0814 19:02:48.291868   613 sgd_solver.cpp:136] Iteration 16900, lr = 0.00735937, m = 0.9
I0814 19:02:49.916357   613 solver.cpp:509] Iteration 17000, Testing net (#0)
I0814 19:02:50.731360   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.918236
I0814 19:02:50.731379   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.997353
I0814 19:02:50.731386   613 solver.cpp:594]     Test net output #2: loss = 0.282802 (* 1 = 0.282802 loss)
I0814 19:02:50.731415   613 solver.cpp:264] [MultiGPU] Tests completed in 0.815037s
I0814 19:02:50.747025   613 solver.cpp:312] Iteration 17000 (40.7311 iter/s, 2.45513s/100 iter), loss = 0.00310713
I0814 19:02:50.747040   613 solver.cpp:334]     Train net output #0: loss = 0.00310713 (* 1 = 0.00310713 loss)
I0814 19:02:50.747046   613 sgd_solver.cpp:136] Iteration 17000, lr = 0.00734375, m = 0.9
I0814 19:02:52.351989   613 solver.cpp:312] Iteration 17100 (62.3086 iter/s, 1.60491s/100 iter), loss = 0.0036535
I0814 19:02:52.352037   613 solver.cpp:334]     Train net output #0: loss = 0.0036535 (* 1 = 0.0036535 loss)
I0814 19:02:52.352051   613 sgd_solver.cpp:136] Iteration 17100, lr = 0.00732813, m = 0.9
I0814 19:02:53.989886   613 solver.cpp:312] Iteration 17200 (61.0558 iter/s, 1.63784s/100 iter), loss = 0.000626812
I0814 19:02:53.989912   613 solver.cpp:334]     Train net output #0: loss = 0.000626813 (* 1 = 0.000626813 loss)
I0814 19:02:53.989917   613 sgd_solver.cpp:136] Iteration 17200, lr = 0.0073125, m = 0.9
I0814 19:02:55.571626   613 solver.cpp:312] Iteration 17300 (63.2234 iter/s, 1.58169s/100 iter), loss = 0.00146118
I0814 19:02:55.571651   613 solver.cpp:334]     Train net output #0: loss = 0.00146118 (* 1 = 0.00146118 loss)
I0814 19:02:55.571657   613 sgd_solver.cpp:136] Iteration 17300, lr = 0.00729688, m = 0.9
I0814 19:02:57.198526   613 solver.cpp:312] Iteration 17400 (61.4684 iter/s, 1.62685s/100 iter), loss = 0.00112822
I0814 19:02:57.198689   613 solver.cpp:334]     Train net output #0: loss = 0.00112822 (* 1 = 0.00112822 loss)
I0814 19:02:57.198772   613 sgd_solver.cpp:136] Iteration 17400, lr = 0.00728125, m = 0.9
I0814 19:02:58.795130   613 solver.cpp:312] Iteration 17500 (62.635 iter/s, 1.59655s/100 iter), loss = 0.00461505
I0814 19:02:58.795192   613 solver.cpp:334]     Train net output #0: loss = 0.00461505 (* 1 = 0.00461505 loss)
I0814 19:02:58.795209   613 sgd_solver.cpp:136] Iteration 17500, lr = 0.00726563, m = 0.9
I0814 19:03:00.467663   613 solver.cpp:312] Iteration 17600 (59.7913 iter/s, 1.67248s/100 iter), loss = 0.00241077
I0814 19:03:00.467803   613 solver.cpp:334]     Train net output #0: loss = 0.00241077 (* 1 = 0.00241077 loss)
I0814 19:03:00.467820   613 sgd_solver.cpp:136] Iteration 17600, lr = 0.00725, m = 0.9
I0814 19:03:02.104017   613 solver.cpp:312] Iteration 17700 (61.1134 iter/s, 1.6363s/100 iter), loss = 0.0015215
I0814 19:03:02.104043   613 solver.cpp:334]     Train net output #0: loss = 0.0015215 (* 1 = 0.0015215 loss)
I0814 19:03:02.104050   613 sgd_solver.cpp:136] Iteration 17700, lr = 0.00723437, m = 0.9
I0814 19:03:03.740682   613 solver.cpp:312] Iteration 17800 (61.1018 iter/s, 1.63661s/100 iter), loss = 0.00227391
I0814 19:03:03.740742   613 solver.cpp:334]     Train net output #0: loss = 0.00227391 (* 1 = 0.00227391 loss)
I0814 19:03:03.740764   613 sgd_solver.cpp:136] Iteration 17800, lr = 0.00721875, m = 0.9
I0814 19:03:05.343962   613 solver.cpp:312] Iteration 17900 (62.374 iter/s, 1.60323s/100 iter), loss = 0.00459324
I0814 19:03:05.344090   613 solver.cpp:334]     Train net output #0: loss = 0.00459324 (* 1 = 0.00459324 loss)
I0814 19:03:05.344110   613 sgd_solver.cpp:136] Iteration 17900, lr = 0.00720312, m = 0.9
I0814 19:03:06.942507   613 solver.cpp:509] Iteration 18000, Testing net (#0)
I0814 19:03:07.419322   611 data_reader.cpp:288] Starting prefetch of epoch 2
I0814 19:03:07.757176   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.927354
I0814 19:03:07.757201   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.997353
I0814 19:03:07.757211   613 solver.cpp:594]     Test net output #2: loss = 0.266419 (* 1 = 0.266419 loss)
I0814 19:03:07.757236   613 solver.cpp:264] [MultiGPU] Tests completed in 0.814704s
I0814 19:03:07.781983   613 solver.cpp:312] Iteration 18000 (41.0181 iter/s, 2.43795s/100 iter), loss = 0.000737331
I0814 19:03:07.782014   613 solver.cpp:334]     Train net output #0: loss = 0.000737331 (* 1 = 0.000737331 loss)
I0814 19:03:07.782021   613 sgd_solver.cpp:136] Iteration 18000, lr = 0.0071875, m = 0.9
I0814 19:03:09.409538   613 solver.cpp:312] Iteration 18100 (61.4438 iter/s, 1.6275s/100 iter), loss = 0.0010484
I0814 19:03:09.409564   613 solver.cpp:334]     Train net output #0: loss = 0.0010484 (* 1 = 0.0010484 loss)
I0814 19:03:09.409570   613 sgd_solver.cpp:136] Iteration 18100, lr = 0.00717187, m = 0.9
I0814 19:03:11.050189   613 solver.cpp:312] Iteration 18200 (60.9532 iter/s, 1.6406s/100 iter), loss = 0.00127794
I0814 19:03:11.050211   613 solver.cpp:334]     Train net output #0: loss = 0.00127794 (* 1 = 0.00127794 loss)
I0814 19:03:11.050217   613 sgd_solver.cpp:136] Iteration 18200, lr = 0.00715625, m = 0.9
I0814 19:03:12.679476   613 solver.cpp:312] Iteration 18300 (61.3784 iter/s, 1.62924s/100 iter), loss = 0.00375784
I0814 19:03:12.679500   613 solver.cpp:334]     Train net output #0: loss = 0.00375784 (* 1 = 0.00375784 loss)
I0814 19:03:12.679505   613 sgd_solver.cpp:136] Iteration 18300, lr = 0.00714062, m = 0.9
I0814 19:03:14.302444   613 solver.cpp:312] Iteration 18400 (61.6175 iter/s, 1.62292s/100 iter), loss = 0.0021986
I0814 19:03:14.302472   613 solver.cpp:334]     Train net output #0: loss = 0.0021986 (* 1 = 0.0021986 loss)
I0814 19:03:14.302479   613 sgd_solver.cpp:136] Iteration 18400, lr = 0.007125, m = 0.9
I0814 19:03:15.896833   613 solver.cpp:312] Iteration 18500 (62.7218 iter/s, 1.59434s/100 iter), loss = 0.000585724
I0814 19:03:15.896893   613 solver.cpp:334]     Train net output #0: loss = 0.000585723 (* 1 = 0.000585723 loss)
I0814 19:03:15.896911   613 sgd_solver.cpp:136] Iteration 18500, lr = 0.00710937, m = 0.9
I0814 19:03:17.500366   613 solver.cpp:312] Iteration 18600 (62.3641 iter/s, 1.60349s/100 iter), loss = 0.00354955
I0814 19:03:17.500427   613 solver.cpp:334]     Train net output #0: loss = 0.00354955 (* 1 = 0.00354955 loss)
I0814 19:03:17.500445   613 sgd_solver.cpp:136] Iteration 18600, lr = 0.00709375, m = 0.9
I0814 19:03:19.124641   613 solver.cpp:312] Iteration 18700 (61.5678 iter/s, 1.62423s/100 iter), loss = 0.00254444
I0814 19:03:19.124665   613 solver.cpp:334]     Train net output #0: loss = 0.00254444 (* 1 = 0.00254444 loss)
I0814 19:03:19.124668   613 sgd_solver.cpp:136] Iteration 18700, lr = 0.00707812, m = 0.9
I0814 19:03:20.750239   613 solver.cpp:312] Iteration 18800 (61.5178 iter/s, 1.62555s/100 iter), loss = 0.00104108
I0814 19:03:20.750268   613 solver.cpp:334]     Train net output #0: loss = 0.00104108 (* 1 = 0.00104108 loss)
I0814 19:03:20.750275   613 sgd_solver.cpp:136] Iteration 18800, lr = 0.0070625, m = 0.9
I0814 19:03:22.331162   613 solver.cpp:312] Iteration 18900 (63.2561 iter/s, 1.58087s/100 iter), loss = 0.00155515
I0814 19:03:22.331187   613 solver.cpp:334]     Train net output #0: loss = 0.00155515 (* 1 = 0.00155515 loss)
I0814 19:03:22.331193   613 sgd_solver.cpp:136] Iteration 18900, lr = 0.00704687, m = 0.9
I0814 19:03:23.932219   613 solver.cpp:509] Iteration 19000, Testing net (#0)
I0814 19:03:24.751765   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.92353
I0814 19:03:24.751781   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.997353
I0814 19:03:24.751803   613 solver.cpp:594]     Test net output #2: loss = 0.27743 (* 1 = 0.27743 loss)
I0814 19:03:24.751823   613 solver.cpp:264] [MultiGPU] Tests completed in 0.819583s
I0814 19:03:24.772634   613 solver.cpp:312] Iteration 19000 (40.9601 iter/s, 2.4414s/100 iter), loss = 0.00470685
I0814 19:03:24.772660   613 solver.cpp:334]     Train net output #0: loss = 0.00470686 (* 1 = 0.00470686 loss)
I0814 19:03:24.772666   613 sgd_solver.cpp:136] Iteration 19000, lr = 0.00703125, m = 0.9
I0814 19:03:26.405289   613 solver.cpp:312] Iteration 19100 (61.2516 iter/s, 1.63261s/100 iter), loss = 0.00294124
I0814 19:03:26.405313   613 solver.cpp:334]     Train net output #0: loss = 0.00294124 (* 1 = 0.00294124 loss)
I0814 19:03:26.405318   613 sgd_solver.cpp:136] Iteration 19100, lr = 0.00701563, m = 0.9
I0814 19:03:28.027969   613 solver.cpp:312] Iteration 19200 (61.6283 iter/s, 1.62263s/100 iter), loss = 0.000795837
I0814 19:03:28.028029   613 solver.cpp:334]     Train net output #0: loss = 0.000795837 (* 1 = 0.000795837 loss)
I0814 19:03:28.028048   613 sgd_solver.cpp:136] Iteration 19200, lr = 0.007, m = 0.9
I0814 19:03:29.644533   613 solver.cpp:312] Iteration 19300 (61.8616 iter/s, 1.61651s/100 iter), loss = 0.000762076
I0814 19:03:29.644562   613 solver.cpp:334]     Train net output #0: loss = 0.000762077 (* 1 = 0.000762077 loss)
I0814 19:03:29.644568   613 sgd_solver.cpp:136] Iteration 19300, lr = 0.00698437, m = 0.9
I0814 19:03:31.244894   613 solver.cpp:312] Iteration 19400 (62.4879 iter/s, 1.60031s/100 iter), loss = 0.00231931
I0814 19:03:31.244917   613 solver.cpp:334]     Train net output #0: loss = 0.00231931 (* 1 = 0.00231931 loss)
I0814 19:03:31.244923   613 sgd_solver.cpp:136] Iteration 19400, lr = 0.00696875, m = 0.9
I0814 19:03:32.828857   613 solver.cpp:312] Iteration 19500 (63.1346 iter/s, 1.58392s/100 iter), loss = 0.0022329
I0814 19:03:32.828923   613 solver.cpp:334]     Train net output #0: loss = 0.0022329 (* 1 = 0.0022329 loss)
I0814 19:03:32.828945   613 sgd_solver.cpp:136] Iteration 19500, lr = 0.00695312, m = 0.9
I0814 19:03:34.432029   613 solver.cpp:312] Iteration 19600 (62.3783 iter/s, 1.60312s/100 iter), loss = 0.00570968
I0814 19:03:34.432054   613 solver.cpp:334]     Train net output #0: loss = 0.00570968 (* 1 = 0.00570968 loss)
I0814 19:03:34.432060   613 sgd_solver.cpp:136] Iteration 19600, lr = 0.0069375, m = 0.9
I0814 19:03:36.048465   613 solver.cpp:312] Iteration 19700 (61.8663 iter/s, 1.61639s/100 iter), loss = 0.000734632
I0814 19:03:36.048537   613 solver.cpp:334]     Train net output #0: loss = 0.000734632 (* 1 = 0.000734632 loss)
I0814 19:03:36.048544   613 sgd_solver.cpp:136] Iteration 19700, lr = 0.00692187, m = 0.9
I0814 19:03:37.664813   613 solver.cpp:312] Iteration 19800 (61.8697 iter/s, 1.6163s/100 iter), loss = 0.00238147
I0814 19:03:37.664836   613 solver.cpp:334]     Train net output #0: loss = 0.00238147 (* 1 = 0.00238147 loss)
I0814 19:03:37.664844   613 sgd_solver.cpp:136] Iteration 19800, lr = 0.00690625, m = 0.9
I0814 19:03:39.303618   613 solver.cpp:312] Iteration 19900 (61.0219 iter/s, 1.63876s/100 iter), loss = 0.00173495
I0814 19:03:39.303679   613 solver.cpp:334]     Train net output #0: loss = 0.00173495 (* 1 = 0.00173495 loss)
I0814 19:03:39.303697   613 sgd_solver.cpp:136] Iteration 19900, lr = 0.00689062, m = 0.9
I0814 19:03:40.900918   613 solver.cpp:639] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/l1reg/cifar10_jacintonet11v2_iter_20000.caffemodel
I0814 19:03:40.910614   613 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/l1reg/cifar10_jacintonet11v2_iter_20000.solverstate
I0814 19:03:40.914304   613 solver.cpp:509] Iteration 20000, Testing net (#0)
I0814 19:03:41.712262   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.918824
I0814 19:03:41.712280   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.997353
I0814 19:03:41.712285   613 solver.cpp:594]     Test net output #2: loss = 0.28781 (* 1 = 0.28781 loss)
I0814 19:03:41.712306   613 solver.cpp:264] [MultiGPU] Tests completed in 0.797976s
I0814 19:03:41.730294   613 solver.cpp:312] Iteration 20000 (41.2098 iter/s, 2.42661s/100 iter), loss = 0.000906871
I0814 19:03:41.730315   613 solver.cpp:334]     Train net output #0: loss = 0.000906869 (* 1 = 0.000906869 loss)
I0814 19:03:41.730321   613 sgd_solver.cpp:136] Iteration 20000, lr = 0.006875, m = 0.9
I0814 19:03:43.371384   613 solver.cpp:312] Iteration 20100 (60.937 iter/s, 1.64104s/100 iter), loss = 0.00163634
I0814 19:03:43.371409   613 solver.cpp:334]     Train net output #0: loss = 0.00163633 (* 1 = 0.00163633 loss)
I0814 19:03:43.371415   613 sgd_solver.cpp:136] Iteration 20100, lr = 0.00685938, m = 0.9
I0814 19:03:44.994832   613 solver.cpp:312] Iteration 20200 (61.5993 iter/s, 1.62339s/100 iter), loss = 0.00267018
I0814 19:03:44.994901   613 solver.cpp:334]     Train net output #0: loss = 0.00267018 (* 1 = 0.00267018 loss)
I0814 19:03:44.994925   613 sgd_solver.cpp:136] Iteration 20200, lr = 0.00684375, m = 0.9
I0814 19:03:46.600505   613 solver.cpp:312] Iteration 20300 (62.281 iter/s, 1.60563s/100 iter), loss = 0.00179529
I0814 19:03:46.600535   613 solver.cpp:334]     Train net output #0: loss = 0.00179529 (* 1 = 0.00179529 loss)
I0814 19:03:46.600543   613 sgd_solver.cpp:136] Iteration 20300, lr = 0.00682813, m = 0.9
I0814 19:03:48.211993   613 solver.cpp:312] Iteration 20400 (62.0564 iter/s, 1.61144s/100 iter), loss = 0.00372159
I0814 19:03:48.212062   613 solver.cpp:334]     Train net output #0: loss = 0.00372159 (* 1 = 0.00372159 loss)
I0814 19:03:48.212082   613 sgd_solver.cpp:136] Iteration 20400, lr = 0.0068125, m = 0.9
I0814 19:03:49.822804   613 solver.cpp:312] Iteration 20500 (62.0824 iter/s, 1.61076s/100 iter), loss = 0.00281403
I0814 19:03:49.822829   613 solver.cpp:334]     Train net output #0: loss = 0.00281402 (* 1 = 0.00281402 loss)
I0814 19:03:49.822835   613 sgd_solver.cpp:136] Iteration 20500, lr = 0.00679688, m = 0.9
I0814 19:03:51.430668   613 solver.cpp:312] Iteration 20600 (62.1962 iter/s, 1.60782s/100 iter), loss = 0.00183386
I0814 19:03:51.430693   613 solver.cpp:334]     Train net output #0: loss = 0.00183386 (* 1 = 0.00183386 loss)
I0814 19:03:51.430698   613 sgd_solver.cpp:136] Iteration 20600, lr = 0.00678125, m = 0.9
I0814 19:03:53.056679   613 solver.cpp:312] Iteration 20700 (61.5022 iter/s, 1.62596s/100 iter), loss = 0.0033849
I0814 19:03:53.056741   613 solver.cpp:334]     Train net output #0: loss = 0.0033849 (* 1 = 0.0033849 loss)
I0814 19:03:53.056772   613 sgd_solver.cpp:136] Iteration 20700, lr = 0.00676562, m = 0.9
I0814 19:03:54.667013   613 solver.cpp:312] Iteration 20800 (62.1008 iter/s, 1.61028s/100 iter), loss = 0.00102706
I0814 19:03:54.667155   613 solver.cpp:334]     Train net output #0: loss = 0.00102706 (* 1 = 0.00102706 loss)
I0814 19:03:54.667173   613 sgd_solver.cpp:136] Iteration 20800, lr = 0.00675, m = 0.9
I0814 19:03:56.288794   613 solver.cpp:312] Iteration 20900 (61.6625 iter/s, 1.62173s/100 iter), loss = 0.00151879
I0814 19:03:56.288818   613 solver.cpp:334]     Train net output #0: loss = 0.00151879 (* 1 = 0.00151879 loss)
I0814 19:03:56.288823   613 sgd_solver.cpp:136] Iteration 20900, lr = 0.00673437, m = 0.9
I0814 19:03:57.896621   613 solver.cpp:509] Iteration 21000, Testing net (#0)
I0814 19:03:58.717090   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.919413
I0814 19:03:58.717108   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.996765
I0814 19:03:58.717115   613 solver.cpp:594]     Test net output #2: loss = 0.293822 (* 1 = 0.293822 loss)
I0814 19:03:58.717133   613 solver.cpp:264] [MultiGPU] Tests completed in 0.820489s
I0814 19:03:58.736523   613 solver.cpp:312] Iteration 21000 (40.8553 iter/s, 2.44766s/100 iter), loss = 0.00344774
I0814 19:03:58.736541   613 solver.cpp:334]     Train net output #0: loss = 0.00344774 (* 1 = 0.00344774 loss)
I0814 19:03:58.736546   613 sgd_solver.cpp:136] Iteration 21000, lr = 0.00671875, m = 0.9
I0814 19:04:00.374426   613 solver.cpp:312] Iteration 21100 (61.0556 iter/s, 1.63785s/100 iter), loss = 0.00048228
I0814 19:04:00.374476   613 solver.cpp:334]     Train net output #0: loss = 0.000482281 (* 1 = 0.000482281 loss)
I0814 19:04:00.374490   613 sgd_solver.cpp:136] Iteration 21100, lr = 0.00670313, m = 0.9
I0814 19:04:01.988874   613 solver.cpp:312] Iteration 21200 (61.9426 iter/s, 1.6144s/100 iter), loss = 0.00248236
I0814 19:04:01.988900   613 solver.cpp:334]     Train net output #0: loss = 0.00248236 (* 1 = 0.00248236 loss)
I0814 19:04:01.988906   613 sgd_solver.cpp:136] Iteration 21200, lr = 0.0066875, m = 0.9
I0814 19:04:03.573149   613 solver.cpp:312] Iteration 21300 (63.1223 iter/s, 1.58423s/100 iter), loss = 0.00168004
I0814 19:04:03.573212   613 solver.cpp:334]     Train net output #0: loss = 0.00168004 (* 1 = 0.00168004 loss)
I0814 19:04:03.573232   613 sgd_solver.cpp:136] Iteration 21300, lr = 0.00667187, m = 0.9
I0814 19:04:05.207016   613 solver.cpp:312] Iteration 21400 (61.2063 iter/s, 1.63382s/100 iter), loss = 0.00240321
I0814 19:04:05.207041   613 solver.cpp:334]     Train net output #0: loss = 0.00240322 (* 1 = 0.00240322 loss)
I0814 19:04:05.207047   613 sgd_solver.cpp:136] Iteration 21400, lr = 0.00665625, m = 0.9
I0814 19:04:06.837733   613 solver.cpp:312] Iteration 21500 (61.3247 iter/s, 1.63066s/100 iter), loss = 0.00129845
I0814 19:04:06.837801   613 solver.cpp:334]     Train net output #0: loss = 0.00129845 (* 1 = 0.00129845 loss)
I0814 19:04:06.837806   613 sgd_solver.cpp:136] Iteration 21500, lr = 0.00664062, m = 0.9
I0814 19:04:08.452221   613 solver.cpp:312] Iteration 21600 (61.9409 iter/s, 1.61444s/100 iter), loss = 0.000980934
I0814 19:04:08.452267   613 solver.cpp:334]     Train net output #0: loss = 0.000980937 (* 1 = 0.000980937 loss)
I0814 19:04:08.452280   613 sgd_solver.cpp:136] Iteration 21600, lr = 0.006625, m = 0.9
I0814 19:04:10.038586   613 solver.cpp:312] Iteration 21700 (63.0392 iter/s, 1.58631s/100 iter), loss = 0.00176299
I0814 19:04:10.038843   613 solver.cpp:334]     Train net output #0: loss = 0.001763 (* 1 = 0.001763 loss)
I0814 19:04:10.038851   613 sgd_solver.cpp:136] Iteration 21700, lr = 0.00660937, m = 0.9
I0814 19:04:11.695492   613 solver.cpp:312] Iteration 21800 (60.3554 iter/s, 1.65685s/100 iter), loss = 0.00176023
I0814 19:04:11.695521   613 solver.cpp:334]     Train net output #0: loss = 0.00176023 (* 1 = 0.00176023 loss)
I0814 19:04:11.695528   613 sgd_solver.cpp:136] Iteration 21800, lr = 0.00659375, m = 0.9
I0814 19:04:13.363286   613 solver.cpp:312] Iteration 21900 (59.9612 iter/s, 1.66774s/100 iter), loss = 0.000521508
I0814 19:04:13.363309   613 solver.cpp:334]     Train net output #0: loss = 0.00052151 (* 1 = 0.00052151 loss)
I0814 19:04:13.363317   613 sgd_solver.cpp:136] Iteration 21900, lr = 0.00657812, m = 0.9
I0814 19:04:14.989109   613 solver.cpp:509] Iteration 22000, Testing net (#0)
I0814 19:04:15.404855   611 data_reader.cpp:288] Starting prefetch of epoch 3
I0814 19:04:15.798588   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.917648
I0814 19:04:15.798611   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.996471
I0814 19:04:15.798619   613 solver.cpp:594]     Test net output #2: loss = 0.294372 (* 1 = 0.294372 loss)
I0814 19:04:15.798648   613 solver.cpp:264] [MultiGPU] Tests completed in 0.809512s
I0814 19:04:15.817553   613 solver.cpp:312] Iteration 22000 (40.7465 iter/s, 2.4542s/100 iter), loss = 0.00435823
I0814 19:04:15.817579   613 solver.cpp:334]     Train net output #0: loss = 0.00435823 (* 1 = 0.00435823 loss)
I0814 19:04:15.817584   613 sgd_solver.cpp:136] Iteration 22000, lr = 0.0065625, m = 0.9
I0814 19:04:17.445997   613 solver.cpp:312] Iteration 22100 (61.4103 iter/s, 1.62839s/100 iter), loss = 0.00471555
I0814 19:04:17.446140   613 solver.cpp:334]     Train net output #0: loss = 0.00471555 (* 1 = 0.00471555 loss)
I0814 19:04:17.446159   613 sgd_solver.cpp:136] Iteration 22100, lr = 0.00654687, m = 0.9
I0814 19:04:19.078338   613 solver.cpp:312] Iteration 22200 (61.2634 iter/s, 1.63229s/100 iter), loss = 0.00286048
I0814 19:04:19.078362   613 solver.cpp:334]     Train net output #0: loss = 0.00286048 (* 1 = 0.00286048 loss)
I0814 19:04:19.078368   613 sgd_solver.cpp:136] Iteration 22200, lr = 0.00653125, m = 0.9
I0814 19:04:20.689061   613 solver.cpp:312] Iteration 22300 (62.0858 iter/s, 1.61067s/100 iter), loss = 0.00219214
I0814 19:04:20.689111   613 solver.cpp:334]     Train net output #0: loss = 0.00219214 (* 1 = 0.00219214 loss)
I0814 19:04:20.689124   613 sgd_solver.cpp:136] Iteration 22300, lr = 0.00651562, m = 0.9
I0814 19:04:22.324229   613 solver.cpp:312] Iteration 22400 (61.1577 iter/s, 1.63512s/100 iter), loss = 0.00215813
I0814 19:04:22.324276   613 solver.cpp:334]     Train net output #0: loss = 0.00215813 (* 1 = 0.00215813 loss)
I0814 19:04:22.324288   613 sgd_solver.cpp:136] Iteration 22400, lr = 0.0065, m = 0.9
I0814 19:04:23.972817   613 solver.cpp:312] Iteration 22500 (60.6599 iter/s, 1.64854s/100 iter), loss = 0.00330128
I0814 19:04:23.972885   613 solver.cpp:334]     Train net output #0: loss = 0.00330128 (* 1 = 0.00330128 loss)
I0814 19:04:23.972908   613 sgd_solver.cpp:136] Iteration 22500, lr = 0.00648437, m = 0.9
I0814 19:04:25.616348   613 solver.cpp:312] Iteration 22600 (60.8463 iter/s, 1.64348s/100 iter), loss = 0.00053988
I0814 19:04:25.616426   613 solver.cpp:334]     Train net output #0: loss = 0.000539878 (* 1 = 0.000539878 loss)
I0814 19:04:25.616459   613 sgd_solver.cpp:136] Iteration 22600, lr = 0.00646875, m = 0.9
I0814 19:04:27.241888   613 solver.cpp:312] Iteration 22700 (61.5198 iter/s, 1.62549s/100 iter), loss = 0.00686422
I0814 19:04:27.241948   613 solver.cpp:334]     Train net output #0: loss = 0.00686422 (* 1 = 0.00686422 loss)
I0814 19:04:27.241966   613 sgd_solver.cpp:136] Iteration 22700, lr = 0.00645312, m = 0.9
I0814 19:04:28.870021   613 solver.cpp:312] Iteration 22800 (61.422 iter/s, 1.62808s/100 iter), loss = 0.00274646
I0814 19:04:28.870080   613 solver.cpp:334]     Train net output #0: loss = 0.00274646 (* 1 = 0.00274646 loss)
I0814 19:04:28.870098   613 sgd_solver.cpp:136] Iteration 22800, lr = 0.0064375, m = 0.9
I0814 19:04:30.511370   613 solver.cpp:312] Iteration 22900 (60.9273 iter/s, 1.6413s/100 iter), loss = 0.000264519
I0814 19:04:30.511427   613 solver.cpp:334]     Train net output #0: loss = 0.000264518 (* 1 = 0.000264518 loss)
I0814 19:04:30.511445   613 sgd_solver.cpp:136] Iteration 22900, lr = 0.00642187, m = 0.9
I0814 19:04:32.120968   613 solver.cpp:509] Iteration 23000, Testing net (#0)
I0814 19:04:32.944051   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.916177
I0814 19:04:32.944070   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.995
I0814 19:04:32.944077   613 solver.cpp:594]     Test net output #2: loss = 0.291836 (* 1 = 0.291836 loss)
I0814 19:04:32.944095   613 solver.cpp:264] [MultiGPU] Tests completed in 0.823107s
I0814 19:04:32.964614   613 solver.cpp:312] Iteration 23000 (40.7635 iter/s, 2.45318s/100 iter), loss = 0.00219191
I0814 19:04:32.964633   613 solver.cpp:334]     Train net output #0: loss = 0.00219191 (* 1 = 0.00219191 loss)
I0814 19:04:32.964638   613 sgd_solver.cpp:136] Iteration 23000, lr = 0.00640625, m = 0.9
I0814 19:04:34.585244   613 solver.cpp:312] Iteration 23100 (61.7064 iter/s, 1.62058s/100 iter), loss = 0.00441107
I0814 19:04:34.585268   613 solver.cpp:334]     Train net output #0: loss = 0.00441107 (* 1 = 0.00441107 loss)
I0814 19:04:34.585273   613 sgd_solver.cpp:136] Iteration 23100, lr = 0.00639063, m = 0.9
I0814 19:04:36.201262   613 solver.cpp:312] Iteration 23200 (61.8825 iter/s, 1.61597s/100 iter), loss = 0.00173958
I0814 19:04:36.201289   613 solver.cpp:334]     Train net output #0: loss = 0.00173958 (* 1 = 0.00173958 loss)
I0814 19:04:36.201295   613 sgd_solver.cpp:136] Iteration 23200, lr = 0.006375, m = 0.9
I0814 19:04:37.789973   613 solver.cpp:312] Iteration 23300 (62.946 iter/s, 1.58866s/100 iter), loss = 0.0031079
I0814 19:04:37.790181   613 solver.cpp:334]     Train net output #0: loss = 0.0031079 (* 1 = 0.0031079 loss)
I0814 19:04:37.790205   613 sgd_solver.cpp:136] Iteration 23300, lr = 0.00635938, m = 0.9
I0814 19:04:39.444963   613 solver.cpp:312] Iteration 23400 (60.4251 iter/s, 1.65494s/100 iter), loss = 0.00281051
I0814 19:04:39.445009   613 solver.cpp:334]     Train net output #0: loss = 0.00281051 (* 1 = 0.00281051 loss)
I0814 19:04:39.445022   613 sgd_solver.cpp:136] Iteration 23400, lr = 0.00634375, m = 0.9
I0814 19:04:41.064201   613 solver.cpp:312] Iteration 23500 (61.7594 iter/s, 1.61919s/100 iter), loss = 0.000432662
I0814 19:04:41.064252   613 solver.cpp:334]     Train net output #0: loss = 0.000432662 (* 1 = 0.000432662 loss)
I0814 19:04:41.064266   613 sgd_solver.cpp:136] Iteration 23500, lr = 0.00632813, m = 0.9
I0814 19:04:42.675755   613 solver.cpp:312] Iteration 23600 (62.0539 iter/s, 1.6115s/100 iter), loss = 0.00194008
I0814 19:04:42.675778   613 solver.cpp:334]     Train net output #0: loss = 0.00194008 (* 1 = 0.00194008 loss)
I0814 19:04:42.675783   613 sgd_solver.cpp:136] Iteration 23600, lr = 0.0063125, m = 0.9
I0814 19:04:44.284289   613 solver.cpp:312] Iteration 23700 (62.1702 iter/s, 1.60849s/100 iter), loss = 0.00201476
I0814 19:04:44.284315   613 solver.cpp:334]     Train net output #0: loss = 0.00201476 (* 1 = 0.00201476 loss)
I0814 19:04:44.284322   613 sgd_solver.cpp:136] Iteration 23700, lr = 0.00629687, m = 0.9
I0814 19:04:45.944391   613 solver.cpp:312] Iteration 23800 (60.2391 iter/s, 1.66005s/100 iter), loss = 0.00134619
I0814 19:04:45.944450   613 solver.cpp:334]     Train net output #0: loss = 0.0013462 (* 1 = 0.0013462 loss)
I0814 19:04:45.944468   613 sgd_solver.cpp:136] Iteration 23800, lr = 0.00628125, m = 0.9
I0814 19:04:47.528363   613 solver.cpp:312] Iteration 23900 (63.1344 iter/s, 1.58392s/100 iter), loss = 0.00208318
I0814 19:04:47.528424   613 solver.cpp:334]     Train net output #0: loss = 0.00208318 (* 1 = 0.00208318 loss)
I0814 19:04:47.528442   613 sgd_solver.cpp:136] Iteration 23900, lr = 0.00626562, m = 0.9
I0814 19:04:49.133083   613 solver.cpp:509] Iteration 24000, Testing net (#0)
I0814 19:04:49.953320   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.91353
I0814 19:04:49.953339   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.995
I0814 19:04:49.953343   613 solver.cpp:594]     Test net output #2: loss = 0.303969 (* 1 = 0.303969 loss)
I0814 19:04:49.953359   613 solver.cpp:264] [MultiGPU] Tests completed in 0.820255s
I0814 19:04:49.969040   613 solver.cpp:312] Iteration 24000 (40.9734 iter/s, 2.44061s/100 iter), loss = 0.00240469
I0814 19:04:49.969056   613 solver.cpp:334]     Train net output #0: loss = 0.00240469 (* 1 = 0.00240469 loss)
I0814 19:04:49.969059   613 sgd_solver.cpp:136] Iteration 24000, lr = 0.00625, m = 0.9
I0814 19:04:51.595706   613 solver.cpp:312] Iteration 24100 (61.4775 iter/s, 1.62661s/100 iter), loss = 0.00447908
I0814 19:04:51.595757   613 solver.cpp:334]     Train net output #0: loss = 0.00447908 (* 1 = 0.00447908 loss)
I0814 19:04:51.595769   613 sgd_solver.cpp:136] Iteration 24100, lr = 0.00623438, m = 0.9
I0814 19:04:53.215042   613 solver.cpp:312] Iteration 24200 (61.7556 iter/s, 1.61929s/100 iter), loss = 0.00180773
I0814 19:04:53.215101   613 solver.cpp:334]     Train net output #0: loss = 0.00180773 (* 1 = 0.00180773 loss)
I0814 19:04:53.215117   613 sgd_solver.cpp:136] Iteration 24200, lr = 0.00621875, m = 0.9
I0814 19:04:54.868645   613 solver.cpp:312] Iteration 24300 (60.4759 iter/s, 1.65355s/100 iter), loss = 0.00156146
I0814 19:04:54.868667   613 solver.cpp:334]     Train net output #0: loss = 0.00156146 (* 1 = 0.00156146 loss)
I0814 19:04:54.868672   613 sgd_solver.cpp:136] Iteration 24300, lr = 0.00620312, m = 0.9
I0814 19:04:56.461805   613 solver.cpp:312] Iteration 24400 (62.7702 iter/s, 1.59311s/100 iter), loss = 0.00068046
I0814 19:04:56.461854   613 solver.cpp:334]     Train net output #0: loss = 0.00068046 (* 1 = 0.00068046 loss)
I0814 19:04:56.461866   613 sgd_solver.cpp:136] Iteration 24400, lr = 0.0061875, m = 0.9
I0814 19:04:58.116303   613 solver.cpp:312] Iteration 24500 (60.4431 iter/s, 1.65445s/100 iter), loss = 0.00273359
I0814 19:04:58.116349   613 solver.cpp:334]     Train net output #0: loss = 0.00273359 (* 1 = 0.00273359 loss)
I0814 19:04:58.116360   613 sgd_solver.cpp:136] Iteration 24500, lr = 0.00617187, m = 0.9
I0814 19:04:59.689074   613 solver.cpp:312] Iteration 24600 (63.5841 iter/s, 1.57272s/100 iter), loss = 0.00144755
I0814 19:04:59.689122   613 solver.cpp:334]     Train net output #0: loss = 0.00144755 (* 1 = 0.00144755 loss)
I0814 19:04:59.689136   613 sgd_solver.cpp:136] Iteration 24600, lr = 0.00615625, m = 0.9
I0814 19:05:01.303139   613 solver.cpp:312] Iteration 24700 (61.9572 iter/s, 1.61402s/100 iter), loss = 0.000753807
I0814 19:05:01.303186   613 solver.cpp:334]     Train net output #0: loss = 0.000753808 (* 1 = 0.000753808 loss)
I0814 19:05:01.303198   613 sgd_solver.cpp:136] Iteration 24700, lr = 0.00614062, m = 0.9
I0814 19:05:02.908033   613 solver.cpp:312] Iteration 24800 (62.3113 iter/s, 1.60484s/100 iter), loss = 0.00184208
I0814 19:05:02.908080   613 solver.cpp:334]     Train net output #0: loss = 0.00184208 (* 1 = 0.00184208 loss)
I0814 19:05:02.908097   613 sgd_solver.cpp:136] Iteration 24800, lr = 0.006125, m = 0.9
I0814 19:05:04.530117   613 solver.cpp:312] Iteration 24900 (61.651 iter/s, 1.62203s/100 iter), loss = 0.00120535
I0814 19:05:04.530141   613 solver.cpp:334]     Train net output #0: loss = 0.00120535 (* 1 = 0.00120535 loss)
I0814 19:05:04.530148   613 sgd_solver.cpp:136] Iteration 24900, lr = 0.00610937, m = 0.9
I0814 19:05:06.097812   613 solver.cpp:509] Iteration 25000, Testing net (#0)
I0814 19:05:06.921210   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.911471
I0814 19:05:06.921226   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.994706
I0814 19:05:06.921231   613 solver.cpp:594]     Test net output #2: loss = 0.316788 (* 1 = 0.316788 loss)
I0814 19:05:06.921252   613 solver.cpp:264] [MultiGPU] Tests completed in 0.823416s
I0814 19:05:06.936925   613 solver.cpp:312] Iteration 25000 (41.5499 iter/s, 2.40674s/100 iter), loss = 0.00108883
I0814 19:05:06.936944   613 solver.cpp:334]     Train net output #0: loss = 0.00108883 (* 1 = 0.00108883 loss)
I0814 19:05:06.936949   613 sgd_solver.cpp:136] Iteration 25000, lr = 0.00609375, m = 0.9
I0814 19:05:08.543546   613 solver.cpp:312] Iteration 25100 (62.2444 iter/s, 1.60657s/100 iter), loss = 0.00245606
I0814 19:05:08.543660   613 solver.cpp:334]     Train net output #0: loss = 0.00245606 (* 1 = 0.00245606 loss)
I0814 19:05:08.543678   613 sgd_solver.cpp:136] Iteration 25100, lr = 0.00607812, m = 0.9
I0814 19:05:10.178711   613 solver.cpp:312] Iteration 25200 (61.1577 iter/s, 1.63512s/100 iter), loss = 0.0063464
I0814 19:05:10.178758   613 solver.cpp:334]     Train net output #0: loss = 0.0063464 (* 1 = 0.0063464 loss)
I0814 19:05:10.178769   613 sgd_solver.cpp:136] Iteration 25200, lr = 0.0060625, m = 0.9
I0814 19:05:11.804309   613 solver.cpp:312] Iteration 25300 (61.5179 iter/s, 1.62554s/100 iter), loss = 0.000997024
I0814 19:05:11.804355   613 solver.cpp:334]     Train net output #0: loss = 0.000997022 (* 1 = 0.000997022 loss)
I0814 19:05:11.804373   613 sgd_solver.cpp:136] Iteration 25300, lr = 0.00604687, m = 0.9
I0814 19:05:13.454617   613 solver.cpp:312] Iteration 25400 (60.5966 iter/s, 1.65026s/100 iter), loss = 0.00138587
I0814 19:05:13.454661   613 solver.cpp:334]     Train net output #0: loss = 0.00138587 (* 1 = 0.00138587 loss)
I0814 19:05:13.454674   613 sgd_solver.cpp:136] Iteration 25400, lr = 0.00603125, m = 0.9
I0814 19:05:15.046357   613 solver.cpp:312] Iteration 25500 (62.8262 iter/s, 1.59169s/100 iter), loss = 0.00241851
I0814 19:05:15.046383   613 solver.cpp:334]     Train net output #0: loss = 0.00241851 (* 1 = 0.00241851 loss)
I0814 19:05:15.046389   613 sgd_solver.cpp:136] Iteration 25500, lr = 0.00601562, m = 0.9
I0814 19:05:16.655443   613 solver.cpp:312] Iteration 25600 (62.1491 iter/s, 1.60903s/100 iter), loss = 0.00251582
I0814 19:05:16.655490   613 solver.cpp:334]     Train net output #0: loss = 0.00251582 (* 1 = 0.00251582 loss)
I0814 19:05:16.655505   613 sgd_solver.cpp:136] Iteration 25600, lr = 0.006, m = 0.9
I0814 19:05:18.313510   613 solver.cpp:312] Iteration 25700 (60.313 iter/s, 1.65802s/100 iter), loss = 0.00182482
I0814 19:05:18.313557   613 solver.cpp:334]     Train net output #0: loss = 0.00182482 (* 1 = 0.00182482 loss)
I0814 19:05:18.313568   613 sgd_solver.cpp:136] Iteration 25700, lr = 0.00598437, m = 0.9
I0814 19:05:19.944317   613 solver.cpp:312] Iteration 25800 (61.3211 iter/s, 1.63076s/100 iter), loss = 0.00243829
I0814 19:05:19.944360   613 solver.cpp:334]     Train net output #0: loss = 0.00243829 (* 1 = 0.00243829 loss)
I0814 19:05:19.944372   613 sgd_solver.cpp:136] Iteration 25800, lr = 0.00596875, m = 0.9
I0814 19:05:21.564703   613 solver.cpp:312] Iteration 25900 (61.7156 iter/s, 1.62034s/100 iter), loss = 0.00236606
I0814 19:05:21.564730   613 solver.cpp:334]     Train net output #0: loss = 0.00236607 (* 1 = 0.00236607 loss)
I0814 19:05:21.564738   613 sgd_solver.cpp:136] Iteration 25900, lr = 0.00595312, m = 0.9
I0814 19:05:23.161217   613 solver.cpp:509] Iteration 26000, Testing net (#0)
I0814 19:05:23.990511   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.907648
I0814 19:05:23.990531   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.993529
I0814 19:05:23.990536   613 solver.cpp:594]     Test net output #2: loss = 0.338682 (* 1 = 0.338682 loss)
I0814 19:05:23.990703   613 solver.cpp:264] [MultiGPU] Tests completed in 0.829313s
I0814 19:05:24.006377   613 solver.cpp:312] Iteration 26000 (40.9567 iter/s, 2.4416s/100 iter), loss = 0.00200366
I0814 19:05:24.006395   613 solver.cpp:334]     Train net output #0: loss = 0.00200367 (* 1 = 0.00200367 loss)
I0814 19:05:24.006402   613 sgd_solver.cpp:136] Iteration 26000, lr = 0.0059375, m = 0.9
I0814 19:05:25.603566   613 solver.cpp:312] Iteration 26100 (62.612 iter/s, 1.59714s/100 iter), loss = 0.00150677
I0814 19:05:25.603615   613 solver.cpp:334]     Train net output #0: loss = 0.00150678 (* 1 = 0.00150678 loss)
I0814 19:05:25.603626   613 sgd_solver.cpp:136] Iteration 26100, lr = 0.00592188, m = 0.9
I0814 19:05:27.210198   613 solver.cpp:312] Iteration 26200 (62.2439 iter/s, 1.60658s/100 iter), loss = 0.00192631
I0814 19:05:27.210223   613 solver.cpp:334]     Train net output #0: loss = 0.00192632 (* 1 = 0.00192632 loss)
I0814 19:05:27.210229   613 sgd_solver.cpp:136] Iteration 26200, lr = 0.00590625, m = 0.9
I0814 19:05:28.845508   613 solver.cpp:312] Iteration 26300 (61.1523 iter/s, 1.63526s/100 iter), loss = 0.0007196
I0814 19:05:28.845556   613 solver.cpp:334]     Train net output #0: loss = 0.000719603 (* 1 = 0.000719603 loss)
I0814 19:05:28.845567   613 sgd_solver.cpp:136] Iteration 26300, lr = 0.00589063, m = 0.9
I0814 19:05:30.481977   613 solver.cpp:312] Iteration 26400 (61.1091 iter/s, 1.63642s/100 iter), loss = 0.0020366
I0814 19:05:30.482002   613 solver.cpp:334]     Train net output #0: loss = 0.0020366 (* 1 = 0.0020366 loss)
I0814 19:05:30.482008   613 sgd_solver.cpp:136] Iteration 26400, lr = 0.005875, m = 0.9
I0814 19:05:32.083915   613 solver.cpp:312] Iteration 26500 (62.4263 iter/s, 1.60189s/100 iter), loss = 0.00100681
I0814 19:05:32.083937   613 solver.cpp:334]     Train net output #0: loss = 0.00100681 (* 1 = 0.00100681 loss)
I0814 19:05:32.083941   613 sgd_solver.cpp:136] Iteration 26500, lr = 0.00585938, m = 0.9
I0814 19:05:32.298688   592 data_reader.cpp:288] Starting prefetch of epoch 4
I0814 19:05:33.718333   613 solver.cpp:312] Iteration 26600 (61.1857 iter/s, 1.63437s/100 iter), loss = 0.00245127
I0814 19:05:33.718380   613 solver.cpp:334]     Train net output #0: loss = 0.00245127 (* 1 = 0.00245127 loss)
I0814 19:05:33.718391   613 sgd_solver.cpp:136] Iteration 26600, lr = 0.00584375, m = 0.9
I0814 19:05:35.332358   613 solver.cpp:312] Iteration 26700 (61.9587 iter/s, 1.61398s/100 iter), loss = 0.000862415
I0814 19:05:35.332404   613 solver.cpp:334]     Train net output #0: loss = 0.000862418 (* 1 = 0.000862418 loss)
I0814 19:05:35.332417   613 sgd_solver.cpp:136] Iteration 26700, lr = 0.00582812, m = 0.9
I0814 19:05:36.955605   613 solver.cpp:312] Iteration 26800 (61.6068 iter/s, 1.6232s/100 iter), loss = 0.00213367
I0814 19:05:36.955627   613 solver.cpp:334]     Train net output #0: loss = 0.00213367 (* 1 = 0.00213367 loss)
I0814 19:05:36.955632   613 sgd_solver.cpp:136] Iteration 26800, lr = 0.0058125, m = 0.9
I0814 19:05:38.558969   613 solver.cpp:312] Iteration 26900 (62.3708 iter/s, 1.60331s/100 iter), loss = 0.00146487
I0814 19:05:38.559089   613 solver.cpp:334]     Train net output #0: loss = 0.00146487 (* 1 = 0.00146487 loss)
I0814 19:05:38.559105   613 sgd_solver.cpp:136] Iteration 26900, lr = 0.00579687, m = 0.9
I0814 19:05:40.185906   613 solver.cpp:509] Iteration 27000, Testing net (#0)
I0814 19:05:41.022527   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.904119
I0814 19:05:41.022547   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.994412
I0814 19:05:41.022552   613 solver.cpp:594]     Test net output #2: loss = 0.35173 (* 1 = 0.35173 loss)
I0814 19:05:41.022570   613 solver.cpp:264] [MultiGPU] Tests completed in 0.836641s
I0814 19:05:41.038179   613 solver.cpp:312] Iteration 27000 (40.3366 iter/s, 2.47914s/100 iter), loss = 0.000517777
I0814 19:05:41.038219   613 solver.cpp:334]     Train net output #0: loss = 0.00051778 (* 1 = 0.00051778 loss)
I0814 19:05:41.038233   613 sgd_solver.cpp:136] Iteration 27000, lr = 0.00578125, m = 0.9
I0814 19:05:42.643024   613 solver.cpp:312] Iteration 27100 (62.3133 iter/s, 1.60479s/100 iter), loss = 0.000853854
I0814 19:05:42.643051   613 solver.cpp:334]     Train net output #0: loss = 0.000853857 (* 1 = 0.000853857 loss)
I0814 19:05:42.643056   613 sgd_solver.cpp:136] Iteration 27100, lr = 0.00576563, m = 0.9
I0814 19:05:44.294350   613 solver.cpp:312] Iteration 27200 (60.5592 iter/s, 1.65128s/100 iter), loss = 0.00395417
I0814 19:05:44.294397   613 solver.cpp:334]     Train net output #0: loss = 0.00395417 (* 1 = 0.00395417 loss)
I0814 19:05:44.294409   613 sgd_solver.cpp:136] Iteration 27200, lr = 0.00575, m = 0.9
I0814 19:05:45.929885   613 solver.cpp:312] Iteration 27300 (61.144 iter/s, 1.63548s/100 iter), loss = 0.00226241
I0814 19:05:45.929908   613 solver.cpp:334]     Train net output #0: loss = 0.00226241 (* 1 = 0.00226241 loss)
I0814 19:05:45.929913   613 sgd_solver.cpp:136] Iteration 27300, lr = 0.00573438, m = 0.9
I0814 19:05:47.568505   613 solver.cpp:312] Iteration 27400 (61.0288 iter/s, 1.63857s/100 iter), loss = 0.000639817
I0814 19:05:47.568565   613 solver.cpp:334]     Train net output #0: loss = 0.00063982 (* 1 = 0.00063982 loss)
I0814 19:05:47.568583   613 sgd_solver.cpp:136] Iteration 27400, lr = 0.00571875, m = 0.9
I0814 19:05:49.195760   613 solver.cpp:312] Iteration 27500 (61.4551 iter/s, 1.6272s/100 iter), loss = 0.00121468
I0814 19:05:49.195827   613 solver.cpp:334]     Train net output #0: loss = 0.00121469 (* 1 = 0.00121469 loss)
I0814 19:05:49.195848   613 sgd_solver.cpp:136] Iteration 27500, lr = 0.00570312, m = 0.9
I0814 19:05:50.834017   613 solver.cpp:312] Iteration 27600 (61.0423 iter/s, 1.63821s/100 iter), loss = 0.00087925
I0814 19:05:50.834089   613 solver.cpp:334]     Train net output #0: loss = 0.000879252 (* 1 = 0.000879252 loss)
I0814 19:05:50.834115   613 sgd_solver.cpp:136] Iteration 27600, lr = 0.0056875, m = 0.9
I0814 19:05:52.489537   613 solver.cpp:312] Iteration 27700 (60.4058 iter/s, 1.65547s/100 iter), loss = 0.000493639
I0814 19:05:52.489560   613 solver.cpp:334]     Train net output #0: loss = 0.000493642 (* 1 = 0.000493642 loss)
I0814 19:05:52.489567   613 sgd_solver.cpp:136] Iteration 27700, lr = 0.00567187, m = 0.9
I0814 19:05:54.103617   613 solver.cpp:312] Iteration 27800 (61.9566 iter/s, 1.61403s/100 iter), loss = 0.00111701
I0814 19:05:54.103642   613 solver.cpp:334]     Train net output #0: loss = 0.00111701 (* 1 = 0.00111701 loss)
I0814 19:05:54.103648   613 sgd_solver.cpp:136] Iteration 27800, lr = 0.00565625, m = 0.9
I0814 19:05:55.677261   613 solver.cpp:312] Iteration 27900 (63.5487 iter/s, 1.5736s/100 iter), loss = 0.00106433
I0814 19:05:55.677309   613 solver.cpp:334]     Train net output #0: loss = 0.00106433 (* 1 = 0.00106433 loss)
I0814 19:05:55.677325   613 sgd_solver.cpp:136] Iteration 27900, lr = 0.00564062, m = 0.9
I0814 19:05:57.294170   613 solver.cpp:509] Iteration 28000, Testing net (#0)
I0814 19:05:58.108824   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.900295
I0814 19:05:58.108841   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.996471
I0814 19:05:58.108847   613 solver.cpp:594]     Test net output #2: loss = 0.365981 (* 1 = 0.365981 loss)
I0814 19:05:58.108878   613 solver.cpp:264] [MultiGPU] Tests completed in 0.814686s
I0814 19:05:58.129106   613 solver.cpp:312] Iteration 28000 (40.7868 iter/s, 2.45177s/100 iter), loss = 0.000745689
I0814 19:05:58.129149   613 solver.cpp:334]     Train net output #0: loss = 0.000745693 (* 1 = 0.000745693 loss)
I0814 19:05:58.129160   613 sgd_solver.cpp:136] Iteration 28000, lr = 0.005625, m = 0.9
I0814 19:05:59.748340   613 solver.cpp:312] Iteration 28100 (61.7595 iter/s, 1.61918s/100 iter), loss = 0.000732339
I0814 19:05:59.748365   613 solver.cpp:334]     Train net output #0: loss = 0.000732342 (* 1 = 0.000732342 loss)
I0814 19:05:59.748371   613 sgd_solver.cpp:136] Iteration 28100, lr = 0.00560937, m = 0.9
I0814 19:06:01.421178   613 solver.cpp:312] Iteration 28200 (59.7804 iter/s, 1.67279s/100 iter), loss = 0.000563306
I0814 19:06:01.421206   613 solver.cpp:334]     Train net output #0: loss = 0.000563308 (* 1 = 0.000563308 loss)
I0814 19:06:01.421213   613 sgd_solver.cpp:136] Iteration 28200, lr = 0.00559375, m = 0.9
I0814 19:06:03.076673   613 solver.cpp:312] Iteration 28300 (60.4068 iter/s, 1.65544s/100 iter), loss = 0.00223918
I0814 19:06:03.076743   613 solver.cpp:334]     Train net output #0: loss = 0.00223918 (* 1 = 0.00223918 loss)
I0814 19:06:03.076764   613 sgd_solver.cpp:136] Iteration 28300, lr = 0.00557812, m = 0.9
I0814 19:06:04.704172   613 solver.cpp:312] Iteration 28400 (61.4458 iter/s, 1.62745s/100 iter), loss = 0.00152164
I0814 19:06:04.704200   613 solver.cpp:334]     Train net output #0: loss = 0.00152164 (* 1 = 0.00152164 loss)
I0814 19:06:04.704206   613 sgd_solver.cpp:136] Iteration 28400, lr = 0.0055625, m = 0.9
I0814 19:06:06.317081   613 solver.cpp:312] Iteration 28500 (62.0017 iter/s, 1.61286s/100 iter), loss = 0.0019488
I0814 19:06:06.317104   613 solver.cpp:334]     Train net output #0: loss = 0.0019488 (* 1 = 0.0019488 loss)
I0814 19:06:06.317108   613 sgd_solver.cpp:136] Iteration 28500, lr = 0.00554687, m = 0.9
I0814 19:06:07.919008   613 solver.cpp:312] Iteration 28600 (62.4268 iter/s, 1.60188s/100 iter), loss = 0.0022939
I0814 19:06:07.919031   613 solver.cpp:334]     Train net output #0: loss = 0.0022939 (* 1 = 0.0022939 loss)
I0814 19:06:07.919039   613 sgd_solver.cpp:136] Iteration 28600, lr = 0.00553125, m = 0.9
I0814 19:06:09.560844   613 solver.cpp:312] Iteration 28700 (60.9091 iter/s, 1.64179s/100 iter), loss = 0.000315197
I0814 19:06:09.560916   613 solver.cpp:334]     Train net output #0: loss = 0.000315198 (* 1 = 0.000315198 loss)
I0814 19:06:09.560922   613 sgd_solver.cpp:136] Iteration 28700, lr = 0.00551562, m = 0.9
I0814 19:06:11.188757   613 solver.cpp:312] Iteration 28800 (61.4304 iter/s, 1.62786s/100 iter), loss = 0.00195202
I0814 19:06:11.188781   613 solver.cpp:334]     Train net output #0: loss = 0.00195202 (* 1 = 0.00195202 loss)
I0814 19:06:11.188784   613 sgd_solver.cpp:136] Iteration 28800, lr = 0.0055, m = 0.9
I0814 19:06:12.822639   613 solver.cpp:312] Iteration 28900 (61.2056 iter/s, 1.63384s/100 iter), loss = 0.0100725
I0814 19:06:12.822703   613 solver.cpp:334]     Train net output #0: loss = 0.0100725 (* 1 = 0.0100725 loss)
I0814 19:06:12.822723   613 sgd_solver.cpp:136] Iteration 28900, lr = 0.00548437, m = 0.9
I0814 19:06:14.447767   613 solver.cpp:509] Iteration 29000, Testing net (#0)
I0814 19:06:15.257841   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.907354
I0814 19:06:15.257859   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.997059
I0814 19:06:15.257864   613 solver.cpp:594]     Test net output #2: loss = 0.32872 (* 1 = 0.32872 loss)
I0814 19:06:15.257879   613 solver.cpp:264] [MultiGPU] Tests completed in 0.810091s
I0814 19:06:15.273560   613 solver.cpp:312] Iteration 29000 (40.8022 iter/s, 2.45085s/100 iter), loss = 0.000663055
I0814 19:06:15.273576   613 solver.cpp:334]     Train net output #0: loss = 0.000663057 (* 1 = 0.000663057 loss)
I0814 19:06:15.273579   613 sgd_solver.cpp:136] Iteration 29000, lr = 0.00546875, m = 0.9
I0814 19:06:16.915151   613 solver.cpp:312] Iteration 29100 (60.9184 iter/s, 1.64154s/100 iter), loss = 0.000427868
I0814 19:06:16.915179   613 solver.cpp:334]     Train net output #0: loss = 0.000427868 (* 1 = 0.000427868 loss)
I0814 19:06:16.915184   613 sgd_solver.cpp:136] Iteration 29100, lr = 0.00545313, m = 0.9
I0814 19:06:18.568418   613 solver.cpp:312] Iteration 29200 (60.488 iter/s, 1.65322s/100 iter), loss = 0.00145948
I0814 19:06:18.568442   613 solver.cpp:334]     Train net output #0: loss = 0.00145948 (* 1 = 0.00145948 loss)
I0814 19:06:18.568446   613 sgd_solver.cpp:136] Iteration 29200, lr = 0.0054375, m = 0.9
I0814 19:06:20.160897   613 solver.cpp:312] Iteration 29300 (62.7972 iter/s, 1.59243s/100 iter), loss = 0.00129487
I0814 19:06:20.160961   613 solver.cpp:334]     Train net output #0: loss = 0.00129487 (* 1 = 0.00129487 loss)
I0814 19:06:20.160980   613 sgd_solver.cpp:136] Iteration 29300, lr = 0.00542188, m = 0.9
I0814 19:06:21.750012   613 solver.cpp:312] Iteration 29400 (62.9299 iter/s, 1.58907s/100 iter), loss = 0.00302093
I0814 19:06:21.750058   613 solver.cpp:334]     Train net output #0: loss = 0.00302093 (* 1 = 0.00302093 loss)
I0814 19:06:21.750069   613 sgd_solver.cpp:136] Iteration 29400, lr = 0.00540625, m = 0.9
I0814 19:06:23.384806   613 solver.cpp:312] Iteration 29500 (61.1717 iter/s, 1.63474s/100 iter), loss = 0.00114148
I0814 19:06:23.384853   613 solver.cpp:334]     Train net output #0: loss = 0.00114148 (* 1 = 0.00114148 loss)
I0814 19:06:23.384866   613 sgd_solver.cpp:136] Iteration 29500, lr = 0.00539062, m = 0.9
I0814 19:06:25.010274   613 solver.cpp:312] Iteration 29600 (61.5225 iter/s, 1.62542s/100 iter), loss = 0.00158248
I0814 19:06:25.010298   613 solver.cpp:334]     Train net output #0: loss = 0.00158248 (* 1 = 0.00158248 loss)
I0814 19:06:25.010304   613 sgd_solver.cpp:136] Iteration 29600, lr = 0.005375, m = 0.9
I0814 19:06:26.611616   613 solver.cpp:312] Iteration 29700 (62.4496 iter/s, 1.60129s/100 iter), loss = 0.0169916
I0814 19:06:26.611675   613 solver.cpp:334]     Train net output #0: loss = 0.0169916 (* 1 = 0.0169916 loss)
I0814 19:06:26.611692   613 sgd_solver.cpp:136] Iteration 29700, lr = 0.00535937, m = 0.9
I0814 19:06:28.188993   613 solver.cpp:312] Iteration 29800 (63.3983 iter/s, 1.57733s/100 iter), loss = 0.00105313
I0814 19:06:28.189019   613 solver.cpp:334]     Train net output #0: loss = 0.00105313 (* 1 = 0.00105313 loss)
I0814 19:06:28.189025   613 sgd_solver.cpp:136] Iteration 29800, lr = 0.00534375, m = 0.9
I0814 19:06:29.783895   613 solver.cpp:312] Iteration 29900 (62.7017 iter/s, 1.59485s/100 iter), loss = 0.000953969
I0814 19:06:29.783921   613 solver.cpp:334]     Train net output #0: loss = 0.00095397 (* 1 = 0.00095397 loss)
I0814 19:06:29.783926   613 sgd_solver.cpp:136] Iteration 29900, lr = 0.00532812, m = 0.9
I0814 19:06:31.417229   613 solver.cpp:639] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/l1reg/cifar10_jacintonet11v2_iter_30000.caffemodel
I0814 19:06:31.426682   613 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/l1reg/cifar10_jacintonet11v2_iter_30000.solverstate
I0814 19:06:31.431435   613 solver.cpp:509] Iteration 30000, Testing net (#0)
I0814 19:06:32.229717   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.920001
I0814 19:06:32.229738   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.996765
I0814 19:06:32.229743   613 solver.cpp:594]     Test net output #2: loss = 0.299295 (* 1 = 0.299295 loss)
I0814 19:06:32.229759   613 solver.cpp:264] [MultiGPU] Tests completed in 0.798302s
I0814 19:06:32.246217   613 solver.cpp:312] Iteration 30000 (40.6132 iter/s, 2.46225s/100 iter), loss = 0.0012747
I0814 19:06:32.246232   613 solver.cpp:334]     Train net output #0: loss = 0.0012747 (* 1 = 0.0012747 loss)
I0814 19:06:32.246238   613 sgd_solver.cpp:136] Iteration 30000, lr = 0.0053125, m = 0.9
I0814 19:06:33.866674   613 solver.cpp:312] Iteration 30100 (61.7129 iter/s, 1.62041s/100 iter), loss = 0.00116765
I0814 19:06:33.866699   613 solver.cpp:334]     Train net output #0: loss = 0.00116766 (* 1 = 0.00116766 loss)
I0814 19:06:33.866705   613 sgd_solver.cpp:136] Iteration 30100, lr = 0.00529688, m = 0.9
I0814 19:06:35.477090   613 solver.cpp:312] Iteration 30200 (62.0977 iter/s, 1.61037s/100 iter), loss = 0.00232306
I0814 19:06:35.477155   613 solver.cpp:334]     Train net output #0: loss = 0.00232306 (* 1 = 0.00232306 loss)
I0814 19:06:35.477176   613 sgd_solver.cpp:136] Iteration 30200, lr = 0.00528125, m = 0.9
I0814 19:06:37.088768   613 solver.cpp:312] Iteration 30300 (62.0491 iter/s, 1.61163s/100 iter), loss = 0.0010685
I0814 19:06:37.088795   613 solver.cpp:334]     Train net output #0: loss = 0.0010685 (* 1 = 0.0010685 loss)
I0814 19:06:37.088800   613 sgd_solver.cpp:136] Iteration 30300, lr = 0.00526563, m = 0.9
I0814 19:06:38.693588   613 solver.cpp:312] Iteration 30400 (62.3142 iter/s, 1.60477s/100 iter), loss = 0.000610738
I0814 19:06:38.693611   613 solver.cpp:334]     Train net output #0: loss = 0.00061074 (* 1 = 0.00061074 loss)
I0814 19:06:38.693616   613 sgd_solver.cpp:136] Iteration 30400, lr = 0.00525, m = 0.9
I0814 19:06:40.293716   613 solver.cpp:312] Iteration 30500 (62.4969 iter/s, 1.60008s/100 iter), loss = 0.0022117
I0814 19:06:40.293800   613 solver.cpp:334]     Train net output #0: loss = 0.00221171 (* 1 = 0.00221171 loss)
I0814 19:06:40.293807   613 sgd_solver.cpp:136] Iteration 30500, lr = 0.00523437, m = 0.9
I0814 19:06:41.916584   613 solver.cpp:312] Iteration 30600 (61.6211 iter/s, 1.62282s/100 iter), loss = 0.0012603
I0814 19:06:41.916728   613 solver.cpp:334]     Train net output #0: loss = 0.0012603 (* 1 = 0.0012603 loss)
I0814 19:06:41.916751   613 sgd_solver.cpp:136] Iteration 30600, lr = 0.00521875, m = 0.9
I0814 19:06:43.525964   613 solver.cpp:312] Iteration 30700 (62.1377 iter/s, 1.60933s/100 iter), loss = 0.000680323
I0814 19:06:43.526041   613 solver.cpp:334]     Train net output #0: loss = 0.00068033 (* 1 = 0.00068033 loss)
I0814 19:06:43.526068   613 sgd_solver.cpp:136] Iteration 30700, lr = 0.00520312, m = 0.9
I0814 19:06:45.154989   613 solver.cpp:312] Iteration 30800 (61.3883 iter/s, 1.62897s/100 iter), loss = 0.000910119
I0814 19:06:45.155050   613 solver.cpp:334]     Train net output #0: loss = 0.000910126 (* 1 = 0.000910126 loss)
I0814 19:06:45.155068   613 sgd_solver.cpp:136] Iteration 30800, lr = 0.0051875, m = 0.9
I0814 19:06:46.769093   613 solver.cpp:312] Iteration 30900 (61.9558 iter/s, 1.61405s/100 iter), loss = 0.00429211
I0814 19:06:46.769119   613 solver.cpp:334]     Train net output #0: loss = 0.00429212 (* 1 = 0.00429212 loss)
I0814 19:06:46.769124   613 sgd_solver.cpp:136] Iteration 30900, lr = 0.00517187, m = 0.9
I0814 19:06:48.387125   613 solver.cpp:509] Iteration 31000, Testing net (#0)
I0814 19:06:48.672564   611 data_reader.cpp:288] Starting prefetch of epoch 4
I0814 19:06:49.196532   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.922354
I0814 19:06:49.196552   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.997059
I0814 19:06:49.196557   613 solver.cpp:594]     Test net output #2: loss = 0.281071 (* 1 = 0.281071 loss)
I0814 19:06:49.196573   613 solver.cpp:264] [MultiGPU] Tests completed in 0.809428s
I0814 19:06:49.212363   613 solver.cpp:312] Iteration 31000 (40.9299 iter/s, 2.4432s/100 iter), loss = 0.00109493
I0814 19:06:49.212379   613 solver.cpp:334]     Train net output #0: loss = 0.00109494 (* 1 = 0.00109494 loss)
I0814 19:06:49.212385   613 sgd_solver.cpp:136] Iteration 31000, lr = 0.00515625, m = 0.9
I0814 19:06:50.834684   613 solver.cpp:312] Iteration 31100 (61.6421 iter/s, 1.62227s/100 iter), loss = 0.00312401
I0814 19:06:50.834731   613 solver.cpp:334]     Train net output #0: loss = 0.00312401 (* 1 = 0.00312401 loss)
I0814 19:06:50.834743   613 sgd_solver.cpp:136] Iteration 31100, lr = 0.00514062, m = 0.9
I0814 19:06:52.478286   613 solver.cpp:312] Iteration 31200 (60.8439 iter/s, 1.64355s/100 iter), loss = 0.00161411
I0814 19:06:52.478456   613 solver.cpp:334]     Train net output #0: loss = 0.00161412 (* 1 = 0.00161412 loss)
I0814 19:06:52.478466   613 sgd_solver.cpp:136] Iteration 31200, lr = 0.005125, m = 0.9
I0814 19:06:54.088609   613 solver.cpp:312] Iteration 31300 (62.1012 iter/s, 1.61028s/100 iter), loss = 0.00232459
I0814 19:06:54.088668   613 solver.cpp:334]     Train net output #0: loss = 0.0023246 (* 1 = 0.0023246 loss)
I0814 19:06:54.088685   613 sgd_solver.cpp:136] Iteration 31300, lr = 0.00510937, m = 0.9
I0814 19:06:55.722692   613 solver.cpp:312] Iteration 31400 (61.1983 iter/s, 1.63403s/100 iter), loss = 0.00221242
I0814 19:06:55.722736   613 solver.cpp:334]     Train net output #0: loss = 0.00221243 (* 1 = 0.00221243 loss)
I0814 19:06:55.722748   613 sgd_solver.cpp:136] Iteration 31400, lr = 0.00509375, m = 0.9
I0814 19:06:57.333865   613 solver.cpp:312] Iteration 31500 (62.0684 iter/s, 1.61113s/100 iter), loss = 0.00101202
I0814 19:06:57.333892   613 solver.cpp:334]     Train net output #0: loss = 0.00101203 (* 1 = 0.00101203 loss)
I0814 19:06:57.333899   613 sgd_solver.cpp:136] Iteration 31500, lr = 0.00507812, m = 0.9
I0814 19:06:58.931884   613 solver.cpp:312] Iteration 31600 (62.5795 iter/s, 1.59797s/100 iter), loss = 0.00398866
I0814 19:06:58.931910   613 solver.cpp:334]     Train net output #0: loss = 0.00398866 (* 1 = 0.00398866 loss)
I0814 19:06:58.931933   613 sgd_solver.cpp:136] Iteration 31600, lr = 0.0050625, m = 0.9
I0814 19:07:00.527154   613 solver.cpp:312] Iteration 31700 (62.6872 iter/s, 1.59522s/100 iter), loss = 0.000412395
I0814 19:07:00.527204   613 solver.cpp:334]     Train net output #0: loss = 0.000412401 (* 1 = 0.000412401 loss)
I0814 19:07:00.527217   613 sgd_solver.cpp:136] Iteration 31700, lr = 0.00504687, m = 0.9
I0814 19:07:02.133250   613 solver.cpp:312] Iteration 31800 (62.2646 iter/s, 1.60605s/100 iter), loss = 0.0015609
I0814 19:07:02.133296   613 solver.cpp:334]     Train net output #0: loss = 0.00156091 (* 1 = 0.00156091 loss)
I0814 19:07:02.133307   613 sgd_solver.cpp:136] Iteration 31800, lr = 0.00503125, m = 0.9
I0814 19:07:03.730506   613 solver.cpp:312] Iteration 31900 (62.6092 iter/s, 1.59721s/100 iter), loss = 0.00103219
I0814 19:07:03.730531   613 solver.cpp:334]     Train net output #0: loss = 0.00103219 (* 1 = 0.00103219 loss)
I0814 19:07:03.730537   613 sgd_solver.cpp:136] Iteration 31900, lr = 0.00501562, m = 0.9
I0814 19:07:05.354261   613 solver.cpp:509] Iteration 32000, Testing net (#0)
I0814 19:07:06.167038   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.908825
I0814 19:07:06.167057   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.997059
I0814 19:07:06.167062   613 solver.cpp:594]     Test net output #2: loss = 0.334485 (* 1 = 0.334485 loss)
I0814 19:07:06.167076   613 solver.cpp:264] [MultiGPU] Tests completed in 0.812793s
I0814 19:07:06.182662   613 solver.cpp:312] Iteration 32000 (40.7816 iter/s, 2.45209s/100 iter), loss = 0.00355713
I0814 19:07:06.182695   613 solver.cpp:334]     Train net output #0: loss = 0.00355714 (* 1 = 0.00355714 loss)
I0814 19:07:06.182708   613 sgd_solver.cpp:136] Iteration 32000, lr = 0.005, m = 0.9
I0814 19:07:07.782886   613 solver.cpp:312] Iteration 32100 (62.4932 iter/s, 1.60017s/100 iter), loss = 0.00259734
I0814 19:07:07.782934   613 solver.cpp:334]     Train net output #0: loss = 0.00259735 (* 1 = 0.00259735 loss)
I0814 19:07:07.782948   613 sgd_solver.cpp:136] Iteration 32100, lr = 0.00498438, m = 0.9
I0814 19:07:09.398686   613 solver.cpp:312] Iteration 32200 (61.8908 iter/s, 1.61575s/100 iter), loss = 0.00564189
I0814 19:07:09.398715   613 solver.cpp:334]     Train net output #0: loss = 0.00564189 (* 1 = 0.00564189 loss)
I0814 19:07:09.398721   613 sgd_solver.cpp:136] Iteration 32200, lr = 0.00496875, m = 0.9
I0814 19:07:11.039486   613 solver.cpp:312] Iteration 32300 (60.9477 iter/s, 1.64075s/100 iter), loss = 0.00361107
I0814 19:07:11.039592   613 solver.cpp:334]     Train net output #0: loss = 0.00361107 (* 1 = 0.00361107 loss)
I0814 19:07:11.039611   613 sgd_solver.cpp:136] Iteration 32300, lr = 0.00495313, m = 0.9
I0814 19:07:12.643287   613 solver.cpp:312] Iteration 32400 (62.3538 iter/s, 1.60375s/100 iter), loss = 0.0013609
I0814 19:07:12.643352   613 solver.cpp:334]     Train net output #0: loss = 0.0013609 (* 1 = 0.0013609 loss)
I0814 19:07:12.643370   613 sgd_solver.cpp:136] Iteration 32400, lr = 0.0049375, m = 0.9
I0814 19:07:14.302295   613 solver.cpp:312] Iteration 32500 (60.2788 iter/s, 1.65896s/100 iter), loss = 0.000625696
I0814 19:07:14.302325   613 solver.cpp:334]     Train net output #0: loss = 0.000625699 (* 1 = 0.000625699 loss)
I0814 19:07:14.302331   613 sgd_solver.cpp:136] Iteration 32500, lr = 0.00492187, m = 0.9
I0814 19:07:15.904858   613 solver.cpp:312] Iteration 32600 (62.4019 iter/s, 1.60252s/100 iter), loss = 0.0044096
I0814 19:07:15.904927   613 solver.cpp:334]     Train net output #0: loss = 0.0044096 (* 1 = 0.0044096 loss)
I0814 19:07:15.904947   613 sgd_solver.cpp:136] Iteration 32600, lr = 0.00490625, m = 0.9
I0814 19:07:17.558605   613 solver.cpp:312] Iteration 32700 (60.4706 iter/s, 1.6537s/100 iter), loss = 0.000515654
I0814 19:07:17.558658   613 solver.cpp:334]     Train net output #0: loss = 0.000515655 (* 1 = 0.000515655 loss)
I0814 19:07:17.558671   613 sgd_solver.cpp:136] Iteration 32700, lr = 0.00489062, m = 0.9
I0814 19:07:19.188149   613 solver.cpp:312] Iteration 32800 (61.3688 iter/s, 1.62949s/100 iter), loss = 0.00848426
I0814 19:07:19.188208   613 solver.cpp:334]     Train net output #0: loss = 0.00848426 (* 1 = 0.00848426 loss)
I0814 19:07:19.188227   613 sgd_solver.cpp:136] Iteration 32800, lr = 0.004875, m = 0.9
I0814 19:07:20.784354   613 solver.cpp:312] Iteration 32900 (62.6504 iter/s, 1.59616s/100 iter), loss = 0.102276
I0814 19:07:20.784415   613 solver.cpp:334]     Train net output #0: loss = 0.102276 (* 1 = 0.102276 loss)
I0814 19:07:20.784433   613 sgd_solver.cpp:136] Iteration 32900, lr = 0.00485937, m = 0.9
I0814 19:07:22.357062   613 solver.cpp:509] Iteration 33000, Testing net (#0)
I0814 19:07:23.175706   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.735295
I0814 19:07:23.175721   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.965589
I0814 19:07:23.175726   613 solver.cpp:594]     Test net output #2: loss = 1.77748 (* 1 = 1.77748 loss)
I0814 19:07:23.175752   613 solver.cpp:264] [MultiGPU] Tests completed in 0.818661s
I0814 19:07:23.191292   613 solver.cpp:312] Iteration 33000 (41.5478 iter/s, 2.40687s/100 iter), loss = 0.206587
I0814 19:07:23.191314   613 solver.cpp:334]     Train net output #0: loss = 0.206587 (* 1 = 0.206587 loss)
I0814 19:07:23.191321   613 sgd_solver.cpp:136] Iteration 33000, lr = 0.00484375, m = 0.9
I0814 19:07:24.834992   613 solver.cpp:312] Iteration 33100 (60.8402 iter/s, 1.64365s/100 iter), loss = 0.0545392
I0814 19:07:24.835052   613 solver.cpp:334]     Train net output #0: loss = 0.0545393 (* 1 = 0.0545393 loss)
I0814 19:07:24.835077   613 sgd_solver.cpp:136] Iteration 33100, lr = 0.00482813, m = 0.9
I0814 19:07:26.429656   613 solver.cpp:312] Iteration 33200 (62.7111 iter/s, 1.59461s/100 iter), loss = 0.0138729
I0814 19:07:26.429680   613 solver.cpp:334]     Train net output #0: loss = 0.0138729 (* 1 = 0.0138729 loss)
I0814 19:07:26.429687   613 sgd_solver.cpp:136] Iteration 33200, lr = 0.0048125, m = 0.9
I0814 19:07:28.091325   613 solver.cpp:312] Iteration 33300 (60.1823 iter/s, 1.66162s/100 iter), loss = 0.260078
I0814 19:07:28.091385   613 solver.cpp:334]     Train net output #0: loss = 0.260078 (* 1 = 0.260078 loss)
I0814 19:07:28.091403   613 sgd_solver.cpp:136] Iteration 33300, lr = 0.00479688, m = 0.9
I0814 19:07:29.700553   613 solver.cpp:312] Iteration 33400 (62.1434 iter/s, 1.60918s/100 iter), loss = 0.0040168
I0814 19:07:29.700577   613 solver.cpp:334]     Train net output #0: loss = 0.00401665 (* 1 = 0.00401665 loss)
I0814 19:07:29.700583   613 sgd_solver.cpp:136] Iteration 33400, lr = 0.00478125, m = 0.9
I0814 19:07:31.310570   613 solver.cpp:312] Iteration 33500 (62.1129 iter/s, 1.60997s/100 iter), loss = 0.195826
I0814 19:07:31.310592   613 solver.cpp:334]     Train net output #0: loss = 0.195826 (* 1 = 0.195826 loss)
I0814 19:07:31.310598   613 sgd_solver.cpp:136] Iteration 33500, lr = 0.00476563, m = 0.9
I0814 19:07:32.894371   613 solver.cpp:312] Iteration 33600 (63.1413 iter/s, 1.58375s/100 iter), loss = 0.0206433
I0814 19:07:32.894418   613 solver.cpp:334]     Train net output #0: loss = 0.0206433 (* 1 = 0.0206433 loss)
I0814 19:07:32.894429   613 sgd_solver.cpp:136] Iteration 33600, lr = 0.00475, m = 0.9
I0814 19:07:34.499771   613 solver.cpp:312] Iteration 33700 (62.2916 iter/s, 1.60535s/100 iter), loss = 0.0796808
I0814 19:07:34.499833   613 solver.cpp:334]     Train net output #0: loss = 0.0796808 (* 1 = 0.0796808 loss)
I0814 19:07:34.499851   613 sgd_solver.cpp:136] Iteration 33700, lr = 0.00473437, m = 0.9
I0814 19:07:36.119072   613 solver.cpp:312] Iteration 33800 (61.7569 iter/s, 1.61925s/100 iter), loss = 0.0639974
I0814 19:07:36.119134   613 solver.cpp:334]     Train net output #0: loss = 0.0639974 (* 1 = 0.0639974 loss)
I0814 19:07:36.119151   613 sgd_solver.cpp:136] Iteration 33800, lr = 0.00471875, m = 0.9
I0814 19:07:37.738488   613 solver.cpp:312] Iteration 33900 (61.7525 iter/s, 1.61937s/100 iter), loss = 0.0214644
I0814 19:07:37.738549   613 solver.cpp:334]     Train net output #0: loss = 0.0214644 (* 1 = 0.0214644 loss)
I0814 19:07:37.738569   613 sgd_solver.cpp:136] Iteration 33900, lr = 0.00470312, m = 0.9
I0814 19:07:39.284940   613 solver.cpp:509] Iteration 34000, Testing net (#0)
I0814 19:07:40.104893   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.806178
I0814 19:07:40.104912   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.987059
I0814 19:07:40.104918   613 solver.cpp:594]     Test net output #2: loss = 0.77042 (* 1 = 0.77042 loss)
I0814 19:07:40.104935   613 solver.cpp:264] [MultiGPU] Tests completed in 0.819974s
I0814 19:07:40.120582   613 solver.cpp:312] Iteration 34000 (41.9811 iter/s, 2.38202s/100 iter), loss = 0.0285851
I0814 19:07:40.120615   613 solver.cpp:334]     Train net output #0: loss = 0.0285851 (* 1 = 0.0285851 loss)
I0814 19:07:40.120625   613 sgd_solver.cpp:136] Iteration 34000, lr = 0.0046875, m = 0.9
I0814 19:07:41.728358   613 solver.cpp:312] Iteration 34100 (62.1997 iter/s, 1.60772s/100 iter), loss = 0.0332484
I0814 19:07:41.728474   613 solver.cpp:334]     Train net output #0: loss = 0.0332484 (* 1 = 0.0332484 loss)
I0814 19:07:41.728492   613 sgd_solver.cpp:136] Iteration 34100, lr = 0.00467187, m = 0.9
I0814 19:07:43.343317   613 solver.cpp:312] Iteration 34200 (61.923 iter/s, 1.61491s/100 iter), loss = 0.238849
I0814 19:07:43.343364   613 solver.cpp:334]     Train net output #0: loss = 0.238849 (* 1 = 0.238849 loss)
I0814 19:07:43.343375   613 sgd_solver.cpp:136] Iteration 34200, lr = 0.00465625, m = 0.9
I0814 19:07:44.953410   613 solver.cpp:312] Iteration 34300 (62.1101 iter/s, 1.61005s/100 iter), loss = 0.0479735
I0814 19:07:44.953434   613 solver.cpp:334]     Train net output #0: loss = 0.0479734 (* 1 = 0.0479734 loss)
I0814 19:07:44.953440   613 sgd_solver.cpp:136] Iteration 34300, lr = 0.00464062, m = 0.9
I0814 19:07:46.582744   613 solver.cpp:312] Iteration 34400 (61.3767 iter/s, 1.62928s/100 iter), loss = 0.0742773
I0814 19:07:46.582768   613 solver.cpp:334]     Train net output #0: loss = 0.0742772 (* 1 = 0.0742772 loss)
I0814 19:07:46.582774   613 sgd_solver.cpp:136] Iteration 34400, lr = 0.004625, m = 0.9
I0814 19:07:48.177839   613 solver.cpp:312] Iteration 34500 (62.6941 iter/s, 1.59505s/100 iter), loss = 0.0499547
I0814 19:07:48.177861   613 solver.cpp:334]     Train net output #0: loss = 0.0499546 (* 1 = 0.0499546 loss)
I0814 19:07:48.177866   613 sgd_solver.cpp:136] Iteration 34500, lr = 0.00460937, m = 0.9
I0814 19:07:49.823281   613 solver.cpp:312] Iteration 34600 (60.7759 iter/s, 1.64539s/100 iter), loss = 0.0116858
I0814 19:07:49.823338   613 solver.cpp:334]     Train net output #0: loss = 0.0116858 (* 1 = 0.0116858 loss)
I0814 19:07:49.823357   613 sgd_solver.cpp:136] Iteration 34600, lr = 0.00459375, m = 0.9
I0814 19:07:51.492287   613 solver.cpp:312] Iteration 34700 (59.9177 iter/s, 1.66896s/100 iter), loss = 0.0527371
I0814 19:07:51.492352   613 solver.cpp:334]     Train net output #0: loss = 0.052737 (* 1 = 0.052737 loss)
I0814 19:07:51.492372   613 sgd_solver.cpp:136] Iteration 34700, lr = 0.00457812, m = 0.9
I0814 19:07:53.117347   613 solver.cpp:312] Iteration 34800 (61.538 iter/s, 1.62501s/100 iter), loss = 0.0356135
I0814 19:07:53.117370   613 solver.cpp:334]     Train net output #0: loss = 0.0356134 (* 1 = 0.0356134 loss)
I0814 19:07:53.117377   613 sgd_solver.cpp:136] Iteration 34800, lr = 0.0045625, m = 0.9
I0814 19:07:54.706791   613 solver.cpp:312] Iteration 34900 (62.917 iter/s, 1.5894s/100 iter), loss = 0.0897899
I0814 19:07:54.706822   613 solver.cpp:334]     Train net output #0: loss = 0.0897899 (* 1 = 0.0897899 loss)
I0814 19:07:54.706830   613 sgd_solver.cpp:136] Iteration 34900, lr = 0.00454687, m = 0.9
I0814 19:07:56.313321   613 solver.cpp:509] Iteration 35000, Testing net (#0)
I0814 19:07:56.548751   611 data_reader.cpp:288] Starting prefetch of epoch 5
I0814 19:07:57.148259   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.881766
I0814 19:07:57.148282   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.992059
I0814 19:07:57.148288   613 solver.cpp:594]     Test net output #2: loss = 0.420559 (* 1 = 0.420559 loss)
I0814 19:07:57.148305   613 solver.cpp:264] [MultiGPU] Tests completed in 0.834962s
I0814 19:07:57.163691   613 solver.cpp:312] Iteration 35000 (40.7029 iter/s, 2.45683s/100 iter), loss = 0.143601
I0814 19:07:57.163720   613 solver.cpp:334]     Train net output #0: loss = 0.143601 (* 1 = 0.143601 loss)
I0814 19:07:57.163733   613 sgd_solver.cpp:136] Iteration 35000, lr = 0.00453125, m = 0.9
I0814 19:07:58.734797   613 solver.cpp:312] Iteration 35100 (63.6515 iter/s, 1.57105s/100 iter), loss = 0.105247
I0814 19:07:58.734822   613 solver.cpp:334]     Train net output #0: loss = 0.105247 (* 1 = 0.105247 loss)
I0814 19:07:58.734828   613 sgd_solver.cpp:136] Iteration 35100, lr = 0.00451563, m = 0.9
I0814 19:08:00.345036   613 solver.cpp:312] Iteration 35200 (62.1045 iter/s, 1.61019s/100 iter), loss = 0.0268567
I0814 19:08:00.345063   613 solver.cpp:334]     Train net output #0: loss = 0.0268567 (* 1 = 0.0268567 loss)
I0814 19:08:00.345070   613 sgd_solver.cpp:136] Iteration 35200, lr = 0.0045, m = 0.9
I0814 19:08:02.004587   613 solver.cpp:312] Iteration 35300 (60.2591 iter/s, 1.6595s/100 iter), loss = 0.0032801
I0814 19:08:02.004799   613 solver.cpp:334]     Train net output #0: loss = 0.00328004 (* 1 = 0.00328004 loss)
I0814 19:08:02.004809   613 sgd_solver.cpp:136] Iteration 35300, lr = 0.00448438, m = 0.9
I0814 19:08:03.632575   613 solver.cpp:312] Iteration 35400 (61.4274 iter/s, 1.62794s/100 iter), loss = 0.0127292
I0814 19:08:03.632602   613 solver.cpp:334]     Train net output #0: loss = 0.0127291 (* 1 = 0.0127291 loss)
I0814 19:08:03.632609   613 sgd_solver.cpp:136] Iteration 35400, lr = 0.00446875, m = 0.9
I0814 19:08:05.254626   613 solver.cpp:312] Iteration 35500 (61.6522 iter/s, 1.622s/100 iter), loss = 0.0331928
I0814 19:08:05.254675   613 solver.cpp:334]     Train net output #0: loss = 0.0331927 (* 1 = 0.0331927 loss)
I0814 19:08:05.254691   613 sgd_solver.cpp:136] Iteration 35500, lr = 0.00445312, m = 0.9
I0814 19:08:06.887248   613 solver.cpp:312] Iteration 35600 (61.253 iter/s, 1.63257s/100 iter), loss = 0.0484342
I0814 19:08:06.887272   613 solver.cpp:334]     Train net output #0: loss = 0.0484341 (* 1 = 0.0484341 loss)
I0814 19:08:06.887277   613 sgd_solver.cpp:136] Iteration 35600, lr = 0.0044375, m = 0.9
I0814 19:08:08.542246   613 solver.cpp:312] Iteration 35700 (60.425 iter/s, 1.65494s/100 iter), loss = 0.033302
I0814 19:08:08.542317   613 solver.cpp:334]     Train net output #0: loss = 0.0333018 (* 1 = 0.0333018 loss)
I0814 19:08:08.542340   613 sgd_solver.cpp:136] Iteration 35700, lr = 0.00442187, m = 0.9
I0814 19:08:10.188094   613 solver.cpp:312] Iteration 35800 (60.7607 iter/s, 1.6458s/100 iter), loss = 0.206288
I0814 19:08:10.188144   613 solver.cpp:334]     Train net output #0: loss = 0.206288 (* 1 = 0.206288 loss)
I0814 19:08:10.188158   613 sgd_solver.cpp:136] Iteration 35800, lr = 0.00440625, m = 0.9
I0814 19:08:11.757380   613 solver.cpp:312] Iteration 35900 (63.7253 iter/s, 1.56924s/100 iter), loss = 0.0475682
I0814 19:08:11.757503   613 solver.cpp:334]     Train net output #0: loss = 0.0475681 (* 1 = 0.0475681 loss)
I0814 19:08:11.757521   613 sgd_solver.cpp:136] Iteration 35900, lr = 0.00439062, m = 0.9
I0814 19:08:13.366859   613 solver.cpp:509] Iteration 36000, Testing net (#0)
I0814 19:08:14.179399   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.894119
I0814 19:08:14.179417   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.993235
I0814 19:08:14.179422   613 solver.cpp:594]     Test net output #2: loss = 0.37666 (* 1 = 0.37666 loss)
I0814 19:08:14.179446   613 solver.cpp:264] [MultiGPU] Tests completed in 0.812563s
I0814 19:08:14.197743   613 solver.cpp:312] Iteration 36000 (40.9787 iter/s, 2.44029s/100 iter), loss = 0.00646078
I0814 19:08:14.197970   613 solver.cpp:334]     Train net output #0: loss = 0.00646061 (* 1 = 0.00646061 loss)
I0814 19:08:14.197984   613 sgd_solver.cpp:136] Iteration 36000, lr = 0.004375, m = 0.9
I0814 19:08:15.810365   613 solver.cpp:312] Iteration 36100 (62.0128 iter/s, 1.61257s/100 iter), loss = 0.00177366
I0814 19:08:15.810392   613 solver.cpp:334]     Train net output #0: loss = 0.00177349 (* 1 = 0.00177349 loss)
I0814 19:08:15.810398   613 sgd_solver.cpp:136] Iteration 36100, lr = 0.00435938, m = 0.9
I0814 19:08:17.455663   613 solver.cpp:312] Iteration 36200 (60.7811 iter/s, 1.64525s/100 iter), loss = 0.0215986
I0814 19:08:17.455710   613 solver.cpp:334]     Train net output #0: loss = 0.0215984 (* 1 = 0.0215984 loss)
I0814 19:08:17.455723   613 sgd_solver.cpp:136] Iteration 36200, lr = 0.00434375, m = 0.9
I0814 19:08:19.059888   613 solver.cpp:312] Iteration 36300 (62.3373 iter/s, 1.60417s/100 iter), loss = 0.00072427
I0814 19:08:19.059937   613 solver.cpp:334]     Train net output #0: loss = 0.000724099 (* 1 = 0.000724099 loss)
I0814 19:08:19.059952   613 sgd_solver.cpp:136] Iteration 36300, lr = 0.00432813, m = 0.9
I0814 19:08:20.647841   613 solver.cpp:312] Iteration 36400 (62.9761 iter/s, 1.5879s/100 iter), loss = 0.00117935
I0814 19:08:20.647869   613 solver.cpp:334]     Train net output #0: loss = 0.0011792 (* 1 = 0.0011792 loss)
I0814 19:08:20.647874   613 sgd_solver.cpp:136] Iteration 36400, lr = 0.0043125, m = 0.9
I0814 19:08:22.253224   613 solver.cpp:312] Iteration 36500 (62.2923 iter/s, 1.60533s/100 iter), loss = 0.0838403
I0814 19:08:22.253252   613 solver.cpp:334]     Train net output #0: loss = 0.0838401 (* 1 = 0.0838401 loss)
I0814 19:08:22.253257   613 sgd_solver.cpp:136] Iteration 36500, lr = 0.00429688, m = 0.9
I0814 19:08:23.874516   613 solver.cpp:312] Iteration 36600 (61.6811 iter/s, 1.62124s/100 iter), loss = 0.016702
I0814 19:08:23.874590   613 solver.cpp:334]     Train net output #0: loss = 0.0167019 (* 1 = 0.0167019 loss)
I0814 19:08:23.874613   613 sgd_solver.cpp:136] Iteration 36600, lr = 0.00428125, m = 0.9
I0814 19:08:25.491875   613 solver.cpp:312] Iteration 36700 (61.831 iter/s, 1.61731s/100 iter), loss = 0.057909
I0814 19:08:25.491900   613 solver.cpp:334]     Train net output #0: loss = 0.0579088 (* 1 = 0.0579088 loss)
I0814 19:08:25.491906   613 sgd_solver.cpp:136] Iteration 36700, lr = 0.00426562, m = 0.9
I0814 19:08:27.119096   613 solver.cpp:312] Iteration 36800 (61.4563 iter/s, 1.62717s/100 iter), loss = 0.00279752
I0814 19:08:27.119123   613 solver.cpp:334]     Train net output #0: loss = 0.00279735 (* 1 = 0.00279735 loss)
I0814 19:08:27.119128   613 sgd_solver.cpp:136] Iteration 36800, lr = 0.00425, m = 0.9
I0814 19:08:28.737275   613 solver.cpp:312] Iteration 36900 (61.7998 iter/s, 1.61813s/100 iter), loss = 0.0050897
I0814 19:08:28.737321   613 solver.cpp:334]     Train net output #0: loss = 0.00508954 (* 1 = 0.00508954 loss)
I0814 19:08:28.737332   613 sgd_solver.cpp:136] Iteration 36900, lr = 0.00423437, m = 0.9
I0814 19:08:30.363559   613 solver.cpp:509] Iteration 37000, Testing net (#0)
I0814 19:08:31.175101   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.888825
I0814 19:08:31.175118   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.993824
I0814 19:08:31.175123   613 solver.cpp:594]     Test net output #2: loss = 0.460336 (* 1 = 0.460336 loss)
I0814 19:08:31.175150   613 solver.cpp:264] [MultiGPU] Tests completed in 0.811569s
I0814 19:08:31.190873   613 solver.cpp:312] Iteration 37000 (40.7576 iter/s, 2.45353s/100 iter), loss = 0.0206861
I0814 19:08:31.190891   613 solver.cpp:334]     Train net output #0: loss = 0.020686 (* 1 = 0.020686 loss)
I0814 19:08:31.190896   613 sgd_solver.cpp:136] Iteration 37000, lr = 0.00421875, m = 0.9
I0814 19:08:32.804273   613 solver.cpp:312] Iteration 37100 (61.9828 iter/s, 1.61335s/100 iter), loss = 0.000446452
I0814 19:08:32.804296   613 solver.cpp:334]     Train net output #0: loss = 0.000446295 (* 1 = 0.000446295 loss)
I0814 19:08:32.804301   613 sgd_solver.cpp:136] Iteration 37100, lr = 0.00420313, m = 0.9
I0814 19:08:34.452745   613 solver.cpp:312] Iteration 37200 (60.6642 iter/s, 1.64842s/100 iter), loss = 0.0076685
I0814 19:08:34.452767   613 solver.cpp:334]     Train net output #0: loss = 0.00766833 (* 1 = 0.00766833 loss)
I0814 19:08:34.452771   613 sgd_solver.cpp:136] Iteration 37200, lr = 0.0041875, m = 0.9
I0814 19:08:36.075112   613 solver.cpp:312] Iteration 37300 (61.6402 iter/s, 1.62232s/100 iter), loss = 0.00514031
I0814 19:08:36.075143   613 solver.cpp:334]     Train net output #0: loss = 0.00514014 (* 1 = 0.00514014 loss)
I0814 19:08:36.075150   613 sgd_solver.cpp:136] Iteration 37300, lr = 0.00417187, m = 0.9
I0814 19:08:37.659490   613 solver.cpp:312] Iteration 37400 (63.1182 iter/s, 1.58433s/100 iter), loss = 0.00871886
I0814 19:08:37.659517   613 solver.cpp:334]     Train net output #0: loss = 0.0087187 (* 1 = 0.0087187 loss)
I0814 19:08:37.659523   613 sgd_solver.cpp:136] Iteration 37400, lr = 0.00415625, m = 0.9
I0814 19:08:39.293591   613 solver.cpp:312] Iteration 37500 (61.1975 iter/s, 1.63405s/100 iter), loss = 0.00666315
I0814 19:08:39.293649   613 solver.cpp:334]     Train net output #0: loss = 0.00666298 (* 1 = 0.00666298 loss)
I0814 19:08:39.293668   613 sgd_solver.cpp:136] Iteration 37500, lr = 0.00414062, m = 0.9
I0814 19:08:40.891549   613 solver.cpp:312] Iteration 37600 (62.5818 iter/s, 1.59791s/100 iter), loss = 0.0070395
I0814 19:08:40.891610   613 solver.cpp:334]     Train net output #0: loss = 0.00703934 (* 1 = 0.00703934 loss)
I0814 19:08:40.891628   613 sgd_solver.cpp:136] Iteration 37600, lr = 0.004125, m = 0.9
I0814 19:08:42.568646   613 solver.cpp:312] Iteration 37700 (59.6286 iter/s, 1.67705s/100 iter), loss = 0.00196609
I0814 19:08:42.568769   613 solver.cpp:334]     Train net output #0: loss = 0.00196591 (* 1 = 0.00196591 loss)
I0814 19:08:42.568790   613 sgd_solver.cpp:136] Iteration 37700, lr = 0.00410937, m = 0.9
I0814 19:08:44.150415   613 solver.cpp:312] Iteration 37800 (63.2223 iter/s, 1.58172s/100 iter), loss = 0.00154227
I0814 19:08:44.150439   613 solver.cpp:334]     Train net output #0: loss = 0.00154208 (* 1 = 0.00154208 loss)
I0814 19:08:44.150444   613 sgd_solver.cpp:136] Iteration 37800, lr = 0.00409375, m = 0.9
I0814 19:08:45.748406   613 solver.cpp:312] Iteration 37900 (62.5805 iter/s, 1.59794s/100 iter), loss = 0.0196866
I0814 19:08:45.748431   613 solver.cpp:334]     Train net output #0: loss = 0.0196864 (* 1 = 0.0196864 loss)
I0814 19:08:45.748437   613 sgd_solver.cpp:136] Iteration 37900, lr = 0.00407812, m = 0.9
I0814 19:08:47.365270   613 solver.cpp:509] Iteration 38000, Testing net (#0)
I0814 19:08:48.175565   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.898236
I0814 19:08:48.175585   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.994706
I0814 19:08:48.175590   613 solver.cpp:594]     Test net output #2: loss = 0.406222 (* 1 = 0.406222 loss)
I0814 19:08:48.175608   613 solver.cpp:264] [MultiGPU] Tests completed in 0.810315s
I0814 19:08:48.191131   613 solver.cpp:312] Iteration 38000 (40.939 iter/s, 2.44266s/100 iter), loss = 0.00469881
I0814 19:08:48.191149   613 solver.cpp:334]     Train net output #0: loss = 0.00469862 (* 1 = 0.00469862 loss)
I0814 19:08:48.191154   613 sgd_solver.cpp:136] Iteration 38000, lr = 0.0040625, m = 0.9
I0814 19:08:49.797472   613 solver.cpp:312] Iteration 38100 (62.2552 iter/s, 1.60629s/100 iter), loss = 0.00378725
I0814 19:08:49.797497   613 solver.cpp:334]     Train net output #0: loss = 0.00378706 (* 1 = 0.00378706 loss)
I0814 19:08:49.797503   613 sgd_solver.cpp:136] Iteration 38100, lr = 0.00404688, m = 0.9
I0814 19:08:51.406745   613 solver.cpp:312] Iteration 38200 (62.1417 iter/s, 1.60922s/100 iter), loss = 0.00249077
I0814 19:08:51.406806   613 solver.cpp:334]     Train net output #0: loss = 0.00249056 (* 1 = 0.00249056 loss)
I0814 19:08:51.406824   613 sgd_solver.cpp:136] Iteration 38200, lr = 0.00403125, m = 0.9
I0814 19:08:53.004896   613 solver.cpp:312] Iteration 38300 (62.5744 iter/s, 1.5981s/100 iter), loss = 0.00416665
I0814 19:08:53.004921   613 solver.cpp:334]     Train net output #0: loss = 0.00416645 (* 1 = 0.00416645 loss)
I0814 19:08:53.004927   613 sgd_solver.cpp:136] Iteration 38300, lr = 0.00401562, m = 0.9
I0814 19:08:54.606511   613 solver.cpp:312] Iteration 38400 (62.4388 iter/s, 1.60157s/100 iter), loss = 0.000731407
I0814 19:08:54.606575   613 solver.cpp:334]     Train net output #0: loss = 0.000731209 (* 1 = 0.000731209 loss)
I0814 19:08:54.606595   613 sgd_solver.cpp:136] Iteration 38400, lr = 0.004, m = 0.9
I0814 19:08:56.242810   613 solver.cpp:312] Iteration 38500 (61.1153 iter/s, 1.63625s/100 iter), loss = 0.12351
I0814 19:08:56.242832   613 solver.cpp:334]     Train net output #0: loss = 0.12351 (* 1 = 0.12351 loss)
I0814 19:08:56.242836   613 sgd_solver.cpp:136] Iteration 38500, lr = 0.00398437, m = 0.9
I0814 19:08:57.876981   613 solver.cpp:312] Iteration 38600 (61.1951 iter/s, 1.63412s/100 iter), loss = 0.00438004
I0814 19:08:57.877005   613 solver.cpp:334]     Train net output #0: loss = 0.00437984 (* 1 = 0.00437984 loss)
I0814 19:08:57.877012   613 sgd_solver.cpp:136] Iteration 38600, lr = 0.00396875, m = 0.9
I0814 19:08:59.442773   613 solver.cpp:312] Iteration 38700 (63.8674 iter/s, 1.56575s/100 iter), loss = 0.00191789
I0814 19:08:59.442823   613 solver.cpp:334]     Train net output #0: loss = 0.00191769 (* 1 = 0.00191769 loss)
I0814 19:08:59.442837   613 sgd_solver.cpp:136] Iteration 38700, lr = 0.00395312, m = 0.9
I0814 19:09:01.075417   613 solver.cpp:312] Iteration 38800 (61.2525 iter/s, 1.63259s/100 iter), loss = 0.00138349
I0814 19:09:01.075462   613 solver.cpp:334]     Train net output #0: loss = 0.00138329 (* 1 = 0.00138329 loss)
I0814 19:09:01.075471   613 sgd_solver.cpp:136] Iteration 38800, lr = 0.0039375, m = 0.9
I0814 19:09:02.706985   613 solver.cpp:312] Iteration 38900 (61.2923 iter/s, 1.63153s/100 iter), loss = 0.00213671
I0814 19:09:02.707010   613 solver.cpp:334]     Train net output #0: loss = 0.00213652 (* 1 = 0.00213652 loss)
I0814 19:09:02.707015   613 sgd_solver.cpp:136] Iteration 38900, lr = 0.00392187, m = 0.9
I0814 19:09:04.290182   613 solver.cpp:509] Iteration 39000, Testing net (#0)
I0814 19:09:05.100741   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.902648
I0814 19:09:05.100759   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.995294
I0814 19:09:05.100764   613 solver.cpp:594]     Test net output #2: loss = 0.379448 (* 1 = 0.379448 loss)
I0814 19:09:05.100838   613 solver.cpp:264] [MultiGPU] Tests completed in 0.810633s
I0814 19:09:05.119067   613 solver.cpp:312] Iteration 39000 (41.4593 iter/s, 2.41201s/100 iter), loss = 0.00151517
I0814 19:09:05.119108   613 solver.cpp:334]     Train net output #0: loss = 0.00151498 (* 1 = 0.00151498 loss)
I0814 19:09:05.119117   613 sgd_solver.cpp:136] Iteration 39000, lr = 0.00390625, m = 0.9
I0814 19:09:06.733034   613 solver.cpp:312] Iteration 39100 (61.9609 iter/s, 1.61392s/100 iter), loss = 0.00159203
I0814 19:09:06.733062   613 solver.cpp:334]     Train net output #0: loss = 0.00159184 (* 1 = 0.00159184 loss)
I0814 19:09:06.733067   613 sgd_solver.cpp:136] Iteration 39100, lr = 0.00389063, m = 0.9
I0814 19:09:08.344581   613 solver.cpp:312] Iteration 39200 (62.0541 iter/s, 1.6115s/100 iter), loss = 0.00267104
I0814 19:09:08.344604   613 solver.cpp:334]     Train net output #0: loss = 0.00267085 (* 1 = 0.00267085 loss)
I0814 19:09:08.344609   613 sgd_solver.cpp:136] Iteration 39200, lr = 0.003875, m = 0.9
I0814 19:09:09.959564   613 solver.cpp:312] Iteration 39300 (61.922 iter/s, 1.61494s/100 iter), loss = 0.00185432
I0814 19:09:09.959628   613 solver.cpp:334]     Train net output #0: loss = 0.00185412 (* 1 = 0.00185412 loss)
I0814 19:09:09.959648   613 sgd_solver.cpp:136] Iteration 39300, lr = 0.00385938, m = 0.9
I0814 19:09:11.413118   592 data_reader.cpp:288] Starting prefetch of epoch 5
I0814 19:09:11.582645   613 solver.cpp:312] Iteration 39400 (61.6132 iter/s, 1.62303s/100 iter), loss = 0.0383216
I0814 19:09:11.582705   613 solver.cpp:334]     Train net output #0: loss = 0.0383214 (* 1 = 0.0383214 loss)
I0814 19:09:11.582722   613 sgd_solver.cpp:136] Iteration 39400, lr = 0.00384375, m = 0.9
I0814 19:09:13.171697   613 solver.cpp:312] Iteration 39500 (62.9325 iter/s, 1.589s/100 iter), loss = 0.000563638
I0814 19:09:13.171778   613 solver.cpp:334]     Train net output #0: loss = 0.000563439 (* 1 = 0.000563439 loss)
I0814 19:09:13.171790   613 sgd_solver.cpp:136] Iteration 39500, lr = 0.00382812, m = 0.9
I0814 19:09:14.798892   613 solver.cpp:312] Iteration 39600 (61.4573 iter/s, 1.62715s/100 iter), loss = 0.00294112
I0814 19:09:14.798936   613 solver.cpp:334]     Train net output #0: loss = 0.00294092 (* 1 = 0.00294092 loss)
I0814 19:09:14.798949   613 sgd_solver.cpp:136] Iteration 39600, lr = 0.0038125, m = 0.9
I0814 19:09:16.394758   613 solver.cpp:312] Iteration 39700 (62.6638 iter/s, 1.59582s/100 iter), loss = 0.00109256
I0814 19:09:16.394783   613 solver.cpp:334]     Train net output #0: loss = 0.00109237 (* 1 = 0.00109237 loss)
I0814 19:09:16.394788   613 sgd_solver.cpp:136] Iteration 39700, lr = 0.00379687, m = 0.9
I0814 19:09:18.014926   613 solver.cpp:312] Iteration 39800 (61.7239 iter/s, 1.62012s/100 iter), loss = 0.00394184
I0814 19:09:18.014988   613 solver.cpp:334]     Train net output #0: loss = 0.00394164 (* 1 = 0.00394164 loss)
I0814 19:09:18.015008   613 sgd_solver.cpp:136] Iteration 39800, lr = 0.00378125, m = 0.9
I0814 19:09:19.621235   613 solver.cpp:312] Iteration 39900 (62.2564 iter/s, 1.60626s/100 iter), loss = 0.000960186
I0814 19:09:19.621297   613 solver.cpp:334]     Train net output #0: loss = 0.000959984 (* 1 = 0.000959984 loss)
I0814 19:09:19.621315   613 sgd_solver.cpp:136] Iteration 39900, lr = 0.00376562, m = 0.9
I0814 19:09:21.243870   613 solver.cpp:639] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/l1reg/cifar10_jacintonet11v2_iter_40000.caffemodel
I0814 19:09:21.251791   613 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/l1reg/cifar10_jacintonet11v2_iter_40000.solverstate
I0814 19:09:21.255410   613 solver.cpp:509] Iteration 40000, Testing net (#0)
I0814 19:09:22.057953   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.902942
I0814 19:09:22.057971   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.996471
I0814 19:09:22.057977   613 solver.cpp:594]     Test net output #2: loss = 0.358747 (* 1 = 0.358747 loss)
I0814 19:09:22.058028   613 solver.cpp:264] [MultiGPU] Tests completed in 0.802596s
I0814 19:09:22.073787   613 solver.cpp:312] Iteration 40000 (40.775 iter/s, 2.45248s/100 iter), loss = 0.000631083
I0814 19:09:22.073804   613 solver.cpp:334]     Train net output #0: loss = 0.000630882 (* 1 = 0.000630882 loss)
I0814 19:09:22.073810   613 sgd_solver.cpp:136] Iteration 40000, lr = 0.00375, m = 0.9
I0814 19:09:23.695361   613 solver.cpp:312] Iteration 40100 (61.6705 iter/s, 1.62152s/100 iter), loss = 0.00163009
I0814 19:09:23.695410   613 solver.cpp:334]     Train net output #0: loss = 0.00162989 (* 1 = 0.00162989 loss)
I0814 19:09:23.695423   613 sgd_solver.cpp:136] Iteration 40100, lr = 0.00373438, m = 0.9
I0814 19:09:25.315073   613 solver.cpp:312] Iteration 40200 (61.7412 iter/s, 1.61966s/100 iter), loss = 0.000181896
I0814 19:09:25.315099   613 solver.cpp:334]     Train net output #0: loss = 0.000181699 (* 1 = 0.000181699 loss)
I0814 19:09:25.315104   613 sgd_solver.cpp:136] Iteration 40200, lr = 0.00371875, m = 0.9
I0814 19:09:26.943068   613 solver.cpp:312] Iteration 40300 (61.4271 iter/s, 1.62795s/100 iter), loss = 0.00129886
I0814 19:09:26.943119   613 solver.cpp:334]     Train net output #0: loss = 0.00129866 (* 1 = 0.00129866 loss)
I0814 19:09:26.943132   613 sgd_solver.cpp:136] Iteration 40300, lr = 0.00370313, m = 0.9
I0814 19:09:28.563990   613 solver.cpp:312] Iteration 40400 (61.6952 iter/s, 1.62087s/100 iter), loss = 0.00357933
I0814 19:09:28.564015   613 solver.cpp:334]     Train net output #0: loss = 0.00357914 (* 1 = 0.00357914 loss)
I0814 19:09:28.564020   613 sgd_solver.cpp:136] Iteration 40400, lr = 0.0036875, m = 0.9
I0814 19:09:30.172710   613 solver.cpp:312] Iteration 40500 (62.1631 iter/s, 1.60867s/100 iter), loss = 0.0020413
I0814 19:09:30.172735   613 solver.cpp:334]     Train net output #0: loss = 0.00204111 (* 1 = 0.00204111 loss)
I0814 19:09:30.172757   613 sgd_solver.cpp:136] Iteration 40500, lr = 0.00367187, m = 0.9
I0814 19:09:31.766396   613 solver.cpp:312] Iteration 40600 (62.7497 iter/s, 1.59363s/100 iter), loss = 0.000145992
I0814 19:09:31.766536   613 solver.cpp:334]     Train net output #0: loss = 0.000145805 (* 1 = 0.000145805 loss)
I0814 19:09:31.766554   613 sgd_solver.cpp:136] Iteration 40600, lr = 0.00365625, m = 0.9
I0814 19:09:33.400741   613 solver.cpp:312] Iteration 40700 (61.1889 iter/s, 1.63428s/100 iter), loss = 0.00343533
I0814 19:09:33.400842   613 solver.cpp:334]     Train net output #0: loss = 0.00343514 (* 1 = 0.00343514 loss)
I0814 19:09:33.400879   613 sgd_solver.cpp:136] Iteration 40700, lr = 0.00364062, m = 0.9
I0814 19:09:35.022871   613 solver.cpp:312] Iteration 40800 (61.6492 iter/s, 1.62208s/100 iter), loss = 0.00113448
I0814 19:09:35.022927   613 solver.cpp:334]     Train net output #0: loss = 0.00113429 (* 1 = 0.00113429 loss)
I0814 19:09:35.022945   613 sgd_solver.cpp:136] Iteration 40800, lr = 0.003625, m = 0.9
I0814 19:09:36.647507   613 solver.cpp:312] Iteration 40900 (61.554 iter/s, 1.62459s/100 iter), loss = 0.00135423
I0814 19:09:36.647572   613 solver.cpp:334]     Train net output #0: loss = 0.00135403 (* 1 = 0.00135403 loss)
I0814 19:09:36.647591   613 sgd_solver.cpp:136] Iteration 40900, lr = 0.00360937, m = 0.9
I0814 19:09:38.236651   613 solver.cpp:509] Iteration 41000, Testing net (#0)
I0814 19:09:39.055471   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.906177
I0814 19:09:39.055492   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.997353
I0814 19:09:39.055500   613 solver.cpp:594]     Test net output #2: loss = 0.363845 (* 1 = 0.363845 loss)
I0814 19:09:39.055519   613 solver.cpp:264] [MultiGPU] Tests completed in 0.818847s
I0814 19:09:39.071223   613 solver.cpp:312] Iteration 41000 (41.2601 iter/s, 2.42365s/100 iter), loss = 0.00100691
I0814 19:09:39.071240   613 solver.cpp:334]     Train net output #0: loss = 0.00100672 (* 1 = 0.00100672 loss)
I0814 19:09:39.071244   613 sgd_solver.cpp:136] Iteration 41000, lr = 0.00359375, m = 0.9
I0814 19:09:40.711818   613 solver.cpp:312] Iteration 41100 (60.9554 iter/s, 1.64054s/100 iter), loss = 0.00126491
I0814 19:09:40.711843   613 solver.cpp:334]     Train net output #0: loss = 0.00126472 (* 1 = 0.00126472 loss)
I0814 19:09:40.711849   613 sgd_solver.cpp:136] Iteration 41100, lr = 0.00357813, m = 0.9
I0814 19:09:42.340250   613 solver.cpp:312] Iteration 41200 (61.4106 iter/s, 1.62838s/100 iter), loss = 0.000263502
I0814 19:09:42.340275   613 solver.cpp:334]     Train net output #0: loss = 0.000263308 (* 1 = 0.000263308 loss)
I0814 19:09:42.340279   613 sgd_solver.cpp:136] Iteration 41200, lr = 0.0035625, m = 0.9
I0814 19:09:43.998565   613 solver.cpp:312] Iteration 41300 (60.304 iter/s, 1.65826s/100 iter), loss = 0.00360963
I0814 19:09:43.998920   613 solver.cpp:334]     Train net output #0: loss = 0.00360944 (* 1 = 0.00360944 loss)
I0814 19:09:43.998942   613 sgd_solver.cpp:136] Iteration 41300, lr = 0.00354687, m = 0.9
I0814 19:09:45.647939   613 solver.cpp:312] Iteration 41400 (60.631 iter/s, 1.64932s/100 iter), loss = 0.00111865
I0814 19:09:45.647987   613 solver.cpp:334]     Train net output #0: loss = 0.00111846 (* 1 = 0.00111846 loss)
I0814 19:09:45.648000   613 sgd_solver.cpp:136] Iteration 41400, lr = 0.00353125, m = 0.9
I0814 19:09:47.269423   613 solver.cpp:312] Iteration 41500 (61.6737 iter/s, 1.62144s/100 iter), loss = 0.00346085
I0814 19:09:47.269448   613 solver.cpp:334]     Train net output #0: loss = 0.00346065 (* 1 = 0.00346065 loss)
I0814 19:09:47.269454   613 sgd_solver.cpp:136] Iteration 41500, lr = 0.00351562, m = 0.9
I0814 19:09:48.858846   613 solver.cpp:312] Iteration 41600 (62.9179 iter/s, 1.58937s/100 iter), loss = 0.00293498
I0814 19:09:48.858911   613 solver.cpp:334]     Train net output #0: loss = 0.00293478 (* 1 = 0.00293478 loss)
I0814 19:09:48.858928   613 sgd_solver.cpp:136] Iteration 41600, lr = 0.0035, m = 0.9
I0814 19:09:50.494462   613 solver.cpp:312] Iteration 41700 (61.1409 iter/s, 1.63557s/100 iter), loss = 0.00701026
I0814 19:09:50.494487   613 solver.cpp:334]     Train net output #0: loss = 0.00701006 (* 1 = 0.00701006 loss)
I0814 19:09:50.494493   613 sgd_solver.cpp:136] Iteration 41700, lr = 0.00348437, m = 0.9
I0814 19:09:52.137043   613 solver.cpp:312] Iteration 41800 (60.8818 iter/s, 1.64253s/100 iter), loss = 0.00462833
I0814 19:09:52.137128   613 solver.cpp:334]     Train net output #0: loss = 0.00462813 (* 1 = 0.00462813 loss)
I0814 19:09:52.137150   613 sgd_solver.cpp:136] Iteration 41800, lr = 0.00346875, m = 0.9
I0814 19:09:53.788580   613 solver.cpp:312] Iteration 41900 (60.5515 iter/s, 1.65149s/100 iter), loss = 0.00151235
I0814 19:09:53.788606   613 solver.cpp:334]     Train net output #0: loss = 0.00151215 (* 1 = 0.00151215 loss)
I0814 19:09:53.788612   613 sgd_solver.cpp:136] Iteration 41900, lr = 0.00345312, m = 0.9
I0814 19:09:55.370249   613 solver.cpp:509] Iteration 42000, Testing net (#0)
I0814 19:09:56.183568   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.916472
I0814 19:09:56.183585   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.997353
I0814 19:09:56.183593   613 solver.cpp:594]     Test net output #2: loss = 0.317332 (* 1 = 0.317332 loss)
I0814 19:09:56.183696   613 solver.cpp:264] [MultiGPU] Tests completed in 0.813426s
I0814 19:09:56.201138   613 solver.cpp:312] Iteration 42000 (41.451 iter/s, 2.41249s/100 iter), loss = 0.000720609
I0814 19:09:56.201165   613 solver.cpp:334]     Train net output #0: loss = 0.000720412 (* 1 = 0.000720412 loss)
I0814 19:09:56.201170   613 sgd_solver.cpp:136] Iteration 42000, lr = 0.0034375, m = 0.9
I0814 19:09:57.824607   613 solver.cpp:312] Iteration 42100 (61.5984 iter/s, 1.62342s/100 iter), loss = 0.00112608
I0814 19:09:57.824633   613 solver.cpp:334]     Train net output #0: loss = 0.00112588 (* 1 = 0.00112588 loss)
I0814 19:09:57.824640   613 sgd_solver.cpp:136] Iteration 42100, lr = 0.00342188, m = 0.9
I0814 19:09:59.426971   613 solver.cpp:312] Iteration 42200 (62.4098 iter/s, 1.60231s/100 iter), loss = 0.000295132
I0814 19:09:59.426996   613 solver.cpp:334]     Train net output #0: loss = 0.000294934 (* 1 = 0.000294934 loss)
I0814 19:09:59.427001   613 sgd_solver.cpp:136] Iteration 42200, lr = 0.00340625, m = 0.9
I0814 19:10:01.046291   613 solver.cpp:312] Iteration 42300 (61.7563 iter/s, 1.61927s/100 iter), loss = 0.000434836
I0814 19:10:01.046471   613 solver.cpp:334]     Train net output #0: loss = 0.000434638 (* 1 = 0.000434638 loss)
I0814 19:10:01.046566   613 sgd_solver.cpp:136] Iteration 42300, lr = 0.00339063, m = 0.9
I0814 19:10:02.678210   613 solver.cpp:312] Iteration 42400 (61.2795 iter/s, 1.63187s/100 iter), loss = 0.00242478
I0814 19:10:02.678236   613 solver.cpp:334]     Train net output #0: loss = 0.00242458 (* 1 = 0.00242458 loss)
I0814 19:10:02.678242   613 sgd_solver.cpp:136] Iteration 42400, lr = 0.003375, m = 0.9
I0814 19:10:04.262579   613 solver.cpp:312] Iteration 42500 (63.1186 iter/s, 1.58432s/100 iter), loss = 0.00152347
I0814 19:10:04.262639   613 solver.cpp:334]     Train net output #0: loss = 0.00152327 (* 1 = 0.00152327 loss)
I0814 19:10:04.262657   613 sgd_solver.cpp:136] Iteration 42500, lr = 0.00335937, m = 0.9
I0814 19:10:05.872861   613 solver.cpp:312] Iteration 42600 (62.1029 iter/s, 1.61023s/100 iter), loss = 0.00199565
I0814 19:10:05.873078   613 solver.cpp:334]     Train net output #0: loss = 0.00199545 (* 1 = 0.00199545 loss)
I0814 19:10:05.873196   613 sgd_solver.cpp:136] Iteration 42600, lr = 0.00334375, m = 0.9
I0814 19:10:07.510170   613 solver.cpp:312] Iteration 42700 (61.0777 iter/s, 1.63726s/100 iter), loss = 0.00183584
I0814 19:10:07.510216   613 solver.cpp:334]     Train net output #0: loss = 0.00183564 (* 1 = 0.00183564 loss)
I0814 19:10:07.510227   613 sgd_solver.cpp:136] Iteration 42700, lr = 0.00332812, m = 0.9
I0814 19:10:09.110486   613 solver.cpp:312] Iteration 42800 (62.4897 iter/s, 1.60026s/100 iter), loss = 0.000779117
I0814 19:10:09.110510   613 solver.cpp:334]     Train net output #0: loss = 0.000778921 (* 1 = 0.000778921 loss)
I0814 19:10:09.110515   613 sgd_solver.cpp:136] Iteration 42800, lr = 0.0033125, m = 0.9
I0814 19:10:10.712728   613 solver.cpp:312] Iteration 42900 (62.4145 iter/s, 1.60219s/100 iter), loss = 0.0023665
I0814 19:10:10.712797   613 solver.cpp:334]     Train net output #0: loss = 0.00236631 (* 1 = 0.00236631 loss)
I0814 19:10:10.712816   613 sgd_solver.cpp:136] Iteration 42900, lr = 0.00329687, m = 0.9
I0814 19:10:12.351410   613 solver.cpp:509] Iteration 43000, Testing net (#0)
I0814 19:10:13.190018   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.921766
I0814 19:10:13.190035   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.998235
I0814 19:10:13.190040   613 solver.cpp:594]     Test net output #2: loss = 0.290765 (* 1 = 0.290765 loss)
I0814 19:10:13.190057   613 solver.cpp:264] [MultiGPU] Tests completed in 0.838623s
I0814 19:10:13.208822   613 solver.cpp:312] Iteration 43000 (40.0638 iter/s, 2.49602s/100 iter), loss = 0.000730149
I0814 19:10:13.208850   613 solver.cpp:334]     Train net output #0: loss = 0.000729954 (* 1 = 0.000729954 loss)
I0814 19:10:13.208856   613 sgd_solver.cpp:136] Iteration 43000, lr = 0.00328125, m = 0.9
I0814 19:10:14.791419   613 solver.cpp:312] Iteration 43100 (63.1893 iter/s, 1.58255s/100 iter), loss = 0.000725857
I0814 19:10:14.791514   613 solver.cpp:334]     Train net output #0: loss = 0.000725663 (* 1 = 0.000725663 loss)
I0814 19:10:14.791527   613 sgd_solver.cpp:136] Iteration 43100, lr = 0.00326563, m = 0.9
I0814 19:10:16.429031   613 solver.cpp:312] Iteration 43200 (61.0664 iter/s, 1.63756s/100 iter), loss = 0.00492749
I0814 19:10:16.429055   613 solver.cpp:334]     Train net output #0: loss = 0.00492729 (* 1 = 0.00492729 loss)
I0814 19:10:16.429061   613 sgd_solver.cpp:136] Iteration 43200, lr = 0.00325, m = 0.9
I0814 19:10:18.054787   613 solver.cpp:312] Iteration 43300 (61.5117 iter/s, 1.62571s/100 iter), loss = 0.00227864
I0814 19:10:18.054811   613 solver.cpp:334]     Train net output #0: loss = 0.00227844 (* 1 = 0.00227844 loss)
I0814 19:10:18.054816   613 sgd_solver.cpp:136] Iteration 43300, lr = 0.00323438, m = 0.9
I0814 19:10:19.658825   613 solver.cpp:312] Iteration 43400 (62.3446 iter/s, 1.60399s/100 iter), loss = 0.00108539
I0814 19:10:19.658850   613 solver.cpp:334]     Train net output #0: loss = 0.0010852 (* 1 = 0.0010852 loss)
I0814 19:10:19.658856   613 sgd_solver.cpp:136] Iteration 43400, lr = 0.00321875, m = 0.9
I0814 19:10:21.284073   613 solver.cpp:312] Iteration 43500 (61.5312 iter/s, 1.62519s/100 iter), loss = 0.000225047
I0814 19:10:21.284121   613 solver.cpp:334]     Train net output #0: loss = 0.00022485 (* 1 = 0.00022485 loss)
I0814 19:10:21.284142   613 sgd_solver.cpp:136] Iteration 43500, lr = 0.00320312, m = 0.9
I0814 19:10:22.918233   613 solver.cpp:312] Iteration 43600 (61.1954 iter/s, 1.63411s/100 iter), loss = 0.000195396
I0814 19:10:22.918259   613 solver.cpp:334]     Train net output #0: loss = 0.000195199 (* 1 = 0.000195199 loss)
I0814 19:10:22.918265   613 sgd_solver.cpp:136] Iteration 43600, lr = 0.0031875, m = 0.9
I0814 19:10:24.555605   613 solver.cpp:312] Iteration 43700 (61.0753 iter/s, 1.63732s/100 iter), loss = 0.00091494
I0814 19:10:24.555665   613 solver.cpp:334]     Train net output #0: loss = 0.00091474 (* 1 = 0.00091474 loss)
I0814 19:10:24.555685   613 sgd_solver.cpp:136] Iteration 43700, lr = 0.00317187, m = 0.9
I0814 19:10:26.201346   613 solver.cpp:312] Iteration 43800 (60.7648 iter/s, 1.64569s/100 iter), loss = 0.0006925
I0814 19:10:26.201370   613 solver.cpp:334]     Train net output #0: loss = 0.000692301 (* 1 = 0.000692301 loss)
I0814 19:10:26.201375   613 sgd_solver.cpp:136] Iteration 43800, lr = 0.00315625, m = 0.9
I0814 19:10:27.804654   613 solver.cpp:312] Iteration 43900 (62.3731 iter/s, 1.60326s/100 iter), loss = 0.000834943
I0814 19:10:27.804678   613 solver.cpp:334]     Train net output #0: loss = 0.000834743 (* 1 = 0.000834743 loss)
I0814 19:10:27.804682   613 sgd_solver.cpp:136] Iteration 43900, lr = 0.00314062, m = 0.9
I0814 19:10:28.408018   592 data_reader.cpp:288] Starting prefetch of epoch 6
I0814 19:10:29.401788   613 solver.cpp:509] Iteration 44000, Testing net (#0)
I0814 19:10:30.225769   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.926766
I0814 19:10:30.225791   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.996765
I0814 19:10:30.225796   613 solver.cpp:594]     Test net output #2: loss = 0.276727 (* 1 = 0.276727 loss)
I0814 19:10:30.225823   613 solver.cpp:264] [MultiGPU] Tests completed in 0.824013s
I0814 19:10:30.242105   613 solver.cpp:312] Iteration 44000 (41.0276 iter/s, 2.43738s/100 iter), loss = 0.000927302
I0814 19:10:30.242123   613 solver.cpp:334]     Train net output #0: loss = 0.000927103 (* 1 = 0.000927103 loss)
I0814 19:10:30.242127   613 sgd_solver.cpp:136] Iteration 44000, lr = 0.003125, m = 0.9
I0814 19:10:31.828783   613 solver.cpp:312] Iteration 44100 (63.0269 iter/s, 1.58662s/100 iter), loss = 0.001005
I0814 19:10:31.828832   613 solver.cpp:334]     Train net output #0: loss = 0.0010048 (* 1 = 0.0010048 loss)
I0814 19:10:31.828846   613 sgd_solver.cpp:136] Iteration 44100, lr = 0.00310938, m = 0.9
I0814 19:10:33.426414   613 solver.cpp:312] Iteration 44200 (62.5947 iter/s, 1.59758s/100 iter), loss = 0.000923711
I0814 19:10:33.426440   613 solver.cpp:334]     Train net output #0: loss = 0.000923514 (* 1 = 0.000923514 loss)
I0814 19:10:33.427999   613 sgd_solver.cpp:136] Iteration 44200, lr = 0.00309375, m = 0.9
I0814 19:10:35.028414   613 solver.cpp:312] Iteration 44300 (62.4239 iter/s, 1.60195s/100 iter), loss = 0.000169598
I0814 19:10:35.028457   613 solver.cpp:334]     Train net output #0: loss = 0.000169401 (* 1 = 0.000169401 loss)
I0814 19:10:35.028470   613 sgd_solver.cpp:136] Iteration 44300, lr = 0.00307812, m = 0.9
I0814 19:10:36.624832   613 solver.cpp:312] Iteration 44400 (62.6422 iter/s, 1.59637s/100 iter), loss = 0.00291703
I0814 19:10:36.624861   613 solver.cpp:334]     Train net output #0: loss = 0.00291683 (* 1 = 0.00291683 loss)
I0814 19:10:36.624867   613 sgd_solver.cpp:136] Iteration 44400, lr = 0.0030625, m = 0.9
I0814 19:10:38.240097   613 solver.cpp:312] Iteration 44500 (61.9114 iter/s, 1.61521s/100 iter), loss = 0.00086036
I0814 19:10:38.240149   613 solver.cpp:334]     Train net output #0: loss = 0.000860163 (* 1 = 0.000860163 loss)
I0814 19:10:38.240162   613 sgd_solver.cpp:136] Iteration 44500, lr = 0.00304687, m = 0.9
I0814 19:10:39.864621   613 solver.cpp:312] Iteration 44600 (61.5584 iter/s, 1.62447s/100 iter), loss = 0.0012991
I0814 19:10:39.864645   613 solver.cpp:334]     Train net output #0: loss = 0.0012989 (* 1 = 0.0012989 loss)
I0814 19:10:39.864650   613 sgd_solver.cpp:136] Iteration 44600, lr = 0.00303125, m = 0.9
I0814 19:10:41.496698   613 solver.cpp:312] Iteration 44700 (61.2736 iter/s, 1.63203s/100 iter), loss = 0.00137271
I0814 19:10:41.496723   613 solver.cpp:334]     Train net output #0: loss = 0.00137251 (* 1 = 0.00137251 loss)
I0814 19:10:41.496729   613 sgd_solver.cpp:136] Iteration 44700, lr = 0.00301562, m = 0.9
I0814 19:10:43.091781   613 solver.cpp:312] Iteration 44800 (62.6946 iter/s, 1.59503s/100 iter), loss = 0.00130456
I0814 19:10:43.091850   613 solver.cpp:334]     Train net output #0: loss = 0.00130436 (* 1 = 0.00130436 loss)
I0814 19:10:43.091873   613 sgd_solver.cpp:136] Iteration 44800, lr = 0.003, m = 0.9
I0814 19:10:44.717278   613 solver.cpp:312] Iteration 44900 (61.5216 iter/s, 1.62545s/100 iter), loss = 0.000756068
I0814 19:10:44.717336   613 solver.cpp:334]     Train net output #0: loss = 0.000755871 (* 1 = 0.000755871 loss)
I0814 19:10:44.717355   613 sgd_solver.cpp:136] Iteration 44900, lr = 0.00298437, m = 0.9
I0814 19:10:46.333463   613 solver.cpp:509] Iteration 45000, Testing net (#0)
I0814 19:10:47.147727   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.917648
I0814 19:10:47.147745   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.996177
I0814 19:10:47.147750   613 solver.cpp:594]     Test net output #2: loss = 0.305562 (* 1 = 0.305562 loss)
I0814 19:10:47.147764   613 solver.cpp:264] [MultiGPU] Tests completed in 0.814278s
I0814 19:10:47.163338   613 solver.cpp:312] Iteration 45000 (40.8833 iter/s, 2.44599s/100 iter), loss = 0.000281358
I0814 19:10:47.163355   613 solver.cpp:334]     Train net output #0: loss = 0.00028116 (* 1 = 0.00028116 loss)
I0814 19:10:47.163360   613 sgd_solver.cpp:136] Iteration 45000, lr = 0.00296875, m = 0.9
I0814 19:10:48.822198   613 solver.cpp:312] Iteration 45100 (60.2844 iter/s, 1.6588s/100 iter), loss = 0.00089973
I0814 19:10:48.822223   613 solver.cpp:334]     Train net output #0: loss = 0.000899532 (* 1 = 0.000899532 loss)
I0814 19:10:48.822229   613 sgd_solver.cpp:136] Iteration 45100, lr = 0.00295313, m = 0.9
I0814 19:10:50.456260   613 solver.cpp:312] Iteration 45200 (61.1991 iter/s, 1.63401s/100 iter), loss = 0.000943092
I0814 19:10:50.456406   613 solver.cpp:334]     Train net output #0: loss = 0.000942893 (* 1 = 0.000942893 loss)
I0814 19:10:50.456423   613 sgd_solver.cpp:136] Iteration 45200, lr = 0.0029375, m = 0.9
I0814 19:10:52.102867   613 solver.cpp:312] Iteration 45300 (60.7328 iter/s, 1.64656s/100 iter), loss = 0.000480841
I0814 19:10:52.102913   613 solver.cpp:334]     Train net output #0: loss = 0.000480643 (* 1 = 0.000480643 loss)
I0814 19:10:52.102926   613 sgd_solver.cpp:136] Iteration 45300, lr = 0.00292188, m = 0.9
I0814 19:10:53.703881   613 solver.cpp:312] Iteration 45400 (62.4624 iter/s, 1.60096s/100 iter), loss = 0.00328456
I0814 19:10:53.703925   613 solver.cpp:334]     Train net output #0: loss = 0.00328436 (* 1 = 0.00328436 loss)
I0814 19:10:53.703936   613 sgd_solver.cpp:136] Iteration 45400, lr = 0.00290625, m = 0.9
I0814 19:10:55.365870   613 solver.cpp:312] Iteration 45500 (60.1708 iter/s, 1.66194s/100 iter), loss = 0.00136303
I0814 19:10:55.365895   613 solver.cpp:334]     Train net output #0: loss = 0.00136283 (* 1 = 0.00136283 loss)
I0814 19:10:55.365900   613 sgd_solver.cpp:136] Iteration 45500, lr = 0.00289063, m = 0.9
I0814 19:10:57.016520   613 solver.cpp:312] Iteration 45600 (60.5842 iter/s, 1.6506s/100 iter), loss = 0.00122352
I0814 19:10:57.016546   613 solver.cpp:334]     Train net output #0: loss = 0.00122333 (* 1 = 0.00122333 loss)
I0814 19:10:57.016551   613 sgd_solver.cpp:136] Iteration 45600, lr = 0.002875, m = 0.9
I0814 19:10:58.646961   613 solver.cpp:312] Iteration 45700 (61.335 iter/s, 1.63039s/100 iter), loss = 0.00177652
I0814 19:10:58.646986   613 solver.cpp:334]     Train net output #0: loss = 0.00177633 (* 1 = 0.00177633 loss)
I0814 19:10:58.646991   613 sgd_solver.cpp:136] Iteration 45700, lr = 0.00285937, m = 0.9
I0814 19:11:00.234938   613 solver.cpp:312] Iteration 45800 (62.9751 iter/s, 1.58793s/100 iter), loss = 0.000674201
I0814 19:11:00.234961   613 solver.cpp:334]     Train net output #0: loss = 0.000674005 (* 1 = 0.000674005 loss)
I0814 19:11:00.234968   613 sgd_solver.cpp:136] Iteration 45800, lr = 0.00284375, m = 0.9
I0814 19:11:01.856184   613 solver.cpp:312] Iteration 45900 (61.6828 iter/s, 1.6212s/100 iter), loss = 0.0025055
I0814 19:11:01.856243   613 solver.cpp:334]     Train net output #0: loss = 0.0025053 (* 1 = 0.0025053 loss)
I0814 19:11:01.856261   613 sgd_solver.cpp:136] Iteration 45900, lr = 0.00282812, m = 0.9
I0814 19:11:03.427736   613 solver.cpp:509] Iteration 46000, Testing net (#0)
I0814 19:11:04.237390   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.920883
I0814 19:11:04.237406   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.995588
I0814 19:11:04.237411   613 solver.cpp:594]     Test net output #2: loss = 0.295255 (* 1 = 0.295255 loss)
I0814 19:11:04.237433   613 solver.cpp:264] [MultiGPU] Tests completed in 0.809674s
I0814 19:11:04.253439   613 solver.cpp:312] Iteration 46000 (41.7156 iter/s, 2.39719s/100 iter), loss = 0.00137337
I0814 19:11:04.253471   613 solver.cpp:334]     Train net output #0: loss = 0.00137318 (* 1 = 0.00137318 loss)
I0814 19:11:04.253479   613 sgd_solver.cpp:136] Iteration 46000, lr = 0.0028125, m = 0.9
I0814 19:11:05.886731   613 solver.cpp:312] Iteration 46100 (61.2281 iter/s, 1.63324s/100 iter), loss = 0.000649925
I0814 19:11:05.886756   613 solver.cpp:334]     Train net output #0: loss = 0.00064973 (* 1 = 0.00064973 loss)
I0814 19:11:05.886762   613 sgd_solver.cpp:136] Iteration 46100, lr = 0.00279688, m = 0.9
I0814 19:11:07.521942   613 solver.cpp:312] Iteration 46200 (61.1561 iter/s, 1.63516s/100 iter), loss = 0.00113563
I0814 19:11:07.521987   613 solver.cpp:334]     Train net output #0: loss = 0.00113543 (* 1 = 0.00113543 loss)
I0814 19:11:07.522001   613 sgd_solver.cpp:136] Iteration 46200, lr = 0.00278125, m = 0.9
I0814 19:11:09.146766   613 solver.cpp:312] Iteration 46300 (61.547 iter/s, 1.62477s/100 iter), loss = 0.000672932
I0814 19:11:09.146814   613 solver.cpp:334]     Train net output #0: loss = 0.000672736 (* 1 = 0.000672736 loss)
I0814 19:11:09.146827   613 sgd_solver.cpp:136] Iteration 46300, lr = 0.00276563, m = 0.9
I0814 19:11:10.760692   613 solver.cpp:312] Iteration 46400 (61.9627 iter/s, 1.61387s/100 iter), loss = 0.000989048
I0814 19:11:10.760720   613 solver.cpp:334]     Train net output #0: loss = 0.000988852 (* 1 = 0.000988852 loss)
I0814 19:11:10.760725   613 sgd_solver.cpp:136] Iteration 46400, lr = 0.00275, m = 0.9
I0814 19:11:12.400082   613 solver.cpp:312] Iteration 46500 (61.0003 iter/s, 1.63934s/100 iter), loss = 0.000460505
I0814 19:11:12.400108   613 solver.cpp:334]     Train net output #0: loss = 0.00046031 (* 1 = 0.00046031 loss)
I0814 19:11:12.400115   613 sgd_solver.cpp:136] Iteration 46500, lr = 0.00273437, m = 0.9
I0814 19:11:14.012054   613 solver.cpp:312] Iteration 46600 (62.0378 iter/s, 1.61192s/100 iter), loss = 0.000382233
I0814 19:11:14.012079   613 solver.cpp:334]     Train net output #0: loss = 0.000382038 (* 1 = 0.000382038 loss)
I0814 19:11:14.012084   613 sgd_solver.cpp:136] Iteration 46600, lr = 0.00271875, m = 0.9
I0814 19:11:15.655050   613 solver.cpp:312] Iteration 46700 (60.8664 iter/s, 1.64294s/100 iter), loss = 0.00150081
I0814 19:11:15.655099   613 solver.cpp:334]     Train net output #0: loss = 0.00150062 (* 1 = 0.00150062 loss)
I0814 19:11:15.655112   613 sgd_solver.cpp:136] Iteration 46700, lr = 0.00270312, m = 0.9
I0814 19:11:17.258934   613 solver.cpp:312] Iteration 46800 (62.3506 iter/s, 1.60383s/100 iter), loss = 0.000535131
I0814 19:11:17.259011   613 solver.cpp:334]     Train net output #0: loss = 0.000534936 (* 1 = 0.000534936 loss)
I0814 19:11:17.259018   613 sgd_solver.cpp:136] Iteration 46800, lr = 0.0026875, m = 0.9
I0814 19:11:18.879930   613 solver.cpp:312] Iteration 46900 (61.6924 iter/s, 1.62095s/100 iter), loss = 0.000372487
I0814 19:11:18.879997   613 solver.cpp:334]     Train net output #0: loss = 0.000372292 (* 1 = 0.000372292 loss)
I0814 19:11:18.880018   613 sgd_solver.cpp:136] Iteration 46900, lr = 0.00267187, m = 0.9
I0814 19:11:20.479991   613 solver.cpp:509] Iteration 47000, Testing net (#0)
I0814 19:11:21.295418   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.915589
I0814 19:11:21.295434   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.995
I0814 19:11:21.295441   613 solver.cpp:594]     Test net output #2: loss = 0.322146 (* 1 = 0.322146 loss)
I0814 19:11:21.295460   613 solver.cpp:264] [MultiGPU] Tests completed in 0.815446s
I0814 19:11:21.311031   613 solver.cpp:312] Iteration 47000 (41.1348 iter/s, 2.43103s/100 iter), loss = 0.00237561
I0814 19:11:21.311048   613 solver.cpp:334]     Train net output #0: loss = 0.00237542 (* 1 = 0.00237542 loss)
I0814 19:11:21.311054   613 sgd_solver.cpp:136] Iteration 47000, lr = 0.00265625, m = 0.9
I0814 19:11:22.960857   613 solver.cpp:312] Iteration 47100 (60.6145 iter/s, 1.64977s/100 iter), loss = 0.00282767
I0814 19:11:22.960886   613 solver.cpp:334]     Train net output #0: loss = 0.00282748 (* 1 = 0.00282748 loss)
I0814 19:11:22.960891   613 sgd_solver.cpp:136] Iteration 47100, lr = 0.00264063, m = 0.9
I0814 19:11:24.595844   613 solver.cpp:312] Iteration 47200 (61.1644 iter/s, 1.63494s/100 iter), loss = 0.000968134
I0814 19:11:24.595906   613 solver.cpp:334]     Train net output #0: loss = 0.00096794 (* 1 = 0.00096794 loss)
I0814 19:11:24.595932   613 sgd_solver.cpp:136] Iteration 47200, lr = 0.002625, m = 0.9
I0814 19:11:26.220190   613 solver.cpp:312] Iteration 47300 (61.5653 iter/s, 1.62429s/100 iter), loss = 0.000658779
I0814 19:11:26.220290   613 solver.cpp:334]     Train net output #0: loss = 0.000658586 (* 1 = 0.000658586 loss)
I0814 19:11:26.220297   613 sgd_solver.cpp:136] Iteration 47300, lr = 0.00260938, m = 0.9
I0814 19:11:27.822966   613 solver.cpp:312] Iteration 47400 (62.3936 iter/s, 1.60273s/100 iter), loss = 0.000510129
I0814 19:11:27.823030   613 solver.cpp:334]     Train net output #0: loss = 0.000509935 (* 1 = 0.000509935 loss)
I0814 19:11:27.823050   613 sgd_solver.cpp:136] Iteration 47400, lr = 0.00259375, m = 0.9
I0814 19:11:29.434669   613 solver.cpp:312] Iteration 47500 (62.0481 iter/s, 1.61165s/100 iter), loss = 0.0011101
I0814 19:11:29.434728   613 solver.cpp:334]     Train net output #0: loss = 0.0011099 (* 1 = 0.0011099 loss)
I0814 19:11:29.434746   613 sgd_solver.cpp:136] Iteration 47500, lr = 0.00257812, m = 0.9
I0814 19:11:31.058871   613 solver.cpp:312] Iteration 47600 (61.5708 iter/s, 1.62415s/100 iter), loss = 0.0002729
I0814 19:11:31.058894   613 solver.cpp:334]     Train net output #0: loss = 0.000272705 (* 1 = 0.000272705 loss)
I0814 19:11:31.058900   613 sgd_solver.cpp:136] Iteration 47600, lr = 0.0025625, m = 0.9
I0814 19:11:32.730572   613 solver.cpp:312] Iteration 47700 (59.8212 iter/s, 1.67165s/100 iter), loss = 0.00322666
I0814 19:11:32.730597   613 solver.cpp:334]     Train net output #0: loss = 0.00322647 (* 1 = 0.00322647 loss)
I0814 19:11:32.730603   613 sgd_solver.cpp:136] Iteration 47700, lr = 0.00254687, m = 0.9
I0814 19:11:34.367100   613 solver.cpp:312] Iteration 47800 (61.1068 iter/s, 1.63648s/100 iter), loss = 0.00155126
I0814 19:11:34.367126   613 solver.cpp:334]     Train net output #0: loss = 0.00155107 (* 1 = 0.00155107 loss)
I0814 19:11:34.367131   613 sgd_solver.cpp:136] Iteration 47800, lr = 0.00253125, m = 0.9
I0814 19:11:36.015431   613 solver.cpp:312] Iteration 47900 (60.6694 iter/s, 1.64828s/100 iter), loss = 0.000147609
I0814 19:11:36.015458   613 solver.cpp:334]     Train net output #0: loss = 0.000147414 (* 1 = 0.000147414 loss)
I0814 19:11:36.015465   613 sgd_solver.cpp:136] Iteration 47900, lr = 0.00251562, m = 0.9
I0814 19:11:37.589439   613 solver.cpp:509] Iteration 48000, Testing net (#0)
I0814 19:11:37.620172   611 data_reader.cpp:288] Starting prefetch of epoch 6
I0814 19:11:38.407500   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.911472
I0814 19:11:38.407516   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.995
I0814 19:11:38.407522   613 solver.cpp:594]     Test net output #2: loss = 0.321733 (* 1 = 0.321733 loss)
I0814 19:11:38.407536   613 solver.cpp:264] [MultiGPU] Tests completed in 0.818075s
I0814 19:11:38.423218   613 solver.cpp:312] Iteration 48000 (41.5331 iter/s, 2.40772s/100 iter), loss = 0.00145816
I0814 19:11:38.423236   613 solver.cpp:334]     Train net output #0: loss = 0.00145796 (* 1 = 0.00145796 loss)
I0814 19:11:38.423243   613 sgd_solver.cpp:136] Iteration 48000, lr = 0.0025, m = 0.9
I0814 19:11:40.034956   613 solver.cpp:312] Iteration 48100 (62.0468 iter/s, 1.61169s/100 iter), loss = 0.00205142
I0814 19:11:40.034978   613 solver.cpp:334]     Train net output #0: loss = 0.00205123 (* 1 = 0.00205123 loss)
I0814 19:11:40.034982   613 sgd_solver.cpp:136] Iteration 48100, lr = 0.00248438, m = 0.9
I0814 19:11:41.644170   613 solver.cpp:312] Iteration 48200 (62.1442 iter/s, 1.60916s/100 iter), loss = 0.00149214
I0814 19:11:41.644193   613 solver.cpp:334]     Train net output #0: loss = 0.00149194 (* 1 = 0.00149194 loss)
I0814 19:11:41.644199   613 sgd_solver.cpp:136] Iteration 48200, lr = 0.00246875, m = 0.9
I0814 19:11:43.219826   613 solver.cpp:312] Iteration 48300 (63.4676 iter/s, 1.57561s/100 iter), loss = 0.00283488
I0814 19:11:43.219849   613 solver.cpp:334]     Train net output #0: loss = 0.00283469 (* 1 = 0.00283469 loss)
I0814 19:11:43.219854   613 sgd_solver.cpp:136] Iteration 48300, lr = 0.00245313, m = 0.9
I0814 19:11:44.836551   613 solver.cpp:312] Iteration 48400 (61.8554 iter/s, 1.61667s/100 iter), loss = 0.000683112
I0814 19:11:44.836603   613 solver.cpp:334]     Train net output #0: loss = 0.000682918 (* 1 = 0.000682918 loss)
I0814 19:11:44.836618   613 sgd_solver.cpp:136] Iteration 48400, lr = 0.0024375, m = 0.9
I0814 19:11:46.491102   613 solver.cpp:312] Iteration 48500 (60.4412 iter/s, 1.6545s/100 iter), loss = 0.00055069
I0814 19:11:46.491150   613 solver.cpp:334]     Train net output #0: loss = 0.000550496 (* 1 = 0.000550496 loss)
I0814 19:11:46.491163   613 sgd_solver.cpp:136] Iteration 48500, lr = 0.00242188, m = 0.9
I0814 19:11:48.118222   613 solver.cpp:312] Iteration 48600 (61.4604 iter/s, 1.62707s/100 iter), loss = 0.00152892
I0814 19:11:48.118333   613 solver.cpp:334]     Train net output #0: loss = 0.00152872 (* 1 = 0.00152872 loss)
I0814 19:11:48.118351   613 sgd_solver.cpp:136] Iteration 48600, lr = 0.00240625, m = 0.9
I0814 19:11:49.711868   613 solver.cpp:312] Iteration 48700 (62.7513 iter/s, 1.59359s/100 iter), loss = 0.000505909
I0814 19:11:49.711930   613 solver.cpp:334]     Train net output #0: loss = 0.000505713 (* 1 = 0.000505713 loss)
I0814 19:11:49.711949   613 sgd_solver.cpp:136] Iteration 48700, lr = 0.00239062, m = 0.9
I0814 19:11:51.338914   613 solver.cpp:312] Iteration 48800 (61.4629 iter/s, 1.627s/100 iter), loss = 0.000574905
I0814 19:11:51.338938   613 solver.cpp:334]     Train net output #0: loss = 0.00057471 (* 1 = 0.00057471 loss)
I0814 19:11:51.338943   613 sgd_solver.cpp:136] Iteration 48800, lr = 0.002375, m = 0.9
I0814 19:11:52.971025   613 solver.cpp:312] Iteration 48900 (61.2723 iter/s, 1.63206s/100 iter), loss = 0.000342894
I0814 19:11:52.971089   613 solver.cpp:334]     Train net output #0: loss = 0.000342698 (* 1 = 0.000342698 loss)
I0814 19:11:52.971118   613 sgd_solver.cpp:136] Iteration 48900, lr = 0.00235937, m = 0.9
I0814 19:11:54.545794   613 solver.cpp:509] Iteration 49000, Testing net (#0)
I0814 19:11:55.359479   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.916177
I0814 19:11:55.359498   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.994412
I0814 19:11:55.359503   613 solver.cpp:594]     Test net output #2: loss = 0.314725 (* 1 = 0.314725 loss)
I0814 19:11:55.359519   613 solver.cpp:264] [MultiGPU] Tests completed in 0.813701s
I0814 19:11:55.375043   613 solver.cpp:312] Iteration 49000 (41.5982 iter/s, 2.40395s/100 iter), loss = 0.00297777
I0814 19:11:55.375075   613 solver.cpp:334]     Train net output #0: loss = 0.00297758 (* 1 = 0.00297758 loss)
I0814 19:11:55.375087   613 sgd_solver.cpp:136] Iteration 49000, lr = 0.00234375, m = 0.9
I0814 19:11:56.987402   613 solver.cpp:312] Iteration 49100 (62.0229 iter/s, 1.61231s/100 iter), loss = 0.00277521
I0814 19:11:56.987428   613 solver.cpp:334]     Train net output #0: loss = 0.00277502 (* 1 = 0.00277502 loss)
I0814 19:11:56.987433   613 sgd_solver.cpp:136] Iteration 49100, lr = 0.00232813, m = 0.9
I0814 19:11:58.590071   613 solver.cpp:312] Iteration 49200 (62.398 iter/s, 1.60262s/100 iter), loss = 0.00125179
I0814 19:11:58.590140   613 solver.cpp:334]     Train net output #0: loss = 0.00125159 (* 1 = 0.00125159 loss)
I0814 19:11:58.590162   613 sgd_solver.cpp:136] Iteration 49200, lr = 0.0023125, m = 0.9
I0814 19:12:00.221596   613 solver.cpp:312] Iteration 49300 (61.2942 iter/s, 1.63147s/100 iter), loss = 0.000314942
I0814 19:12:00.221622   613 solver.cpp:334]     Train net output #0: loss = 0.000314747 (* 1 = 0.000314747 loss)
I0814 19:12:00.221627   613 sgd_solver.cpp:136] Iteration 49300, lr = 0.00229687, m = 0.9
I0814 19:12:01.857727   613 solver.cpp:312] Iteration 49400 (61.1219 iter/s, 1.63607s/100 iter), loss = 0.000704738
I0814 19:12:01.857775   613 solver.cpp:334]     Train net output #0: loss = 0.000704543 (* 1 = 0.000704543 loss)
I0814 19:12:01.857789   613 sgd_solver.cpp:136] Iteration 49400, lr = 0.00228125, m = 0.9
I0814 19:12:03.521880   613 solver.cpp:312] Iteration 49500 (60.0924 iter/s, 1.6641s/100 iter), loss = 0.000926789
I0814 19:12:03.521930   613 solver.cpp:334]     Train net output #0: loss = 0.000926593 (* 1 = 0.000926593 loss)
I0814 19:12:03.521944   613 sgd_solver.cpp:136] Iteration 49500, lr = 0.00226562, m = 0.9
I0814 19:12:05.153570   613 solver.cpp:312] Iteration 49600 (61.2881 iter/s, 1.63164s/100 iter), loss = 0.00110798
I0814 19:12:05.153614   613 solver.cpp:334]     Train net output #0: loss = 0.00110779 (* 1 = 0.00110779 loss)
I0814 19:12:05.153720   613 sgd_solver.cpp:136] Iteration 49600, lr = 0.00225, m = 0.9
I0814 19:12:06.749265   613 solver.cpp:312] Iteration 49700 (62.6707 iter/s, 1.59564s/100 iter), loss = 0.000155018
I0814 19:12:06.749325   613 solver.cpp:334]     Train net output #0: loss = 0.000154823 (* 1 = 0.000154823 loss)
I0814 19:12:06.749342   613 sgd_solver.cpp:136] Iteration 49700, lr = 0.00223437, m = 0.9
I0814 19:12:08.407992   613 solver.cpp:312] Iteration 49800 (60.289 iter/s, 1.65868s/100 iter), loss = 0.000403863
I0814 19:12:08.408054   613 solver.cpp:334]     Train net output #0: loss = 0.000403669 (* 1 = 0.000403669 loss)
I0814 19:12:08.408073   613 sgd_solver.cpp:136] Iteration 49800, lr = 0.00221875, m = 0.9
I0814 19:12:10.065203   613 solver.cpp:312] Iteration 49900 (60.3442 iter/s, 1.65716s/100 iter), loss = 0.000469129
I0814 19:12:10.065230   613 solver.cpp:334]     Train net output #0: loss = 0.000468935 (* 1 = 0.000468935 loss)
I0814 19:12:10.065237   613 sgd_solver.cpp:136] Iteration 49900, lr = 0.00220312, m = 0.9
I0814 19:12:11.668686   613 solver.cpp:639] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/l1reg/cifar10_jacintonet11v2_iter_50000.caffemodel
I0814 19:12:11.676733   613 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/l1reg/cifar10_jacintonet11v2_iter_50000.solverstate
I0814 19:12:11.680392   613 solver.cpp:509] Iteration 50000, Testing net (#0)
I0814 19:12:12.484498   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.913236
I0814 19:12:12.484518   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.994706
I0814 19:12:12.484522   613 solver.cpp:594]     Test net output #2: loss = 0.336716 (* 1 = 0.336716 loss)
I0814 19:12:12.484536   613 solver.cpp:264] [MultiGPU] Tests completed in 0.804122s
I0814 19:12:12.500227   613 solver.cpp:312] Iteration 50000 (41.0686 iter/s, 2.43495s/100 iter), loss = 0.000987399
I0814 19:12:12.500247   613 solver.cpp:334]     Train net output #0: loss = 0.000987205 (* 1 = 0.000987205 loss)
I0814 19:12:12.500252   613 sgd_solver.cpp:136] Iteration 50000, lr = 0.0021875, m = 0.9
I0814 19:12:14.127074   613 solver.cpp:312] Iteration 50100 (61.4707 iter/s, 1.62679s/100 iter), loss = 0.00187994
I0814 19:12:14.127099   613 solver.cpp:334]     Train net output #0: loss = 0.00187974 (* 1 = 0.00187974 loss)
I0814 19:12:14.127104   613 sgd_solver.cpp:136] Iteration 50100, lr = 0.00217188, m = 0.9
I0814 19:12:15.711103   613 solver.cpp:312] Iteration 50200 (63.1322 iter/s, 1.58398s/100 iter), loss = 0.00256797
I0814 19:12:15.711151   613 solver.cpp:334]     Train net output #0: loss = 0.00256777 (* 1 = 0.00256777 loss)
I0814 19:12:15.711163   613 sgd_solver.cpp:136] Iteration 50200, lr = 0.00215625, m = 0.9
I0814 19:12:17.310173   613 solver.cpp:312] Iteration 50300 (62.5383 iter/s, 1.59902s/100 iter), loss = 0.000531755
I0814 19:12:17.310216   613 solver.cpp:334]     Train net output #0: loss = 0.000531559 (* 1 = 0.000531559 loss)
I0814 19:12:17.310230   613 sgd_solver.cpp:136] Iteration 50300, lr = 0.00214063, m = 0.9
I0814 19:12:19.050264   613 solver.cpp:312] Iteration 50400 (57.4701 iter/s, 1.74004s/100 iter), loss = 0.0012119
I0814 19:12:19.050374   613 solver.cpp:334]     Train net output #0: loss = 0.00121171 (* 1 = 0.00121171 loss)
I0814 19:12:19.050392   613 sgd_solver.cpp:136] Iteration 50400, lr = 0.002125, m = 0.9
I0814 19:12:20.737241   613 solver.cpp:312] Iteration 50500 (59.2794 iter/s, 1.68693s/100 iter), loss = 0.0012757
I0814 19:12:20.737293   613 solver.cpp:334]     Train net output #0: loss = 0.0012755 (* 1 = 0.0012755 loss)
I0814 19:12:20.737308   613 sgd_solver.cpp:136] Iteration 50500, lr = 0.00210937, m = 0.9
I0814 19:12:22.345952   613 solver.cpp:312] Iteration 50600 (62.1636 iter/s, 1.60866s/100 iter), loss = 0.00135308
I0814 19:12:22.345978   613 solver.cpp:334]     Train net output #0: loss = 0.00135288 (* 1 = 0.00135288 loss)
I0814 19:12:22.345981   613 sgd_solver.cpp:136] Iteration 50600, lr = 0.00209375, m = 0.9
I0814 19:12:23.978142   613 solver.cpp:312] Iteration 50700 (61.2694 iter/s, 1.63214s/100 iter), loss = 0.000444065
I0814 19:12:23.978163   613 solver.cpp:334]     Train net output #0: loss = 0.00044387 (* 1 = 0.00044387 loss)
I0814 19:12:23.978168   613 sgd_solver.cpp:136] Iteration 50700, lr = 0.00207812, m = 0.9
I0814 19:12:25.606401   613 solver.cpp:312] Iteration 50800 (61.4171 iter/s, 1.62821s/100 iter), loss = 0.000914598
I0814 19:12:25.606449   613 solver.cpp:334]     Train net output #0: loss = 0.000914403 (* 1 = 0.000914403 loss)
I0814 19:12:25.606462   613 sgd_solver.cpp:136] Iteration 50800, lr = 0.0020625, m = 0.9
I0814 19:12:27.225606   613 solver.cpp:312] Iteration 50900 (61.7606 iter/s, 1.61915s/100 iter), loss = 0.00063187
I0814 19:12:27.225653   613 solver.cpp:334]     Train net output #0: loss = 0.000631676 (* 1 = 0.000631676 loss)
I0814 19:12:27.225666   613 sgd_solver.cpp:136] Iteration 50900, lr = 0.00204687, m = 0.9
I0814 19:12:28.821693   613 solver.cpp:509] Iteration 51000, Testing net (#0)
I0814 19:12:29.636981   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.910001
I0814 19:12:29.636998   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.995
I0814 19:12:29.637003   613 solver.cpp:594]     Test net output #2: loss = 0.351211 (* 1 = 0.351211 loss)
I0814 19:12:29.637018   613 solver.cpp:264] [MultiGPU] Tests completed in 0.815303s
I0814 19:12:29.656695   613 solver.cpp:312] Iteration 51000 (41.135 iter/s, 2.43102s/100 iter), loss = 0.00157698
I0814 19:12:29.656713   613 solver.cpp:334]     Train net output #0: loss = 0.00157679 (* 1 = 0.00157679 loss)
I0814 19:12:29.656716   613 sgd_solver.cpp:136] Iteration 51000, lr = 0.00203125, m = 0.9
I0814 19:12:31.259333   613 solver.cpp:312] Iteration 51100 (62.3991 iter/s, 1.60259s/100 iter), loss = 0.000660087
I0814 19:12:31.259358   613 solver.cpp:334]     Train net output #0: loss = 0.000659892 (* 1 = 0.000659892 loss)
I0814 19:12:31.259363   613 sgd_solver.cpp:136] Iteration 51100, lr = 0.00201563, m = 0.9
I0814 19:12:32.840857   613 solver.cpp:312] Iteration 51200 (63.2321 iter/s, 1.58147s/100 iter), loss = 0.00916277
I0814 19:12:32.840901   613 solver.cpp:334]     Train net output #0: loss = 0.00916258 (* 1 = 0.00916258 loss)
I0814 19:12:32.840914   613 sgd_solver.cpp:136] Iteration 51200, lr = 0.002, m = 0.9
I0814 19:12:34.445493   613 solver.cpp:312] Iteration 51300 (62.3214 iter/s, 1.60458s/100 iter), loss = 0.00129054
I0814 19:12:34.445518   613 solver.cpp:334]     Train net output #0: loss = 0.00129035 (* 1 = 0.00129035 loss)
I0814 19:12:34.445523   613 sgd_solver.cpp:136] Iteration 51300, lr = 0.00198438, m = 0.9
I0814 19:12:36.063861   613 solver.cpp:312] Iteration 51400 (61.7925 iter/s, 1.61832s/100 iter), loss = 0.0014402
I0814 19:12:36.063927   613 solver.cpp:334]     Train net output #0: loss = 0.00144001 (* 1 = 0.00144001 loss)
I0814 19:12:36.063947   613 sgd_solver.cpp:136] Iteration 51400, lr = 0.00196875, m = 0.9
I0814 19:12:37.697497   613 solver.cpp:312] Iteration 51500 (61.2151 iter/s, 1.63358s/100 iter), loss = 0.000564373
I0814 19:12:37.697547   613 solver.cpp:334]     Train net output #0: loss = 0.000564177 (* 1 = 0.000564177 loss)
I0814 19:12:37.697561   613 sgd_solver.cpp:136] Iteration 51500, lr = 0.00195312, m = 0.9
I0814 19:12:39.288358   613 solver.cpp:312] Iteration 51600 (62.8611 iter/s, 1.59081s/100 iter), loss = 0.000885502
I0814 19:12:39.288383   613 solver.cpp:334]     Train net output #0: loss = 0.000885306 (* 1 = 0.000885306 loss)
I0814 19:12:39.288388   613 sgd_solver.cpp:136] Iteration 51600, lr = 0.0019375, m = 0.9
I0814 19:12:40.921553   613 solver.cpp:312] Iteration 51700 (61.2316 iter/s, 1.63314s/100 iter), loss = 0.000484147
I0814 19:12:40.921622   613 solver.cpp:334]     Train net output #0: loss = 0.00048395 (* 1 = 0.00048395 loss)
I0814 19:12:40.921639   613 sgd_solver.cpp:136] Iteration 51700, lr = 0.00192187, m = 0.9
I0814 19:12:42.569620   613 solver.cpp:312] Iteration 51800 (60.6791 iter/s, 1.64801s/100 iter), loss = 0.00100339
I0814 19:12:42.569665   613 solver.cpp:334]     Train net output #0: loss = 0.0010032 (* 1 = 0.0010032 loss)
I0814 19:12:42.569677   613 sgd_solver.cpp:136] Iteration 51800, lr = 0.00190625, m = 0.9
I0814 19:12:44.211886   613 solver.cpp:312] Iteration 51900 (60.8933 iter/s, 1.64222s/100 iter), loss = 0.000678729
I0814 19:12:44.211949   613 solver.cpp:334]     Train net output #0: loss = 0.000678533 (* 1 = 0.000678533 loss)
I0814 19:12:44.211969   613 sgd_solver.cpp:136] Iteration 51900, lr = 0.00189062, m = 0.9
I0814 19:12:45.817054   613 solver.cpp:509] Iteration 52000, Testing net (#0)
I0814 19:12:46.557572   611 data_reader.cpp:288] Starting prefetch of epoch 7
I0814 19:12:46.647630   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.909413
I0814 19:12:46.647650   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.996177
I0814 19:12:46.647655   613 solver.cpp:594]     Test net output #2: loss = 0.352891 (* 1 = 0.352891 loss)
I0814 19:12:46.647670   613 solver.cpp:264] [MultiGPU] Tests completed in 0.830595s
I0814 19:12:46.663411   613 solver.cpp:312] Iteration 52000 (40.7921 iter/s, 2.45145s/100 iter), loss = 0.000248034
I0814 19:12:46.663427   613 solver.cpp:334]     Train net output #0: loss = 0.000247838 (* 1 = 0.000247838 loss)
I0814 19:12:46.663434   613 sgd_solver.cpp:136] Iteration 52000, lr = 0.001875, m = 0.9
I0814 19:12:48.300037   613 solver.cpp:312] Iteration 52100 (61.1034 iter/s, 1.63657s/100 iter), loss = 0.000967355
I0814 19:12:48.300096   613 solver.cpp:334]     Train net output #0: loss = 0.000967158 (* 1 = 0.000967158 loss)
I0814 19:12:48.300112   613 sgd_solver.cpp:136] Iteration 52100, lr = 0.00185938, m = 0.9
I0814 19:12:49.882455   613 solver.cpp:312] Iteration 52200 (63.1964 iter/s, 1.58237s/100 iter), loss = 0.00126357
I0814 19:12:49.882566   613 solver.cpp:334]     Train net output #0: loss = 0.00126338 (* 1 = 0.00126338 loss)
I0814 19:12:49.882583   613 sgd_solver.cpp:136] Iteration 52200, lr = 0.00184375, m = 0.9
I0814 19:12:51.504448   613 solver.cpp:312] Iteration 52300 (61.6545 iter/s, 1.62194s/100 iter), loss = 0.00224237
I0814 19:12:51.504578   613 solver.cpp:334]     Train net output #0: loss = 0.00224218 (* 1 = 0.00224218 loss)
I0814 19:12:51.504596   613 sgd_solver.cpp:136] Iteration 52300, lr = 0.00182813, m = 0.9
I0814 19:12:53.117820   613 solver.cpp:312] Iteration 52400 (61.9839 iter/s, 1.61332s/100 iter), loss = 0.000889893
I0814 19:12:53.117889   613 solver.cpp:334]     Train net output #0: loss = 0.000889698 (* 1 = 0.000889698 loss)
I0814 19:12:53.117913   613 sgd_solver.cpp:136] Iteration 52400, lr = 0.0018125, m = 0.9
I0814 19:12:54.736692   613 solver.cpp:312] Iteration 52500 (61.7733 iter/s, 1.61882s/100 iter), loss = 0.00168973
I0814 19:12:54.736958   613 solver.cpp:334]     Train net output #0: loss = 0.00168953 (* 1 = 0.00168953 loss)
I0814 19:12:54.736964   613 sgd_solver.cpp:136] Iteration 52500, lr = 0.00179687, m = 0.9
I0814 19:12:56.325379   613 solver.cpp:312] Iteration 52600 (62.947 iter/s, 1.58864s/100 iter), loss = 0.00093692
I0814 19:12:56.325405   613 solver.cpp:334]     Train net output #0: loss = 0.000936724 (* 1 = 0.000936724 loss)
I0814 19:12:56.325412   613 sgd_solver.cpp:136] Iteration 52600, lr = 0.00178125, m = 0.9
I0814 19:12:57.965597   613 solver.cpp:312] Iteration 52700 (60.9694 iter/s, 1.64017s/100 iter), loss = 0.000245013
I0814 19:12:57.965642   613 solver.cpp:334]     Train net output #0: loss = 0.000244818 (* 1 = 0.000244818 loss)
I0814 19:12:57.965653   613 sgd_solver.cpp:136] Iteration 52700, lr = 0.00176562, m = 0.9
I0814 19:12:59.624940   613 solver.cpp:312] Iteration 52800 (60.2667 iter/s, 1.65929s/100 iter), loss = 0.000550303
I0814 19:12:59.625011   613 solver.cpp:334]     Train net output #0: loss = 0.000550109 (* 1 = 0.000550109 loss)
I0814 19:12:59.625038   613 sgd_solver.cpp:136] Iteration 52800, lr = 0.00175, m = 0.9
I0814 19:13:01.254320   613 solver.cpp:312] Iteration 52900 (61.3751 iter/s, 1.62933s/100 iter), loss = 0.00138242
I0814 19:13:01.254384   613 solver.cpp:334]     Train net output #0: loss = 0.00138223 (* 1 = 0.00138223 loss)
I0814 19:13:01.254405   613 sgd_solver.cpp:136] Iteration 52900, lr = 0.00173437, m = 0.9
I0814 19:13:02.842218   613 solver.cpp:509] Iteration 53000, Testing net (#0)
I0814 19:13:03.676280   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.912942
I0814 19:13:03.676301   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.995588
I0814 19:13:03.676304   613 solver.cpp:594]     Test net output #2: loss = 0.33903 (* 1 = 0.33903 loss)
I0814 19:13:03.676319   613 solver.cpp:264] [MultiGPU] Tests completed in 0.83408s
I0814 19:13:03.692448   613 solver.cpp:312] Iteration 53000 (41.0162 iter/s, 2.43806s/100 iter), loss = 0.000588241
I0814 19:13:03.692469   613 solver.cpp:334]     Train net output #0: loss = 0.000588047 (* 1 = 0.000588047 loss)
I0814 19:13:03.692477   613 sgd_solver.cpp:136] Iteration 53000, lr = 0.00171875, m = 0.9
I0814 19:13:05.296648   613 solver.cpp:312] Iteration 53100 (62.3383 iter/s, 1.60415s/100 iter), loss = 0.00102272
I0814 19:13:05.296699   613 solver.cpp:334]     Train net output #0: loss = 0.00102252 (* 1 = 0.00102252 loss)
I0814 19:13:05.296707   613 sgd_solver.cpp:136] Iteration 53100, lr = 0.00170313, m = 0.9
I0814 19:13:06.933173   613 solver.cpp:312] Iteration 53200 (61.1072 iter/s, 1.63647s/100 iter), loss = 0.000212771
I0814 19:13:06.933198   613 solver.cpp:334]     Train net output #0: loss = 0.000212576 (* 1 = 0.000212576 loss)
I0814 19:13:06.933203   613 sgd_solver.cpp:136] Iteration 53200, lr = 0.0016875, m = 0.9
I0814 19:13:08.547691   613 solver.cpp:312] Iteration 53300 (61.9398 iter/s, 1.61447s/100 iter), loss = 0.000728705
I0814 19:13:08.547745   613 solver.cpp:334]     Train net output #0: loss = 0.000728511 (* 1 = 0.000728511 loss)
I0814 19:13:08.547760   613 sgd_solver.cpp:136] Iteration 53300, lr = 0.00167188, m = 0.9
I0814 19:13:10.169041   613 solver.cpp:312] Iteration 53400 (61.6789 iter/s, 1.6213s/100 iter), loss = 0.000756696
I0814 19:13:10.169087   613 solver.cpp:334]     Train net output #0: loss = 0.000756501 (* 1 = 0.000756501 loss)
I0814 19:13:10.169100   613 sgd_solver.cpp:136] Iteration 53400, lr = 0.00165625, m = 0.9
I0814 19:13:11.781137   613 solver.cpp:312] Iteration 53500 (62.033 iter/s, 1.61205s/100 iter), loss = 0.00268828
I0814 19:13:11.781203   613 solver.cpp:334]     Train net output #0: loss = 0.00268809 (* 1 = 0.00268809 loss)
I0814 19:13:11.781224   613 sgd_solver.cpp:136] Iteration 53500, lr = 0.00164062, m = 0.9
I0814 19:13:13.399871   613 solver.cpp:312] Iteration 53600 (61.7786 iter/s, 1.61868s/100 iter), loss = 0.000763351
I0814 19:13:13.399894   613 solver.cpp:334]     Train net output #0: loss = 0.000763155 (* 1 = 0.000763155 loss)
I0814 19:13:13.399899   613 sgd_solver.cpp:136] Iteration 53600, lr = 0.001625, m = 0.9
I0814 19:13:15.052706   613 solver.cpp:312] Iteration 53700 (60.5041 iter/s, 1.65278s/100 iter), loss = 0.000423735
I0814 19:13:15.052729   613 solver.cpp:334]     Train net output #0: loss = 0.000423539 (* 1 = 0.000423539 loss)
I0814 19:13:15.052736   613 sgd_solver.cpp:136] Iteration 53700, lr = 0.00160937, m = 0.9
I0814 19:13:16.672395   613 solver.cpp:312] Iteration 53800 (61.742 iter/s, 1.61964s/100 iter), loss = 0.000823352
I0814 19:13:16.672441   613 solver.cpp:334]     Train net output #0: loss = 0.000823156 (* 1 = 0.000823156 loss)
I0814 19:13:16.672452   613 sgd_solver.cpp:136] Iteration 53800, lr = 0.00159375, m = 0.9
I0814 19:13:18.287758   613 solver.cpp:312] Iteration 53900 (61.9076 iter/s, 1.61531s/100 iter), loss = 0.00432964
I0814 19:13:18.287786   613 solver.cpp:334]     Train net output #0: loss = 0.00432945 (* 1 = 0.00432945 loss)
I0814 19:13:18.287792   613 sgd_solver.cpp:136] Iteration 53900, lr = 0.00157812, m = 0.9
I0814 19:13:19.900918   613 solver.cpp:509] Iteration 54000, Testing net (#0)
I0814 19:13:20.184164   621 blocking_queue.cpp:40] Waiting for datum
I0814 19:13:20.723284   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.917648
I0814 19:13:20.723304   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.996765
I0814 19:13:20.723309   613 solver.cpp:594]     Test net output #2: loss = 0.30761 (* 1 = 0.30761 loss)
I0814 19:13:20.723325   613 solver.cpp:264] [MultiGPU] Tests completed in 0.822384s
I0814 19:13:20.740979   613 solver.cpp:312] Iteration 54000 (40.7639 iter/s, 2.45315s/100 iter), loss = 0.000643323
I0814 19:13:20.740995   613 solver.cpp:334]     Train net output #0: loss = 0.000643129 (* 1 = 0.000643129 loss)
I0814 19:13:20.741001   613 sgd_solver.cpp:136] Iteration 54000, lr = 0.0015625, m = 0.9
I0814 19:13:22.328306   613 solver.cpp:312] Iteration 54100 (63.0011 iter/s, 1.58727s/100 iter), loss = 0.000745889
I0814 19:13:22.328368   613 solver.cpp:334]     Train net output #0: loss = 0.000745695 (* 1 = 0.000745695 loss)
I0814 19:13:22.328385   613 sgd_solver.cpp:136] Iteration 54100, lr = 0.00154688, m = 0.9
I0814 19:13:23.977360   613 solver.cpp:312] Iteration 54200 (60.6427 iter/s, 1.649s/100 iter), loss = 0.000538481
I0814 19:13:23.977385   613 solver.cpp:334]     Train net output #0: loss = 0.000538287 (* 1 = 0.000538287 loss)
I0814 19:13:23.977391   613 sgd_solver.cpp:136] Iteration 54200, lr = 0.00153125, m = 0.9
I0814 19:13:25.609180   613 solver.cpp:312] Iteration 54300 (61.2833 iter/s, 1.63177s/100 iter), loss = 0.000933999
I0814 19:13:25.609207   613 solver.cpp:334]     Train net output #0: loss = 0.000933804 (* 1 = 0.000933804 loss)
I0814 19:13:25.609215   613 sgd_solver.cpp:136] Iteration 54300, lr = 0.00151563, m = 0.9
I0814 19:13:27.247759   613 solver.cpp:312] Iteration 54400 (61.0302 iter/s, 1.63853s/100 iter), loss = 0.000624677
I0814 19:13:27.247784   613 solver.cpp:334]     Train net output #0: loss = 0.000624481 (* 1 = 0.000624481 loss)
I0814 19:13:27.247790   613 sgd_solver.cpp:136] Iteration 54400, lr = 0.0015, m = 0.9
I0814 19:13:28.852190   613 solver.cpp:312] Iteration 54500 (62.3294 iter/s, 1.60438s/100 iter), loss = 0.000566006
I0814 19:13:28.852216   613 solver.cpp:334]     Train net output #0: loss = 0.000565811 (* 1 = 0.000565811 loss)
I0814 19:13:28.852222   613 sgd_solver.cpp:136] Iteration 54500, lr = 0.00148437, m = 0.9
I0814 19:13:30.460671   613 solver.cpp:312] Iteration 54600 (62.1723 iter/s, 1.60843s/100 iter), loss = 0.00056443
I0814 19:13:30.460697   613 solver.cpp:334]     Train net output #0: loss = 0.000564235 (* 1 = 0.000564235 loss)
I0814 19:13:30.460705   613 sgd_solver.cpp:136] Iteration 54600, lr = 0.00146875, m = 0.9
I0814 19:13:32.068125   613 solver.cpp:312] Iteration 54700 (62.2122 iter/s, 1.6074s/100 iter), loss = 0.00651327
I0814 19:13:32.068156   613 solver.cpp:334]     Train net output #0: loss = 0.00651307 (* 1 = 0.00651307 loss)
I0814 19:13:32.068162   613 sgd_solver.cpp:136] Iteration 54700, lr = 0.00145312, m = 0.9
I0814 19:13:33.709308   613 solver.cpp:312] Iteration 54800 (60.9336 iter/s, 1.64113s/100 iter), loss = 0.00120459
I0814 19:13:33.709333   613 solver.cpp:334]     Train net output #0: loss = 0.0012044 (* 1 = 0.0012044 loss)
I0814 19:13:33.709339   613 sgd_solver.cpp:136] Iteration 54800, lr = 0.0014375, m = 0.9
I0814 19:13:35.283931   613 solver.cpp:312] Iteration 54900 (63.5092 iter/s, 1.57457s/100 iter), loss = 0.000286021
I0814 19:13:35.283958   613 solver.cpp:334]     Train net output #0: loss = 0.000285827 (* 1 = 0.000285827 loss)
I0814 19:13:35.283965   613 sgd_solver.cpp:136] Iteration 54900, lr = 0.00142187, m = 0.9
I0814 19:13:36.910495   613 solver.cpp:509] Iteration 55000, Testing net (#0)
I0814 19:13:37.727433   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.92353
I0814 19:13:37.727453   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.997941
I0814 19:13:37.727459   613 solver.cpp:594]     Test net output #2: loss = 0.283337 (* 1 = 0.283337 loss)
I0814 19:13:37.727478   613 solver.cpp:264] [MultiGPU] Tests completed in 0.81696s
I0814 19:13:37.743332   613 solver.cpp:312] Iteration 55000 (40.6615 iter/s, 2.45933s/100 iter), loss = 0.00130107
I0814 19:13:37.743360   613 solver.cpp:334]     Train net output #0: loss = 0.00130088 (* 1 = 0.00130088 loss)
I0814 19:13:37.743366   613 sgd_solver.cpp:136] Iteration 55000, lr = 0.00140625, m = 0.9
I0814 19:13:39.406357   613 solver.cpp:312] Iteration 55100 (60.1334 iter/s, 1.66297s/100 iter), loss = 0.00069349
I0814 19:13:39.406502   613 solver.cpp:334]     Train net output #0: loss = 0.000693295 (* 1 = 0.000693295 loss)
I0814 19:13:39.406577   613 sgd_solver.cpp:136] Iteration 55100, lr = 0.00139063, m = 0.9
I0814 19:13:41.045289   613 solver.cpp:312] Iteration 55200 (61.0172 iter/s, 1.63888s/100 iter), loss = 0.00163812
I0814 19:13:41.045310   613 solver.cpp:334]     Train net output #0: loss = 0.00163792 (* 1 = 0.00163792 loss)
I0814 19:13:41.045315   613 sgd_solver.cpp:136] Iteration 55200, lr = 0.001375, m = 0.9
I0814 19:13:42.660694   613 solver.cpp:312] Iteration 55300 (61.9059 iter/s, 1.61536s/100 iter), loss = 0.00109261
I0814 19:13:42.660758   613 solver.cpp:334]     Train net output #0: loss = 0.00109241 (* 1 = 0.00109241 loss)
I0814 19:13:42.660776   613 sgd_solver.cpp:136] Iteration 55300, lr = 0.00135938, m = 0.9
I0814 19:13:44.268653   613 solver.cpp:312] Iteration 55400 (62.1926 iter/s, 1.60791s/100 iter), loss = 0.000434343
I0814 19:13:44.268730   613 solver.cpp:334]     Train net output #0: loss = 0.000434149 (* 1 = 0.000434149 loss)
I0814 19:13:44.268756   613 sgd_solver.cpp:136] Iteration 55400, lr = 0.00134375, m = 0.9
I0814 19:13:45.876451   613 solver.cpp:312] Iteration 55500 (62.1988 iter/s, 1.60775s/100 iter), loss = 0.000768183
I0814 19:13:45.876477   613 solver.cpp:334]     Train net output #0: loss = 0.000767989 (* 1 = 0.000767989 loss)
I0814 19:13:45.876482   613 sgd_solver.cpp:136] Iteration 55500, lr = 0.00132813, m = 0.9
I0814 19:13:47.490258   613 solver.cpp:312] Iteration 55600 (61.9671 iter/s, 1.61376s/100 iter), loss = 0.00075796
I0814 19:13:47.490319   613 solver.cpp:334]     Train net output #0: loss = 0.000757766 (* 1 = 0.000757766 loss)
I0814 19:13:47.490339   613 sgd_solver.cpp:136] Iteration 55600, lr = 0.0013125, m = 0.9
I0814 19:13:49.112522   613 solver.cpp:312] Iteration 55700 (61.6442 iter/s, 1.62221s/100 iter), loss = 0.000269589
I0814 19:13:49.112545   613 solver.cpp:334]     Train net output #0: loss = 0.000269396 (* 1 = 0.000269396 loss)
I0814 19:13:49.112548   613 sgd_solver.cpp:136] Iteration 55700, lr = 0.00129687, m = 0.9
I0814 19:13:50.708226   613 solver.cpp:312] Iteration 55800 (62.6702 iter/s, 1.59566s/100 iter), loss = 0.000683465
I0814 19:13:50.708353   613 solver.cpp:334]     Train net output #0: loss = 0.000683272 (* 1 = 0.000683272 loss)
I0814 19:13:50.708372   613 sgd_solver.cpp:136] Iteration 55800, lr = 0.00128125, m = 0.9
I0814 19:13:52.347543   613 solver.cpp:312] Iteration 55900 (61.003 iter/s, 1.63926s/100 iter), loss = 0.00142602
I0814 19:13:52.347568   613 solver.cpp:334]     Train net output #0: loss = 0.00142582 (* 1 = 0.00142582 loss)
I0814 19:13:52.347574   613 sgd_solver.cpp:136] Iteration 55900, lr = 0.00126562, m = 0.9
I0814 19:13:53.927754   613 solver.cpp:509] Iteration 56000, Testing net (#0)
I0814 19:13:54.739979   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.928824
I0814 19:13:54.739997   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.997353
I0814 19:13:54.740005   613 solver.cpp:594]     Test net output #2: loss = 0.272097 (* 1 = 0.272097 loss)
I0814 19:13:54.740021   613 solver.cpp:264] [MultiGPU] Tests completed in 0.812245s
I0814 19:13:54.755614   613 solver.cpp:312] Iteration 56000 (41.5282 iter/s, 2.408s/100 iter), loss = 0.000504016
I0814 19:13:54.755630   613 solver.cpp:334]     Train net output #0: loss = 0.000503824 (* 1 = 0.000503824 loss)
I0814 19:13:54.755635   613 sgd_solver.cpp:136] Iteration 56000, lr = 0.00125, m = 0.9
I0814 19:13:55.691763   592 data_reader.cpp:288] Starting prefetch of epoch 7
I0814 19:13:56.368233   613 solver.cpp:312] Iteration 56100 (62.0129 iter/s, 1.61257s/100 iter), loss = 0.00139256
I0814 19:13:56.368288   613 solver.cpp:334]     Train net output #0: loss = 0.00139237 (* 1 = 0.00139237 loss)
I0814 19:13:56.368301   613 sgd_solver.cpp:136] Iteration 56100, lr = 0.00123438, m = 0.9
I0814 19:13:58.015171   613 solver.cpp:312] Iteration 56200 (60.7206 iter/s, 1.64689s/100 iter), loss = 0.00132154
I0814 19:13:58.015219   613 solver.cpp:334]     Train net output #0: loss = 0.00132135 (* 1 = 0.00132135 loss)
I0814 19:13:58.015234   613 sgd_solver.cpp:136] Iteration 56200, lr = 0.00121875, m = 0.9
I0814 19:13:59.639606   613 solver.cpp:312] Iteration 56300 (61.5617 iter/s, 1.62439s/100 iter), loss = 0.00138546
I0814 19:13:59.639631   613 solver.cpp:334]     Train net output #0: loss = 0.00138527 (* 1 = 0.00138527 loss)
I0814 19:13:59.639636   613 sgd_solver.cpp:136] Iteration 56300, lr = 0.00120313, m = 0.9
I0814 19:14:01.250710   613 solver.cpp:312] Iteration 56400 (62.0712 iter/s, 1.61105s/100 iter), loss = 0.00222113
I0814 19:14:01.250851   613 solver.cpp:334]     Train net output #0: loss = 0.00222094 (* 1 = 0.00222094 loss)
I0814 19:14:01.250871   613 sgd_solver.cpp:136] Iteration 56400, lr = 0.0011875, m = 0.9
I0814 19:14:02.852708   613 solver.cpp:312] Iteration 56500 (62.424 iter/s, 1.60195s/100 iter), loss = 0.00057469
I0814 19:14:02.852733   613 solver.cpp:334]     Train net output #0: loss = 0.000574497 (* 1 = 0.000574497 loss)
I0814 19:14:02.852740   613 sgd_solver.cpp:136] Iteration 56500, lr = 0.00117187, m = 0.9
I0814 19:14:04.492292   613 solver.cpp:312] Iteration 56600 (60.9928 iter/s, 1.63954s/100 iter), loss = 0.000937809
I0814 19:14:04.492316   613 solver.cpp:334]     Train net output #0: loss = 0.000937617 (* 1 = 0.000937617 loss)
I0814 19:14:04.492321   613 sgd_solver.cpp:136] Iteration 56600, lr = 0.00115625, m = 0.9
I0814 19:14:06.135954   613 solver.cpp:312] Iteration 56700 (60.8416 iter/s, 1.64361s/100 iter), loss = 0.000194073
I0814 19:14:06.135982   613 solver.cpp:334]     Train net output #0: loss = 0.00019388 (* 1 = 0.00019388 loss)
I0814 19:14:06.135987   613 sgd_solver.cpp:136] Iteration 56700, lr = 0.00114062, m = 0.9
I0814 19:14:07.740455   613 solver.cpp:312] Iteration 56800 (62.3266 iter/s, 1.60445s/100 iter), loss = 0.000555627
I0814 19:14:07.740479   613 solver.cpp:334]     Train net output #0: loss = 0.000555434 (* 1 = 0.000555434 loss)
I0814 19:14:07.740485   613 sgd_solver.cpp:136] Iteration 56800, lr = 0.001125, m = 0.9
I0814 19:14:09.362591   613 solver.cpp:312] Iteration 56900 (61.649 iter/s, 1.62209s/100 iter), loss = 0.00085945
I0814 19:14:09.362653   613 solver.cpp:334]     Train net output #0: loss = 0.000859258 (* 1 = 0.000859258 loss)
I0814 19:14:09.362685   613 sgd_solver.cpp:136] Iteration 56900, lr = 0.00110937, m = 0.9
I0814 19:14:10.985059   613 solver.cpp:509] Iteration 57000, Testing net (#0)
I0814 19:14:11.819135   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.926766
I0814 19:14:11.819154   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.996765
I0814 19:14:11.819159   613 solver.cpp:594]     Test net output #2: loss = 0.287946 (* 1 = 0.287946 loss)
I0814 19:14:11.819173   613 solver.cpp:264] [MultiGPU] Tests completed in 0.834093s
I0814 19:14:11.836732   613 solver.cpp:312] Iteration 57000 (40.4192 iter/s, 2.47407s/100 iter), loss = 0.00205957
I0814 19:14:11.836751   613 solver.cpp:334]     Train net output #0: loss = 0.00205938 (* 1 = 0.00205938 loss)
I0814 19:14:11.836757   613 sgd_solver.cpp:136] Iteration 57000, lr = 0.00109375, m = 0.9
I0814 19:14:13.467335   613 solver.cpp:312] Iteration 57100 (61.3291 iter/s, 1.63055s/100 iter), loss = 0.00130063
I0814 19:14:13.467360   613 solver.cpp:334]     Train net output #0: loss = 0.00130044 (* 1 = 0.00130044 loss)
I0814 19:14:13.467366   613 sgd_solver.cpp:136] Iteration 57100, lr = 0.00107813, m = 0.9
I0814 19:14:15.108762   613 solver.cpp:312] Iteration 57200 (60.9244 iter/s, 1.64138s/100 iter), loss = 0.00238271
I0814 19:14:15.108808   613 solver.cpp:334]     Train net output #0: loss = 0.00238252 (* 1 = 0.00238252 loss)
I0814 19:14:15.108820   613 sgd_solver.cpp:136] Iteration 57200, lr = 0.0010625, m = 0.9
I0814 19:14:16.732713   613 solver.cpp:312] Iteration 57300 (61.5802 iter/s, 1.6239s/100 iter), loss = 0.00636473
I0814 19:14:16.733021   613 solver.cpp:334]     Train net output #0: loss = 0.00636454 (* 1 = 0.00636454 loss)
I0814 19:14:16.733036   613 sgd_solver.cpp:136] Iteration 57300, lr = 0.00104688, m = 0.9
I0814 19:14:18.335400   613 solver.cpp:312] Iteration 57400 (62.3971 iter/s, 1.60264s/100 iter), loss = 0.000838508
I0814 19:14:18.335425   613 solver.cpp:334]     Train net output #0: loss = 0.000838316 (* 1 = 0.000838316 loss)
I0814 19:14:18.335431   613 sgd_solver.cpp:136] Iteration 57400, lr = 0.00103125, m = 0.9
I0814 19:14:19.996417   613 solver.cpp:312] Iteration 57500 (60.206 iter/s, 1.66096s/100 iter), loss = 0.000250811
I0814 19:14:19.996444   613 solver.cpp:334]     Train net output #0: loss = 0.000250619 (* 1 = 0.000250619 loss)
I0814 19:14:19.996453   613 sgd_solver.cpp:136] Iteration 57500, lr = 0.00101562, m = 0.9
I0814 19:14:21.623462   613 solver.cpp:312] Iteration 57600 (61.4629 iter/s, 1.627s/100 iter), loss = 0.00287358
I0814 19:14:21.623548   613 solver.cpp:334]     Train net output #0: loss = 0.00287339 (* 1 = 0.00287339 loss)
I0814 19:14:21.623555   613 sgd_solver.cpp:136] Iteration 57600, lr = 0.001, m = 0.9
I0814 19:14:23.223930   613 solver.cpp:312] Iteration 57700 (62.4837 iter/s, 1.60042s/100 iter), loss = 0.000693637
I0814 19:14:23.223954   613 solver.cpp:334]     Train net output #0: loss = 0.000693444 (* 1 = 0.000693444 loss)
I0814 19:14:23.223960   613 sgd_solver.cpp:136] Iteration 57700, lr = 0.000984375, m = 0.9
I0814 19:14:24.871544   613 solver.cpp:312] Iteration 57800 (60.6957 iter/s, 1.64756s/100 iter), loss = 0.000866125
I0814 19:14:24.871598   613 solver.cpp:334]     Train net output #0: loss = 0.000865931 (* 1 = 0.000865931 loss)
I0814 19:14:24.871610   613 sgd_solver.cpp:136] Iteration 57800, lr = 0.00096875, m = 0.9
I0814 19:14:26.527604   613 solver.cpp:312] Iteration 57900 (60.3861 iter/s, 1.65601s/100 iter), loss = 0.000593252
I0814 19:14:26.527751   613 solver.cpp:334]     Train net output #0: loss = 0.000593059 (* 1 = 0.000593059 loss)
I0814 19:14:26.527828   613 sgd_solver.cpp:136] Iteration 57900, lr = 0.000953125, m = 0.9
I0814 19:14:28.133599   613 solver.cpp:509] Iteration 58000, Testing net (#0)
I0814 19:14:28.964867   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.918236
I0814 19:14:28.964885   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.995588
I0814 19:14:28.964890   613 solver.cpp:594]     Test net output #2: loss = 0.319302 (* 1 = 0.319302 loss)
I0814 19:14:28.964906   613 solver.cpp:264] [MultiGPU] Tests completed in 0.831284s
I0814 19:14:28.980962   613 solver.cpp:312] Iteration 58000 (40.7617 iter/s, 2.45329s/100 iter), loss = 0.00253755
I0814 19:14:28.980979   613 solver.cpp:334]     Train net output #0: loss = 0.00253735 (* 1 = 0.00253735 loss)
I0814 19:14:28.980984   613 sgd_solver.cpp:136] Iteration 58000, lr = 0.0009375, m = 0.9
I0814 19:14:30.606820   613 solver.cpp:312] Iteration 58100 (61.5079 iter/s, 1.62581s/100 iter), loss = 0.00608398
I0814 19:14:30.607029   613 solver.cpp:334]     Train net output #0: loss = 0.00608378 (* 1 = 0.00608378 loss)
I0814 19:14:30.607092   613 sgd_solver.cpp:136] Iteration 58100, lr = 0.000921875, m = 0.9
I0814 19:14:32.246266   613 solver.cpp:312] Iteration 58200 (60.9982 iter/s, 1.63939s/100 iter), loss = 0.000571924
I0814 19:14:32.246292   613 solver.cpp:334]     Train net output #0: loss = 0.000571731 (* 1 = 0.000571731 loss)
I0814 19:14:32.246299   613 sgd_solver.cpp:136] Iteration 58200, lr = 0.00090625, m = 0.9
I0814 19:14:33.851166   613 solver.cpp:312] Iteration 58300 (62.3111 iter/s, 1.60485s/100 iter), loss = 0.000714348
I0814 19:14:33.851189   613 solver.cpp:334]     Train net output #0: loss = 0.000714155 (* 1 = 0.000714155 loss)
I0814 19:14:33.851193   613 sgd_solver.cpp:136] Iteration 58300, lr = 0.000890625, m = 0.9
I0814 19:14:35.468067   613 solver.cpp:312] Iteration 58400 (61.8485 iter/s, 1.61685s/100 iter), loss = 0.00192373
I0814 19:14:35.468091   613 solver.cpp:334]     Train net output #0: loss = 0.00192353 (* 1 = 0.00192353 loss)
I0814 19:14:35.468097   613 sgd_solver.cpp:136] Iteration 58400, lr = 0.000875, m = 0.9
I0814 19:14:37.101158   613 solver.cpp:312] Iteration 58500 (61.2355 iter/s, 1.63304s/100 iter), loss = 0.00132546
I0814 19:14:37.101204   613 solver.cpp:334]     Train net output #0: loss = 0.00132527 (* 1 = 0.00132527 loss)
I0814 19:14:37.101217   613 sgd_solver.cpp:136] Iteration 58500, lr = 0.000859375, m = 0.9
I0814 19:14:38.717130   613 solver.cpp:312] Iteration 58600 (61.8841 iter/s, 1.61592s/100 iter), loss = 0.000223666
I0814 19:14:38.717175   613 solver.cpp:334]     Train net output #0: loss = 0.000223471 (* 1 = 0.000223471 loss)
I0814 19:14:38.717186   613 sgd_solver.cpp:136] Iteration 58600, lr = 0.00084375, m = 0.9
I0814 19:14:40.342741   613 solver.cpp:312] Iteration 58700 (61.5173 iter/s, 1.62556s/100 iter), loss = 0.000490509
I0814 19:14:40.342768   613 solver.cpp:334]     Train net output #0: loss = 0.000490314 (* 1 = 0.000490314 loss)
I0814 19:14:40.342773   613 sgd_solver.cpp:136] Iteration 58700, lr = 0.000828125, m = 0.9
I0814 19:14:41.986130   613 solver.cpp:312] Iteration 58800 (60.8518 iter/s, 1.64334s/100 iter), loss = 0.000481489
I0814 19:14:41.986155   613 solver.cpp:334]     Train net output #0: loss = 0.000481295 (* 1 = 0.000481295 loss)
I0814 19:14:41.986158   613 sgd_solver.cpp:136] Iteration 58800, lr = 0.0008125, m = 0.9
I0814 19:14:43.662510   613 solver.cpp:312] Iteration 58900 (59.6542 iter/s, 1.67633s/100 iter), loss = 0.000873105
I0814 19:14:43.662536   613 solver.cpp:334]     Train net output #0: loss = 0.000872912 (* 1 = 0.000872912 loss)
I0814 19:14:43.662544   613 sgd_solver.cpp:136] Iteration 58900, lr = 0.000796875, m = 0.9
I0814 19:14:45.262933   613 solver.cpp:509] Iteration 59000, Testing net (#0)
I0814 19:14:46.075053   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.915883
I0814 19:14:46.075070   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.995
I0814 19:14:46.075075   613 solver.cpp:594]     Test net output #2: loss = 0.312787 (* 1 = 0.312787 loss)
I0814 19:14:46.075091   613 solver.cpp:264] [MultiGPU] Tests completed in 0.812137s
I0814 19:14:46.090919   613 solver.cpp:312] Iteration 59000 (41.1804 iter/s, 2.42834s/100 iter), loss = 0.000907719
I0814 19:14:46.090935   613 solver.cpp:334]     Train net output #0: loss = 0.000907526 (* 1 = 0.000907526 loss)
I0814 19:14:46.090941   613 sgd_solver.cpp:136] Iteration 59000, lr = 0.00078125, m = 0.9
I0814 19:14:47.729897   613 solver.cpp:312] Iteration 59100 (61.0156 iter/s, 1.63892s/100 iter), loss = 0.00181612
I0814 19:14:47.729923   613 solver.cpp:334]     Train net output #0: loss = 0.00181593 (* 1 = 0.00181593 loss)
I0814 19:14:47.729928   613 sgd_solver.cpp:136] Iteration 59100, lr = 0.000765625, m = 0.9
I0814 19:14:49.349674   613 solver.cpp:312] Iteration 59200 (61.7388 iter/s, 1.61973s/100 iter), loss = 0.000910037
I0814 19:14:49.349704   613 solver.cpp:334]     Train net output #0: loss = 0.000909844 (* 1 = 0.000909844 loss)
I0814 19:14:49.349711   613 sgd_solver.cpp:136] Iteration 59200, lr = 0.00075, m = 0.9
I0814 19:14:50.962692   613 solver.cpp:312] Iteration 59300 (61.9976 iter/s, 1.61296s/100 iter), loss = 0.000566687
I0814 19:14:50.962716   613 solver.cpp:334]     Train net output #0: loss = 0.000566493 (* 1 = 0.000566493 loss)
I0814 19:14:50.962721   613 sgd_solver.cpp:136] Iteration 59300, lr = 0.000734375, m = 0.9
I0814 19:14:52.540957   613 solver.cpp:312] Iteration 59400 (63.3625 iter/s, 1.57822s/100 iter), loss = 0.00306824
I0814 19:14:52.541030   613 solver.cpp:334]     Train net output #0: loss = 0.00306804 (* 1 = 0.00306804 loss)
I0814 19:14:52.541038   613 sgd_solver.cpp:136] Iteration 59400, lr = 0.00071875, m = 0.9
I0814 19:14:54.151327   613 solver.cpp:312] Iteration 59500 (62.0995 iter/s, 1.61032s/100 iter), loss = 0.000278579
I0814 19:14:54.151356   613 solver.cpp:334]     Train net output #0: loss = 0.000278384 (* 1 = 0.000278384 loss)
I0814 19:14:54.151363   613 sgd_solver.cpp:136] Iteration 59500, lr = 0.000703125, m = 0.9
I0814 19:14:55.784466   613 solver.cpp:312] Iteration 59600 (61.2336 iter/s, 1.63309s/100 iter), loss = 0.00138084
I0814 19:14:55.784612   613 solver.cpp:334]     Train net output #0: loss = 0.00138065 (* 1 = 0.00138065 loss)
I0814 19:14:55.784709   613 sgd_solver.cpp:136] Iteration 59600, lr = 0.0006875, m = 0.9
I0814 19:14:57.398236   613 solver.cpp:312] Iteration 59700 (61.9686 iter/s, 1.61372s/100 iter), loss = 0.0029104
I0814 19:14:57.398282   613 solver.cpp:334]     Train net output #0: loss = 0.0029102 (* 1 = 0.0029102 loss)
I0814 19:14:57.398293   613 sgd_solver.cpp:136] Iteration 59700, lr = 0.000671875, m = 0.9
I0814 19:14:59.029199   613 solver.cpp:312] Iteration 59800 (61.3153 iter/s, 1.63091s/100 iter), loss = 0.00193224
I0814 19:14:59.029247   613 solver.cpp:334]     Train net output #0: loss = 0.00193204 (* 1 = 0.00193204 loss)
I0814 19:14:59.029263   613 sgd_solver.cpp:136] Iteration 59800, lr = 0.00065625, m = 0.9
I0814 19:15:00.661589   613 solver.cpp:312] Iteration 59900 (61.2619 iter/s, 1.63234s/100 iter), loss = 0.00061853
I0814 19:15:00.661639   613 solver.cpp:334]     Train net output #0: loss = 0.000618336 (* 1 = 0.000618336 loss)
I0814 19:15:00.661653   613 sgd_solver.cpp:136] Iteration 59900, lr = 0.000640625, m = 0.9
I0814 19:15:02.252465   613 solver.cpp:639] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/l1reg/cifar10_jacintonet11v2_iter_60000.caffemodel
I0814 19:15:02.260396   613 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/l1reg/cifar10_jacintonet11v2_iter_60000.solverstate
I0814 19:15:02.263861   613 solver.cpp:509] Iteration 60000, Testing net (#0)
I0814 19:15:03.071303   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.914119
I0814 19:15:03.071321   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.994706
I0814 19:15:03.071326   613 solver.cpp:594]     Test net output #2: loss = 0.332166 (* 1 = 0.332166 loss)
I0814 19:15:03.071341   613 solver.cpp:264] [MultiGPU] Tests completed in 0.807457s
I0814 19:15:03.086921   613 solver.cpp:312] Iteration 60000 (41.2326 iter/s, 2.42526s/100 iter), loss = 0.00160001
I0814 19:15:03.086937   613 solver.cpp:334]     Train net output #0: loss = 0.00159981 (* 1 = 0.00159981 loss)
I0814 19:15:03.086941   613 sgd_solver.cpp:136] Iteration 60000, lr = 0.000625, m = 0.9
I0814 19:15:04.703081   613 solver.cpp:312] Iteration 60100 (61.877 iter/s, 1.61611s/100 iter), loss = 0.00154639
I0814 19:15:04.703107   613 solver.cpp:334]     Train net output #0: loss = 0.00154619 (* 1 = 0.00154619 loss)
I0814 19:15:04.703112   613 sgd_solver.cpp:136] Iteration 60100, lr = 0.000609375, m = 0.9
I0814 19:15:06.278401   613 solver.cpp:312] Iteration 60200 (63.4812 iter/s, 1.57527s/100 iter), loss = 0.000553183
I0814 19:15:06.278475   613 solver.cpp:334]     Train net output #0: loss = 0.00055299 (* 1 = 0.00055299 loss)
I0814 19:15:06.278501   613 sgd_solver.cpp:136] Iteration 60200, lr = 0.00059375, m = 0.9
I0814 19:15:07.905796   613 solver.cpp:312] Iteration 60300 (61.4498 iter/s, 1.62734s/100 iter), loss = 0.0018664
I0814 19:15:07.905951   613 solver.cpp:334]     Train net output #0: loss = 0.0018662 (* 1 = 0.0018662 loss)
I0814 19:15:07.905977   613 sgd_solver.cpp:136] Iteration 60300, lr = 0.000578125, m = 0.9
I0814 19:15:09.544441   613 solver.cpp:312] Iteration 60400 (61.0279 iter/s, 1.6386s/100 iter), loss = 0.00028911
I0814 19:15:09.544466   613 solver.cpp:334]     Train net output #0: loss = 0.000288916 (* 1 = 0.000288916 loss)
I0814 19:15:09.544497   613 sgd_solver.cpp:136] Iteration 60400, lr = 0.0005625, m = 0.9
I0814 19:15:11.162394   613 solver.cpp:312] Iteration 60500 (61.8085 iter/s, 1.6179s/100 iter), loss = 0.00134083
I0814 19:15:11.162458   613 solver.cpp:334]     Train net output #0: loss = 0.00134063 (* 1 = 0.00134063 loss)
I0814 19:15:11.162478   613 sgd_solver.cpp:136] Iteration 60500, lr = 0.000546875, m = 0.9
I0814 19:15:12.801955   613 solver.cpp:312] Iteration 60600 (60.9939 iter/s, 1.63951s/100 iter), loss = 0.00305291
I0814 19:15:12.802022   613 solver.cpp:334]     Train net output #0: loss = 0.00305271 (* 1 = 0.00305271 loss)
I0814 19:15:12.802047   613 sgd_solver.cpp:136] Iteration 60600, lr = 0.00053125, m = 0.9
I0814 19:15:12.860913   592 data_reader.cpp:288] Starting prefetch of epoch 8
I0814 19:15:14.401856   613 solver.cpp:312] Iteration 60700 (62.5058 iter/s, 1.59985s/100 iter), loss = 0.00130965
I0814 19:15:14.402112   613 solver.cpp:334]     Train net output #0: loss = 0.00130946 (* 1 = 0.00130946 loss)
I0814 19:15:14.402118   613 sgd_solver.cpp:136] Iteration 60700, lr = 0.000515625, m = 0.9
I0814 19:15:16.041265   613 solver.cpp:312] Iteration 60800 (60.9996 iter/s, 1.63936s/100 iter), loss = 0.00204671
I0814 19:15:16.041287   613 solver.cpp:334]     Train net output #0: loss = 0.00204652 (* 1 = 0.00204652 loss)
I0814 19:15:16.041293   613 sgd_solver.cpp:136] Iteration 60800, lr = 0.0005, m = 0.9
I0814 19:15:17.673768   613 solver.cpp:312] Iteration 60900 (61.2575 iter/s, 1.63245s/100 iter), loss = 0.00169358
I0814 19:15:17.673790   613 solver.cpp:334]     Train net output #0: loss = 0.00169339 (* 1 = 0.00169339 loss)
I0814 19:15:17.673794   613 sgd_solver.cpp:136] Iteration 60900, lr = 0.000484375, m = 0.9
I0814 19:15:19.252734   613 solver.cpp:509] Iteration 61000, Testing net (#0)
I0814 19:15:20.083407   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.909413
I0814 19:15:20.083425   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.994412
I0814 19:15:20.083431   613 solver.cpp:594]     Test net output #2: loss = 0.341405 (* 1 = 0.341405 loss)
I0814 19:15:20.083480   613 solver.cpp:264] [MultiGPU] Tests completed in 0.830724s
I0814 19:15:20.098951   613 solver.cpp:312] Iteration 61000 (41.2352 iter/s, 2.42511s/100 iter), loss = 0.000427757
I0814 19:15:20.098968   613 solver.cpp:334]     Train net output #0: loss = 0.000427564 (* 1 = 0.000427564 loss)
I0814 19:15:20.098973   613 sgd_solver.cpp:136] Iteration 61000, lr = 0.00046875, m = 0.9
I0814 19:15:21.705335   613 solver.cpp:312] Iteration 61100 (62.2536 iter/s, 1.60633s/100 iter), loss = 0.00085722
I0814 19:15:21.705358   613 solver.cpp:334]     Train net output #0: loss = 0.000857027 (* 1 = 0.000857027 loss)
I0814 19:15:21.705363   613 sgd_solver.cpp:136] Iteration 61100, lr = 0.000453125, m = 0.9
I0814 19:15:23.297592   613 solver.cpp:312] Iteration 61200 (62.8059 iter/s, 1.59221s/100 iter), loss = 0.000820572
I0814 19:15:23.297737   613 solver.cpp:334]     Train net output #0: loss = 0.000820379 (* 1 = 0.000820379 loss)
I0814 19:15:23.297745   613 sgd_solver.cpp:136] Iteration 61200, lr = 0.0004375, m = 0.9
I0814 19:15:24.953053   613 solver.cpp:312] Iteration 61300 (60.408 iter/s, 1.65541s/100 iter), loss = 0.001401
I0814 19:15:24.953122   613 solver.cpp:334]     Train net output #0: loss = 0.00140081 (* 1 = 0.00140081 loss)
I0814 19:15:24.953145   613 sgd_solver.cpp:136] Iteration 61300, lr = 0.000421875, m = 0.9
I0814 19:15:26.575523   613 solver.cpp:312] Iteration 61400 (61.6363 iter/s, 1.62242s/100 iter), loss = 0.00141695
I0814 19:15:26.575546   613 solver.cpp:334]     Train net output #0: loss = 0.00141675 (* 1 = 0.00141675 loss)
I0814 19:15:26.575552   613 sgd_solver.cpp:136] Iteration 61400, lr = 0.00040625, m = 0.9
I0814 19:15:28.229060   613 solver.cpp:312] Iteration 61500 (60.4784 iter/s, 1.65348s/100 iter), loss = 0.0028573
I0814 19:15:28.229107   613 solver.cpp:334]     Train net output #0: loss = 0.0028571 (* 1 = 0.0028571 loss)
I0814 19:15:28.229120   613 sgd_solver.cpp:136] Iteration 61500, lr = 0.000390625, m = 0.9
I0814 19:15:29.844717   613 solver.cpp:312] Iteration 61600 (61.8962 iter/s, 1.61561s/100 iter), loss = 0.0024157
I0814 19:15:29.844741   613 solver.cpp:334]     Train net output #0: loss = 0.00241551 (* 1 = 0.00241551 loss)
I0814 19:15:29.844748   613 sgd_solver.cpp:136] Iteration 61600, lr = 0.000375, m = 0.9
I0814 19:15:31.423151   613 solver.cpp:312] Iteration 61700 (63.356 iter/s, 1.57838s/100 iter), loss = 0.000199069
I0814 19:15:31.423221   613 solver.cpp:334]     Train net output #0: loss = 0.000198876 (* 1 = 0.000198876 loss)
I0814 19:15:31.423243   613 sgd_solver.cpp:136] Iteration 61700, lr = 0.000359375, m = 0.9
I0814 19:15:33.051873   613 solver.cpp:312] Iteration 61800 (61.3996 iter/s, 1.62867s/100 iter), loss = 0.000304017
I0814 19:15:33.051897   613 solver.cpp:334]     Train net output #0: loss = 0.000303823 (* 1 = 0.000303823 loss)
I0814 19:15:33.051901   613 sgd_solver.cpp:136] Iteration 61800, lr = 0.00034375, m = 0.9
I0814 19:15:34.698359   613 solver.cpp:312] Iteration 61900 (60.7373 iter/s, 1.64644s/100 iter), loss = 0.00174319
I0814 19:15:34.698385   613 solver.cpp:334]     Train net output #0: loss = 0.001743 (* 1 = 0.001743 loss)
I0814 19:15:34.698390   613 sgd_solver.cpp:136] Iteration 61900, lr = 0.000328125, m = 0.9
I0814 19:15:36.291245   613 solver.cpp:509] Iteration 62000, Testing net (#0)
I0814 19:15:37.118389   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.914119
I0814 19:15:37.118407   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.994706
I0814 19:15:37.118412   613 solver.cpp:594]     Test net output #2: loss = 0.329698 (* 1 = 0.329698 loss)
I0814 19:15:37.118427   613 solver.cpp:264] [MultiGPU] Tests completed in 0.82716s
I0814 19:15:37.134057   613 solver.cpp:312] Iteration 62000 (41.0572 iter/s, 2.43563s/100 iter), loss = 0.000569987
I0814 19:15:37.134073   613 solver.cpp:334]     Train net output #0: loss = 0.000569794 (* 1 = 0.000569794 loss)
I0814 19:15:37.134075   613 sgd_solver.cpp:136] Iteration 62000, lr = 0.0003125, m = 0.9
I0814 19:15:38.821662   613 solver.cpp:312] Iteration 62100 (59.2575 iter/s, 1.68755s/100 iter), loss = 0.000310227
I0814 19:15:38.821719   613 solver.cpp:334]     Train net output #0: loss = 0.000310034 (* 1 = 0.000310034 loss)
I0814 19:15:38.821743   613 sgd_solver.cpp:136] Iteration 62100, lr = 0.000296875, m = 0.9
I0814 19:15:40.432026   613 solver.cpp:312] Iteration 62200 (62.0998 iter/s, 1.61031s/100 iter), loss = 0.000879724
I0814 19:15:40.432091   613 solver.cpp:334]     Train net output #0: loss = 0.00087953 (* 1 = 0.00087953 loss)
I0814 19:15:40.432109   613 sgd_solver.cpp:136] Iteration 62200, lr = 0.00028125, m = 0.9
I0814 19:15:42.095234   613 solver.cpp:312] Iteration 62300 (60.1266 iter/s, 1.66316s/100 iter), loss = 0.000756207
I0814 19:15:42.095297   613 solver.cpp:334]     Train net output #0: loss = 0.000756013 (* 1 = 0.000756013 loss)
I0814 19:15:42.095314   613 sgd_solver.cpp:136] Iteration 62300, lr = 0.000265625, m = 0.9
I0814 19:15:43.735851   613 solver.cpp:312] Iteration 62400 (60.9545 iter/s, 1.64057s/100 iter), loss = 0.000303245
I0814 19:15:43.735909   613 solver.cpp:334]     Train net output #0: loss = 0.000303052 (* 1 = 0.000303052 loss)
I0814 19:15:43.735929   613 sgd_solver.cpp:136] Iteration 62400, lr = 0.00025, m = 0.9
I0814 19:15:45.360646   613 solver.cpp:312] Iteration 62500 (61.5483 iter/s, 1.62474s/100 iter), loss = 0.000848219
I0814 19:15:45.360692   613 solver.cpp:334]     Train net output #0: loss = 0.000848026 (* 1 = 0.000848026 loss)
I0814 19:15:45.360707   613 sgd_solver.cpp:136] Iteration 62500, lr = 0.000234375, m = 0.9
I0814 19:15:46.972729   613 solver.cpp:312] Iteration 62600 (62.0334 iter/s, 1.61204s/100 iter), loss = 0.00147055
I0814 19:15:46.972776   613 solver.cpp:334]     Train net output #0: loss = 0.00147035 (* 1 = 0.00147035 loss)
I0814 19:15:46.972790   613 sgd_solver.cpp:136] Iteration 62600, lr = 0.00021875, m = 0.9
I0814 19:15:48.579478   613 solver.cpp:312] Iteration 62700 (62.2394 iter/s, 1.6067s/100 iter), loss = 0.000820019
I0814 19:15:48.579538   613 solver.cpp:334]     Train net output #0: loss = 0.000819824 (* 1 = 0.000819824 loss)
I0814 19:15:48.579557   613 sgd_solver.cpp:136] Iteration 62700, lr = 0.000203125, m = 0.9
I0814 19:15:50.200582   613 solver.cpp:312] Iteration 62800 (61.6884 iter/s, 1.62105s/100 iter), loss = 0.00142233
I0814 19:15:50.200634   613 solver.cpp:334]     Train net output #0: loss = 0.00142213 (* 1 = 0.00142213 loss)
I0814 19:15:50.200647   613 sgd_solver.cpp:136] Iteration 62800, lr = 0.0001875, m = 0.9
I0814 19:15:51.812494   613 solver.cpp:312] Iteration 62900 (62.0401 iter/s, 1.61186s/100 iter), loss = 0.00137886
I0814 19:15:51.812556   613 solver.cpp:334]     Train net output #0: loss = 0.00137866 (* 1 = 0.00137866 loss)
I0814 19:15:51.812574   613 sgd_solver.cpp:136] Iteration 62900, lr = 0.000171875, m = 0.9
I0814 19:15:53.421255   613 solver.cpp:509] Iteration 63000, Testing net (#0)
I0814 19:15:54.238636   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.912648
I0814 19:15:54.238656   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.995
I0814 19:15:54.238661   613 solver.cpp:594]     Test net output #2: loss = 0.340784 (* 1 = 0.340784 loss)
I0814 19:15:54.238674   613 solver.cpp:264] [MultiGPU] Tests completed in 0.817398s
I0814 19:15:54.254387   613 solver.cpp:312] Iteration 63000 (40.953 iter/s, 2.44183s/100 iter), loss = 0.00172038
I0814 19:15:54.254403   613 solver.cpp:334]     Train net output #0: loss = 0.00172019 (* 1 = 0.00172019 loss)
I0814 19:15:54.254407   613 sgd_solver.cpp:136] Iteration 63000, lr = 0.00015625, m = 0.9
I0814 19:15:55.850627   613 solver.cpp:312] Iteration 63100 (62.6494 iter/s, 1.59619s/100 iter), loss = 0.00104731
I0814 19:15:55.850656   613 solver.cpp:334]     Train net output #0: loss = 0.00104711 (* 1 = 0.00104711 loss)
I0814 19:15:55.850663   613 sgd_solver.cpp:136] Iteration 63100, lr = 0.000140625, m = 0.9
I0814 19:15:57.510680   613 solver.cpp:312] Iteration 63200 (60.2408 iter/s, 1.66s/100 iter), loss = 0.00151257
I0814 19:15:57.510705   613 solver.cpp:334]     Train net output #0: loss = 0.00151237 (* 1 = 0.00151237 loss)
I0814 19:15:57.510712   613 sgd_solver.cpp:136] Iteration 63200, lr = 0.000125, m = 0.9
I0814 19:15:59.134155   613 solver.cpp:312] Iteration 63300 (61.5981 iter/s, 1.62343s/100 iter), loss = 0.00130969
I0814 19:15:59.134179   613 solver.cpp:334]     Train net output #0: loss = 0.00130949 (* 1 = 0.00130949 loss)
I0814 19:15:59.134186   613 sgd_solver.cpp:136] Iteration 63300, lr = 0.000109375, m = 0.9
I0814 19:16:00.771884   613 solver.cpp:312] Iteration 63400 (61.0621 iter/s, 1.63768s/100 iter), loss = 0.000394305
I0814 19:16:00.771908   613 solver.cpp:334]     Train net output #0: loss = 0.000394112 (* 1 = 0.000394112 loss)
I0814 19:16:00.771914   613 sgd_solver.cpp:136] Iteration 63400, lr = 9.37498e-05, m = 0.9
I0814 19:16:02.340396   613 solver.cpp:312] Iteration 63500 (63.7567 iter/s, 1.56846s/100 iter), loss = 0.000177362
I0814 19:16:02.340423   613 solver.cpp:334]     Train net output #0: loss = 0.000177169 (* 1 = 0.000177169 loss)
I0814 19:16:02.340430   613 sgd_solver.cpp:136] Iteration 63500, lr = 7.8125e-05, m = 0.9
I0814 19:16:03.988221   613 solver.cpp:312] Iteration 63600 (60.688 iter/s, 1.64777s/100 iter), loss = 0.00163312
I0814 19:16:03.988248   613 solver.cpp:334]     Train net output #0: loss = 0.00163293 (* 1 = 0.00163293 loss)
I0814 19:16:03.988255   613 sgd_solver.cpp:136] Iteration 63600, lr = 6.25002e-05, m = 0.9
I0814 19:16:05.639859   613 solver.cpp:312] Iteration 63700 (60.5478 iter/s, 1.65159s/100 iter), loss = 0.000635101
I0814 19:16:05.639886   613 solver.cpp:334]     Train net output #0: loss = 0.000634909 (* 1 = 0.000634909 loss)
I0814 19:16:05.639892   613 sgd_solver.cpp:136] Iteration 63700, lr = 4.68749e-05, m = 0.9
I0814 19:16:07.264003   613 solver.cpp:312] Iteration 63800 (61.5728 iter/s, 1.62409s/100 iter), loss = 0.000968047
I0814 19:16:07.264032   613 solver.cpp:334]     Train net output #0: loss = 0.000967856 (* 1 = 0.000967856 loss)
I0814 19:16:07.264039   613 sgd_solver.cpp:136] Iteration 63800, lr = 3.12501e-05, m = 0.9
I0814 19:16:08.872730   613 solver.cpp:312] Iteration 63900 (62.163 iter/s, 1.60868s/100 iter), loss = 0.00146501
I0814 19:16:08.872755   613 solver.cpp:334]     Train net output #0: loss = 0.00146482 (* 1 = 0.00146482 loss)
I0814 19:16:08.872761   613 sgd_solver.cpp:136] Iteration 63900, lr = 1.56248e-05, m = 0.9
I0814 19:16:10.465710   613 solver.cpp:312] Iteration 63999 (62.1496 iter/s, 1.59293s/99 iter), loss = 0.000846131
I0814 19:16:10.465735   613 solver.cpp:334]     Train net output #0: loss = 0.000845939 (* 1 = 0.000845939 loss)
I0814 19:16:10.465864   613 solver.cpp:639] Snapshotting to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/l1reg/cifar10_jacintonet11v2_iter_64000.caffemodel
I0814 19:16:10.473784   613 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cifar10_jacintonet11v2_2017-08-14_18-39-46/l1reg/cifar10_jacintonet11v2_iter_64000.solverstate
I0814 19:16:10.482251   613 solver.cpp:486] Iteration 64000, loss = 0.00069849
I0814 19:16:10.482272   613 solver.cpp:509] Iteration 64000, Testing net (#0)
I0814 19:16:11.291815   613 solver.cpp:594]     Test net output #0: accuracy/top1 = 0.908236
I0814 19:16:11.291836   613 solver.cpp:594]     Test net output #1: accuracy/top5 = 0.995
I0814 19:16:11.291841   613 solver.cpp:594]     Test net output #2: loss = 0.358975 (* 1 = 0.358975 loss)
I0814 19:16:11.294932   556 parallel.cpp:71] Root Solver performance on device 0: 58.75 * 22 = 1292 img/sec (64000 itr in 1089 sec)
I0814 19:16:11.294945   556 parallel.cpp:76]      Solver performance on device 1: 58.75 * 22 = 1292 img/sec (64000 itr in 1089 sec)
I0814 19:16:11.294950   556 parallel.cpp:76]      Solver performance on device 2: 58.75 * 22 = 1292 img/sec (64000 itr in 1089 sec)
I0814 19:16:11.294951   556 parallel.cpp:79] Overall multi-GPU performance: 3877.4 img/sec
I0814 19:16:11.368559   556 caffe.cpp:247] Optimization Done in 18m 13s
