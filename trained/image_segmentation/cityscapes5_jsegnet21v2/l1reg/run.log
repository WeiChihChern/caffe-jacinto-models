I0916 17:01:07.133924 20128 caffe.cpp:807] This is NVCaffe 0.16.4 started at Sat Sep 16 17:01:06 2017
I0916 17:01:07.134588 20128 caffe.cpp:810] CuDNN version: 6021
I0916 17:01:07.134594 20128 caffe.cpp:811] CuBLAS version: 8000
I0916 17:01:07.134598 20128 caffe.cpp:812] CUDA version: 8000
I0916 17:01:07.134600 20128 caffe.cpp:813] CUDA driver version: 8000
I0916 17:01:07.625830 20128 gpu_memory.cpp:159] GPUMemory::Manager initialized with Caching (CUB) GPU Allocator
I0916 17:01:07.626406 20128 gpu_memory.cpp:161] Total memory: 8506769408, Free: 8278441984, dev_info[0]: total=8506769408 free=8278441984
I0916 17:01:07.626929 20128 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8278441984, dev_info[1]: total=8508145664 free=8379236352
I0916 17:01:07.627446 20128 gpu_memory.cpp:161] Total memory: 8508145664, Free: 8278441984, dev_info[2]: total=8508145664 free=8379236352
I0916 17:01:07.627454 20128 caffe.cpp:214] Using GPUs 0, 1, 2
I0916 17:01:07.627786 20128 caffe.cpp:219] GPU 0: GeForce GTX 1080
I0916 17:01:07.628127 20128 caffe.cpp:219] GPU 1: GeForce GTX 1080
I0916 17:01:07.628458 20128 caffe.cpp:219] GPU 2: GeForce GTX 1080
I0916 17:01:07.628496 20128 solver.cpp:43] Solver data type: FLOAT
I0916 17:01:07.628531 20128 solver.cpp:46] Initializing solver from parameters: 
train_net: "training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/train.prototxt"
test_net: "training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/test.prototxt"
test_iter: 125
test_interval: 2000
base_lr: 0.01
display: 100
max_iter: 60000
lr_policy: "multistep"
gamma: 0.1
power: 1
momentum: 0.9
weight_decay: 1e-05
snapshot: 10000
snapshot_prefix: "training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/cityscapes5_jsegnet21v2"
solver_mode: GPU
device_id: 0
random_seed: 33
debug_info: false
snapshot_after_train: true
regularization_type: "L1"
test_initialization: false
stepvalue: 30000
stepvalue: 45000
iter_size: 1
type: "SGD"
I0916 17:01:07.647444 20128 solver.cpp:78] Creating training net from train_net file: training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/train.prototxt
I0916 17:01:07.660696 20128 net.cpp:443] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top1
I0916 17:01:07.660712 20128 net.cpp:443] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy/top5
W0916 17:01:07.660763 20128 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 16 to 18
I0916 17:01:07.661136 20128 net.cpp:72] Initializing net from parameters: 
name: "jsegnet21v2_train"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "ImageLabelData"
  top: "data"
  top: "label"
  transform_param {
    mirror: true
    crop_size: 640
    mean_value: 0
  }
  image_label_data_param {
    image_list_path: "data/train-image-lmdb"
    label_list_path: "data/train-label-lmdb"
    batch_size: 6
    shuffle: true
    threads: 1
    backend: LMDB
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "out5a"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "out5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "out5a/bn"
  type: "BatchNorm"
  bottom: "out5a"
  top: "out5a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out5a/relu"
  type: "ReLU"
  bottom: "out5a"
  top: "out5a"
}
layer {
  name: "out5a_up2"
  type: "Deconvolution"
  bottom: "out5a"
  top: "out5a_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 64
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out3a"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "out3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "out3a/bn"
  type: "BatchNorm"
  bottom: "out3a"
  top: "out3a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out3a/relu"
  type: "ReLU"
  bottom: "out3a"
  top: "out3a"
}
layer {
  name: "out3_out5_combined"
  type: "Eltwise"
  bottom: "out5a_up2"
  bottom: "out3a"
  top: "out3_out5_combined"
}
layer {
  name: "ctx_conv1"
  type: "Convolution"
  bottom: "out3_out5_combined"
  top: "ctx_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_conv1/bn"
  type: "BatchNorm"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv1/relu"
  type: "ReLU"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
}
layer {
  name: "ctx_conv2"
  type: "Convolution"
  bottom: "ctx_conv1"
  top: "ctx_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv2/bn"
  type: "BatchNorm"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv2/relu"
  type: "ReLU"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
}
layer {
  name: "ctx_conv3"
  type: "Convolution"
  bottom: "ctx_conv2"
  top: "ctx_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv3/bn"
  type: "BatchNorm"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv3/relu"
  type: "ReLU"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
}
layer {
  name: "ctx_conv4"
  type: "Convolution"
  bottom: "ctx_conv3"
  top: "ctx_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv4/bn"
  type: "BatchNorm"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv4/relu"
  type: "ReLU"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
}
layer {
  name: "ctx_final"
  type: "Convolution"
  bottom: "ctx_conv4"
  top: "ctx_final"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_final/relu"
  type: "ReLU"
  bottom: "ctx_final"
  top: "ctx_final"
}
layer {
  name: "out_deconv_final_up2"
  type: "Deconvolution"
  bottom: "ctx_final"
  top: "out_deconv_final_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up4"
  type: "Deconvolution"
  bottom: "out_deconv_final_up2"
  top: "out_deconv_final_up4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up8"
  type: "Deconvolution"
  bottom: "out_deconv_final_up4"
  top: "out_deconv_final_up8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: 255
    normalization: VALID
  }
}
I0916 17:01:07.661348 20128 net.cpp:104] Using FLOAT as default forward math type
I0916 17:01:07.661355 20128 net.cpp:110] Using FLOAT as default backward math type
I0916 17:01:07.661358 20128 layer_factory.hpp:136] Creating layer 'data' of type 'ImageLabelData'
I0916 17:01:07.661363 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:07.661377 20128 net.cpp:184] Created Layer data (0)
I0916 17:01:07.661382 20128 net.cpp:530] data -> data
I0916 17:01:07.661398 20128 net.cpp:530] data -> label
I0916 17:01:07.684540 20128 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0916 17:01:07.684571 20128 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 17:01:07.736806 20195 db_lmdb.cpp:24] Opened lmdb data/train-image-lmdb
I0916 17:01:07.739987 20128 data_layer.cpp:187] [0] ReshapePrefetch 6, 3, 640, 640
I0916 17:01:07.740047 20128 data_layer.cpp:211] [0] Output data size: 6, 3, 640, 640
I0916 17:01:07.740054 20128 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 17:01:07.740108 20128 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0916 17:01:07.740119 20128 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 17:01:07.740808 20196 data_layer.cpp:101] [0] Parser threads: 1
I0916 17:01:07.740818 20196 data_layer.cpp:103] [0] Transformer threads: 1
I0916 17:01:07.763118 20197 db_lmdb.cpp:24] Opened lmdb data/train-label-lmdb
I0916 17:01:07.764173 20128 data_layer.cpp:187] [0] ReshapePrefetch 6, 1, 640, 640
I0916 17:01:07.764225 20128 data_layer.cpp:211] [0] Output data size: 6, 1, 640, 640
I0916 17:01:07.764232 20128 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 17:01:07.764292 20128 net.cpp:245] Setting up data
I0916 17:01:07.764305 20128 net.cpp:252] TRAIN Top shape for layer 0 'data' 6 3 640 640 (7372800)
I0916 17:01:07.764314 20128 net.cpp:252] TRAIN Top shape for layer 0 'data' 6 1 640 640 (2457600)
I0916 17:01:07.764322 20128 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0916 17:01:07.764328 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:07.764350 20128 net.cpp:184] Created Layer data/bias (1)
I0916 17:01:07.764355 20128 net.cpp:561] data/bias <- data
I0916 17:01:07.764366 20128 net.cpp:530] data/bias -> data/bias
I0916 17:01:07.766208 20198 data_layer.cpp:101] [0] Parser threads: 1
I0916 17:01:07.766227 20198 data_layer.cpp:103] [0] Transformer threads: 1
I0916 17:01:07.780812 20128 net.cpp:245] Setting up data/bias
I0916 17:01:07.780838 20128 net.cpp:252] TRAIN Top shape for layer 1 'data/bias' 6 3 640 640 (7372800)
I0916 17:01:07.780853 20128 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0916 17:01:07.780859 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:07.780890 20128 net.cpp:184] Created Layer conv1a (2)
I0916 17:01:07.780896 20128 net.cpp:561] conv1a <- data/bias
I0916 17:01:07.780902 20128 net.cpp:530] conv1a -> conv1a
I0916 17:01:08.431376 20128 net.cpp:245] Setting up conv1a
I0916 17:01:08.431404 20128 net.cpp:252] TRAIN Top shape for layer 2 'conv1a' 6 32 320 320 (19660800)
I0916 17:01:08.431418 20128 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0916 17:01:08.431424 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.431438 20128 net.cpp:184] Created Layer conv1a/bn (3)
I0916 17:01:08.431442 20128 net.cpp:561] conv1a/bn <- conv1a
I0916 17:01:08.431448 20128 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0916 17:01:08.432309 20128 net.cpp:245] Setting up conv1a/bn
I0916 17:01:08.432319 20128 net.cpp:252] TRAIN Top shape for layer 3 'conv1a/bn' 6 32 320 320 (19660800)
I0916 17:01:08.432329 20128 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0916 17:01:08.432333 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.432341 20128 net.cpp:184] Created Layer conv1a/relu (4)
I0916 17:01:08.432344 20128 net.cpp:561] conv1a/relu <- conv1a
I0916 17:01:08.432348 20128 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0916 17:01:08.432654 20128 net.cpp:245] Setting up conv1a/relu
I0916 17:01:08.432662 20128 net.cpp:252] TRAIN Top shape for layer 4 'conv1a/relu' 6 32 320 320 (19660800)
I0916 17:01:08.432665 20128 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0916 17:01:08.432669 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.432689 20128 net.cpp:184] Created Layer conv1b (5)
I0916 17:01:08.432693 20128 net.cpp:561] conv1b <- conv1a
I0916 17:01:08.432698 20128 net.cpp:530] conv1b -> conv1b
I0916 17:01:08.435050 20128 net.cpp:245] Setting up conv1b
I0916 17:01:08.435062 20128 net.cpp:252] TRAIN Top shape for layer 5 'conv1b' 6 32 320 320 (19660800)
I0916 17:01:08.435070 20128 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0916 17:01:08.435075 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.435081 20128 net.cpp:184] Created Layer conv1b/bn (6)
I0916 17:01:08.435083 20128 net.cpp:561] conv1b/bn <- conv1b
I0916 17:01:08.435087 20128 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0916 17:01:08.435864 20128 net.cpp:245] Setting up conv1b/bn
I0916 17:01:08.435873 20128 net.cpp:252] TRAIN Top shape for layer 6 'conv1b/bn' 6 32 320 320 (19660800)
I0916 17:01:08.435881 20128 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0916 17:01:08.435885 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.435889 20128 net.cpp:184] Created Layer conv1b/relu (7)
I0916 17:01:08.435892 20128 net.cpp:561] conv1b/relu <- conv1b
I0916 17:01:08.435896 20128 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0916 17:01:08.435901 20128 net.cpp:245] Setting up conv1b/relu
I0916 17:01:08.435905 20128 net.cpp:252] TRAIN Top shape for layer 7 'conv1b/relu' 6 32 320 320 (19660800)
I0916 17:01:08.435909 20128 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0916 17:01:08.435912 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.435920 20128 net.cpp:184] Created Layer pool1 (8)
I0916 17:01:08.435923 20128 net.cpp:561] pool1 <- conv1b
I0916 17:01:08.435927 20128 net.cpp:530] pool1 -> pool1
I0916 17:01:08.436015 20128 net.cpp:245] Setting up pool1
I0916 17:01:08.436022 20128 net.cpp:252] TRAIN Top shape for layer 8 'pool1' 6 32 160 160 (4915200)
I0916 17:01:08.436025 20128 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0916 17:01:08.436029 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.436036 20128 net.cpp:184] Created Layer res2a_branch2a (9)
I0916 17:01:08.436050 20128 net.cpp:561] res2a_branch2a <- pool1
I0916 17:01:08.436054 20128 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0916 17:01:08.438700 20128 net.cpp:245] Setting up res2a_branch2a
I0916 17:01:08.438711 20128 net.cpp:252] TRAIN Top shape for layer 9 'res2a_branch2a' 6 64 160 160 (9830400)
I0916 17:01:08.438720 20128 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0916 17:01:08.438724 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.438730 20128 net.cpp:184] Created Layer res2a_branch2a/bn (10)
I0916 17:01:08.438733 20128 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0916 17:01:08.438737 20128 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0916 17:01:08.440078 20128 net.cpp:245] Setting up res2a_branch2a/bn
I0916 17:01:08.440088 20128 net.cpp:252] TRAIN Top shape for layer 10 'res2a_branch2a/bn' 6 64 160 160 (9830400)
I0916 17:01:08.440096 20128 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0916 17:01:08.440100 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.440104 20128 net.cpp:184] Created Layer res2a_branch2a/relu (11)
I0916 17:01:08.440109 20128 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0916 17:01:08.440111 20128 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0916 17:01:08.440119 20128 net.cpp:245] Setting up res2a_branch2a/relu
I0916 17:01:08.440124 20128 net.cpp:252] TRAIN Top shape for layer 11 'res2a_branch2a/relu' 6 64 160 160 (9830400)
I0916 17:01:08.440127 20128 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0916 17:01:08.440131 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.440142 20128 net.cpp:184] Created Layer res2a_branch2b (12)
I0916 17:01:08.440146 20128 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0916 17:01:08.440150 20128 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0916 17:01:08.441963 20128 net.cpp:245] Setting up res2a_branch2b
I0916 17:01:08.441975 20128 net.cpp:252] TRAIN Top shape for layer 12 'res2a_branch2b' 6 64 160 160 (9830400)
I0916 17:01:08.441982 20128 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0916 17:01:08.441985 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.441992 20128 net.cpp:184] Created Layer res2a_branch2b/bn (13)
I0916 17:01:08.441994 20128 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0916 17:01:08.441998 20128 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0916 17:01:08.442667 20128 net.cpp:245] Setting up res2a_branch2b/bn
I0916 17:01:08.442677 20128 net.cpp:252] TRAIN Top shape for layer 13 'res2a_branch2b/bn' 6 64 160 160 (9830400)
I0916 17:01:08.442684 20128 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0916 17:01:08.442688 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.442692 20128 net.cpp:184] Created Layer res2a_branch2b/relu (14)
I0916 17:01:08.442694 20128 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0916 17:01:08.442698 20128 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0916 17:01:08.442701 20128 net.cpp:245] Setting up res2a_branch2b/relu
I0916 17:01:08.442704 20128 net.cpp:252] TRAIN Top shape for layer 14 'res2a_branch2b/relu' 6 64 160 160 (9830400)
I0916 17:01:08.442708 20128 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0916 17:01:08.442709 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.442713 20128 net.cpp:184] Created Layer pool2 (15)
I0916 17:01:08.442716 20128 net.cpp:561] pool2 <- res2a_branch2b
I0916 17:01:08.442720 20128 net.cpp:530] pool2 -> pool2
I0916 17:01:08.442785 20128 net.cpp:245] Setting up pool2
I0916 17:01:08.442790 20128 net.cpp:252] TRAIN Top shape for layer 15 'pool2' 6 64 80 80 (2457600)
I0916 17:01:08.442800 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0916 17:01:08.442803 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.442809 20128 net.cpp:184] Created Layer res3a_branch2a (16)
I0916 17:01:08.442812 20128 net.cpp:561] res3a_branch2a <- pool2
I0916 17:01:08.442814 20128 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0916 17:01:08.444597 20128 net.cpp:245] Setting up res3a_branch2a
I0916 17:01:08.444605 20128 net.cpp:252] TRAIN Top shape for layer 16 'res3a_branch2a' 6 128 80 80 (4915200)
I0916 17:01:08.444610 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0916 17:01:08.444612 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.444617 20128 net.cpp:184] Created Layer res3a_branch2a/bn (17)
I0916 17:01:08.444620 20128 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0916 17:01:08.444622 20128 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0916 17:01:08.445622 20128 net.cpp:245] Setting up res3a_branch2a/bn
I0916 17:01:08.445632 20128 net.cpp:252] TRAIN Top shape for layer 17 'res3a_branch2a/bn' 6 128 80 80 (4915200)
I0916 17:01:08.445643 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0916 17:01:08.445647 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.445657 20128 net.cpp:184] Created Layer res3a_branch2a/relu (18)
I0916 17:01:08.445662 20128 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0916 17:01:08.445664 20128 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0916 17:01:08.445670 20128 net.cpp:245] Setting up res3a_branch2a/relu
I0916 17:01:08.445675 20128 net.cpp:252] TRAIN Top shape for layer 18 'res3a_branch2a/relu' 6 128 80 80 (4915200)
I0916 17:01:08.445679 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0916 17:01:08.445683 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.445694 20128 net.cpp:184] Created Layer res3a_branch2b (19)
I0916 17:01:08.445698 20128 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0916 17:01:08.445703 20128 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0916 17:01:08.447105 20128 net.cpp:245] Setting up res3a_branch2b
I0916 17:01:08.447115 20128 net.cpp:252] TRAIN Top shape for layer 19 'res3a_branch2b' 6 128 80 80 (4915200)
I0916 17:01:08.447121 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0916 17:01:08.447125 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.447131 20128 net.cpp:184] Created Layer res3a_branch2b/bn (20)
I0916 17:01:08.447134 20128 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0916 17:01:08.447139 20128 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0916 17:01:08.447906 20128 net.cpp:245] Setting up res3a_branch2b/bn
I0916 17:01:08.447916 20128 net.cpp:252] TRAIN Top shape for layer 20 'res3a_branch2b/bn' 6 128 80 80 (4915200)
I0916 17:01:08.447924 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0916 17:01:08.447927 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.447932 20128 net.cpp:184] Created Layer res3a_branch2b/relu (21)
I0916 17:01:08.447935 20128 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0916 17:01:08.447938 20128 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0916 17:01:08.447943 20128 net.cpp:245] Setting up res3a_branch2b/relu
I0916 17:01:08.447947 20128 net.cpp:252] TRAIN Top shape for layer 21 'res3a_branch2b/relu' 6 128 80 80 (4915200)
I0916 17:01:08.447952 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0916 17:01:08.447955 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.447971 20128 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (22)
I0916 17:01:08.447975 20128 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0916 17:01:08.447980 20128 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0916 17:01:08.447985 20128 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0916 17:01:08.448040 20128 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0916 17:01:08.448046 20128 net.cpp:252] TRAIN Top shape for layer 22 'res3a_branch2b_res3a_branch2b/relu_0_split' 6 128 80 80 (4915200)
I0916 17:01:08.448051 20128 net.cpp:252] TRAIN Top shape for layer 22 'res3a_branch2b_res3a_branch2b/relu_0_split' 6 128 80 80 (4915200)
I0916 17:01:08.448055 20128 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0916 17:01:08.448060 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.448065 20128 net.cpp:184] Created Layer pool3 (23)
I0916 17:01:08.448070 20128 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0916 17:01:08.448074 20128 net.cpp:530] pool3 -> pool3
I0916 17:01:08.448151 20128 net.cpp:245] Setting up pool3
I0916 17:01:08.448158 20128 net.cpp:252] TRAIN Top shape for layer 23 'pool3' 6 128 40 40 (1228800)
I0916 17:01:08.448161 20128 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0916 17:01:08.448166 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.448175 20128 net.cpp:184] Created Layer res4a_branch2a (24)
I0916 17:01:08.448180 20128 net.cpp:561] res4a_branch2a <- pool3
I0916 17:01:08.448184 20128 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0916 17:01:08.458075 20128 net.cpp:245] Setting up res4a_branch2a
I0916 17:01:08.458086 20128 net.cpp:252] TRAIN Top shape for layer 24 'res4a_branch2a' 6 256 40 40 (2457600)
I0916 17:01:08.458094 20128 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0916 17:01:08.458098 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.458106 20128 net.cpp:184] Created Layer res4a_branch2a/bn (25)
I0916 17:01:08.458111 20128 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0916 17:01:08.458114 20128 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0916 17:01:08.458920 20128 net.cpp:245] Setting up res4a_branch2a/bn
I0916 17:01:08.458930 20128 net.cpp:252] TRAIN Top shape for layer 25 'res4a_branch2a/bn' 6 256 40 40 (2457600)
I0916 17:01:08.458940 20128 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0916 17:01:08.458943 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.458950 20128 net.cpp:184] Created Layer res4a_branch2a/relu (26)
I0916 17:01:08.458953 20128 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0916 17:01:08.458957 20128 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0916 17:01:08.458974 20128 net.cpp:245] Setting up res4a_branch2a/relu
I0916 17:01:08.458981 20128 net.cpp:252] TRAIN Top shape for layer 26 'res4a_branch2a/relu' 6 256 40 40 (2457600)
I0916 17:01:08.458984 20128 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0916 17:01:08.458988 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.458997 20128 net.cpp:184] Created Layer res4a_branch2b (27)
I0916 17:01:08.459002 20128 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0916 17:01:08.459005 20128 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0916 17:01:08.463346 20128 net.cpp:245] Setting up res4a_branch2b
I0916 17:01:08.463362 20128 net.cpp:252] TRAIN Top shape for layer 27 'res4a_branch2b' 6 256 40 40 (2457600)
I0916 17:01:08.463371 20128 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0916 17:01:08.463374 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.463397 20128 net.cpp:184] Created Layer res4a_branch2b/bn (28)
I0916 17:01:08.463400 20128 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0916 17:01:08.463405 20128 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0916 17:01:08.464203 20128 net.cpp:245] Setting up res4a_branch2b/bn
I0916 17:01:08.464212 20128 net.cpp:252] TRAIN Top shape for layer 28 'res4a_branch2b/bn' 6 256 40 40 (2457600)
I0916 17:01:08.464221 20128 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0916 17:01:08.464226 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.464229 20128 net.cpp:184] Created Layer res4a_branch2b/relu (29)
I0916 17:01:08.464232 20128 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0916 17:01:08.464236 20128 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0916 17:01:08.464241 20128 net.cpp:245] Setting up res4a_branch2b/relu
I0916 17:01:08.464246 20128 net.cpp:252] TRAIN Top shape for layer 29 'res4a_branch2b/relu' 6 256 40 40 (2457600)
I0916 17:01:08.464251 20128 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0916 17:01:08.464253 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.464259 20128 net.cpp:184] Created Layer pool4 (30)
I0916 17:01:08.464263 20128 net.cpp:561] pool4 <- res4a_branch2b
I0916 17:01:08.464267 20128 net.cpp:530] pool4 -> pool4
I0916 17:01:08.464352 20128 net.cpp:245] Setting up pool4
I0916 17:01:08.464359 20128 net.cpp:252] TRAIN Top shape for layer 30 'pool4' 6 256 40 40 (2457600)
I0916 17:01:08.464362 20128 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0916 17:01:08.464366 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.464380 20128 net.cpp:184] Created Layer res5a_branch2a (31)
I0916 17:01:08.464383 20128 net.cpp:561] res5a_branch2a <- pool4
I0916 17:01:08.464387 20128 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0916 17:01:08.490763 20128 net.cpp:245] Setting up res5a_branch2a
I0916 17:01:08.490793 20128 net.cpp:252] TRAIN Top shape for layer 31 'res5a_branch2a' 6 512 40 40 (4915200)
I0916 17:01:08.490803 20128 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0916 17:01:08.490808 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.490828 20128 net.cpp:184] Created Layer res5a_branch2a/bn (32)
I0916 17:01:08.490833 20128 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0916 17:01:08.490840 20128 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0916 17:01:08.491541 20128 net.cpp:245] Setting up res5a_branch2a/bn
I0916 17:01:08.491551 20128 net.cpp:252] TRAIN Top shape for layer 32 'res5a_branch2a/bn' 6 512 40 40 (4915200)
I0916 17:01:08.491559 20128 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0916 17:01:08.491561 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.491565 20128 net.cpp:184] Created Layer res5a_branch2a/relu (33)
I0916 17:01:08.491569 20128 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0916 17:01:08.491570 20128 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0916 17:01:08.491575 20128 net.cpp:245] Setting up res5a_branch2a/relu
I0916 17:01:08.491577 20128 net.cpp:252] TRAIN Top shape for layer 33 'res5a_branch2a/relu' 6 512 40 40 (4915200)
I0916 17:01:08.491580 20128 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0916 17:01:08.491583 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.491595 20128 net.cpp:184] Created Layer res5a_branch2b (34)
I0916 17:01:08.491606 20128 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0916 17:01:08.491628 20128 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0916 17:01:08.504639 20128 net.cpp:245] Setting up res5a_branch2b
I0916 17:01:08.504657 20128 net.cpp:252] TRAIN Top shape for layer 34 'res5a_branch2b' 6 512 40 40 (4915200)
I0916 17:01:08.504667 20128 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0916 17:01:08.504669 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.504676 20128 net.cpp:184] Created Layer res5a_branch2b/bn (35)
I0916 17:01:08.504679 20128 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0916 17:01:08.504683 20128 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0916 17:01:08.505385 20128 net.cpp:245] Setting up res5a_branch2b/bn
I0916 17:01:08.505395 20128 net.cpp:252] TRAIN Top shape for layer 35 'res5a_branch2b/bn' 6 512 40 40 (4915200)
I0916 17:01:08.505409 20128 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0916 17:01:08.505414 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.505421 20128 net.cpp:184] Created Layer res5a_branch2b/relu (36)
I0916 17:01:08.505426 20128 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0916 17:01:08.505430 20128 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0916 17:01:08.505437 20128 net.cpp:245] Setting up res5a_branch2b/relu
I0916 17:01:08.505441 20128 net.cpp:252] TRAIN Top shape for layer 36 'res5a_branch2b/relu' 6 512 40 40 (4915200)
I0916 17:01:08.505446 20128 layer_factory.hpp:136] Creating layer 'out5a' of type 'Convolution'
I0916 17:01:08.505450 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.505461 20128 net.cpp:184] Created Layer out5a (37)
I0916 17:01:08.505465 20128 net.cpp:561] out5a <- res5a_branch2b
I0916 17:01:08.505470 20128 net.cpp:530] out5a -> out5a
I0916 17:01:08.509696 20128 net.cpp:245] Setting up out5a
I0916 17:01:08.509706 20128 net.cpp:252] TRAIN Top shape for layer 37 'out5a' 6 64 40 40 (614400)
I0916 17:01:08.509714 20128 layer_factory.hpp:136] Creating layer 'out5a/bn' of type 'BatchNorm'
I0916 17:01:08.509721 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.509728 20128 net.cpp:184] Created Layer out5a/bn (38)
I0916 17:01:08.509732 20128 net.cpp:561] out5a/bn <- out5a
I0916 17:01:08.509738 20128 net.cpp:513] out5a/bn -> out5a (in-place)
I0916 17:01:08.510391 20128 net.cpp:245] Setting up out5a/bn
I0916 17:01:08.510401 20128 net.cpp:252] TRAIN Top shape for layer 38 'out5a/bn' 6 64 40 40 (614400)
I0916 17:01:08.510409 20128 layer_factory.hpp:136] Creating layer 'out5a/relu' of type 'ReLU'
I0916 17:01:08.510414 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.510421 20128 net.cpp:184] Created Layer out5a/relu (39)
I0916 17:01:08.510424 20128 net.cpp:561] out5a/relu <- out5a
I0916 17:01:08.510429 20128 net.cpp:513] out5a/relu -> out5a (in-place)
I0916 17:01:08.510437 20128 net.cpp:245] Setting up out5a/relu
I0916 17:01:08.510442 20128 net.cpp:252] TRAIN Top shape for layer 39 'out5a/relu' 6 64 40 40 (614400)
I0916 17:01:08.510445 20128 layer_factory.hpp:136] Creating layer 'out5a_up2' of type 'Deconvolution'
I0916 17:01:08.510450 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.510464 20128 net.cpp:184] Created Layer out5a_up2 (40)
I0916 17:01:08.510468 20128 net.cpp:561] out5a_up2 <- out5a
I0916 17:01:08.510473 20128 net.cpp:530] out5a_up2 -> out5a_up2
I0916 17:01:08.510759 20128 net.cpp:245] Setting up out5a_up2
I0916 17:01:08.510766 20128 net.cpp:252] TRAIN Top shape for layer 40 'out5a_up2' 6 64 80 80 (2457600)
I0916 17:01:08.510771 20128 layer_factory.hpp:136] Creating layer 'out3a' of type 'Convolution'
I0916 17:01:08.510776 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.510785 20128 net.cpp:184] Created Layer out3a (41)
I0916 17:01:08.510789 20128 net.cpp:561] out3a <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0916 17:01:08.510803 20128 net.cpp:530] out3a -> out3a
I0916 17:01:08.511899 20128 net.cpp:245] Setting up out3a
I0916 17:01:08.511907 20128 net.cpp:252] TRAIN Top shape for layer 41 'out3a' 6 64 80 80 (2457600)
I0916 17:01:08.511914 20128 layer_factory.hpp:136] Creating layer 'out3a/bn' of type 'BatchNorm'
I0916 17:01:08.511920 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.511927 20128 net.cpp:184] Created Layer out3a/bn (42)
I0916 17:01:08.511932 20128 net.cpp:561] out3a/bn <- out3a
I0916 17:01:08.511937 20128 net.cpp:513] out3a/bn -> out3a (in-place)
I0916 17:01:08.512575 20128 net.cpp:245] Setting up out3a/bn
I0916 17:01:08.512583 20128 net.cpp:252] TRAIN Top shape for layer 42 'out3a/bn' 6 64 80 80 (2457600)
I0916 17:01:08.512593 20128 layer_factory.hpp:136] Creating layer 'out3a/relu' of type 'ReLU'
I0916 17:01:08.512598 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.512603 20128 net.cpp:184] Created Layer out3a/relu (43)
I0916 17:01:08.512607 20128 net.cpp:561] out3a/relu <- out3a
I0916 17:01:08.512612 20128 net.cpp:513] out3a/relu -> out3a (in-place)
I0916 17:01:08.512619 20128 net.cpp:245] Setting up out3a/relu
I0916 17:01:08.512624 20128 net.cpp:252] TRAIN Top shape for layer 43 'out3a/relu' 6 64 80 80 (2457600)
I0916 17:01:08.512629 20128 layer_factory.hpp:136] Creating layer 'out3_out5_combined' of type 'Eltwise'
I0916 17:01:08.512634 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.513010 20128 net.cpp:184] Created Layer out3_out5_combined (44)
I0916 17:01:08.513015 20128 net.cpp:561] out3_out5_combined <- out5a_up2
I0916 17:01:08.513020 20128 net.cpp:561] out3_out5_combined <- out3a
I0916 17:01:08.513025 20128 net.cpp:530] out3_out5_combined -> out3_out5_combined
I0916 17:01:08.513056 20128 net.cpp:245] Setting up out3_out5_combined
I0916 17:01:08.513062 20128 net.cpp:252] TRAIN Top shape for layer 44 'out3_out5_combined' 6 64 80 80 (2457600)
I0916 17:01:08.513067 20128 layer_factory.hpp:136] Creating layer 'ctx_conv1' of type 'Convolution'
I0916 17:01:08.513070 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.513084 20128 net.cpp:184] Created Layer ctx_conv1 (45)
I0916 17:01:08.513088 20128 net.cpp:561] ctx_conv1 <- out3_out5_combined
I0916 17:01:08.513093 20128 net.cpp:530] ctx_conv1 -> ctx_conv1
I0916 17:01:08.514189 20128 net.cpp:245] Setting up ctx_conv1
I0916 17:01:08.514199 20128 net.cpp:252] TRAIN Top shape for layer 45 'ctx_conv1' 6 64 80 80 (2457600)
I0916 17:01:08.514205 20128 layer_factory.hpp:136] Creating layer 'ctx_conv1/bn' of type 'BatchNorm'
I0916 17:01:08.514210 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.514217 20128 net.cpp:184] Created Layer ctx_conv1/bn (46)
I0916 17:01:08.514222 20128 net.cpp:561] ctx_conv1/bn <- ctx_conv1
I0916 17:01:08.514227 20128 net.cpp:513] ctx_conv1/bn -> ctx_conv1 (in-place)
I0916 17:01:08.514879 20128 net.cpp:245] Setting up ctx_conv1/bn
I0916 17:01:08.514888 20128 net.cpp:252] TRAIN Top shape for layer 46 'ctx_conv1/bn' 6 64 80 80 (2457600)
I0916 17:01:08.514896 20128 layer_factory.hpp:136] Creating layer 'ctx_conv1/relu' of type 'ReLU'
I0916 17:01:08.514901 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.514906 20128 net.cpp:184] Created Layer ctx_conv1/relu (47)
I0916 17:01:08.514911 20128 net.cpp:561] ctx_conv1/relu <- ctx_conv1
I0916 17:01:08.514916 20128 net.cpp:513] ctx_conv1/relu -> ctx_conv1 (in-place)
I0916 17:01:08.514922 20128 net.cpp:245] Setting up ctx_conv1/relu
I0916 17:01:08.514928 20128 net.cpp:252] TRAIN Top shape for layer 47 'ctx_conv1/relu' 6 64 80 80 (2457600)
I0916 17:01:08.514931 20128 layer_factory.hpp:136] Creating layer 'ctx_conv2' of type 'Convolution'
I0916 17:01:08.514933 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.514946 20128 net.cpp:184] Created Layer ctx_conv2 (48)
I0916 17:01:08.514948 20128 net.cpp:561] ctx_conv2 <- ctx_conv1
I0916 17:01:08.514950 20128 net.cpp:530] ctx_conv2 -> ctx_conv2
I0916 17:01:08.516031 20128 net.cpp:245] Setting up ctx_conv2
I0916 17:01:08.516038 20128 net.cpp:252] TRAIN Top shape for layer 48 'ctx_conv2' 6 64 80 80 (2457600)
I0916 17:01:08.516042 20128 layer_factory.hpp:136] Creating layer 'ctx_conv2/bn' of type 'BatchNorm'
I0916 17:01:08.516046 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.516049 20128 net.cpp:184] Created Layer ctx_conv2/bn (49)
I0916 17:01:08.516052 20128 net.cpp:561] ctx_conv2/bn <- ctx_conv2
I0916 17:01:08.516053 20128 net.cpp:513] ctx_conv2/bn -> ctx_conv2 (in-place)
I0916 17:01:08.516685 20128 net.cpp:245] Setting up ctx_conv2/bn
I0916 17:01:08.516691 20128 net.cpp:252] TRAIN Top shape for layer 49 'ctx_conv2/bn' 6 64 80 80 (2457600)
I0916 17:01:08.516697 20128 layer_factory.hpp:136] Creating layer 'ctx_conv2/relu' of type 'ReLU'
I0916 17:01:08.516700 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.516702 20128 net.cpp:184] Created Layer ctx_conv2/relu (50)
I0916 17:01:08.516705 20128 net.cpp:561] ctx_conv2/relu <- ctx_conv2
I0916 17:01:08.516706 20128 net.cpp:513] ctx_conv2/relu -> ctx_conv2 (in-place)
I0916 17:01:08.516710 20128 net.cpp:245] Setting up ctx_conv2/relu
I0916 17:01:08.516712 20128 net.cpp:252] TRAIN Top shape for layer 50 'ctx_conv2/relu' 6 64 80 80 (2457600)
I0916 17:01:08.516715 20128 layer_factory.hpp:136] Creating layer 'ctx_conv3' of type 'Convolution'
I0916 17:01:08.516716 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.516729 20128 net.cpp:184] Created Layer ctx_conv3 (51)
I0916 17:01:08.516733 20128 net.cpp:561] ctx_conv3 <- ctx_conv2
I0916 17:01:08.516737 20128 net.cpp:530] ctx_conv3 -> ctx_conv3
I0916 17:01:08.517874 20128 net.cpp:245] Setting up ctx_conv3
I0916 17:01:08.517881 20128 net.cpp:252] TRAIN Top shape for layer 51 'ctx_conv3' 6 64 80 80 (2457600)
I0916 17:01:08.517885 20128 layer_factory.hpp:136] Creating layer 'ctx_conv3/bn' of type 'BatchNorm'
I0916 17:01:08.517887 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.517891 20128 net.cpp:184] Created Layer ctx_conv3/bn (52)
I0916 17:01:08.517894 20128 net.cpp:561] ctx_conv3/bn <- ctx_conv3
I0916 17:01:08.517896 20128 net.cpp:513] ctx_conv3/bn -> ctx_conv3 (in-place)
I0916 17:01:08.518534 20128 net.cpp:245] Setting up ctx_conv3/bn
I0916 17:01:08.518543 20128 net.cpp:252] TRAIN Top shape for layer 52 'ctx_conv3/bn' 6 64 80 80 (2457600)
I0916 17:01:08.518548 20128 layer_factory.hpp:136] Creating layer 'ctx_conv3/relu' of type 'ReLU'
I0916 17:01:08.518550 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.518554 20128 net.cpp:184] Created Layer ctx_conv3/relu (53)
I0916 17:01:08.518556 20128 net.cpp:561] ctx_conv3/relu <- ctx_conv3
I0916 17:01:08.518558 20128 net.cpp:513] ctx_conv3/relu -> ctx_conv3 (in-place)
I0916 17:01:08.518566 20128 net.cpp:245] Setting up ctx_conv3/relu
I0916 17:01:08.518569 20128 net.cpp:252] TRAIN Top shape for layer 53 'ctx_conv3/relu' 6 64 80 80 (2457600)
I0916 17:01:08.518571 20128 layer_factory.hpp:136] Creating layer 'ctx_conv4' of type 'Convolution'
I0916 17:01:08.518574 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.518585 20128 net.cpp:184] Created Layer ctx_conv4 (54)
I0916 17:01:08.518590 20128 net.cpp:561] ctx_conv4 <- ctx_conv3
I0916 17:01:08.518594 20128 net.cpp:530] ctx_conv4 -> ctx_conv4
I0916 17:01:08.519671 20128 net.cpp:245] Setting up ctx_conv4
I0916 17:01:08.519678 20128 net.cpp:252] TRAIN Top shape for layer 54 'ctx_conv4' 6 64 80 80 (2457600)
I0916 17:01:08.519682 20128 layer_factory.hpp:136] Creating layer 'ctx_conv4/bn' of type 'BatchNorm'
I0916 17:01:08.519691 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.519695 20128 net.cpp:184] Created Layer ctx_conv4/bn (55)
I0916 17:01:08.519698 20128 net.cpp:561] ctx_conv4/bn <- ctx_conv4
I0916 17:01:08.519701 20128 net.cpp:513] ctx_conv4/bn -> ctx_conv4 (in-place)
I0916 17:01:08.520344 20128 net.cpp:245] Setting up ctx_conv4/bn
I0916 17:01:08.520351 20128 net.cpp:252] TRAIN Top shape for layer 55 'ctx_conv4/bn' 6 64 80 80 (2457600)
I0916 17:01:08.520357 20128 layer_factory.hpp:136] Creating layer 'ctx_conv4/relu' of type 'ReLU'
I0916 17:01:08.520359 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.520362 20128 net.cpp:184] Created Layer ctx_conv4/relu (56)
I0916 17:01:08.520364 20128 net.cpp:561] ctx_conv4/relu <- ctx_conv4
I0916 17:01:08.520366 20128 net.cpp:513] ctx_conv4/relu -> ctx_conv4 (in-place)
I0916 17:01:08.520370 20128 net.cpp:245] Setting up ctx_conv4/relu
I0916 17:01:08.520372 20128 net.cpp:252] TRAIN Top shape for layer 56 'ctx_conv4/relu' 6 64 80 80 (2457600)
I0916 17:01:08.520375 20128 layer_factory.hpp:136] Creating layer 'ctx_final' of type 'Convolution'
I0916 17:01:08.520376 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.520387 20128 net.cpp:184] Created Layer ctx_final (57)
I0916 17:01:08.520392 20128 net.cpp:561] ctx_final <- ctx_conv4
I0916 17:01:08.520396 20128 net.cpp:530] ctx_final -> ctx_final
I0916 17:01:08.520849 20128 net.cpp:245] Setting up ctx_final
I0916 17:01:08.520856 20128 net.cpp:252] TRAIN Top shape for layer 57 'ctx_final' 6 8 80 80 (307200)
I0916 17:01:08.520860 20128 layer_factory.hpp:136] Creating layer 'ctx_final/relu' of type 'ReLU'
I0916 17:01:08.520864 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.520866 20128 net.cpp:184] Created Layer ctx_final/relu (58)
I0916 17:01:08.520869 20128 net.cpp:561] ctx_final/relu <- ctx_final
I0916 17:01:08.520870 20128 net.cpp:513] ctx_final/relu -> ctx_final (in-place)
I0916 17:01:08.520874 20128 net.cpp:245] Setting up ctx_final/relu
I0916 17:01:08.520876 20128 net.cpp:252] TRAIN Top shape for layer 58 'ctx_final/relu' 6 8 80 80 (307200)
I0916 17:01:08.520879 20128 layer_factory.hpp:136] Creating layer 'out_deconv_final_up2' of type 'Deconvolution'
I0916 17:01:08.520880 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.520885 20128 net.cpp:184] Created Layer out_deconv_final_up2 (59)
I0916 17:01:08.520889 20128 net.cpp:561] out_deconv_final_up2 <- ctx_final
I0916 17:01:08.520894 20128 net.cpp:530] out_deconv_final_up2 -> out_deconv_final_up2
I0916 17:01:08.521163 20128 net.cpp:245] Setting up out_deconv_final_up2
I0916 17:01:08.521169 20128 net.cpp:252] TRAIN Top shape for layer 59 'out_deconv_final_up2' 6 8 160 160 (1228800)
I0916 17:01:08.521173 20128 layer_factory.hpp:136] Creating layer 'out_deconv_final_up4' of type 'Deconvolution'
I0916 17:01:08.521174 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.521178 20128 net.cpp:184] Created Layer out_deconv_final_up4 (60)
I0916 17:01:08.521180 20128 net.cpp:561] out_deconv_final_up4 <- out_deconv_final_up2
I0916 17:01:08.521183 20128 net.cpp:530] out_deconv_final_up4 -> out_deconv_final_up4
I0916 17:01:08.521458 20128 net.cpp:245] Setting up out_deconv_final_up4
I0916 17:01:08.521464 20128 net.cpp:252] TRAIN Top shape for layer 60 'out_deconv_final_up4' 6 8 320 320 (4915200)
I0916 17:01:08.521467 20128 layer_factory.hpp:136] Creating layer 'out_deconv_final_up8' of type 'Deconvolution'
I0916 17:01:08.521471 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.521474 20128 net.cpp:184] Created Layer out_deconv_final_up8 (61)
I0916 17:01:08.521476 20128 net.cpp:561] out_deconv_final_up8 <- out_deconv_final_up4
I0916 17:01:08.521478 20128 net.cpp:530] out_deconv_final_up8 -> out_deconv_final_up8
I0916 17:01:08.521746 20128 net.cpp:245] Setting up out_deconv_final_up8
I0916 17:01:08.521752 20128 net.cpp:252] TRAIN Top shape for layer 61 'out_deconv_final_up8' 6 8 640 640 (19660800)
I0916 17:01:08.521756 20128 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0916 17:01:08.521759 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.521767 20128 net.cpp:184] Created Layer loss (62)
I0916 17:01:08.521770 20128 net.cpp:561] loss <- out_deconv_final_up8
I0916 17:01:08.521772 20128 net.cpp:561] loss <- label
I0916 17:01:08.521776 20128 net.cpp:530] loss -> loss
I0916 17:01:08.523178 20128 net.cpp:245] Setting up loss
I0916 17:01:08.523195 20128 net.cpp:252] TRAIN Top shape for layer 62 'loss' (1)
I0916 17:01:08.523197 20128 net.cpp:256]     with loss weight 1
I0916 17:01:08.523208 20128 net.cpp:323] loss needs backward computation.
I0916 17:01:08.523211 20128 net.cpp:323] out_deconv_final_up8 needs backward computation.
I0916 17:01:08.523213 20128 net.cpp:323] out_deconv_final_up4 needs backward computation.
I0916 17:01:08.523223 20128 net.cpp:323] out_deconv_final_up2 needs backward computation.
I0916 17:01:08.523226 20128 net.cpp:323] ctx_final/relu needs backward computation.
I0916 17:01:08.523229 20128 net.cpp:323] ctx_final needs backward computation.
I0916 17:01:08.523231 20128 net.cpp:323] ctx_conv4/relu needs backward computation.
I0916 17:01:08.523236 20128 net.cpp:323] ctx_conv4/bn needs backward computation.
I0916 17:01:08.523239 20128 net.cpp:323] ctx_conv4 needs backward computation.
I0916 17:01:08.523243 20128 net.cpp:323] ctx_conv3/relu needs backward computation.
I0916 17:01:08.523247 20128 net.cpp:323] ctx_conv3/bn needs backward computation.
I0916 17:01:08.523259 20128 net.cpp:323] ctx_conv3 needs backward computation.
I0916 17:01:08.523265 20128 net.cpp:323] ctx_conv2/relu needs backward computation.
I0916 17:01:08.523269 20128 net.cpp:323] ctx_conv2/bn needs backward computation.
I0916 17:01:08.523273 20128 net.cpp:323] ctx_conv2 needs backward computation.
I0916 17:01:08.523278 20128 net.cpp:323] ctx_conv1/relu needs backward computation.
I0916 17:01:08.523283 20128 net.cpp:323] ctx_conv1/bn needs backward computation.
I0916 17:01:08.523288 20128 net.cpp:323] ctx_conv1 needs backward computation.
I0916 17:01:08.523291 20128 net.cpp:323] out3_out5_combined needs backward computation.
I0916 17:01:08.523296 20128 net.cpp:323] out3a/relu needs backward computation.
I0916 17:01:08.523301 20128 net.cpp:323] out3a/bn needs backward computation.
I0916 17:01:08.523305 20128 net.cpp:323] out3a needs backward computation.
I0916 17:01:08.523310 20128 net.cpp:323] out5a_up2 needs backward computation.
I0916 17:01:08.523314 20128 net.cpp:323] out5a/relu needs backward computation.
I0916 17:01:08.523319 20128 net.cpp:323] out5a/bn needs backward computation.
I0916 17:01:08.523322 20128 net.cpp:323] out5a needs backward computation.
I0916 17:01:08.523327 20128 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0916 17:01:08.523331 20128 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0916 17:01:08.523336 20128 net.cpp:323] res5a_branch2b needs backward computation.
I0916 17:01:08.523340 20128 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0916 17:01:08.523344 20128 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0916 17:01:08.523350 20128 net.cpp:323] res5a_branch2a needs backward computation.
I0916 17:01:08.523353 20128 net.cpp:323] pool4 needs backward computation.
I0916 17:01:08.523358 20128 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0916 17:01:08.523362 20128 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0916 17:01:08.523366 20128 net.cpp:323] res4a_branch2b needs backward computation.
I0916 17:01:08.523370 20128 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0916 17:01:08.523375 20128 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0916 17:01:08.523380 20128 net.cpp:323] res4a_branch2a needs backward computation.
I0916 17:01:08.523391 20128 net.cpp:323] pool3 needs backward computation.
I0916 17:01:08.523396 20128 net.cpp:323] res3a_branch2b_res3a_branch2b/relu_0_split needs backward computation.
I0916 17:01:08.523401 20128 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0916 17:01:08.523406 20128 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0916 17:01:08.523411 20128 net.cpp:323] res3a_branch2b needs backward computation.
I0916 17:01:08.523414 20128 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0916 17:01:08.523419 20128 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0916 17:01:08.523423 20128 net.cpp:323] res3a_branch2a needs backward computation.
I0916 17:01:08.523427 20128 net.cpp:323] pool2 needs backward computation.
I0916 17:01:08.523432 20128 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0916 17:01:08.523437 20128 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0916 17:01:08.523442 20128 net.cpp:323] res2a_branch2b needs backward computation.
I0916 17:01:08.523445 20128 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0916 17:01:08.523450 20128 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0916 17:01:08.523454 20128 net.cpp:323] res2a_branch2a needs backward computation.
I0916 17:01:08.523459 20128 net.cpp:323] pool1 needs backward computation.
I0916 17:01:08.523463 20128 net.cpp:323] conv1b/relu needs backward computation.
I0916 17:01:08.523468 20128 net.cpp:323] conv1b/bn needs backward computation.
I0916 17:01:08.523473 20128 net.cpp:323] conv1b needs backward computation.
I0916 17:01:08.523478 20128 net.cpp:323] conv1a/relu needs backward computation.
I0916 17:01:08.523481 20128 net.cpp:323] conv1a/bn needs backward computation.
I0916 17:01:08.523485 20128 net.cpp:323] conv1a needs backward computation.
I0916 17:01:08.523490 20128 net.cpp:325] data/bias does not need backward computation.
I0916 17:01:08.523495 20128 net.cpp:325] data does not need backward computation.
I0916 17:01:08.523500 20128 net.cpp:367] This network produces output loss
I0916 17:01:08.523547 20128 net.cpp:389] Top memory (TRAIN) required for data: 1435238408 diff: 1435238408
I0916 17:01:08.523551 20128 net.cpp:392] Bottom memory (TRAIN) required for data: 1435238400 diff: 1435238400
I0916 17:01:08.523555 20128 net.cpp:395] Shared (in-place) memory (TRAIN) by data: 772915200 diff: 772915200
I0916 17:01:08.523560 20128 net.cpp:398] Parameters memory (TRAIN) required for data: 10817840 diff: 10817840
I0916 17:01:08.523563 20128 net.cpp:401] Parameters shared memory (TRAIN) by data: 0 diff: 0
I0916 17:01:08.523567 20128 net.cpp:407] Network initialization done.
I0916 17:01:08.524612 20128 solver.cpp:177] Creating test net (#0) specified by test_net file: training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/test.prototxt
W0916 17:01:08.524713 20128 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 4 to 6
I0916 17:01:08.525012 20128 net.cpp:72] Initializing net from parameters: 
name: "jsegnet21v2_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageLabelData"
  top: "data"
  top: "label"
  transform_param {
    mirror: false
    crop_size: 640
    mean_value: 0
  }
  image_label_data_param {
    image_list_path: "data/val-image-lmdb"
    label_list_path: "data/val-label-lmdb"
    batch_size: 2
    threads: 1
    backend: LMDB
  }
}
layer {
  name: "data/bias"
  type: "Bias"
  bottom: "data"
  top: "data/bias"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  bias_param {
    filler {
      type: "constant"
      value: -128
    }
  }
}
layer {
  name: "conv1a"
  type: "Convolution"
  bottom: "data/bias"
  top: "conv1a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 2
    kernel_size: 5
    group: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1a/bn"
  type: "BatchNorm"
  bottom: "conv1a"
  top: "conv1a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1a/relu"
  type: "ReLU"
  bottom: "conv1a"
  top: "conv1a"
}
layer {
  name: "conv1b"
  type: "Convolution"
  bottom: "conv1a"
  top: "conv1b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "conv1b/bn"
  type: "BatchNorm"
  bottom: "conv1b"
  top: "conv1b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "conv1b/relu"
  type: "ReLU"
  bottom: "conv1b"
  top: "conv1b"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1b"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2a/relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res2a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res2a_branch2b/relu"
  type: "ReLU"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "res2a_branch2b"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "pool2"
  top: "res3a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2a/relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res3a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res3a_branch2b/relu"
  type: "ReLU"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "res3a_branch2b"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "pool3"
  top: "res4a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2a/relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "res4a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res4a_branch2b/relu"
  type: "ReLU"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "res4a_branch2b"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "pool4"
  top: "res5a_branch2a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2a/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2a/relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 3
    group: 4
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 2
  }
}
layer {
  name: "res5a_branch2b/bn"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "res5a_branch2b/relu"
  type: "ReLU"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
}
layer {
  name: "out5a"
  type: "Convolution"
  bottom: "res5a_branch2b"
  top: "out5a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "out5a/bn"
  type: "BatchNorm"
  bottom: "out5a"
  top: "out5a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out5a/relu"
  type: "ReLU"
  bottom: "out5a"
  top: "out5a"
}
layer {
  name: "out5a_up2"
  type: "Deconvolution"
  bottom: "out5a"
  top: "out5a_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 64
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out3a"
  type: "Convolution"
  bottom: "res3a_branch2b"
  top: "out3a"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 2
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "out3a/bn"
  type: "BatchNorm"
  bottom: "out3a"
  top: "out3a"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "out3a/relu"
  type: "ReLU"
  bottom: "out3a"
  top: "out3a"
}
layer {
  name: "out3_out5_combined"
  type: "Eltwise"
  bottom: "out5a_up2"
  bottom: "out3a"
  top: "out3_out5_combined"
}
layer {
  name: "ctx_conv1"
  type: "Convolution"
  bottom: "out3_out5_combined"
  top: "ctx_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_conv1/bn"
  type: "BatchNorm"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv1/relu"
  type: "ReLU"
  bottom: "ctx_conv1"
  top: "ctx_conv1"
}
layer {
  name: "ctx_conv2"
  type: "Convolution"
  bottom: "ctx_conv1"
  top: "ctx_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv2/bn"
  type: "BatchNorm"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv2/relu"
  type: "ReLU"
  bottom: "ctx_conv2"
  top: "ctx_conv2"
}
layer {
  name: "ctx_conv3"
  type: "Convolution"
  bottom: "ctx_conv2"
  top: "ctx_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv3/bn"
  type: "BatchNorm"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv3/relu"
  type: "ReLU"
  bottom: "ctx_conv3"
  top: "ctx_conv3"
}
layer {
  name: "ctx_conv4"
  type: "Convolution"
  bottom: "ctx_conv3"
  top: "ctx_conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 4
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 4
  }
}
layer {
  name: "ctx_conv4/bn"
  type: "BatchNorm"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
  batch_norm_param {
    moving_average_fraction: 0.99
    eps: 0.0001
    scale_bias: true
  }
}
layer {
  name: "ctx_conv4/relu"
  type: "ReLU"
  bottom: "ctx_conv4"
  top: "ctx_conv4"
}
layer {
  name: "ctx_final"
  type: "Convolution"
  bottom: "ctx_conv4"
  top: "ctx_final"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 1
    kernel_size: 3
    kernel_size: 3
    group: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "ctx_final/relu"
  type: "ReLU"
  bottom: "ctx_final"
  top: "ctx_final"
}
layer {
  name: "out_deconv_final_up2"
  type: "Deconvolution"
  bottom: "ctx_final"
  top: "out_deconv_final_up2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up4"
  type: "Deconvolution"
  bottom: "out_deconv_final_up2"
  top: "out_deconv_final_up4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "out_deconv_final_up8"
  type: "Deconvolution"
  bottom: "out_deconv_final_up4"
  top: "out_deconv_final_up8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 4
    group: 8
    stride: 2
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "loss"
  propagate_down: true
  propagate_down: false
  loss_param {
    ignore_label: 255
    normalization: VALID
  }
}
layer {
  name: "accuracy/top1"
  type: "Accuracy"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "accuracy/top1"
  include {
    phase: TEST
  }
  accuracy_param {
    ignore_label: 255
  }
}
layer {
  name: "accuracy/top5"
  type: "Accuracy"
  bottom: "out_deconv_final_up8"
  bottom: "label"
  top: "accuracy/top5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
    ignore_label: 255
  }
}
I0916 17:01:08.525225 20128 net.cpp:104] Using FLOAT as default forward math type
I0916 17:01:08.525231 20128 net.cpp:110] Using FLOAT as default backward math type
I0916 17:01:08.525235 20128 layer_factory.hpp:136] Creating layer 'data' of type 'ImageLabelData'
I0916 17:01:08.525241 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.525249 20128 net.cpp:184] Created Layer data (0)
I0916 17:01:08.525252 20128 net.cpp:530] data -> data
I0916 17:01:08.525259 20128 net.cpp:530] data -> label
I0916 17:01:08.525295 20128 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 2
I0916 17:01:08.525302 20128 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 17:01:08.549280 20202 db_lmdb.cpp:24] Opened lmdb data/val-image-lmdb
I0916 17:01:08.550817 20128 data_layer.cpp:187] (0) ReshapePrefetch 2, 3, 640, 640
I0916 17:01:08.550870 20128 data_layer.cpp:211] (0) Output data size: 2, 3, 640, 640
I0916 17:01:08.550876 20128 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 17:01:08.550915 20128 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 2
I0916 17:01:08.550925 20128 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 17:01:08.551724 20203 data_layer.cpp:101] (0) Parser threads: 1
I0916 17:01:08.551743 20203 data_layer.cpp:103] (0) Transformer threads: 1
I0916 17:01:08.560511 20204 db_lmdb.cpp:24] Opened lmdb data/val-label-lmdb
I0916 17:01:08.561828 20128 data_layer.cpp:187] (0) ReshapePrefetch 2, 1, 640, 640
I0916 17:01:08.561946 20128 data_layer.cpp:211] (0) Output data size: 2, 1, 640, 640
I0916 17:01:08.561956 20128 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 17:01:08.562018 20128 net.cpp:245] Setting up data
I0916 17:01:08.562048 20128 net.cpp:252] TEST Top shape for layer 0 'data' 2 3 640 640 (2457600)
I0916 17:01:08.562106 20128 net.cpp:252] TEST Top shape for layer 0 'data' 2 1 640 640 (819200)
I0916 17:01:08.562121 20128 layer_factory.hpp:136] Creating layer 'label_data_1_split' of type 'Split'
I0916 17:01:08.562135 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.562151 20128 net.cpp:184] Created Layer label_data_1_split (1)
I0916 17:01:08.562161 20128 net.cpp:561] label_data_1_split <- label
I0916 17:01:08.562173 20128 net.cpp:530] label_data_1_split -> label_data_1_split_0
I0916 17:01:08.562189 20128 net.cpp:530] label_data_1_split -> label_data_1_split_1
I0916 17:01:08.562204 20128 net.cpp:530] label_data_1_split -> label_data_1_split_2
I0916 17:01:08.562336 20128 net.cpp:245] Setting up label_data_1_split
I0916 17:01:08.562360 20128 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 2 1 640 640 (819200)
I0916 17:01:08.562371 20128 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 2 1 640 640 (819200)
I0916 17:01:08.562387 20128 net.cpp:252] TEST Top shape for layer 1 'label_data_1_split' 2 1 640 640 (819200)
I0916 17:01:08.562405 20128 layer_factory.hpp:136] Creating layer 'data/bias' of type 'Bias'
I0916 17:01:08.562425 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.562443 20128 net.cpp:184] Created Layer data/bias (2)
I0916 17:01:08.562453 20128 net.cpp:561] data/bias <- data
I0916 17:01:08.562463 20128 net.cpp:530] data/bias -> data/bias
I0916 17:01:08.564023 20205 data_layer.cpp:101] (0) Parser threads: 1
I0916 17:01:08.564043 20205 data_layer.cpp:103] (0) Transformer threads: 1
I0916 17:01:08.565803 20128 net.cpp:245] Setting up data/bias
I0916 17:01:08.565817 20128 net.cpp:252] TEST Top shape for layer 2 'data/bias' 2 3 640 640 (2457600)
I0916 17:01:08.565826 20128 layer_factory.hpp:136] Creating layer 'conv1a' of type 'Convolution'
I0916 17:01:08.565834 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.565847 20128 net.cpp:184] Created Layer conv1a (3)
I0916 17:01:08.565851 20128 net.cpp:561] conv1a <- data/bias
I0916 17:01:08.565856 20128 net.cpp:530] conv1a -> conv1a
I0916 17:01:08.566372 20128 net.cpp:245] Setting up conv1a
I0916 17:01:08.566381 20128 net.cpp:252] TEST Top shape for layer 3 'conv1a' 2 32 320 320 (6553600)
I0916 17:01:08.566386 20128 layer_factory.hpp:136] Creating layer 'conv1a/bn' of type 'BatchNorm'
I0916 17:01:08.566390 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.566396 20128 net.cpp:184] Created Layer conv1a/bn (4)
I0916 17:01:08.566398 20128 net.cpp:561] conv1a/bn <- conv1a
I0916 17:01:08.566401 20128 net.cpp:513] conv1a/bn -> conv1a (in-place)
I0916 17:01:08.567113 20128 net.cpp:245] Setting up conv1a/bn
I0916 17:01:08.567122 20128 net.cpp:252] TEST Top shape for layer 4 'conv1a/bn' 2 32 320 320 (6553600)
I0916 17:01:08.567131 20128 layer_factory.hpp:136] Creating layer 'conv1a/relu' of type 'ReLU'
I0916 17:01:08.567136 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.567142 20128 net.cpp:184] Created Layer conv1a/relu (5)
I0916 17:01:08.567145 20128 net.cpp:561] conv1a/relu <- conv1a
I0916 17:01:08.567148 20128 net.cpp:513] conv1a/relu -> conv1a (in-place)
I0916 17:01:08.567154 20128 net.cpp:245] Setting up conv1a/relu
I0916 17:01:08.567159 20128 net.cpp:252] TEST Top shape for layer 5 'conv1a/relu' 2 32 320 320 (6553600)
I0916 17:01:08.567162 20128 layer_factory.hpp:136] Creating layer 'conv1b' of type 'Convolution'
I0916 17:01:08.567167 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.567175 20128 net.cpp:184] Created Layer conv1b (6)
I0916 17:01:08.567178 20128 net.cpp:561] conv1b <- conv1a
I0916 17:01:08.567180 20128 net.cpp:530] conv1b -> conv1b
I0916 17:01:08.568224 20128 net.cpp:245] Setting up conv1b
I0916 17:01:08.568233 20128 net.cpp:252] TEST Top shape for layer 6 'conv1b' 2 32 320 320 (6553600)
I0916 17:01:08.568250 20128 layer_factory.hpp:136] Creating layer 'conv1b/bn' of type 'BatchNorm'
I0916 17:01:08.568256 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.568270 20128 net.cpp:184] Created Layer conv1b/bn (7)
I0916 17:01:08.568274 20128 net.cpp:561] conv1b/bn <- conv1b
I0916 17:01:08.568276 20128 net.cpp:513] conv1b/bn -> conv1b (in-place)
I0916 17:01:08.568989 20128 net.cpp:245] Setting up conv1b/bn
I0916 17:01:08.568996 20128 net.cpp:252] TEST Top shape for layer 7 'conv1b/bn' 2 32 320 320 (6553600)
I0916 17:01:08.569003 20128 layer_factory.hpp:136] Creating layer 'conv1b/relu' of type 'ReLU'
I0916 17:01:08.569008 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.569013 20128 net.cpp:184] Created Layer conv1b/relu (8)
I0916 17:01:08.569016 20128 net.cpp:561] conv1b/relu <- conv1b
I0916 17:01:08.569020 20128 net.cpp:513] conv1b/relu -> conv1b (in-place)
I0916 17:01:08.569025 20128 net.cpp:245] Setting up conv1b/relu
I0916 17:01:08.569030 20128 net.cpp:252] TEST Top shape for layer 8 'conv1b/relu' 2 32 320 320 (6553600)
I0916 17:01:08.569033 20128 layer_factory.hpp:136] Creating layer 'pool1' of type 'Pooling'
I0916 17:01:08.569037 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.569042 20128 net.cpp:184] Created Layer pool1 (9)
I0916 17:01:08.569046 20128 net.cpp:561] pool1 <- conv1b
I0916 17:01:08.569049 20128 net.cpp:530] pool1 -> pool1
I0916 17:01:08.569113 20128 net.cpp:245] Setting up pool1
I0916 17:01:08.569118 20128 net.cpp:252] TEST Top shape for layer 9 'pool1' 2 32 160 160 (1638400)
I0916 17:01:08.569121 20128 layer_factory.hpp:136] Creating layer 'res2a_branch2a' of type 'Convolution'
I0916 17:01:08.569125 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.569136 20128 net.cpp:184] Created Layer res2a_branch2a (10)
I0916 17:01:08.569139 20128 net.cpp:561] res2a_branch2a <- pool1
I0916 17:01:08.569142 20128 net.cpp:530] res2a_branch2a -> res2a_branch2a
I0916 17:01:08.569885 20128 net.cpp:245] Setting up res2a_branch2a
I0916 17:01:08.569896 20128 net.cpp:252] TEST Top shape for layer 10 'res2a_branch2a' 2 64 160 160 (3276800)
I0916 17:01:08.569907 20128 layer_factory.hpp:136] Creating layer 'res2a_branch2a/bn' of type 'BatchNorm'
I0916 17:01:08.569911 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.569921 20128 net.cpp:184] Created Layer res2a_branch2a/bn (11)
I0916 17:01:08.569924 20128 net.cpp:561] res2a_branch2a/bn <- res2a_branch2a
I0916 17:01:08.569927 20128 net.cpp:513] res2a_branch2a/bn -> res2a_branch2a (in-place)
I0916 17:01:08.570601 20128 net.cpp:245] Setting up res2a_branch2a/bn
I0916 17:01:08.570608 20128 net.cpp:252] TEST Top shape for layer 11 'res2a_branch2a/bn' 2 64 160 160 (3276800)
I0916 17:01:08.570616 20128 layer_factory.hpp:136] Creating layer 'res2a_branch2a/relu' of type 'ReLU'
I0916 17:01:08.570621 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.570626 20128 net.cpp:184] Created Layer res2a_branch2a/relu (12)
I0916 17:01:08.570629 20128 net.cpp:561] res2a_branch2a/relu <- res2a_branch2a
I0916 17:01:08.570633 20128 net.cpp:513] res2a_branch2a/relu -> res2a_branch2a (in-place)
I0916 17:01:08.570638 20128 net.cpp:245] Setting up res2a_branch2a/relu
I0916 17:01:08.570643 20128 net.cpp:252] TEST Top shape for layer 12 'res2a_branch2a/relu' 2 64 160 160 (3276800)
I0916 17:01:08.570647 20128 layer_factory.hpp:136] Creating layer 'res2a_branch2b' of type 'Convolution'
I0916 17:01:08.570650 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.570657 20128 net.cpp:184] Created Layer res2a_branch2b (13)
I0916 17:01:08.570660 20128 net.cpp:561] res2a_branch2b <- res2a_branch2a
I0916 17:01:08.570663 20128 net.cpp:530] res2a_branch2b -> res2a_branch2b
I0916 17:01:08.571221 20128 net.cpp:245] Setting up res2a_branch2b
I0916 17:01:08.571228 20128 net.cpp:252] TEST Top shape for layer 13 'res2a_branch2b' 2 64 160 160 (3276800)
I0916 17:01:08.571234 20128 layer_factory.hpp:136] Creating layer 'res2a_branch2b/bn' of type 'BatchNorm'
I0916 17:01:08.571238 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.571244 20128 net.cpp:184] Created Layer res2a_branch2b/bn (14)
I0916 17:01:08.571247 20128 net.cpp:561] res2a_branch2b/bn <- res2a_branch2b
I0916 17:01:08.571251 20128 net.cpp:513] res2a_branch2b/bn -> res2a_branch2b (in-place)
I0916 17:01:08.571964 20128 net.cpp:245] Setting up res2a_branch2b/bn
I0916 17:01:08.571971 20128 net.cpp:252] TEST Top shape for layer 14 'res2a_branch2b/bn' 2 64 160 160 (3276800)
I0916 17:01:08.571980 20128 layer_factory.hpp:136] Creating layer 'res2a_branch2b/relu' of type 'ReLU'
I0916 17:01:08.571983 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.571995 20128 net.cpp:184] Created Layer res2a_branch2b/relu (15)
I0916 17:01:08.571998 20128 net.cpp:561] res2a_branch2b/relu <- res2a_branch2b
I0916 17:01:08.572000 20128 net.cpp:513] res2a_branch2b/relu -> res2a_branch2b (in-place)
I0916 17:01:08.572006 20128 net.cpp:245] Setting up res2a_branch2b/relu
I0916 17:01:08.572010 20128 net.cpp:252] TEST Top shape for layer 15 'res2a_branch2b/relu' 2 64 160 160 (3276800)
I0916 17:01:08.572015 20128 layer_factory.hpp:136] Creating layer 'pool2' of type 'Pooling'
I0916 17:01:08.572017 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.572023 20128 net.cpp:184] Created Layer pool2 (16)
I0916 17:01:08.572027 20128 net.cpp:561] pool2 <- res2a_branch2b
I0916 17:01:08.572029 20128 net.cpp:530] pool2 -> pool2
I0916 17:01:08.572093 20128 net.cpp:245] Setting up pool2
I0916 17:01:08.572098 20128 net.cpp:252] TEST Top shape for layer 16 'pool2' 2 64 80 80 (819200)
I0916 17:01:08.572101 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2a' of type 'Convolution'
I0916 17:01:08.572105 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.572113 20128 net.cpp:184] Created Layer res3a_branch2a (17)
I0916 17:01:08.572116 20128 net.cpp:561] res3a_branch2a <- pool2
I0916 17:01:08.572118 20128 net.cpp:530] res3a_branch2a -> res3a_branch2a
I0916 17:01:08.573937 20128 net.cpp:245] Setting up res3a_branch2a
I0916 17:01:08.573945 20128 net.cpp:252] TEST Top shape for layer 17 'res3a_branch2a' 2 128 80 80 (1638400)
I0916 17:01:08.573951 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2a/bn' of type 'BatchNorm'
I0916 17:01:08.573954 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.573961 20128 net.cpp:184] Created Layer res3a_branch2a/bn (18)
I0916 17:01:08.573964 20128 net.cpp:561] res3a_branch2a/bn <- res3a_branch2a
I0916 17:01:08.573967 20128 net.cpp:513] res3a_branch2a/bn -> res3a_branch2a (in-place)
I0916 17:01:08.574611 20128 net.cpp:245] Setting up res3a_branch2a/bn
I0916 17:01:08.574620 20128 net.cpp:252] TEST Top shape for layer 18 'res3a_branch2a/bn' 2 128 80 80 (1638400)
I0916 17:01:08.574632 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2a/relu' of type 'ReLU'
I0916 17:01:08.574635 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.574640 20128 net.cpp:184] Created Layer res3a_branch2a/relu (19)
I0916 17:01:08.574643 20128 net.cpp:561] res3a_branch2a/relu <- res3a_branch2a
I0916 17:01:08.574647 20128 net.cpp:513] res3a_branch2a/relu -> res3a_branch2a (in-place)
I0916 17:01:08.574652 20128 net.cpp:245] Setting up res3a_branch2a/relu
I0916 17:01:08.574656 20128 net.cpp:252] TEST Top shape for layer 19 'res3a_branch2a/relu' 2 128 80 80 (1638400)
I0916 17:01:08.574661 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2b' of type 'Convolution'
I0916 17:01:08.574664 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.574686 20128 net.cpp:184] Created Layer res3a_branch2b (20)
I0916 17:01:08.574688 20128 net.cpp:561] res3a_branch2b <- res3a_branch2a
I0916 17:01:08.574692 20128 net.cpp:530] res3a_branch2b -> res3a_branch2b
I0916 17:01:08.575778 20128 net.cpp:245] Setting up res3a_branch2b
I0916 17:01:08.575784 20128 net.cpp:252] TEST Top shape for layer 20 'res3a_branch2b' 2 128 80 80 (1638400)
I0916 17:01:08.575790 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2b/bn' of type 'BatchNorm'
I0916 17:01:08.575794 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.575800 20128 net.cpp:184] Created Layer res3a_branch2b/bn (21)
I0916 17:01:08.575804 20128 net.cpp:561] res3a_branch2b/bn <- res3a_branch2b
I0916 17:01:08.575808 20128 net.cpp:513] res3a_branch2b/bn -> res3a_branch2b (in-place)
I0916 17:01:08.576436 20128 net.cpp:245] Setting up res3a_branch2b/bn
I0916 17:01:08.576443 20128 net.cpp:252] TEST Top shape for layer 21 'res3a_branch2b/bn' 2 128 80 80 (1638400)
I0916 17:01:08.576452 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2b/relu' of type 'ReLU'
I0916 17:01:08.576455 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.576458 20128 net.cpp:184] Created Layer res3a_branch2b/relu (22)
I0916 17:01:08.576462 20128 net.cpp:561] res3a_branch2b/relu <- res3a_branch2b
I0916 17:01:08.576465 20128 net.cpp:513] res3a_branch2b/relu -> res3a_branch2b (in-place)
I0916 17:01:08.576470 20128 net.cpp:245] Setting up res3a_branch2b/relu
I0916 17:01:08.576475 20128 net.cpp:252] TEST Top shape for layer 22 'res3a_branch2b/relu' 2 128 80 80 (1638400)
I0916 17:01:08.576478 20128 layer_factory.hpp:136] Creating layer 'res3a_branch2b_res3a_branch2b/relu_0_split' of type 'Split'
I0916 17:01:08.576483 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.576488 20128 net.cpp:184] Created Layer res3a_branch2b_res3a_branch2b/relu_0_split (23)
I0916 17:01:08.576491 20128 net.cpp:561] res3a_branch2b_res3a_branch2b/relu_0_split <- res3a_branch2b
I0916 17:01:08.576494 20128 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_0
I0916 17:01:08.576499 20128 net.cpp:530] res3a_branch2b_res3a_branch2b/relu_0_split -> res3a_branch2b_res3a_branch2b/relu_0_split_1
I0916 17:01:08.576550 20128 net.cpp:245] Setting up res3a_branch2b_res3a_branch2b/relu_0_split
I0916 17:01:08.576555 20128 net.cpp:252] TEST Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 2 128 80 80 (1638400)
I0916 17:01:08.576560 20128 net.cpp:252] TEST Top shape for layer 23 'res3a_branch2b_res3a_branch2b/relu_0_split' 2 128 80 80 (1638400)
I0916 17:01:08.576562 20128 layer_factory.hpp:136] Creating layer 'pool3' of type 'Pooling'
I0916 17:01:08.576566 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.576572 20128 net.cpp:184] Created Layer pool3 (24)
I0916 17:01:08.576575 20128 net.cpp:561] pool3 <- res3a_branch2b_res3a_branch2b/relu_0_split_0
I0916 17:01:08.576580 20128 net.cpp:530] pool3 -> pool3
I0916 17:01:08.576640 20128 net.cpp:245] Setting up pool3
I0916 17:01:08.576645 20128 net.cpp:252] TEST Top shape for layer 24 'pool3' 2 128 40 40 (409600)
I0916 17:01:08.576649 20128 layer_factory.hpp:136] Creating layer 'res4a_branch2a' of type 'Convolution'
I0916 17:01:08.576653 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.576660 20128 net.cpp:184] Created Layer res4a_branch2a (25)
I0916 17:01:08.576664 20128 net.cpp:561] res4a_branch2a <- pool3
I0916 17:01:08.576666 20128 net.cpp:530] res4a_branch2a -> res4a_branch2a
I0916 17:01:08.582860 20128 net.cpp:245] Setting up res4a_branch2a
I0916 17:01:08.582870 20128 net.cpp:252] TEST Top shape for layer 25 'res4a_branch2a' 2 256 40 40 (819200)
I0916 17:01:08.582875 20128 layer_factory.hpp:136] Creating layer 'res4a_branch2a/bn' of type 'BatchNorm'
I0916 17:01:08.582886 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.582890 20128 net.cpp:184] Created Layer res4a_branch2a/bn (26)
I0916 17:01:08.582893 20128 net.cpp:561] res4a_branch2a/bn <- res4a_branch2a
I0916 17:01:08.582895 20128 net.cpp:513] res4a_branch2a/bn -> res4a_branch2a (in-place)
I0916 17:01:08.583547 20128 net.cpp:245] Setting up res4a_branch2a/bn
I0916 17:01:08.583555 20128 net.cpp:252] TEST Top shape for layer 26 'res4a_branch2a/bn' 2 256 40 40 (819200)
I0916 17:01:08.583561 20128 layer_factory.hpp:136] Creating layer 'res4a_branch2a/relu' of type 'ReLU'
I0916 17:01:08.583564 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.583567 20128 net.cpp:184] Created Layer res4a_branch2a/relu (27)
I0916 17:01:08.583570 20128 net.cpp:561] res4a_branch2a/relu <- res4a_branch2a
I0916 17:01:08.583571 20128 net.cpp:513] res4a_branch2a/relu -> res4a_branch2a (in-place)
I0916 17:01:08.583575 20128 net.cpp:245] Setting up res4a_branch2a/relu
I0916 17:01:08.583577 20128 net.cpp:252] TEST Top shape for layer 27 'res4a_branch2a/relu' 2 256 40 40 (819200)
I0916 17:01:08.583580 20128 layer_factory.hpp:136] Creating layer 'res4a_branch2b' of type 'Convolution'
I0916 17:01:08.583581 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.583595 20128 net.cpp:184] Created Layer res4a_branch2b (28)
I0916 17:01:08.583597 20128 net.cpp:561] res4a_branch2b <- res4a_branch2a
I0916 17:01:08.583600 20128 net.cpp:530] res4a_branch2b -> res4a_branch2b
I0916 17:01:08.588017 20128 net.cpp:245] Setting up res4a_branch2b
I0916 17:01:08.588034 20128 net.cpp:252] TEST Top shape for layer 28 'res4a_branch2b' 2 256 40 40 (819200)
I0916 17:01:08.588040 20128 layer_factory.hpp:136] Creating layer 'res4a_branch2b/bn' of type 'BatchNorm'
I0916 17:01:08.588043 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.588049 20128 net.cpp:184] Created Layer res4a_branch2b/bn (29)
I0916 17:01:08.588052 20128 net.cpp:561] res4a_branch2b/bn <- res4a_branch2b
I0916 17:01:08.588054 20128 net.cpp:513] res4a_branch2b/bn -> res4a_branch2b (in-place)
I0916 17:01:08.588707 20128 net.cpp:245] Setting up res4a_branch2b/bn
I0916 17:01:08.588714 20128 net.cpp:252] TEST Top shape for layer 29 'res4a_branch2b/bn' 2 256 40 40 (819200)
I0916 17:01:08.588721 20128 layer_factory.hpp:136] Creating layer 'res4a_branch2b/relu' of type 'ReLU'
I0916 17:01:08.588722 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.588726 20128 net.cpp:184] Created Layer res4a_branch2b/relu (30)
I0916 17:01:08.588728 20128 net.cpp:561] res4a_branch2b/relu <- res4a_branch2b
I0916 17:01:08.588731 20128 net.cpp:513] res4a_branch2b/relu -> res4a_branch2b (in-place)
I0916 17:01:08.588734 20128 net.cpp:245] Setting up res4a_branch2b/relu
I0916 17:01:08.588737 20128 net.cpp:252] TEST Top shape for layer 30 'res4a_branch2b/relu' 2 256 40 40 (819200)
I0916 17:01:08.588739 20128 layer_factory.hpp:136] Creating layer 'pool4' of type 'Pooling'
I0916 17:01:08.588742 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.588745 20128 net.cpp:184] Created Layer pool4 (31)
I0916 17:01:08.588748 20128 net.cpp:561] pool4 <- res4a_branch2b
I0916 17:01:08.588750 20128 net.cpp:530] pool4 -> pool4
I0916 17:01:08.588819 20128 net.cpp:245] Setting up pool4
I0916 17:01:08.588822 20128 net.cpp:252] TEST Top shape for layer 31 'pool4' 2 256 40 40 (819200)
I0916 17:01:08.588825 20128 layer_factory.hpp:136] Creating layer 'res5a_branch2a' of type 'Convolution'
I0916 17:01:08.588827 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.588835 20128 net.cpp:184] Created Layer res5a_branch2a (32)
I0916 17:01:08.588836 20128 net.cpp:561] res5a_branch2a <- pool4
I0916 17:01:08.588848 20128 net.cpp:530] res5a_branch2a -> res5a_branch2a
I0916 17:01:08.613878 20128 net.cpp:245] Setting up res5a_branch2a
I0916 17:01:08.613906 20128 net.cpp:252] TEST Top shape for layer 32 'res5a_branch2a' 2 512 40 40 (1638400)
I0916 17:01:08.613915 20128 layer_factory.hpp:136] Creating layer 'res5a_branch2a/bn' of type 'BatchNorm'
I0916 17:01:08.613920 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.613932 20128 net.cpp:184] Created Layer res5a_branch2a/bn (33)
I0916 17:01:08.613936 20128 net.cpp:561] res5a_branch2a/bn <- res5a_branch2a
I0916 17:01:08.613941 20128 net.cpp:513] res5a_branch2a/bn -> res5a_branch2a (in-place)
I0916 17:01:08.614737 20128 net.cpp:245] Setting up res5a_branch2a/bn
I0916 17:01:08.614749 20128 net.cpp:252] TEST Top shape for layer 33 'res5a_branch2a/bn' 2 512 40 40 (1638400)
I0916 17:01:08.614759 20128 layer_factory.hpp:136] Creating layer 'res5a_branch2a/relu' of type 'ReLU'
I0916 17:01:08.614763 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.614768 20128 net.cpp:184] Created Layer res5a_branch2a/relu (34)
I0916 17:01:08.614770 20128 net.cpp:561] res5a_branch2a/relu <- res5a_branch2a
I0916 17:01:08.614773 20128 net.cpp:513] res5a_branch2a/relu -> res5a_branch2a (in-place)
I0916 17:01:08.614778 20128 net.cpp:245] Setting up res5a_branch2a/relu
I0916 17:01:08.614779 20128 net.cpp:252] TEST Top shape for layer 34 'res5a_branch2a/relu' 2 512 40 40 (1638400)
I0916 17:01:08.614781 20128 layer_factory.hpp:136] Creating layer 'res5a_branch2b' of type 'Convolution'
I0916 17:01:08.614784 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.614791 20128 net.cpp:184] Created Layer res5a_branch2b (35)
I0916 17:01:08.614795 20128 net.cpp:561] res5a_branch2b <- res5a_branch2a
I0916 17:01:08.614800 20128 net.cpp:530] res5a_branch2b -> res5a_branch2b
I0916 17:01:08.627890 20128 net.cpp:245] Setting up res5a_branch2b
I0916 17:01:08.627907 20128 net.cpp:252] TEST Top shape for layer 35 'res5a_branch2b' 2 512 40 40 (1638400)
I0916 17:01:08.627915 20128 layer_factory.hpp:136] Creating layer 'res5a_branch2b/bn' of type 'BatchNorm'
I0916 17:01:08.627919 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.627925 20128 net.cpp:184] Created Layer res5a_branch2b/bn (36)
I0916 17:01:08.627928 20128 net.cpp:561] res5a_branch2b/bn <- res5a_branch2b
I0916 17:01:08.627931 20128 net.cpp:513] res5a_branch2b/bn -> res5a_branch2b (in-place)
I0916 17:01:08.628584 20128 net.cpp:245] Setting up res5a_branch2b/bn
I0916 17:01:08.628592 20128 net.cpp:252] TEST Top shape for layer 36 'res5a_branch2b/bn' 2 512 40 40 (1638400)
I0916 17:01:08.628597 20128 layer_factory.hpp:136] Creating layer 'res5a_branch2b/relu' of type 'ReLU'
I0916 17:01:08.628599 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.628602 20128 net.cpp:184] Created Layer res5a_branch2b/relu (37)
I0916 17:01:08.628605 20128 net.cpp:561] res5a_branch2b/relu <- res5a_branch2b
I0916 17:01:08.628607 20128 net.cpp:513] res5a_branch2b/relu -> res5a_branch2b (in-place)
I0916 17:01:08.628612 20128 net.cpp:245] Setting up res5a_branch2b/relu
I0916 17:01:08.628613 20128 net.cpp:252] TEST Top shape for layer 37 'res5a_branch2b/relu' 2 512 40 40 (1638400)
I0916 17:01:08.628615 20128 layer_factory.hpp:136] Creating layer 'out5a' of type 'Convolution'
I0916 17:01:08.628618 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.628628 20128 net.cpp:184] Created Layer out5a (38)
I0916 17:01:08.628630 20128 net.cpp:561] out5a <- res5a_branch2b
I0916 17:01:08.628633 20128 net.cpp:530] out5a -> out5a
I0916 17:01:08.631914 20128 net.cpp:245] Setting up out5a
I0916 17:01:08.631922 20128 net.cpp:252] TEST Top shape for layer 38 'out5a' 2 64 40 40 (204800)
I0916 17:01:08.631927 20128 layer_factory.hpp:136] Creating layer 'out5a/bn' of type 'BatchNorm'
I0916 17:01:08.631938 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.631942 20128 net.cpp:184] Created Layer out5a/bn (39)
I0916 17:01:08.631945 20128 net.cpp:561] out5a/bn <- out5a
I0916 17:01:08.631947 20128 net.cpp:513] out5a/bn -> out5a (in-place)
I0916 17:01:08.632616 20128 net.cpp:245] Setting up out5a/bn
I0916 17:01:08.632623 20128 net.cpp:252] TEST Top shape for layer 39 'out5a/bn' 2 64 40 40 (204800)
I0916 17:01:08.632628 20128 layer_factory.hpp:136] Creating layer 'out5a/relu' of type 'ReLU'
I0916 17:01:08.632632 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.632634 20128 net.cpp:184] Created Layer out5a/relu (40)
I0916 17:01:08.632637 20128 net.cpp:561] out5a/relu <- out5a
I0916 17:01:08.632638 20128 net.cpp:513] out5a/relu -> out5a (in-place)
I0916 17:01:08.632642 20128 net.cpp:245] Setting up out5a/relu
I0916 17:01:08.632644 20128 net.cpp:252] TEST Top shape for layer 40 'out5a/relu' 2 64 40 40 (204800)
I0916 17:01:08.632647 20128 layer_factory.hpp:136] Creating layer 'out5a_up2' of type 'Deconvolution'
I0916 17:01:08.632648 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.632653 20128 net.cpp:184] Created Layer out5a_up2 (41)
I0916 17:01:08.632655 20128 net.cpp:561] out5a_up2 <- out5a
I0916 17:01:08.632658 20128 net.cpp:530] out5a_up2 -> out5a_up2
I0916 17:01:08.632949 20128 net.cpp:245] Setting up out5a_up2
I0916 17:01:08.632954 20128 net.cpp:252] TEST Top shape for layer 41 'out5a_up2' 2 64 80 80 (819200)
I0916 17:01:08.632957 20128 layer_factory.hpp:136] Creating layer 'out3a' of type 'Convolution'
I0916 17:01:08.632961 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.632968 20128 net.cpp:184] Created Layer out3a (42)
I0916 17:01:08.632972 20128 net.cpp:561] out3a <- res3a_branch2b_res3a_branch2b/relu_0_split_1
I0916 17:01:08.632973 20128 net.cpp:530] out3a -> out3a
I0916 17:01:08.634084 20128 net.cpp:245] Setting up out3a
I0916 17:01:08.634093 20128 net.cpp:252] TEST Top shape for layer 42 'out3a' 2 64 80 80 (819200)
I0916 17:01:08.634096 20128 layer_factory.hpp:136] Creating layer 'out3a/bn' of type 'BatchNorm'
I0916 17:01:08.634099 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.634102 20128 net.cpp:184] Created Layer out3a/bn (43)
I0916 17:01:08.634105 20128 net.cpp:561] out3a/bn <- out3a
I0916 17:01:08.634107 20128 net.cpp:513] out3a/bn -> out3a (in-place)
I0916 17:01:08.634781 20128 net.cpp:245] Setting up out3a/bn
I0916 17:01:08.634788 20128 net.cpp:252] TEST Top shape for layer 43 'out3a/bn' 2 64 80 80 (819200)
I0916 17:01:08.634793 20128 layer_factory.hpp:136] Creating layer 'out3a/relu' of type 'ReLU'
I0916 17:01:08.634795 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.634799 20128 net.cpp:184] Created Layer out3a/relu (44)
I0916 17:01:08.634800 20128 net.cpp:561] out3a/relu <- out3a
I0916 17:01:08.634804 20128 net.cpp:513] out3a/relu -> out3a (in-place)
I0916 17:01:08.634806 20128 net.cpp:245] Setting up out3a/relu
I0916 17:01:08.634809 20128 net.cpp:252] TEST Top shape for layer 44 'out3a/relu' 2 64 80 80 (819200)
I0916 17:01:08.634810 20128 layer_factory.hpp:136] Creating layer 'out3_out5_combined' of type 'Eltwise'
I0916 17:01:08.634814 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.634816 20128 net.cpp:184] Created Layer out3_out5_combined (45)
I0916 17:01:08.634819 20128 net.cpp:561] out3_out5_combined <- out5a_up2
I0916 17:01:08.634820 20128 net.cpp:561] out3_out5_combined <- out3a
I0916 17:01:08.634824 20128 net.cpp:530] out3_out5_combined -> out3_out5_combined
I0916 17:01:08.634848 20128 net.cpp:245] Setting up out3_out5_combined
I0916 17:01:08.634852 20128 net.cpp:252] TEST Top shape for layer 45 'out3_out5_combined' 2 64 80 80 (819200)
I0916 17:01:08.634860 20128 layer_factory.hpp:136] Creating layer 'ctx_conv1' of type 'Convolution'
I0916 17:01:08.634863 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.634868 20128 net.cpp:184] Created Layer ctx_conv1 (46)
I0916 17:01:08.634871 20128 net.cpp:561] ctx_conv1 <- out3_out5_combined
I0916 17:01:08.634873 20128 net.cpp:530] ctx_conv1 -> ctx_conv1
I0916 17:01:08.635972 20128 net.cpp:245] Setting up ctx_conv1
I0916 17:01:08.635978 20128 net.cpp:252] TEST Top shape for layer 46 'ctx_conv1' 2 64 80 80 (819200)
I0916 17:01:08.635983 20128 layer_factory.hpp:136] Creating layer 'ctx_conv1/bn' of type 'BatchNorm'
I0916 17:01:08.635985 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.635998 20128 net.cpp:184] Created Layer ctx_conv1/bn (47)
I0916 17:01:08.636001 20128 net.cpp:561] ctx_conv1/bn <- ctx_conv1
I0916 17:01:08.636003 20128 net.cpp:513] ctx_conv1/bn -> ctx_conv1 (in-place)
I0916 17:01:08.636662 20128 net.cpp:245] Setting up ctx_conv1/bn
I0916 17:01:08.636670 20128 net.cpp:252] TEST Top shape for layer 47 'ctx_conv1/bn' 2 64 80 80 (819200)
I0916 17:01:08.636675 20128 layer_factory.hpp:136] Creating layer 'ctx_conv1/relu' of type 'ReLU'
I0916 17:01:08.636678 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.636682 20128 net.cpp:184] Created Layer ctx_conv1/relu (48)
I0916 17:01:08.636683 20128 net.cpp:561] ctx_conv1/relu <- ctx_conv1
I0916 17:01:08.636685 20128 net.cpp:513] ctx_conv1/relu -> ctx_conv1 (in-place)
I0916 17:01:08.636688 20128 net.cpp:245] Setting up ctx_conv1/relu
I0916 17:01:08.636692 20128 net.cpp:252] TEST Top shape for layer 48 'ctx_conv1/relu' 2 64 80 80 (819200)
I0916 17:01:08.636693 20128 layer_factory.hpp:136] Creating layer 'ctx_conv2' of type 'Convolution'
I0916 17:01:08.636695 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.636699 20128 net.cpp:184] Created Layer ctx_conv2 (49)
I0916 17:01:08.636703 20128 net.cpp:561] ctx_conv2 <- ctx_conv1
I0916 17:01:08.636704 20128 net.cpp:530] ctx_conv2 -> ctx_conv2
I0916 17:01:08.637853 20128 net.cpp:245] Setting up ctx_conv2
I0916 17:01:08.637861 20128 net.cpp:252] TEST Top shape for layer 49 'ctx_conv2' 2 64 80 80 (819200)
I0916 17:01:08.637866 20128 layer_factory.hpp:136] Creating layer 'ctx_conv2/bn' of type 'BatchNorm'
I0916 17:01:08.637868 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.637873 20128 net.cpp:184] Created Layer ctx_conv2/bn (50)
I0916 17:01:08.637876 20128 net.cpp:561] ctx_conv2/bn <- ctx_conv2
I0916 17:01:08.637877 20128 net.cpp:513] ctx_conv2/bn -> ctx_conv2 (in-place)
I0916 17:01:08.638550 20128 net.cpp:245] Setting up ctx_conv2/bn
I0916 17:01:08.638558 20128 net.cpp:252] TEST Top shape for layer 50 'ctx_conv2/bn' 2 64 80 80 (819200)
I0916 17:01:08.638563 20128 layer_factory.hpp:136] Creating layer 'ctx_conv2/relu' of type 'ReLU'
I0916 17:01:08.638566 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.638569 20128 net.cpp:184] Created Layer ctx_conv2/relu (51)
I0916 17:01:08.638571 20128 net.cpp:561] ctx_conv2/relu <- ctx_conv2
I0916 17:01:08.638573 20128 net.cpp:513] ctx_conv2/relu -> ctx_conv2 (in-place)
I0916 17:01:08.638577 20128 net.cpp:245] Setting up ctx_conv2/relu
I0916 17:01:08.638579 20128 net.cpp:252] TEST Top shape for layer 51 'ctx_conv2/relu' 2 64 80 80 (819200)
I0916 17:01:08.638581 20128 layer_factory.hpp:136] Creating layer 'ctx_conv3' of type 'Convolution'
I0916 17:01:08.638583 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.638588 20128 net.cpp:184] Created Layer ctx_conv3 (52)
I0916 17:01:08.638590 20128 net.cpp:561] ctx_conv3 <- ctx_conv2
I0916 17:01:08.638593 20128 net.cpp:530] ctx_conv3 -> ctx_conv3
I0916 17:01:08.639729 20128 net.cpp:245] Setting up ctx_conv3
I0916 17:01:08.639747 20128 net.cpp:252] TEST Top shape for layer 52 'ctx_conv3' 2 64 80 80 (819200)
I0916 17:01:08.639753 20128 layer_factory.hpp:136] Creating layer 'ctx_conv3/bn' of type 'BatchNorm'
I0916 17:01:08.639756 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.639770 20128 net.cpp:184] Created Layer ctx_conv3/bn (53)
I0916 17:01:08.639773 20128 net.cpp:561] ctx_conv3/bn <- ctx_conv3
I0916 17:01:08.639776 20128 net.cpp:513] ctx_conv3/bn -> ctx_conv3 (in-place)
I0916 17:01:08.640477 20128 net.cpp:245] Setting up ctx_conv3/bn
I0916 17:01:08.640491 20128 net.cpp:252] TEST Top shape for layer 53 'ctx_conv3/bn' 2 64 80 80 (819200)
I0916 17:01:08.640497 20128 layer_factory.hpp:136] Creating layer 'ctx_conv3/relu' of type 'ReLU'
I0916 17:01:08.640501 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.640508 20128 net.cpp:184] Created Layer ctx_conv3/relu (54)
I0916 17:01:08.640511 20128 net.cpp:561] ctx_conv3/relu <- ctx_conv3
I0916 17:01:08.640516 20128 net.cpp:513] ctx_conv3/relu -> ctx_conv3 (in-place)
I0916 17:01:08.640522 20128 net.cpp:245] Setting up ctx_conv3/relu
I0916 17:01:08.640527 20128 net.cpp:252] TEST Top shape for layer 54 'ctx_conv3/relu' 2 64 80 80 (819200)
I0916 17:01:08.640530 20128 layer_factory.hpp:136] Creating layer 'ctx_conv4' of type 'Convolution'
I0916 17:01:08.640533 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.640543 20128 net.cpp:184] Created Layer ctx_conv4 (55)
I0916 17:01:08.640547 20128 net.cpp:561] ctx_conv4 <- ctx_conv3
I0916 17:01:08.640549 20128 net.cpp:530] ctx_conv4 -> ctx_conv4
I0916 17:01:08.641708 20128 net.cpp:245] Setting up ctx_conv4
I0916 17:01:08.641719 20128 net.cpp:252] TEST Top shape for layer 55 'ctx_conv4' 2 64 80 80 (819200)
I0916 17:01:08.641724 20128 layer_factory.hpp:136] Creating layer 'ctx_conv4/bn' of type 'BatchNorm'
I0916 17:01:08.641727 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.641733 20128 net.cpp:184] Created Layer ctx_conv4/bn (56)
I0916 17:01:08.641736 20128 net.cpp:561] ctx_conv4/bn <- ctx_conv4
I0916 17:01:08.641739 20128 net.cpp:513] ctx_conv4/bn -> ctx_conv4 (in-place)
I0916 17:01:08.642490 20128 net.cpp:245] Setting up ctx_conv4/bn
I0916 17:01:08.642518 20128 net.cpp:252] TEST Top shape for layer 56 'ctx_conv4/bn' 2 64 80 80 (819200)
I0916 17:01:08.642530 20128 layer_factory.hpp:136] Creating layer 'ctx_conv4/relu' of type 'ReLU'
I0916 17:01:08.642535 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.642544 20128 net.cpp:184] Created Layer ctx_conv4/relu (57)
I0916 17:01:08.642549 20128 net.cpp:561] ctx_conv4/relu <- ctx_conv4
I0916 17:01:08.642554 20128 net.cpp:513] ctx_conv4/relu -> ctx_conv4 (in-place)
I0916 17:01:08.642558 20128 net.cpp:245] Setting up ctx_conv4/relu
I0916 17:01:08.642561 20128 net.cpp:252] TEST Top shape for layer 57 'ctx_conv4/relu' 2 64 80 80 (819200)
I0916 17:01:08.642563 20128 layer_factory.hpp:136] Creating layer 'ctx_final' of type 'Convolution'
I0916 17:01:08.642565 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.642580 20128 net.cpp:184] Created Layer ctx_final (58)
I0916 17:01:08.642583 20128 net.cpp:561] ctx_final <- ctx_conv4
I0916 17:01:08.642586 20128 net.cpp:530] ctx_final -> ctx_final
I0916 17:01:08.643231 20128 net.cpp:245] Setting up ctx_final
I0916 17:01:08.643250 20128 net.cpp:252] TEST Top shape for layer 58 'ctx_final' 2 8 80 80 (102400)
I0916 17:01:08.643255 20128 layer_factory.hpp:136] Creating layer 'ctx_final/relu' of type 'ReLU'
I0916 17:01:08.643260 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.643265 20128 net.cpp:184] Created Layer ctx_final/relu (59)
I0916 17:01:08.643267 20128 net.cpp:561] ctx_final/relu <- ctx_final
I0916 17:01:08.643270 20128 net.cpp:513] ctx_final/relu -> ctx_final (in-place)
I0916 17:01:08.643286 20128 net.cpp:245] Setting up ctx_final/relu
I0916 17:01:08.643290 20128 net.cpp:252] TEST Top shape for layer 59 'ctx_final/relu' 2 8 80 80 (102400)
I0916 17:01:08.643292 20128 layer_factory.hpp:136] Creating layer 'out_deconv_final_up2' of type 'Deconvolution'
I0916 17:01:08.643295 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.643306 20128 net.cpp:184] Created Layer out_deconv_final_up2 (60)
I0916 17:01:08.643309 20128 net.cpp:561] out_deconv_final_up2 <- ctx_final
I0916 17:01:08.643312 20128 net.cpp:530] out_deconv_final_up2 -> out_deconv_final_up2
I0916 17:01:08.643599 20128 net.cpp:245] Setting up out_deconv_final_up2
I0916 17:01:08.643604 20128 net.cpp:252] TEST Top shape for layer 60 'out_deconv_final_up2' 2 8 160 160 (409600)
I0916 17:01:08.643607 20128 layer_factory.hpp:136] Creating layer 'out_deconv_final_up4' of type 'Deconvolution'
I0916 17:01:08.643610 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.643615 20128 net.cpp:184] Created Layer out_deconv_final_up4 (61)
I0916 17:01:08.643617 20128 net.cpp:561] out_deconv_final_up4 <- out_deconv_final_up2
I0916 17:01:08.643620 20128 net.cpp:530] out_deconv_final_up4 -> out_deconv_final_up4
I0916 17:01:08.643903 20128 net.cpp:245] Setting up out_deconv_final_up4
I0916 17:01:08.643908 20128 net.cpp:252] TEST Top shape for layer 61 'out_deconv_final_up4' 2 8 320 320 (1638400)
I0916 17:01:08.643911 20128 layer_factory.hpp:136] Creating layer 'out_deconv_final_up8' of type 'Deconvolution'
I0916 17:01:08.643914 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.643919 20128 net.cpp:184] Created Layer out_deconv_final_up8 (62)
I0916 17:01:08.643924 20128 net.cpp:561] out_deconv_final_up8 <- out_deconv_final_up4
I0916 17:01:08.643929 20128 net.cpp:530] out_deconv_final_up8 -> out_deconv_final_up8
I0916 17:01:08.644207 20128 net.cpp:245] Setting up out_deconv_final_up8
I0916 17:01:08.644212 20128 net.cpp:252] TEST Top shape for layer 62 'out_deconv_final_up8' 2 8 640 640 (6553600)
I0916 17:01:08.644215 20128 layer_factory.hpp:136] Creating layer 'out_deconv_final_up8_out_deconv_final_up8_0_split' of type 'Split'
I0916 17:01:08.644218 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.644222 20128 net.cpp:184] Created Layer out_deconv_final_up8_out_deconv_final_up8_0_split (63)
I0916 17:01:08.644227 20128 net.cpp:561] out_deconv_final_up8_out_deconv_final_up8_0_split <- out_deconv_final_up8
I0916 17:01:08.644229 20128 net.cpp:530] out_deconv_final_up8_out_deconv_final_up8_0_split -> out_deconv_final_up8_out_deconv_final_up8_0_split_0
I0916 17:01:08.644233 20128 net.cpp:530] out_deconv_final_up8_out_deconv_final_up8_0_split -> out_deconv_final_up8_out_deconv_final_up8_0_split_1
I0916 17:01:08.644237 20128 net.cpp:530] out_deconv_final_up8_out_deconv_final_up8_0_split -> out_deconv_final_up8_out_deconv_final_up8_0_split_2
I0916 17:01:08.644304 20128 net.cpp:245] Setting up out_deconv_final_up8_out_deconv_final_up8_0_split
I0916 17:01:08.644309 20128 net.cpp:252] TEST Top shape for layer 63 'out_deconv_final_up8_out_deconv_final_up8_0_split' 2 8 640 640 (6553600)
I0916 17:01:08.644311 20128 net.cpp:252] TEST Top shape for layer 63 'out_deconv_final_up8_out_deconv_final_up8_0_split' 2 8 640 640 (6553600)
I0916 17:01:08.644314 20128 net.cpp:252] TEST Top shape for layer 63 'out_deconv_final_up8_out_deconv_final_up8_0_split' 2 8 640 640 (6553600)
I0916 17:01:08.644316 20128 layer_factory.hpp:136] Creating layer 'loss' of type 'SoftmaxWithLoss'
I0916 17:01:08.644320 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.644331 20128 net.cpp:184] Created Layer loss (64)
I0916 17:01:08.644335 20128 net.cpp:561] loss <- out_deconv_final_up8_out_deconv_final_up8_0_split_0
I0916 17:01:08.644338 20128 net.cpp:561] loss <- label_data_1_split_0
I0916 17:01:08.644346 20128 net.cpp:530] loss -> loss
I0916 17:01:08.645406 20128 net.cpp:245] Setting up loss
I0916 17:01:08.645450 20128 net.cpp:252] TEST Top shape for layer 64 'loss' (1)
I0916 17:01:08.645455 20128 net.cpp:256]     with loss weight 1
I0916 17:01:08.645470 20128 layer_factory.hpp:136] Creating layer 'accuracy/top1' of type 'Accuracy'
I0916 17:01:08.645476 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.645505 20128 net.cpp:184] Created Layer accuracy/top1 (65)
I0916 17:01:08.645512 20128 net.cpp:561] accuracy/top1 <- out_deconv_final_up8_out_deconv_final_up8_0_split_1
I0916 17:01:08.645520 20128 net.cpp:561] accuracy/top1 <- label_data_1_split_1
I0916 17:01:08.645525 20128 net.cpp:530] accuracy/top1 -> accuracy/top1
I0916 17:01:08.645535 20128 net.cpp:245] Setting up accuracy/top1
I0916 17:01:08.645539 20128 net.cpp:252] TEST Top shape for layer 65 'accuracy/top1' (1)
I0916 17:01:08.645541 20128 layer_factory.hpp:136] Creating layer 'accuracy/top5' of type 'Accuracy'
I0916 17:01:08.645543 20128 layer_factory.hpp:148] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT
I0916 17:01:08.645547 20128 net.cpp:184] Created Layer accuracy/top5 (66)
I0916 17:01:08.645550 20128 net.cpp:561] accuracy/top5 <- out_deconv_final_up8_out_deconv_final_up8_0_split_2
I0916 17:01:08.645552 20128 net.cpp:561] accuracy/top5 <- label_data_1_split_2
I0916 17:01:08.645555 20128 net.cpp:530] accuracy/top5 -> accuracy/top5
I0916 17:01:08.645570 20128 net.cpp:245] Setting up accuracy/top5
I0916 17:01:08.645575 20128 net.cpp:252] TEST Top shape for layer 66 'accuracy/top5' (1)
I0916 17:01:08.645576 20128 net.cpp:325] accuracy/top5 does not need backward computation.
I0916 17:01:08.645579 20128 net.cpp:325] accuracy/top1 does not need backward computation.
I0916 17:01:08.645582 20128 net.cpp:323] loss needs backward computation.
I0916 17:01:08.645586 20128 net.cpp:323] out_deconv_final_up8_out_deconv_final_up8_0_split needs backward computation.
I0916 17:01:08.645588 20128 net.cpp:323] out_deconv_final_up8 needs backward computation.
I0916 17:01:08.645591 20128 net.cpp:323] out_deconv_final_up4 needs backward computation.
I0916 17:01:08.645592 20128 net.cpp:323] out_deconv_final_up2 needs backward computation.
I0916 17:01:08.645596 20128 net.cpp:323] ctx_final/relu needs backward computation.
I0916 17:01:08.645597 20128 net.cpp:323] ctx_final needs backward computation.
I0916 17:01:08.645601 20128 net.cpp:323] ctx_conv4/relu needs backward computation.
I0916 17:01:08.645602 20128 net.cpp:323] ctx_conv4/bn needs backward computation.
I0916 17:01:08.645604 20128 net.cpp:323] ctx_conv4 needs backward computation.
I0916 17:01:08.645606 20128 net.cpp:323] ctx_conv3/relu needs backward computation.
I0916 17:01:08.645608 20128 net.cpp:323] ctx_conv3/bn needs backward computation.
I0916 17:01:08.645611 20128 net.cpp:323] ctx_conv3 needs backward computation.
I0916 17:01:08.645612 20128 net.cpp:323] ctx_conv2/relu needs backward computation.
I0916 17:01:08.645614 20128 net.cpp:323] ctx_conv2/bn needs backward computation.
I0916 17:01:08.645617 20128 net.cpp:323] ctx_conv2 needs backward computation.
I0916 17:01:08.645619 20128 net.cpp:323] ctx_conv1/relu needs backward computation.
I0916 17:01:08.645622 20128 net.cpp:323] ctx_conv1/bn needs backward computation.
I0916 17:01:08.645623 20128 net.cpp:323] ctx_conv1 needs backward computation.
I0916 17:01:08.645625 20128 net.cpp:323] out3_out5_combined needs backward computation.
I0916 17:01:08.645628 20128 net.cpp:323] out3a/relu needs backward computation.
I0916 17:01:08.645630 20128 net.cpp:323] out3a/bn needs backward computation.
I0916 17:01:08.645632 20128 net.cpp:323] out3a needs backward computation.
I0916 17:01:08.645634 20128 net.cpp:323] out5a_up2 needs backward computation.
I0916 17:01:08.645637 20128 net.cpp:323] out5a/relu needs backward computation.
I0916 17:01:08.645640 20128 net.cpp:323] out5a/bn needs backward computation.
I0916 17:01:08.645642 20128 net.cpp:323] out5a needs backward computation.
I0916 17:01:08.645655 20128 net.cpp:323] res5a_branch2b/relu needs backward computation.
I0916 17:01:08.645658 20128 net.cpp:323] res5a_branch2b/bn needs backward computation.
I0916 17:01:08.645659 20128 net.cpp:323] res5a_branch2b needs backward computation.
I0916 17:01:08.645661 20128 net.cpp:323] res5a_branch2a/relu needs backward computation.
I0916 17:01:08.645663 20128 net.cpp:323] res5a_branch2a/bn needs backward computation.
I0916 17:01:08.645665 20128 net.cpp:323] res5a_branch2a needs backward computation.
I0916 17:01:08.645668 20128 net.cpp:323] pool4 needs backward computation.
I0916 17:01:08.645669 20128 net.cpp:323] res4a_branch2b/relu needs backward computation.
I0916 17:01:08.645671 20128 net.cpp:323] res4a_branch2b/bn needs backward computation.
I0916 17:01:08.645673 20128 net.cpp:323] res4a_branch2b needs backward computation.
I0916 17:01:08.645675 20128 net.cpp:323] res4a_branch2a/relu needs backward computation.
I0916 17:01:08.645678 20128 net.cpp:323] res4a_branch2a/bn needs backward computation.
I0916 17:01:08.645679 20128 net.cpp:323] res4a_branch2a needs backward computation.
I0916 17:01:08.645681 20128 net.cpp:323] pool3 needs backward computation.
I0916 17:01:08.645684 20128 net.cpp:323] res3a_branch2b_res3a_branch2b/relu_0_split needs backward computation.
I0916 17:01:08.645685 20128 net.cpp:323] res3a_branch2b/relu needs backward computation.
I0916 17:01:08.645687 20128 net.cpp:323] res3a_branch2b/bn needs backward computation.
I0916 17:01:08.645689 20128 net.cpp:323] res3a_branch2b needs backward computation.
I0916 17:01:08.645691 20128 net.cpp:323] res3a_branch2a/relu needs backward computation.
I0916 17:01:08.645694 20128 net.cpp:323] res3a_branch2a/bn needs backward computation.
I0916 17:01:08.645696 20128 net.cpp:323] res3a_branch2a needs backward computation.
I0916 17:01:08.645699 20128 net.cpp:323] pool2 needs backward computation.
I0916 17:01:08.645701 20128 net.cpp:323] res2a_branch2b/relu needs backward computation.
I0916 17:01:08.645704 20128 net.cpp:323] res2a_branch2b/bn needs backward computation.
I0916 17:01:08.645705 20128 net.cpp:323] res2a_branch2b needs backward computation.
I0916 17:01:08.645707 20128 net.cpp:323] res2a_branch2a/relu needs backward computation.
I0916 17:01:08.645709 20128 net.cpp:323] res2a_branch2a/bn needs backward computation.
I0916 17:01:08.645711 20128 net.cpp:323] res2a_branch2a needs backward computation.
I0916 17:01:08.645720 20128 net.cpp:323] pool1 needs backward computation.
I0916 17:01:08.645721 20128 net.cpp:323] conv1b/relu needs backward computation.
I0916 17:01:08.645725 20128 net.cpp:323] conv1b/bn needs backward computation.
I0916 17:01:08.645726 20128 net.cpp:323] conv1b needs backward computation.
I0916 17:01:08.645728 20128 net.cpp:323] conv1a/relu needs backward computation.
I0916 17:01:08.645730 20128 net.cpp:323] conv1a/bn needs backward computation.
I0916 17:01:08.645732 20128 net.cpp:323] conv1a needs backward computation.
I0916 17:01:08.645735 20128 net.cpp:325] data/bias does not need backward computation.
I0916 17:01:08.645736 20128 net.cpp:325] label_data_1_split does not need backward computation.
I0916 17:01:08.645740 20128 net.cpp:325] data does not need backward computation.
I0916 17:01:08.645741 20128 net.cpp:367] This network produces output accuracy/top1
I0916 17:01:08.645743 20128 net.cpp:367] This network produces output accuracy/top5
I0916 17:01:08.645745 20128 net.cpp:367] This network produces output loss
I0916 17:01:08.645803 20128 net.cpp:389] Top memory (TEST) required for data: 566886424 diff: 566886424
I0916 17:01:08.645807 20128 net.cpp:392] Bottom memory (TEST) required for data: 566886400 diff: 566886400
I0916 17:01:08.645809 20128 net.cpp:395] Shared (in-place) memory (TEST) by data: 257638400 diff: 257638400
I0916 17:01:08.645812 20128 net.cpp:398] Parameters memory (TEST) required for data: 10817840 diff: 10817840
I0916 17:01:08.645813 20128 net.cpp:401] Parameters shared memory (TEST) by data: 0 diff: 0
I0916 17:01:08.645815 20128 net.cpp:407] Network initialization done.
I0916 17:01:08.645946 20128 solver.cpp:57] Solver scaffolding done.
I0916 17:01:08.653220 20128 caffe.cpp:143] Finetuning from training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/initial/cityscapes5_jsegnet21v2_iter_120000.caffemodel
I0916 17:01:08.657879 20128 net.cpp:1094] Copying source layer data Type:ImageLabelData #blobs=0
I0916 17:01:08.657902 20128 net.cpp:1094] Copying source layer data/bias Type:Bias #blobs=1
I0916 17:01:08.657930 20128 net.cpp:1094] Copying source layer conv1a Type:Convolution #blobs=2
I0916 17:01:08.657941 20128 net.cpp:1094] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.658216 20128 net.cpp:1094] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0916 17:01:08.658223 20128 net.cpp:1094] Copying source layer conv1b Type:Convolution #blobs=2
I0916 17:01:08.658233 20128 net.cpp:1094] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0916 17:01:08.658380 20128 net.cpp:1094] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0916 17:01:08.658383 20128 net.cpp:1094] Copying source layer pool1 Type:Pooling #blobs=0
I0916 17:01:08.658385 20128 net.cpp:1094] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0916 17:01:08.658401 20128 net.cpp:1094] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.658552 20128 net.cpp:1094] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0916 17:01:08.658556 20128 net.cpp:1094] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0916 17:01:08.658568 20128 net.cpp:1094] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0916 17:01:08.658707 20128 net.cpp:1094] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0916 17:01:08.658712 20128 net.cpp:1094] Copying source layer pool2 Type:Pooling #blobs=0
I0916 17:01:08.658715 20128 net.cpp:1094] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0916 17:01:08.658756 20128 net.cpp:1094] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.658890 20128 net.cpp:1094] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0916 17:01:08.658893 20128 net.cpp:1094] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0916 17:01:08.658916 20128 net.cpp:1094] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0916 17:01:08.659034 20128 net.cpp:1094] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0916 17:01:08.659039 20128 net.cpp:1094] Copying source layer res3a_branch2b_res3a_branch2b/relu_0_split Type:Split #blobs=0
I0916 17:01:08.659041 20128 net.cpp:1094] Copying source layer pool3 Type:Pooling #blobs=0
I0916 17:01:08.659044 20128 net.cpp:1094] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0916 17:01:08.659155 20128 net.cpp:1094] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.659276 20128 net.cpp:1094] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0916 17:01:08.659281 20128 net.cpp:1094] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0916 17:01:08.659339 20128 net.cpp:1094] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0916 17:01:08.659459 20128 net.cpp:1094] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0916 17:01:08.659464 20128 net.cpp:1094] Copying source layer pool4 Type:Pooling #blobs=0
I0916 17:01:08.659466 20128 net.cpp:1094] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0916 17:01:08.659812 20128 net.cpp:1094] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.659935 20128 net.cpp:1094] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0916 17:01:08.659940 20128 net.cpp:1094] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0916 17:01:08.660114 20128 net.cpp:1094] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0916 17:01:08.660230 20128 net.cpp:1094] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0916 17:01:08.660235 20128 net.cpp:1094] Copying source layer out5a Type:Convolution #blobs=2
I0916 17:01:08.660277 20128 net.cpp:1094] Copying source layer out5a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.660437 20128 net.cpp:1094] Copying source layer out5a/relu Type:ReLU #blobs=0
I0916 17:01:08.660442 20128 net.cpp:1094] Copying source layer out5a_up2 Type:Deconvolution #blobs=1
I0916 17:01:08.660449 20128 net.cpp:1094] Copying source layer out3a Type:Convolution #blobs=2
I0916 17:01:08.660466 20128 net.cpp:1094] Copying source layer out3a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.660610 20128 net.cpp:1094] Copying source layer out3a/relu Type:ReLU #blobs=0
I0916 17:01:08.660615 20128 net.cpp:1094] Copying source layer out3_out5_combined Type:Eltwise #blobs=0
I0916 17:01:08.660617 20128 net.cpp:1094] Copying source layer ctx_conv1 Type:Convolution #blobs=2
I0916 17:01:08.660634 20128 net.cpp:1094] Copying source layer ctx_conv1/bn Type:BatchNorm #blobs=5
I0916 17:01:08.660779 20128 net.cpp:1094] Copying source layer ctx_conv1/relu Type:ReLU #blobs=0
I0916 17:01:08.660784 20128 net.cpp:1094] Copying source layer ctx_conv2 Type:Convolution #blobs=2
I0916 17:01:08.660801 20128 net.cpp:1094] Copying source layer ctx_conv2/bn Type:BatchNorm #blobs=5
I0916 17:01:08.660946 20128 net.cpp:1094] Copying source layer ctx_conv2/relu Type:ReLU #blobs=0
I0916 17:01:08.660951 20128 net.cpp:1094] Copying source layer ctx_conv3 Type:Convolution #blobs=2
I0916 17:01:08.660969 20128 net.cpp:1094] Copying source layer ctx_conv3/bn Type:BatchNorm #blobs=5
I0916 17:01:08.661113 20128 net.cpp:1094] Copying source layer ctx_conv3/relu Type:ReLU #blobs=0
I0916 17:01:08.661118 20128 net.cpp:1094] Copying source layer ctx_conv4 Type:Convolution #blobs=2
I0916 17:01:08.661134 20128 net.cpp:1094] Copying source layer ctx_conv4/bn Type:BatchNorm #blobs=5
I0916 17:01:08.661276 20128 net.cpp:1094] Copying source layer ctx_conv4/relu Type:ReLU #blobs=0
I0916 17:01:08.661281 20128 net.cpp:1094] Copying source layer ctx_final Type:Convolution #blobs=2
I0916 17:01:08.661290 20128 net.cpp:1094] Copying source layer ctx_final/relu Type:ReLU #blobs=0
I0916 17:01:08.661294 20128 net.cpp:1094] Copying source layer out_deconv_final_up2 Type:Deconvolution #blobs=1
I0916 17:01:08.661298 20128 net.cpp:1094] Copying source layer out_deconv_final_up4 Type:Deconvolution #blobs=1
I0916 17:01:08.661305 20128 net.cpp:1094] Copying source layer out_deconv_final_up8 Type:Deconvolution #blobs=1
I0916 17:01:08.661311 20128 net.cpp:1094] Copying source layer loss Type:SoftmaxWithLoss #blobs=0
I0916 17:01:08.664500 20128 net.cpp:1094] Copying source layer data Type:ImageLabelData #blobs=0
I0916 17:01:08.664521 20128 net.cpp:1094] Copying source layer data/bias Type:Bias #blobs=1
I0916 17:01:08.664547 20128 net.cpp:1094] Copying source layer conv1a Type:Convolution #blobs=2
I0916 17:01:08.664561 20128 net.cpp:1094] Copying source layer conv1a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.664815 20128 net.cpp:1094] Copying source layer conv1a/relu Type:ReLU #blobs=0
I0916 17:01:08.664821 20128 net.cpp:1094] Copying source layer conv1b Type:Convolution #blobs=2
I0916 17:01:08.664831 20128 net.cpp:1094] Copying source layer conv1b/bn Type:BatchNorm #blobs=5
I0916 17:01:08.664983 20128 net.cpp:1094] Copying source layer conv1b/relu Type:ReLU #blobs=0
I0916 17:01:08.664988 20128 net.cpp:1094] Copying source layer pool1 Type:Pooling #blobs=0
I0916 17:01:08.664989 20128 net.cpp:1094] Copying source layer res2a_branch2a Type:Convolution #blobs=2
I0916 17:01:08.665005 20128 net.cpp:1094] Copying source layer res2a_branch2a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.665156 20128 net.cpp:1094] Copying source layer res2a_branch2a/relu Type:ReLU #blobs=0
I0916 17:01:08.665161 20128 net.cpp:1094] Copying source layer res2a_branch2b Type:Convolution #blobs=2
I0916 17:01:08.665174 20128 net.cpp:1094] Copying source layer res2a_branch2b/bn Type:BatchNorm #blobs=5
I0916 17:01:08.665319 20128 net.cpp:1094] Copying source layer res2a_branch2b/relu Type:ReLU #blobs=0
I0916 17:01:08.665324 20128 net.cpp:1094] Copying source layer pool2 Type:Pooling #blobs=0
I0916 17:01:08.665326 20128 net.cpp:1094] Copying source layer res3a_branch2a Type:Convolution #blobs=2
I0916 17:01:08.665374 20128 net.cpp:1094] Copying source layer res3a_branch2a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.665510 20128 net.cpp:1094] Copying source layer res3a_branch2a/relu Type:ReLU #blobs=0
I0916 17:01:08.665515 20128 net.cpp:1094] Copying source layer res3a_branch2b Type:Convolution #blobs=2
I0916 17:01:08.665539 20128 net.cpp:1094] Copying source layer res3a_branch2b/bn Type:BatchNorm #blobs=5
I0916 17:01:08.665658 20128 net.cpp:1094] Copying source layer res3a_branch2b/relu Type:ReLU #blobs=0
I0916 17:01:08.665664 20128 net.cpp:1094] Copying source layer res3a_branch2b_res3a_branch2b/relu_0_split Type:Split #blobs=0
I0916 17:01:08.665666 20128 net.cpp:1094] Copying source layer pool3 Type:Pooling #blobs=0
I0916 17:01:08.665669 20128 net.cpp:1094] Copying source layer res4a_branch2a Type:Convolution #blobs=2
I0916 17:01:08.665783 20128 net.cpp:1094] Copying source layer res4a_branch2a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.665906 20128 net.cpp:1094] Copying source layer res4a_branch2a/relu Type:ReLU #blobs=0
I0916 17:01:08.665910 20128 net.cpp:1094] Copying source layer res4a_branch2b Type:Convolution #blobs=2
I0916 17:01:08.665969 20128 net.cpp:1094] Copying source layer res4a_branch2b/bn Type:BatchNorm #blobs=5
I0916 17:01:08.666097 20128 net.cpp:1094] Copying source layer res4a_branch2b/relu Type:ReLU #blobs=0
I0916 17:01:08.666102 20128 net.cpp:1094] Copying source layer pool4 Type:Pooling #blobs=0
I0916 17:01:08.666105 20128 net.cpp:1094] Copying source layer res5a_branch2a Type:Convolution #blobs=2
I0916 17:01:08.666450 20128 net.cpp:1094] Copying source layer res5a_branch2a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.666575 20128 net.cpp:1094] Copying source layer res5a_branch2a/relu Type:ReLU #blobs=0
I0916 17:01:08.666580 20128 net.cpp:1094] Copying source layer res5a_branch2b Type:Convolution #blobs=2
I0916 17:01:08.666755 20128 net.cpp:1094] Copying source layer res5a_branch2b/bn Type:BatchNorm #blobs=5
I0916 17:01:08.666873 20128 net.cpp:1094] Copying source layer res5a_branch2b/relu Type:ReLU #blobs=0
I0916 17:01:08.666877 20128 net.cpp:1094] Copying source layer out5a Type:Convolution #blobs=2
I0916 17:01:08.666921 20128 net.cpp:1094] Copying source layer out5a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.667079 20128 net.cpp:1094] Copying source layer out5a/relu Type:ReLU #blobs=0
I0916 17:01:08.667084 20128 net.cpp:1094] Copying source layer out5a_up2 Type:Deconvolution #blobs=1
I0916 17:01:08.667091 20128 net.cpp:1094] Copying source layer out3a Type:Convolution #blobs=2
I0916 17:01:08.667110 20128 net.cpp:1094] Copying source layer out3a/bn Type:BatchNorm #blobs=5
I0916 17:01:08.667255 20128 net.cpp:1094] Copying source layer out3a/relu Type:ReLU #blobs=0
I0916 17:01:08.667260 20128 net.cpp:1094] Copying source layer out3_out5_combined Type:Eltwise #blobs=0
I0916 17:01:08.667263 20128 net.cpp:1094] Copying source layer ctx_conv1 Type:Convolution #blobs=2
I0916 17:01:08.667281 20128 net.cpp:1094] Copying source layer ctx_conv1/bn Type:BatchNorm #blobs=5
I0916 17:01:08.667425 20128 net.cpp:1094] Copying source layer ctx_conv1/relu Type:ReLU #blobs=0
I0916 17:01:08.667429 20128 net.cpp:1094] Copying source layer ctx_conv2 Type:Convolution #blobs=2
I0916 17:01:08.667448 20128 net.cpp:1094] Copying source layer ctx_conv2/bn Type:BatchNorm #blobs=5
I0916 17:01:08.667592 20128 net.cpp:1094] Copying source layer ctx_conv2/relu Type:ReLU #blobs=0
I0916 17:01:08.667596 20128 net.cpp:1094] Copying source layer ctx_conv3 Type:Convolution #blobs=2
I0916 17:01:08.667614 20128 net.cpp:1094] Copying source layer ctx_conv3/bn Type:BatchNorm #blobs=5
I0916 17:01:08.667757 20128 net.cpp:1094] Copying source layer ctx_conv3/relu Type:ReLU #blobs=0
I0916 17:01:08.667762 20128 net.cpp:1094] Copying source layer ctx_conv4 Type:Convolution #blobs=2
I0916 17:01:08.667779 20128 net.cpp:1094] Copying source layer ctx_conv4/bn Type:BatchNorm #blobs=5
I0916 17:01:08.667922 20128 net.cpp:1094] Copying source layer ctx_conv4/relu Type:ReLU #blobs=0
I0916 17:01:08.667927 20128 net.cpp:1094] Copying source layer ctx_final Type:Convolution #blobs=2
I0916 17:01:08.667943 20128 net.cpp:1094] Copying source layer ctx_final/relu Type:ReLU #blobs=0
I0916 17:01:08.667946 20128 net.cpp:1094] Copying source layer out_deconv_final_up2 Type:Deconvolution #blobs=1
I0916 17:01:08.667951 20128 net.cpp:1094] Copying source layer out_deconv_final_up4 Type:Deconvolution #blobs=1
I0916 17:01:08.667959 20128 net.cpp:1094] Copying source layer out_deconv_final_up8 Type:Deconvolution #blobs=1
I0916 17:01:08.667968 20128 net.cpp:1094] Copying source layer loss Type:SoftmaxWithLoss #blobs=0
I0916 17:01:08.668063 20128 parallel.cpp:106] [0 - 0] P2pSync adding callback
I0916 17:01:08.668068 20128 parallel.cpp:106] [1 - 1] P2pSync adding callback
I0916 17:01:08.668072 20128 parallel.cpp:106] [2 - 2] P2pSync adding callback
I0916 17:01:08.668076 20128 parallel.cpp:59] Starting Optimization
I0916 17:01:08.668081 20128 internal_thread.cpp:19] Starting 1 internal thread(s) on device 0
I0916 17:01:08.668108 20128 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 17:01:08.668123 20128 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 17:01:08.668817 20216 device_alternate.hpp:116] NVML initialized on thread 136238948763392
I0916 17:01:08.690589 20216 common.cpp:585] NVML succeeded to set CPU affinity on device 0
I0916 17:01:08.690649 20217 device_alternate.hpp:116] NVML initialized on thread 136238940370688
I0916 17:01:08.691726 20217 common.cpp:585] NVML succeeded to set CPU affinity on device 1
I0916 17:01:08.691764 20218 device_alternate.hpp:116] NVML initialized on thread 136238931977984
I0916 17:01:08.692556 20218 common.cpp:585] NVML succeeded to set CPU affinity on device 2
I0916 17:01:08.696141 20217 solver.cpp:43] Solver data type: FLOAT
W0916 17:01:08.696712 20217 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 16 to 18
I0916 17:01:08.696846 20217 net.cpp:104] Using FLOAT as default forward math type
I0916 17:01:08.696851 20217 net.cpp:110] Using FLOAT as default backward math type
I0916 17:01:08.696887 20217 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0916 17:01:08.696895 20217 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 17:01:08.700120 20218 solver.cpp:43] Solver data type: FLOAT
W0916 17:01:08.700634 20218 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 16 to 18
I0916 17:01:08.700740 20218 net.cpp:104] Using FLOAT as default forward math type
I0916 17:01:08.700747 20218 net.cpp:110] Using FLOAT as default backward math type
I0916 17:01:08.700775 20218 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0916 17:01:08.700783 20218 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 17:01:08.700898 20219 db_lmdb.cpp:24] Opened lmdb data/train-image-lmdb
I0916 17:01:08.701552 20220 db_lmdb.cpp:24] Opened lmdb data/train-image-lmdb
I0916 17:01:08.705286 20217 data_layer.cpp:187] [1] ReshapePrefetch 6, 3, 640, 640
I0916 17:01:08.705651 20218 data_layer.cpp:187] [2] ReshapePrefetch 6, 3, 640, 640
I0916 17:01:08.705708 20217 data_layer.cpp:211] [1] Output data size: 6, 3, 640, 640
I0916 17:01:08.705724 20217 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 17:01:08.705744 20218 data_layer.cpp:211] [2] Output data size: 6, 3, 640, 640
I0916 17:01:08.705754 20218 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 17:01:08.705811 20218 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0916 17:01:08.705811 20217 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 6
I0916 17:01:08.705823 20218 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 17:01:08.705904 20217 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 17:01:08.707024 20223 db_lmdb.cpp:24] Opened lmdb data/train-label-lmdb
I0916 17:01:08.707909 20221 data_layer.cpp:101] [1] Parser threads: 1
I0916 17:01:08.707936 20221 data_layer.cpp:103] [1] Transformer threads: 1
I0916 17:01:08.713850 20218 data_layer.cpp:187] [2] ReshapePrefetch 6, 1, 640, 640
I0916 17:01:08.714679 20218 data_layer.cpp:211] [2] Output data size: 6, 1, 640, 640
I0916 17:01:08.714694 20218 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 17:01:08.718097 20224 db_lmdb.cpp:24] Opened lmdb data/train-label-lmdb
I0916 17:01:08.720157 20222 data_layer.cpp:101] [2] Parser threads: 1
I0916 17:01:08.720204 20222 data_layer.cpp:103] [2] Transformer threads: 1
I0916 17:01:08.721855 20221 blocking_queue.cpp:40] Waiting for datum
I0916 17:01:08.728801 20217 data_layer.cpp:187] [1] ReshapePrefetch 6, 1, 640, 640
I0916 17:01:08.728780 20225 data_layer.cpp:101] [2] Parser threads: 1
I0916 17:01:08.729179 20225 data_layer.cpp:103] [2] Transformer threads: 1
I0916 17:01:08.732703 20217 data_layer.cpp:211] [1] Output data size: 6, 1, 640, 640
I0916 17:01:08.732743 20217 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 17:01:08.744824 20226 data_layer.cpp:101] [1] Parser threads: 1
I0916 17:01:08.744922 20226 data_layer.cpp:103] [1] Transformer threads: 1
I0916 17:01:09.412298 20218 solver.cpp:177] Creating test net (#0) specified by test_net file: training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/test.prototxt
W0916 17:01:09.412379 20218 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 4 to 6
I0916 17:01:09.412595 20218 net.cpp:104] Using FLOAT as default forward math type
I0916 17:01:09.412601 20218 net.cpp:110] Using FLOAT as default backward math type
I0916 17:01:09.412629 20218 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 2
I0916 17:01:09.412639 20218 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 17:01:09.413552 20241 db_lmdb.cpp:24] Opened lmdb data/val-image-lmdb
I0916 17:01:09.418262 20218 data_layer.cpp:187] (2) ReshapePrefetch 2, 3, 640, 640
I0916 17:01:09.418324 20218 data_layer.cpp:211] (2) Output data size: 2, 3, 640, 640
I0916 17:01:09.418331 20218 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 17:01:09.418385 20218 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 2
I0916 17:01:09.418392 20218 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 17:01:09.421582 20242 data_layer.cpp:101] (2) Parser threads: 1
I0916 17:01:09.421610 20242 data_layer.cpp:103] (2) Transformer threads: 1
I0916 17:01:09.422456 20243 db_lmdb.cpp:24] Opened lmdb data/val-label-lmdb
I0916 17:01:09.425357 20218 data_layer.cpp:187] (2) ReshapePrefetch 2, 1, 640, 640
I0916 17:01:09.425622 20218 data_layer.cpp:211] (2) Output data size: 2, 1, 640, 640
I0916 17:01:09.425699 20218 internal_thread.cpp:19] Starting 1 internal thread(s) on device 2
I0916 17:01:09.427683 20244 data_layer.cpp:101] (2) Parser threads: 1
I0916 17:01:09.427713 20244 data_layer.cpp:103] (2) Transformer threads: 1
I0916 17:01:09.439486 20217 solver.cpp:177] Creating test net (#0) specified by test_net file: training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/test.prototxt
W0916 17:01:09.439612 20217 parallel.cpp:272] Batch size must be divisible by the number of solvers (GPUs): it's been adjusted from 4 to 6
I0916 17:01:09.439821 20217 net.cpp:104] Using FLOAT as default forward math type
I0916 17:01:09.439831 20217 net.cpp:110] Using FLOAT as default backward math type
I0916 17:01:09.439869 20217 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 2
I0916 17:01:09.439879 20217 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 17:01:09.440915 20248 db_lmdb.cpp:24] Opened lmdb data/val-image-lmdb
I0916 17:01:09.446621 20217 data_layer.cpp:187] (1) ReshapePrefetch 2, 3, 640, 640
I0916 17:01:09.446789 20217 data_layer.cpp:211] (1) Output data size: 2, 3, 640, 640
I0916 17:01:09.446799 20217 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 17:01:09.446840 20217 data_reader.cpp:58] Data Reader threads: 1, out queues: 1, depth: 2
I0916 17:01:09.446877 20217 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 17:01:09.450449 20249 data_layer.cpp:101] (1) Parser threads: 1
I0916 17:01:09.450474 20249 data_layer.cpp:103] (1) Transformer threads: 1
I0916 17:01:09.451863 20250 db_lmdb.cpp:24] Opened lmdb data/val-label-lmdb
I0916 17:01:09.457919 20217 data_layer.cpp:187] (1) ReshapePrefetch 2, 1, 640, 640
I0916 17:01:09.458359 20217 data_layer.cpp:211] (1) Output data size: 2, 1, 640, 640
I0916 17:01:09.458495 20217 internal_thread.cpp:19] Starting 1 internal thread(s) on device 1
I0916 17:01:09.460402 20251 data_layer.cpp:101] (1) Parser threads: 1
I0916 17:01:09.460417 20251 data_layer.cpp:103] (1) Transformer threads: 1
I0916 17:01:09.531520 20218 solver.cpp:57] Solver scaffolding done.
I0916 17:01:09.553792 20217 solver.cpp:57] Solver scaffolding done.
I0916 17:01:09.582753 20216 parallel.cpp:161] [0 - 0] P2pSync adding callback
I0916 17:01:09.582778 20217 parallel.cpp:161] [1 - 1] P2pSync adding callback
I0916 17:01:09.582753 20218 parallel.cpp:161] [2 - 2] P2pSync adding callback
I0916 17:01:09.853294 20218 solver.cpp:490] Solving jsegnet21v2_train
I0916 17:01:09.853315 20216 solver.cpp:490] Solving jsegnet21v2_train
I0916 17:01:09.853317 20217 solver.cpp:490] Solving jsegnet21v2_train
I0916 17:01:09.853335 20216 solver.cpp:491] Learning Rate Policy: multistep
I0916 17:01:09.853341 20217 solver.cpp:491] Learning Rate Policy: multistep
I0916 17:01:09.853327 20218 solver.cpp:491] Learning Rate Policy: multistep
I0916 17:01:09.868331 20218 net.cpp:1412] [2] Reserving 10800128 bytes of shared learnable space
I0916 17:01:09.868337 20217 net.cpp:1412] [1] Reserving 10800128 bytes of shared learnable space
I0916 17:01:09.872915 20216 net.cpp:1412] [0] Reserving 10800128 bytes of shared learnable space
I0916 17:01:09.880023 20216 solver.cpp:228] Starting Optimization on GPU 0
I0916 17:01:09.880026 20218 solver.cpp:228] Starting Optimization on GPU 2
I0916 17:01:09.880110 20216 solver.cpp:563] Iteration 0, Testing net (#0)
I0916 17:01:09.880132 20266 device_alternate.hpp:116] NVML initialized on thread 128238780503808
I0916 17:01:09.880156 20266 common.cpp:585] NVML succeeded to set CPU affinity on device 0
I0916 17:01:09.880026 20217 solver.cpp:228] Starting Optimization on GPU 1
I0916 17:01:09.880278 20268 device_alternate.hpp:116] NVML initialized on thread 128238763718400
I0916 17:01:09.880290 20268 common.cpp:585] NVML succeeded to set CPU affinity on device 1
I0916 17:01:09.880414 20267 device_alternate.hpp:116] NVML initialized on thread 128238772111104
I0916 17:01:09.880431 20267 common.cpp:585] NVML succeeded to set CPU affinity on device 2
I0916 17:01:10.128381 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.85041
I0916 17:01:10.128402 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 17:01:10.128407 20216 solver.cpp:655]     Test net output #2: loss = 0.553253 (* 1 = 0.553253 loss)
I0916 17:01:10.128412 20216 solver.cpp:255] [MultiGPU] Initial Test completed
I0916 17:01:10.526026 20216 solver.cpp:319] Iteration 0 (0.397575 s), loss = 0.0770469
I0916 17:01:10.526052 20216 solver.cpp:336]     Train net output #0: loss = 0.0770469 (* 1 = 0.0770469 loss)
I0916 17:01:10.526058 20216 sgd_solver.cpp:136] Iteration 0, lr = 0.01, m = 0.9
I0916 17:01:10.735280 20216 solver.cpp:319] Iteration 1 (0.209235 s), loss = 0.0552685
I0916 17:01:10.735325 20216 solver.cpp:336]     Train net output #0: loss = 0.0552685 (* 1 = 0.0552685 loss)
I0916 17:01:10.902369 20216 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'conv1a' with space 4.24G 3/1 1 0 3 	(avail 0.07G, req 0G)	t: 0 2.85 2.6
I0916 17:01:10.910156 20218 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'conv1a' with space 4.24G 3/1 1 0 0 	(avail 0.14G, req 0G)	t: 0 2.99 2.6
I0916 17:01:10.922483 20217 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'conv1a' with space 4.24G 3/1 1 0 0 	(avail 0.14G, req 0G)	t: 0 3.05 2.62
I0916 17:01:11.022840 20216 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'conv1b' with space 4.24G 32/4 6 4 3 	(avail 0.07G, req 0G)	t: 0 0.6 1.25
I0916 17:01:11.028100 20218 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'conv1b' with space 4.24G 32/4 6 4 3 	(avail 0.14G, req 0G)	t: 0 0.64 1.28
I0916 17:01:11.036377 20217 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'conv1b' with space 4.24G 32/4 6 4 3 	(avail 0.14G, req 0G)	t: 0 0.65 1.37
I0916 17:01:11.270355 20216 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 4.24G 32/1 6 4 3 	(avail 0.07G, req 0G)	t: 0 0.74 1.47
I0916 17:01:11.280431 20218 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 4.24G 32/1 6 4 3 	(avail 0.14G, req 0G)	t: 0 0.75 1.51
I0916 17:01:11.315793 20217 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res2a_branch2a' with space 4.24G 32/1 6 4 3 	(avail 0.14G, req 0G)	t: 0 0.74 1.53
I0916 17:01:11.378304 20216 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 4.24G 64/4 6 4 3 	(avail 0.07G, req 0G)	t: 0 0.27 0.62
I0916 17:01:11.380890 20218 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 4.24G 64/4 6 4 3 	(avail 0.14G, req 0G)	t: 0 0.27 0.65
I0916 17:01:11.398882 20217 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res2a_branch2b' with space 4.24G 64/4 6 4 3 	(avail 0.14G, req 0G)	t: 0 0.27 0.66
I0916 17:01:11.566035 20216 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 4.24G 64/1 6 4 5 	(avail 0.07G, req 0.07G)	t: 0 0.45 0.92
I0916 17:01:11.573259 20218 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 4.24G 64/1 6 4 5 	(avail 0.14G, req 0.07G)	t: 0 0.48 0.94
I0916 17:01:11.607038 20217 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res3a_branch2a' with space 4.24G 64/1 6 4 5 	(avail 0.14G, req 0.07G)	t: 0 0.46 0.95
I0916 17:01:11.613423 20216 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 4.24G 128/4 6 4 3 	(avail 0.07G, req 0.07G)	t: 0 0.14 0.28
I0916 17:01:11.623404 20218 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 4.24G 128/4 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.14 0.3
I0916 17:01:11.667399 20217 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res3a_branch2b' with space 4.24G 128/4 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.18 0.29
I0916 17:01:11.750689 20216 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 4.24G 128/1 6 4 5 	(avail 0.07G, req 0.07G)	t: 0 0.45 0.55
I0916 17:01:11.781801 20216 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 4.24G 256/4 6 4 5 	(avail 0.07G, req 0.07G)	t: 0 0.11 0.21
I0916 17:01:11.813982 20218 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 4.24G 128/1 6 4 5 	(avail 0.14G, req 0.07G)	t: 0 0.48 0.55
I0916 17:01:11.820802 20217 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res4a_branch2a' with space 4.24G 128/1 6 4 5 	(avail 0.14G, req 0.07G)	t: 0 0.48 0.56
I0916 17:01:11.848260 20218 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 4.24G 256/4 6 4 5 	(avail 0.14G, req 0.07G)	t: 0 0.11 0.21
I0916 17:01:11.851670 20217 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'res4a_branch2b' with space 4.24G 256/4 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.11 0.2
I0916 17:01:11.878221 20216 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'out3a' with space 4.24G 128/2 6 4 3 	(avail 0.07G, req 0.07G)	t: 0 0.22 0.42
I0916 17:01:11.947870 20218 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'out3a' with space 4.24G 128/2 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.24 0.43
I0916 17:01:11.949642 20217 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'out3a' with space 4.24G 128/2 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.22 0.43
I0916 17:01:11.988658 20216 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_conv1' with space 4.24G 64/1 6 4 3 	(avail 0.07G, req 0.07G)	t: 0 0.28 0.62
I0916 17:01:12.052358 20216 cudnn_conv_layer.cpp:872] [0] Conv Algos (F,BD,BF): 'ctx_final' with space 4.24G 64/1 6 1 3 	(avail 0.07G, req 0.07G)	t: 0 0.11 0.35
I0916 17:01:12.072341 20218 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'ctx_conv1' with space 4.24G 64/1 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.29 0.62
I0916 17:01:12.078866 20217 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_conv1' with space 4.24G 64/1 6 4 3 	(avail 0.14G, req 0.07G)	t: 0 0.3 0.63
I0916 17:01:12.120690 20218 cudnn_conv_layer.cpp:872] [2] Conv Algos (F,BD,BF): 'ctx_final' with space 4.24G 64/1 6 1 5 	(avail 0.14G, req 0.07G)	t: 0 0.11 0.36
I0916 17:01:12.131413 20217 cudnn_conv_layer.cpp:872] [1] Conv Algos (F,BD,BF): 'ctx_final' with space 4.24G 64/1 6 1 5 	(avail 0.14G, req 0.07G)	t: 0 0.11 0.36
I0916 17:01:12.257953 20216 solver.cpp:319] Iteration 2 (1.52263 s), loss = 0.0501653
I0916 17:01:12.257979 20216 solver.cpp:336]     Train net output #0: loss = 0.0501653 (* 1 = 0.0501653 loss)
I0916 17:01:12.258620 20217 cudnn_conv_layer.cpp:474] [1] Layer 'conv1a' reallocating workspace 4.24G to 0.14G
I0916 17:01:12.277644 20218 cudnn_conv_layer.cpp:474] [2] Layer 'conv1a' reallocating workspace 4.24G to 0.14G
I0916 17:01:12.279466 20216 cudnn_conv_layer.cpp:474] [0] Layer 'conv1a' reallocating workspace 4.24G to 0.14G
I0916 17:01:31.872104 20216 solver.cpp:314] Iteration 100 (4.99653 iter/s, 19.6136s/98 iter), loss = 0.0711057
I0916 17:01:31.872133 20216 solver.cpp:336]     Train net output #0: loss = 0.0711057 (* 1 = 0.0711057 loss)
I0916 17:01:31.872138 20216 sgd_solver.cpp:136] Iteration 100, lr = 0.01, m = 0.9
I0916 17:01:43.604835 20223 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 17:01:51.006911 20216 solver.cpp:314] Iteration 200 (5.22623 iter/s, 19.1343s/100 iter), loss = 0.138968
I0916 17:01:51.006935 20216 solver.cpp:336]     Train net output #0: loss = 0.138968 (* 1 = 0.138968 loss)
I0916 17:01:51.006940 20216 sgd_solver.cpp:136] Iteration 200, lr = 0.01, m = 0.9
I0916 17:02:10.141578 20216 solver.cpp:314] Iteration 300 (5.22626 iter/s, 19.1341s/100 iter), loss = 0.0643851
I0916 17:02:10.141602 20216 solver.cpp:336]     Train net output #0: loss = 0.0643851 (* 1 = 0.0643851 loss)
I0916 17:02:10.141607 20216 sgd_solver.cpp:136] Iteration 300, lr = 0.01, m = 0.9
I0916 17:02:15.544680 20219 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 17:02:29.578482 20216 solver.cpp:314] Iteration 400 (5.145 iter/s, 19.4364s/100 iter), loss = 0.0747495
I0916 17:02:29.578506 20216 solver.cpp:336]     Train net output #0: loss = 0.0747495 (* 1 = 0.0747495 loss)
I0916 17:02:29.578511 20216 sgd_solver.cpp:136] Iteration 400, lr = 0.01, m = 0.9
I0916 17:02:48.696818 20216 solver.cpp:314] Iteration 500 (5.23073 iter/s, 19.1178s/100 iter), loss = 0.2153
I0916 17:02:48.696869 20216 solver.cpp:336]     Train net output #0: loss = 0.2153 (* 1 = 0.2153 loss)
I0916 17:02:48.696876 20216 sgd_solver.cpp:136] Iteration 500, lr = 0.01, m = 0.9
I0916 17:03:08.239327 20216 solver.cpp:314] Iteration 600 (5.1172 iter/s, 19.542s/100 iter), loss = 0.0720644
I0916 17:03:08.239356 20216 solver.cpp:336]     Train net output #0: loss = 0.0720644 (* 1 = 0.0720644 loss)
I0916 17:03:08.239362 20216 sgd_solver.cpp:136] Iteration 600, lr = 0.01, m = 0.9
I0916 17:03:19.547545 20220 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 17:03:27.584372 20216 solver.cpp:314] Iteration 700 (5.16943 iter/s, 19.3445s/100 iter), loss = 0.0681331
I0916 17:03:27.584398 20216 solver.cpp:336]     Train net output #0: loss = 0.0681331 (* 1 = 0.0681331 loss)
I0916 17:03:27.584403 20216 sgd_solver.cpp:136] Iteration 700, lr = 0.01, m = 0.9
I0916 17:03:47.418560 20216 solver.cpp:314] Iteration 800 (5.04194 iter/s, 19.8336s/100 iter), loss = 0.121633
I0916 17:03:47.418587 20216 solver.cpp:336]     Train net output #0: loss = 0.121633 (* 1 = 0.121633 loss)
I0916 17:03:47.418593 20216 sgd_solver.cpp:136] Iteration 800, lr = 0.01, m = 0.9
I0916 17:04:06.791327 20216 solver.cpp:314] Iteration 900 (5.16203 iter/s, 19.3722s/100 iter), loss = 0.0570977
I0916 17:04:06.791404 20216 solver.cpp:336]     Train net output #0: loss = 0.0570977 (* 1 = 0.0570977 loss)
I0916 17:04:06.791411 20216 sgd_solver.cpp:136] Iteration 900, lr = 0.01, m = 0.9
I0916 17:04:24.137939 20224 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 17:04:26.471331 20216 solver.cpp:314] Iteration 1000 (5.08144 iter/s, 19.6794s/100 iter), loss = 0.107357
I0916 17:04:26.471360 20216 solver.cpp:336]     Train net output #0: loss = 0.107357 (* 1 = 0.107357 loss)
I0916 17:04:26.471369 20216 sgd_solver.cpp:136] Iteration 1000, lr = 0.01, m = 0.9
I0916 17:04:45.892304 20216 solver.cpp:314] Iteration 1100 (5.14922 iter/s, 19.4204s/100 iter), loss = 0.0685477
I0916 17:04:45.892361 20216 solver.cpp:336]     Train net output #0: loss = 0.0685477 (* 1 = 0.0685477 loss)
I0916 17:04:45.892367 20216 sgd_solver.cpp:136] Iteration 1100, lr = 0.01, m = 0.9
I0916 17:04:56.321072 20220 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 17:05:05.903656 20216 solver.cpp:314] Iteration 1200 (4.99731 iter/s, 20.0108s/100 iter), loss = 0.0857634
I0916 17:05:05.903751 20216 solver.cpp:336]     Train net output #0: loss = 0.0857633 (* 1 = 0.0857633 loss)
I0916 17:05:05.903780 20216 sgd_solver.cpp:136] Iteration 1200, lr = 0.01, m = 0.9
I0916 17:05:26.150696 20216 solver.cpp:314] Iteration 1300 (4.93913 iter/s, 20.2465s/100 iter), loss = 0.0913946
I0916 17:05:26.150746 20216 solver.cpp:336]     Train net output #0: loss = 0.0913945 (* 1 = 0.0913945 loss)
I0916 17:05:26.150753 20216 sgd_solver.cpp:136] Iteration 1300, lr = 0.01, m = 0.9
I0916 17:05:46.773881 20216 solver.cpp:314] Iteration 1400 (4.84905 iter/s, 20.6226s/100 iter), loss = 0.113304
I0916 17:05:46.773912 20216 solver.cpp:336]     Train net output #0: loss = 0.113304 (* 1 = 0.113304 loss)
I0916 17:05:46.773918 20216 sgd_solver.cpp:136] Iteration 1400, lr = 0.01, m = 0.9
I0916 17:06:03.250057 20197 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 17:06:06.460095 20216 solver.cpp:314] Iteration 1500 (5.07984 iter/s, 19.6857s/100 iter), loss = 0.099099
I0916 17:06:06.460119 20216 solver.cpp:336]     Train net output #0: loss = 0.0990989 (* 1 = 0.0990989 loss)
I0916 17:06:06.460124 20216 sgd_solver.cpp:136] Iteration 1500, lr = 0.01, m = 0.9
I0916 17:06:26.529528 20216 solver.cpp:314] Iteration 1600 (4.98284 iter/s, 20.0689s/100 iter), loss = 0.0729654
I0916 17:06:26.529553 20216 solver.cpp:336]     Train net output #0: loss = 0.0729653 (* 1 = 0.0729653 loss)
I0916 17:06:26.529559 20216 sgd_solver.cpp:136] Iteration 1600, lr = 0.01, m = 0.9
I0916 17:06:47.050789 20216 solver.cpp:314] Iteration 1700 (4.87313 iter/s, 20.5207s/100 iter), loss = 0.0887681
I0916 17:06:47.050865 20216 solver.cpp:336]     Train net output #0: loss = 0.088768 (* 1 = 0.088768 loss)
I0916 17:06:47.050886 20216 sgd_solver.cpp:136] Iteration 1700, lr = 0.01, m = 0.9
I0916 17:07:07.862329 20216 solver.cpp:314] Iteration 1800 (4.80516 iter/s, 20.811s/100 iter), loss = 0.0591615
I0916 17:07:07.862359 20216 solver.cpp:336]     Train net output #0: loss = 0.0591613 (* 1 = 0.0591613 loss)
I0916 17:07:07.862365 20216 sgd_solver.cpp:136] Iteration 1800, lr = 0.01, m = 0.9
I0916 17:07:10.778779 20197 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 17:07:27.851717 20216 solver.cpp:314] Iteration 1900 (5.00279 iter/s, 19.9888s/100 iter), loss = 0.0568081
I0916 17:07:27.851768 20216 solver.cpp:336]     Train net output #0: loss = 0.056808 (* 1 = 0.056808 loss)
I0916 17:07:27.851774 20216 sgd_solver.cpp:136] Iteration 1900, lr = 0.01, m = 0.9
I0916 17:07:44.463848 20220 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 17:07:48.255661 20216 solver.cpp:563] Iteration 2000, Testing net (#0)
I0916 17:07:48.405552 20218 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'conv1a' with space 0.14G 3/1 1 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.409044 20217 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'conv1a' with space 0.14G 3/1 1 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.421433 20216 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1a' with space 0.14G 3/1 1 	(avail 4.17G, req 0G)	t: 0
I0916 17:07:48.436369 20218 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'conv1b' with space 0.14G 32/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.437356 20217 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'conv1b' with space 0.14G 32/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.448125 20216 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'conv1b' with space 0.14G 32/4 6 	(avail 4.17G, req 0G)	t: 0
I0916 17:07:48.453173 20218 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'res2a_branch2a' with space 0.14G 32/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.453707 20217 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res2a_branch2a' with space 0.14G 32/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.463475 20216 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2a' with space 0.14G 32/1 6 	(avail 4.17G, req 0G)	t: 0
I0916 17:07:48.466066 20217 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res2a_branch2b' with space 0.14G 64/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.466229 20218 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'res2a_branch2b' with space 0.14G 64/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.474311 20216 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res2a_branch2b' with space 0.14G 64/4 6 	(avail 4.17G, req 0G)	t: 0
I0916 17:07:48.478147 20218 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'res3a_branch2a' with space 0.14G 64/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.478654 20217 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res3a_branch2a' with space 0.14G 64/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.485363 20218 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'res3a_branch2b' with space 0.14G 128/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.485513 20216 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2a' with space 0.14G 64/1 6 	(avail 4.17G, req 0G)	t: 0
I0916 17:07:48.485904 20217 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res3a_branch2b' with space 0.14G 128/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.493932 20216 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res3a_branch2b' with space 0.14G 128/4 6 	(avail 4.17G, req 0G)	t: 0
I0916 17:07:48.494494 20218 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'res4a_branch2a' with space 0.14G 128/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.497350 20217 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res4a_branch2a' with space 0.14G 128/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.499073 20218 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'res4a_branch2b' with space 0.14G 256/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.502584 20216 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2a' with space 0.14G 128/1 6 	(avail 4.17G, req 0G)	t: 0
I0916 17:07:48.502714 20217 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'res4a_branch2b' with space 0.14G 256/4 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.506958 20216 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'res4a_branch2b' with space 0.14G 256/4 6 	(avail 4.17G, req 0G)	t: 0
I0916 17:07:48.512787 20218 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'out3a' with space 0.14G 128/2 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.517554 20217 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'out3a' with space 0.14G 128/2 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.519292 20216 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'out3a' with space 0.14G 128/2 6 	(avail 4.17G, req 0G)	t: 0
I0916 17:07:48.522647 20218 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'ctx_conv1' with space 0.14G 64/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.529104 20216 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_conv1' with space 0.14G 64/1 6 	(avail 4.17G, req 0G)	t: 0
I0916 17:07:48.531992 20217 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_conv1' with space 0.14G 64/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.537729 20218 cudnn_conv_layer.cpp:872] (2) Conv Algo (F): 'ctx_final' with space 0.14G 64/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.542989 20216 cudnn_conv_layer.cpp:872] (0) Conv Algo (F): 'ctx_final' with space 0.14G 64/1 6 	(avail 4.17G, req 0G)	t: 0
I0916 17:07:48.548434 20217 cudnn_conv_layer.cpp:872] (1) Conv Algo (F): 'ctx_final' with space 0.14G 64/1 6 	(avail 4.24G, req 0G)	t: 0
I0916 17:07:48.786357 20218 blocking_queue.cpp:40] Data layer prefetch queue empty
I0916 17:08:13.006459 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.945378
I0916 17:08:13.006588 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 17:08:13.006598 20216 solver.cpp:655]     Test net output #2: loss = 0.164353 (* 1 = 0.164353 loss)
I0916 17:08:13.006664 20216 solver.cpp:265] [MultiGPU] Tests completed in 24.7503s
I0916 17:08:13.239820 20216 solver.cpp:314] Iteration 2000 (2.20328 iter/s, 45.3868s/100 iter), loss = 0.0703897
I0916 17:08:13.239850 20216 solver.cpp:336]     Train net output #0: loss = 0.0703895 (* 1 = 0.0703895 loss)
I0916 17:08:13.239857 20216 sgd_solver.cpp:136] Iteration 2000, lr = 0.01, m = 0.9
I0916 17:08:32.851845 20216 solver.cpp:314] Iteration 2100 (5.09906 iter/s, 19.6115s/100 iter), loss = 0.0557726
I0916 17:08:32.851874 20216 solver.cpp:336]     Train net output #0: loss = 0.0557724 (* 1 = 0.0557724 loss)
I0916 17:08:32.851881 20216 sgd_solver.cpp:136] Iteration 2100, lr = 0.01, m = 0.9
I0916 17:08:52.494669 20216 solver.cpp:314] Iteration 2200 (5.09106 iter/s, 19.6423s/100 iter), loss = 0.126393
I0916 17:08:52.494719 20216 solver.cpp:336]     Train net output #0: loss = 0.126393 (* 1 = 0.126393 loss)
I0916 17:08:52.494724 20216 sgd_solver.cpp:136] Iteration 2200, lr = 0.01, m = 0.9
I0916 17:09:12.793864 20216 solver.cpp:314] Iteration 2300 (4.92644 iter/s, 20.2986s/100 iter), loss = 0.059445
I0916 17:09:12.793893 20216 solver.cpp:336]     Train net output #0: loss = 0.0594448 (* 1 = 0.0594448 loss)
I0916 17:09:12.793900 20216 sgd_solver.cpp:136] Iteration 2300, lr = 0.01, m = 0.9
I0916 17:09:14.875787 20197 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 17:09:32.981691 20216 solver.cpp:314] Iteration 2400 (4.95362 iter/s, 20.1873s/100 iter), loss = 0.0690486
I0916 17:09:32.981751 20216 solver.cpp:336]     Train net output #0: loss = 0.0690484 (* 1 = 0.0690484 loss)
I0916 17:09:32.981758 20216 sgd_solver.cpp:136] Iteration 2400, lr = 0.01, m = 0.9
I0916 17:09:48.169400 20220 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 17:09:52.736311 20216 solver.cpp:314] Iteration 2500 (5.06225 iter/s, 19.7541s/100 iter), loss = 0.0868975
I0916 17:09:52.736335 20216 solver.cpp:336]     Train net output #0: loss = 0.0868973 (* 1 = 0.0868973 loss)
I0916 17:09:52.736340 20216 sgd_solver.cpp:136] Iteration 2500, lr = 0.01, m = 0.9
I0916 17:10:12.918685 20216 solver.cpp:314] Iteration 2600 (4.95496 iter/s, 20.1818s/100 iter), loss = 0.0749141
I0916 17:10:12.918748 20216 solver.cpp:336]     Train net output #0: loss = 0.0749138 (* 1 = 0.0749138 loss)
I0916 17:10:12.918756 20216 sgd_solver.cpp:136] Iteration 2600, lr = 0.01, m = 0.9
I0916 17:10:33.108183 20216 solver.cpp:314] Iteration 2700 (4.95321 iter/s, 20.1889s/100 iter), loss = 0.0715937
I0916 17:10:33.108204 20216 solver.cpp:336]     Train net output #0: loss = 0.0715935 (* 1 = 0.0715935 loss)
I0916 17:10:33.108209 20216 sgd_solver.cpp:136] Iteration 2700, lr = 0.01, m = 0.9
I0916 17:10:52.969238 20216 solver.cpp:314] Iteration 2800 (5.03512 iter/s, 19.8605s/100 iter), loss = 0.0502637
I0916 17:10:52.969295 20216 solver.cpp:336]     Train net output #0: loss = 0.0502635 (* 1 = 0.0502635 loss)
I0916 17:10:52.969301 20216 sgd_solver.cpp:136] Iteration 2800, lr = 0.01, m = 0.9
I0916 17:10:54.196893 20223 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 17:11:12.922165 20216 solver.cpp:314] Iteration 2900 (5.01194 iter/s, 19.9524s/100 iter), loss = 0.0996417
I0916 17:11:12.922189 20216 solver.cpp:336]     Train net output #0: loss = 0.0996415 (* 1 = 0.0996415 loss)
I0916 17:11:12.922194 20216 sgd_solver.cpp:136] Iteration 2900, lr = 0.01, m = 0.9
I0916 17:11:33.148785 20216 solver.cpp:314] Iteration 3000 (4.94412 iter/s, 20.2261s/100 iter), loss = 0.1
I0916 17:11:33.148867 20216 solver.cpp:336]     Train net output #0: loss = 0.1 (* 1 = 0.1 loss)
I0916 17:11:33.148875 20216 sgd_solver.cpp:136] Iteration 3000, lr = 0.01, m = 0.9
I0916 17:11:53.450981 20216 solver.cpp:314] Iteration 3100 (4.92571 iter/s, 20.3016s/100 iter), loss = 0.0623326
I0916 17:11:53.451016 20216 solver.cpp:336]     Train net output #0: loss = 0.0623324 (* 1 = 0.0623324 loss)
I0916 17:11:53.451025 20216 sgd_solver.cpp:136] Iteration 3100, lr = 0.01, m = 0.9
I0916 17:12:00.817440 20223 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 17:12:13.219429 20216 solver.cpp:314] Iteration 3200 (5.05871 iter/s, 19.7679s/100 iter), loss = 0.19464
I0916 17:12:13.219506 20216 solver.cpp:336]     Train net output #0: loss = 0.19464 (* 1 = 0.19464 loss)
I0916 17:12:13.219511 20216 sgd_solver.cpp:136] Iteration 3200, lr = 0.01, m = 0.9
I0916 17:12:33.663414 20216 solver.cpp:314] Iteration 3300 (4.89155 iter/s, 20.4434s/100 iter), loss = 0.0852514
I0916 17:12:33.663435 20216 solver.cpp:336]     Train net output #0: loss = 0.0852513 (* 1 = 0.0852513 loss)
I0916 17:12:33.663440 20216 sgd_solver.cpp:136] Iteration 3300, lr = 0.01, m = 0.9
I0916 17:12:34.069646 20197 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 17:12:54.086925 20216 solver.cpp:314] Iteration 3400 (4.89645 iter/s, 20.4229s/100 iter), loss = 0.0507501
I0916 17:12:54.087002 20216 solver.cpp:336]     Train net output #0: loss = 0.0507499 (* 1 = 0.0507499 loss)
I0916 17:12:54.087009 20216 sgd_solver.cpp:136] Iteration 3400, lr = 0.01, m = 0.9
I0916 17:13:14.129034 20216 solver.cpp:314] Iteration 3500 (4.98963 iter/s, 20.0415s/100 iter), loss = 0.11384
I0916 17:13:14.129062 20216 solver.cpp:336]     Train net output #0: loss = 0.113839 (* 1 = 0.113839 loss)
I0916 17:13:14.129068 20216 sgd_solver.cpp:136] Iteration 3500, lr = 0.01, m = 0.9
I0916 17:13:34.054585 20216 solver.cpp:314] Iteration 3600 (5.01882 iter/s, 19.925s/100 iter), loss = 0.094554
I0916 17:13:34.054636 20216 solver.cpp:336]     Train net output #0: loss = 0.0945538 (* 1 = 0.0945538 loss)
I0916 17:13:34.054641 20216 sgd_solver.cpp:136] Iteration 3600, lr = 0.01, m = 0.9
I0916 17:13:40.699476 20220 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 17:13:54.297402 20216 solver.cpp:314] Iteration 3700 (4.94016 iter/s, 20.2423s/100 iter), loss = 0.0670862
I0916 17:13:54.297428 20216 solver.cpp:336]     Train net output #0: loss = 0.0670861 (* 1 = 0.0670861 loss)
I0916 17:13:54.297435 20216 sgd_solver.cpp:136] Iteration 3700, lr = 0.01, m = 0.9
I0916 17:14:14.385627 20216 solver.cpp:314] Iteration 3800 (4.97818 iter/s, 20.0877s/100 iter), loss = 0.154844
I0916 17:14:14.385677 20216 solver.cpp:336]     Train net output #0: loss = 0.154843 (* 1 = 0.154843 loss)
I0916 17:14:14.385684 20216 sgd_solver.cpp:136] Iteration 3800, lr = 0.01, m = 0.9
I0916 17:14:34.224048 20216 solver.cpp:314] Iteration 3900 (5.04087 iter/s, 19.8379s/100 iter), loss = 0.0910186
I0916 17:14:34.224074 20216 solver.cpp:336]     Train net output #0: loss = 0.0910185 (* 1 = 0.0910185 loss)
I0916 17:14:34.224078 20216 sgd_solver.cpp:136] Iteration 3900, lr = 0.01, m = 0.9
I0916 17:14:47.211580 20197 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 17:14:54.576632 20216 solver.cpp:563] Iteration 4000, Testing net (#0)
I0916 17:15:26.565824 20204 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 17:15:27.170097 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.940676
I0916 17:15:27.170121 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 17:15:27.170126 20216 solver.cpp:655]     Test net output #2: loss = 0.178434 (* 1 = 0.178434 loss)
I0916 17:15:27.170156 20216 solver.cpp:265] [MultiGPU] Tests completed in 32.5926s
I0916 17:15:27.369248 20216 solver.cpp:314] Iteration 4000 (1.88169 iter/s, 53.1437s/100 iter), loss = 0.0611546
I0916 17:15:27.369277 20216 solver.cpp:336]     Train net output #0: loss = 0.0611545 (* 1 = 0.0611545 loss)
I0916 17:15:27.369284 20216 sgd_solver.cpp:136] Iteration 4000, lr = 0.01, m = 0.9
I0916 17:15:46.942544 20216 solver.cpp:314] Iteration 4100 (5.10915 iter/s, 19.5727s/100 iter), loss = 0.170168
I0916 17:15:46.942571 20216 solver.cpp:336]     Train net output #0: loss = 0.170168 (* 1 = 0.170168 loss)
I0916 17:15:46.942577 20216 sgd_solver.cpp:136] Iteration 4100, lr = 0.01, m = 0.9
I0916 17:15:52.477354 20219 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 17:16:06.815688 20216 solver.cpp:314] Iteration 4200 (5.03206 iter/s, 19.8726s/100 iter), loss = 0.0688574
I0916 17:16:06.815757 20216 solver.cpp:336]     Train net output #0: loss = 0.0688573 (* 1 = 0.0688573 loss)
I0916 17:16:06.815762 20216 sgd_solver.cpp:136] Iteration 4200, lr = 0.01, m = 0.9
I0916 17:16:26.733546 20216 solver.cpp:314] Iteration 4300 (5.02076 iter/s, 19.9173s/100 iter), loss = 0.0766944
I0916 17:16:26.733584 20216 solver.cpp:336]     Train net output #0: loss = 0.0766943 (* 1 = 0.0766943 loss)
I0916 17:16:26.733592 20216 sgd_solver.cpp:136] Iteration 4300, lr = 0.01, m = 0.9
I0916 17:16:46.557196 20216 solver.cpp:314] Iteration 4400 (5.04462 iter/s, 19.8231s/100 iter), loss = 0.0633302
I0916 17:16:46.557283 20216 solver.cpp:336]     Train net output #0: loss = 0.06333 (* 1 = 0.06333 loss)
I0916 17:16:46.557291 20216 sgd_solver.cpp:136] Iteration 4400, lr = 0.01, m = 0.9
I0916 17:16:58.059345 20224 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 17:17:06.353163 20216 solver.cpp:314] Iteration 4500 (5.05168 iter/s, 19.7954s/100 iter), loss = 0.0464319
I0916 17:17:06.353194 20216 solver.cpp:336]     Train net output #0: loss = 0.0464317 (* 1 = 0.0464317 loss)
I0916 17:17:06.353201 20216 sgd_solver.cpp:136] Iteration 4500, lr = 0.01, m = 0.9
I0916 17:17:26.320341 20216 solver.cpp:314] Iteration 4600 (5.00836 iter/s, 19.9666s/100 iter), loss = 0.101606
I0916 17:17:26.320448 20216 solver.cpp:336]     Train net output #0: loss = 0.101606 (* 1 = 0.101606 loss)
I0916 17:17:26.320456 20216 sgd_solver.cpp:136] Iteration 4600, lr = 0.01, m = 0.9
I0916 17:17:46.274945 20216 solver.cpp:314] Iteration 4700 (5.01152 iter/s, 19.954s/100 iter), loss = 0.0938497
I0916 17:17:46.274972 20216 solver.cpp:336]     Train net output #0: loss = 0.0938496 (* 1 = 0.0938496 loss)
I0916 17:17:46.274978 20216 sgd_solver.cpp:136] Iteration 4700, lr = 0.01, m = 0.9
I0916 17:18:03.877588 20219 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 17:18:05.813802 20216 solver.cpp:314] Iteration 4800 (5.11815 iter/s, 19.5383s/100 iter), loss = 0.0952472
I0916 17:18:05.813834 20216 solver.cpp:336]     Train net output #0: loss = 0.0952471 (* 1 = 0.0952471 loss)
I0916 17:18:05.813841 20216 sgd_solver.cpp:136] Iteration 4800, lr = 0.01, m = 0.9
I0916 17:18:25.605921 20216 solver.cpp:314] Iteration 4900 (5.05266 iter/s, 19.7916s/100 iter), loss = 0.0969652
I0916 17:18:25.605944 20216 solver.cpp:336]     Train net output #0: loss = 0.096965 (* 1 = 0.096965 loss)
I0916 17:18:25.605949 20216 sgd_solver.cpp:136] Iteration 4900, lr = 0.01, m = 0.9
I0916 17:18:36.501451 20220 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 17:18:45.411703 20216 solver.cpp:314] Iteration 5000 (5.04917 iter/s, 19.8052s/100 iter), loss = 0.112146
I0916 17:18:45.411727 20216 solver.cpp:336]     Train net output #0: loss = 0.112146 (* 1 = 0.112146 loss)
I0916 17:18:45.411732 20216 sgd_solver.cpp:136] Iteration 5000, lr = 0.01, m = 0.9
I0916 17:19:04.898316 20216 solver.cpp:314] Iteration 5100 (5.13187 iter/s, 19.4861s/100 iter), loss = 0.115609
I0916 17:19:04.898342 20216 solver.cpp:336]     Train net output #0: loss = 0.115609 (* 1 = 0.115609 loss)
I0916 17:19:04.898350 20216 sgd_solver.cpp:136] Iteration 5100, lr = 0.01, m = 0.9
I0916 17:19:24.674283 20216 solver.cpp:314] Iteration 5200 (5.05679 iter/s, 19.7754s/100 iter), loss = 0.0918244
I0916 17:19:24.674360 20216 solver.cpp:336]     Train net output #0: loss = 0.0918243 (* 1 = 0.0918243 loss)
I0916 17:19:24.674368 20216 sgd_solver.cpp:136] Iteration 5200, lr = 0.01, m = 0.9
I0916 17:19:41.645246 20220 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 17:19:44.490795 20216 solver.cpp:314] Iteration 5300 (5.04644 iter/s, 19.816s/100 iter), loss = 0.068944
I0916 17:19:44.490821 20216 solver.cpp:336]     Train net output #0: loss = 0.0689439 (* 1 = 0.0689439 loss)
I0916 17:19:44.490828 20216 sgd_solver.cpp:136] Iteration 5300, lr = 0.01, m = 0.9
I0916 17:20:04.359000 20216 solver.cpp:314] Iteration 5400 (5.03331 iter/s, 19.8676s/100 iter), loss = 0.0621616
I0916 17:20:04.359077 20216 solver.cpp:336]     Train net output #0: loss = 0.0621615 (* 1 = 0.0621615 loss)
I0916 17:20:04.359086 20216 sgd_solver.cpp:136] Iteration 5400, lr = 0.01, m = 0.9
I0916 17:20:24.254957 20216 solver.cpp:314] Iteration 5500 (5.02629 iter/s, 19.8954s/100 iter), loss = 0.0760806
I0916 17:20:24.254981 20216 solver.cpp:336]     Train net output #0: loss = 0.0760805 (* 1 = 0.0760805 loss)
I0916 17:20:24.254987 20216 sgd_solver.cpp:136] Iteration 5500, lr = 0.01, m = 0.9
I0916 17:20:43.809629 20216 solver.cpp:314] Iteration 5600 (5.11401 iter/s, 19.5541s/100 iter), loss = 0.0385456
I0916 17:20:43.809689 20216 solver.cpp:336]     Train net output #0: loss = 0.0385455 (* 1 = 0.0385455 loss)
I0916 17:20:43.809697 20216 sgd_solver.cpp:136] Iteration 5600, lr = 0.01, m = 0.9
I0916 17:20:47.080631 20224 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 17:21:04.003371 20216 solver.cpp:314] Iteration 5700 (4.95217 iter/s, 20.1932s/100 iter), loss = 0.128877
I0916 17:21:04.003430 20216 solver.cpp:336]     Train net output #0: loss = 0.128877 (* 1 = 0.128877 loss)
I0916 17:21:04.003446 20216 sgd_solver.cpp:136] Iteration 5700, lr = 0.01, m = 0.9
I0916 17:21:23.878000 20216 solver.cpp:314] Iteration 5800 (5.03168 iter/s, 19.8741s/100 iter), loss = 0.0713308
I0916 17:21:23.878087 20216 solver.cpp:336]     Train net output #0: loss = 0.0713307 (* 1 = 0.0713307 loss)
I0916 17:21:23.878100 20216 sgd_solver.cpp:136] Iteration 5800, lr = 0.01, m = 0.9
I0916 17:21:43.520931 20216 solver.cpp:314] Iteration 5900 (5.09103 iter/s, 19.6424s/100 iter), loss = 0.158409
I0916 17:21:43.520956 20216 solver.cpp:336]     Train net output #0: loss = 0.158409 (* 1 = 0.158409 loss)
I0916 17:21:43.520961 20216 sgd_solver.cpp:136] Iteration 5900, lr = 0.01, m = 0.9
I0916 17:21:52.712836 20224 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 17:22:03.406215 20216 solver.cpp:563] Iteration 6000, Testing net (#0)
I0916 17:22:13.107606 20250 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 17:22:17.430575 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.94797
I0916 17:22:17.430599 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 17:22:17.430605 20216 solver.cpp:655]     Test net output #2: loss = 0.157664 (* 1 = 0.157664 loss)
I0916 17:22:17.430697 20216 solver.cpp:265] [MultiGPU] Tests completed in 14.0241s
I0916 17:22:17.641198 20216 solver.cpp:314] Iteration 6000 (2.93089 iter/s, 34.1193s/100 iter), loss = 0.110208
I0916 17:22:17.641227 20216 solver.cpp:336]     Train net output #0: loss = 0.110208 (* 1 = 0.110208 loss)
I0916 17:22:17.641234 20216 sgd_solver.cpp:136] Iteration 6000, lr = 0.01, m = 0.9
I0916 17:22:37.093201 20216 solver.cpp:314] Iteration 6100 (5.14101 iter/s, 19.4515s/100 iter), loss = 0.249439
I0916 17:22:37.093252 20216 solver.cpp:336]     Train net output #0: loss = 0.249439 (* 1 = 0.249439 loss)
I0916 17:22:37.093260 20216 sgd_solver.cpp:136] Iteration 6100, lr = 0.01, m = 0.9
I0916 17:22:56.542809 20216 solver.cpp:314] Iteration 6200 (5.14164 iter/s, 19.4491s/100 iter), loss = 0.0887299
I0916 17:22:56.542834 20216 solver.cpp:336]     Train net output #0: loss = 0.0887299 (* 1 = 0.0887299 loss)
I0916 17:22:56.542839 20216 sgd_solver.cpp:136] Iteration 6200, lr = 0.01, m = 0.9
I0916 17:23:11.475636 20224 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 17:23:15.949113 20216 solver.cpp:314] Iteration 6300 (5.15311 iter/s, 19.4058s/100 iter), loss = 0.0904803
I0916 17:23:15.949143 20216 solver.cpp:336]     Train net output #0: loss = 0.0904803 (* 1 = 0.0904803 loss)
I0916 17:23:15.949151 20216 sgd_solver.cpp:136] Iteration 6300, lr = 0.01, m = 0.9
I0916 17:23:35.546825 20216 solver.cpp:314] Iteration 6400 (5.10278 iter/s, 19.5972s/100 iter), loss = 0.0796616
I0916 17:23:35.546852 20216 solver.cpp:336]     Train net output #0: loss = 0.0796615 (* 1 = 0.0796615 loss)
I0916 17:23:35.546859 20216 sgd_solver.cpp:136] Iteration 6400, lr = 0.01, m = 0.9
I0916 17:23:55.024096 20216 solver.cpp:314] Iteration 6500 (5.13433 iter/s, 19.4767s/100 iter), loss = 0.113316
I0916 17:23:55.024595 20216 solver.cpp:336]     Train net output #0: loss = 0.113316 (* 1 = 0.113316 loss)
I0916 17:23:55.024611 20216 sgd_solver.cpp:136] Iteration 6500, lr = 0.01, m = 0.9
I0916 17:24:14.789343 20216 solver.cpp:314] Iteration 6600 (5.05953 iter/s, 19.7647s/100 iter), loss = 0.114017
I0916 17:24:14.789371 20216 solver.cpp:336]     Train net output #0: loss = 0.114017 (* 1 = 0.114017 loss)
I0916 17:24:14.789377 20216 sgd_solver.cpp:136] Iteration 6600, lr = 0.01, m = 0.9
I0916 17:24:16.368454 20223 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 17:24:34.407810 20216 solver.cpp:314] Iteration 6700 (5.09738 iter/s, 19.6179s/100 iter), loss = 0.113417
I0916 17:24:34.407869 20216 solver.cpp:336]     Train net output #0: loss = 0.113417 (* 1 = 0.113417 loss)
I0916 17:24:34.407876 20216 sgd_solver.cpp:136] Iteration 6700, lr = 0.01, m = 0.9
I0916 17:24:53.796352 20216 solver.cpp:314] Iteration 6800 (5.15783 iter/s, 19.388s/100 iter), loss = 0.0456348
I0916 17:24:53.796377 20216 solver.cpp:336]     Train net output #0: loss = 0.0456348 (* 1 = 0.0456348 loss)
I0916 17:24:53.796382 20216 sgd_solver.cpp:136] Iteration 6800, lr = 0.01, m = 0.9
I0916 17:25:13.279264 20216 solver.cpp:314] Iteration 6900 (5.13285 iter/s, 19.4824s/100 iter), loss = 0.106546
I0916 17:25:13.279312 20216 solver.cpp:336]     Train net output #0: loss = 0.106546 (* 1 = 0.106546 loss)
I0916 17:25:13.279317 20216 sgd_solver.cpp:136] Iteration 6900, lr = 0.01, m = 0.9
I0916 17:25:21.004822 20223 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 17:25:33.893582 20216 solver.cpp:314] Iteration 7000 (4.85113 iter/s, 20.6137s/100 iter), loss = 0.126016
I0916 17:25:33.893609 20216 solver.cpp:336]     Train net output #0: loss = 0.126016 (* 1 = 0.126016 loss)
I0916 17:25:33.893615 20216 sgd_solver.cpp:136] Iteration 7000, lr = 0.01, m = 0.9
I0916 17:25:54.113678 20216 solver.cpp:314] Iteration 7100 (4.94571 iter/s, 20.2195s/100 iter), loss = 0.0802786
I0916 17:25:54.113737 20216 solver.cpp:336]     Train net output #0: loss = 0.0802785 (* 1 = 0.0802785 loss)
I0916 17:25:54.113744 20216 sgd_solver.cpp:136] Iteration 7100, lr = 0.01, m = 0.9
I0916 17:25:54.808028 20219 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 17:26:14.121845 20216 solver.cpp:314] Iteration 7200 (4.9981 iter/s, 20.0076s/100 iter), loss = 0.0883156
I0916 17:26:14.121872 20216 solver.cpp:336]     Train net output #0: loss = 0.0883155 (* 1 = 0.0883155 loss)
I0916 17:26:14.121879 20216 sgd_solver.cpp:136] Iteration 7200, lr = 0.01, m = 0.9
I0916 17:26:34.148424 20216 solver.cpp:314] Iteration 7300 (4.9935 iter/s, 20.026s/100 iter), loss = 0.0662843
I0916 17:26:34.148475 20216 solver.cpp:336]     Train net output #0: loss = 0.0662842 (* 1 = 0.0662842 loss)
I0916 17:26:34.148481 20216 sgd_solver.cpp:136] Iteration 7300, lr = 0.01, m = 0.9
I0916 17:26:54.488734 20216 solver.cpp:314] Iteration 7400 (4.91648 iter/s, 20.3397s/100 iter), loss = 0.147958
I0916 17:26:54.488790 20216 solver.cpp:336]     Train net output #0: loss = 0.147958 (* 1 = 0.147958 loss)
I0916 17:26:54.488812 20216 sgd_solver.cpp:136] Iteration 7400, lr = 0.01, m = 0.9
I0916 17:27:01.487717 20224 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 17:27:14.738914 20216 solver.cpp:314] Iteration 7500 (4.93837 iter/s, 20.2496s/100 iter), loss = 0.0945349
I0916 17:27:14.738978 20216 solver.cpp:336]     Train net output #0: loss = 0.0945348 (* 1 = 0.0945348 loss)
I0916 17:27:14.738987 20216 sgd_solver.cpp:136] Iteration 7500, lr = 0.01, m = 0.9
I0916 17:27:34.916519 20216 solver.cpp:314] Iteration 7600 (4.95613 iter/s, 20.177s/100 iter), loss = 0.057806
I0916 17:27:34.916543 20216 solver.cpp:336]     Train net output #0: loss = 0.0578059 (* 1 = 0.0578059 loss)
I0916 17:27:34.916548 20216 sgd_solver.cpp:136] Iteration 7600, lr = 0.01, m = 0.9
I0916 17:27:55.125870 20216 solver.cpp:314] Iteration 7700 (4.94834 iter/s, 20.2088s/100 iter), loss = 0.0631604
I0916 17:27:55.125954 20216 solver.cpp:336]     Train net output #0: loss = 0.0631604 (* 1 = 0.0631604 loss)
I0916 17:27:55.125962 20216 sgd_solver.cpp:136] Iteration 7700, lr = 0.01, m = 0.9
I0916 17:28:08.518646 20223 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 17:28:15.585372 20216 solver.cpp:314] Iteration 7800 (4.88784 iter/s, 20.4589s/100 iter), loss = 0.15585
I0916 17:28:15.585393 20216 solver.cpp:336]     Train net output #0: loss = 0.15585 (* 1 = 0.15585 loss)
I0916 17:28:15.585398 20216 sgd_solver.cpp:136] Iteration 7800, lr = 0.01, m = 0.9
I0916 17:28:35.611838 20216 solver.cpp:314] Iteration 7900 (4.99353 iter/s, 20.0259s/100 iter), loss = 0.119486
I0916 17:28:35.612126 20216 solver.cpp:336]     Train net output #0: loss = 0.119486 (* 1 = 0.119486 loss)
I0916 17:28:35.612238 20216 sgd_solver.cpp:136] Iteration 7900, lr = 0.01, m = 0.9
I0916 17:28:41.490084 20220 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 17:28:55.568976 20216 solver.cpp:563] Iteration 8000, Testing net (#0)
I0916 17:29:14.059849 20202 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 17:29:14.867595 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.916309
I0916 17:29:14.867624 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.999998
I0916 17:29:14.867630 20216 solver.cpp:655]     Test net output #2: loss = 0.249231 (* 1 = 0.249231 loss)
I0916 17:29:14.867663 20216 solver.cpp:265] [MultiGPU] Tests completed in 19.2982s
I0916 17:29:15.094511 20216 solver.cpp:314] Iteration 8000 (2.53283 iter/s, 39.4816s/100 iter), loss = 0.098198
I0916 17:29:15.094534 20216 solver.cpp:336]     Train net output #0: loss = 0.0981979 (* 1 = 0.0981979 loss)
I0916 17:29:15.094539 20216 sgd_solver.cpp:136] Iteration 8000, lr = 0.01, m = 0.9
I0916 17:29:34.621361 20216 solver.cpp:314] Iteration 8100 (5.1213 iter/s, 19.5263s/100 iter), loss = 0.0675431
I0916 17:29:34.621387 20216 solver.cpp:336]     Train net output #0: loss = 0.067543 (* 1 = 0.067543 loss)
I0916 17:29:34.621392 20216 sgd_solver.cpp:136] Iteration 8100, lr = 0.01, m = 0.9
I0916 17:29:54.231922 20216 solver.cpp:314] Iteration 8200 (5.09944 iter/s, 19.61s/100 iter), loss = 0.0709209
I0916 17:29:54.231984 20216 solver.cpp:336]     Train net output #0: loss = 0.0709208 (* 1 = 0.0709208 loss)
I0916 17:29:54.231992 20216 sgd_solver.cpp:136] Iteration 8200, lr = 0.01, m = 0.9
I0916 17:30:05.968854 20224 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 17:30:13.825264 20216 solver.cpp:314] Iteration 8300 (5.10392 iter/s, 19.5928s/100 iter), loss = 0.22628
I0916 17:30:13.825290 20216 solver.cpp:336]     Train net output #0: loss = 0.22628 (* 1 = 0.22628 loss)
I0916 17:30:13.825296 20216 sgd_solver.cpp:136] Iteration 8300, lr = 0.01, m = 0.9
I0916 17:30:33.230700 20216 solver.cpp:314] Iteration 8400 (5.15334 iter/s, 19.4049s/100 iter), loss = 0.070129
I0916 17:30:33.230764 20216 solver.cpp:336]     Train net output #0: loss = 0.0701289 (* 1 = 0.0701289 loss)
I0916 17:30:33.230773 20216 sgd_solver.cpp:136] Iteration 8400, lr = 0.01, m = 0.9
I0916 17:30:38.317651 20219 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 17:30:52.799983 20216 solver.cpp:314] Iteration 8500 (5.11019 iter/s, 19.5687s/100 iter), loss = 0.066922
I0916 17:30:52.800007 20216 solver.cpp:336]     Train net output #0: loss = 0.0669219 (* 1 = 0.0669219 loss)
I0916 17:30:52.800014 20216 sgd_solver.cpp:136] Iteration 8500, lr = 0.01, m = 0.9
I0916 17:31:12.381579 20216 solver.cpp:314] Iteration 8600 (5.10698 iter/s, 19.581s/100 iter), loss = 0.0859915
I0916 17:31:12.381633 20216 solver.cpp:336]     Train net output #0: loss = 0.0859914 (* 1 = 0.0859914 loss)
I0916 17:31:12.381639 20216 sgd_solver.cpp:136] Iteration 8600, lr = 0.01, m = 0.9
I0916 17:31:32.121379 20216 solver.cpp:314] Iteration 8700 (5.06605 iter/s, 19.7392s/100 iter), loss = 0.0679814
I0916 17:31:32.121400 20216 solver.cpp:336]     Train net output #0: loss = 0.0679813 (* 1 = 0.0679813 loss)
I0916 17:31:32.121404 20216 sgd_solver.cpp:136] Iteration 8700, lr = 0.01, m = 0.9
I0916 17:31:43.117573 20224 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 17:31:51.622787 20216 solver.cpp:314] Iteration 8800 (5.12798 iter/s, 19.5009s/100 iter), loss = 0.0679392
I0916 17:31:51.622817 20216 solver.cpp:336]     Train net output #0: loss = 0.0679392 (* 1 = 0.0679392 loss)
I0916 17:31:51.622824 20216 sgd_solver.cpp:136] Iteration 8800, lr = 0.01, m = 0.9
I0916 17:32:11.224231 20216 solver.cpp:314] Iteration 8900 (5.10181 iter/s, 19.6009s/100 iter), loss = 0.0701668
I0916 17:32:11.224258 20216 solver.cpp:336]     Train net output #0: loss = 0.0701668 (* 1 = 0.0701668 loss)
I0916 17:32:11.224264 20216 sgd_solver.cpp:136] Iteration 8900, lr = 0.01, m = 0.9
I0916 17:32:30.933195 20216 solver.cpp:314] Iteration 9000 (5.07398 iter/s, 19.7084s/100 iter), loss = 0.0844631
I0916 17:32:30.933244 20216 solver.cpp:336]     Train net output #0: loss = 0.0844631 (* 1 = 0.0844631 loss)
I0916 17:32:30.933249 20216 sgd_solver.cpp:136] Iteration 9000, lr = 0.01, m = 0.9
I0916 17:32:48.105202 20197 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 17:32:50.563141 20216 solver.cpp:314] Iteration 9100 (5.0944 iter/s, 19.6294s/100 iter), loss = 0.103181
I0916 17:32:50.563169 20216 solver.cpp:336]     Train net output #0: loss = 0.103181 (* 1 = 0.103181 loss)
I0916 17:32:50.563174 20216 sgd_solver.cpp:136] Iteration 9100, lr = 0.01, m = 0.9
I0916 17:33:10.322782 20216 solver.cpp:314] Iteration 9200 (5.06096 iter/s, 19.7591s/100 iter), loss = 0.0863194
I0916 17:33:10.322841 20216 solver.cpp:336]     Train net output #0: loss = 0.0863192 (* 1 = 0.0863192 loss)
I0916 17:33:10.322849 20216 sgd_solver.cpp:136] Iteration 9200, lr = 0.01, m = 0.9
I0916 17:33:20.381431 20219 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 17:33:29.703932 20216 solver.cpp:314] Iteration 9300 (5.1598 iter/s, 19.3806s/100 iter), loss = 0.086032
I0916 17:33:29.703958 20216 solver.cpp:336]     Train net output #0: loss = 0.0860318 (* 1 = 0.0860318 loss)
I0916 17:33:29.703964 20216 sgd_solver.cpp:136] Iteration 9300, lr = 0.01, m = 0.9
I0916 17:33:48.964045 20216 solver.cpp:314] Iteration 9400 (5.19222 iter/s, 19.2596s/100 iter), loss = 0.0968377
I0916 17:33:48.964090 20216 solver.cpp:336]     Train net output #0: loss = 0.0968375 (* 1 = 0.0968375 loss)
I0916 17:33:48.964095 20216 sgd_solver.cpp:136] Iteration 9400, lr = 0.01, m = 0.9
I0916 17:34:08.132643 20216 solver.cpp:314] Iteration 9500 (5.21701 iter/s, 19.1681s/100 iter), loss = 0.0649179
I0916 17:34:08.132668 20216 solver.cpp:336]     Train net output #0: loss = 0.0649177 (* 1 = 0.0649177 loss)
I0916 17:34:08.132674 20216 sgd_solver.cpp:136] Iteration 9500, lr = 0.01, m = 0.9
I0916 17:34:24.488903 20195 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 17:34:27.817129 20216 solver.cpp:314] Iteration 9600 (5.08029 iter/s, 19.6839s/100 iter), loss = 0.0893848
I0916 17:34:27.817155 20216 solver.cpp:336]     Train net output #0: loss = 0.0893845 (* 1 = 0.0893845 loss)
I0916 17:34:27.817162 20216 sgd_solver.cpp:136] Iteration 9600, lr = 0.01, m = 0.9
I0916 17:34:47.264158 20216 solver.cpp:314] Iteration 9700 (5.14232 iter/s, 19.4465s/100 iter), loss = 0.0690491
I0916 17:34:47.264183 20216 solver.cpp:336]     Train net output #0: loss = 0.0690489 (* 1 = 0.0690489 loss)
I0916 17:34:47.264189 20216 sgd_solver.cpp:136] Iteration 9700, lr = 0.01, m = 0.9
I0916 17:35:06.582811 20216 solver.cpp:314] Iteration 9800 (5.17649 iter/s, 19.3181s/100 iter), loss = 0.0663428
I0916 17:35:06.582891 20216 solver.cpp:336]     Train net output #0: loss = 0.0663425 (* 1 = 0.0663425 loss)
I0916 17:35:06.582898 20216 sgd_solver.cpp:136] Iteration 9800, lr = 0.01, m = 0.9
I0916 17:35:25.916343 20216 solver.cpp:314] Iteration 9900 (5.17251 iter/s, 19.333s/100 iter), loss = 0.101346
I0916 17:35:25.916374 20216 solver.cpp:336]     Train net output #0: loss = 0.101346 (* 1 = 0.101346 loss)
I0916 17:35:25.916380 20216 sgd_solver.cpp:136] Iteration 9900, lr = 0.01, m = 0.9
I0916 17:35:28.489147 20223 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 17:35:45.318506 20216 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/cityscapes5_jsegnet21v2_iter_10000.caffemodel
I0916 17:35:45.432381 20216 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/cityscapes5_jsegnet21v2_iter_10000.solverstate
I0916 17:35:45.438395 20216 solver.cpp:563] Iteration 10000, Testing net (#0)
I0916 17:35:52.720719 20202 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 17:35:56.563422 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.928857
I0916 17:35:56.563443 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 17:35:56.563449 20216 solver.cpp:655]     Test net output #2: loss = 0.219072 (* 1 = 0.219072 loss)
I0916 17:35:56.563475 20216 solver.cpp:265] [MultiGPU] Tests completed in 11.1248s
I0916 17:35:56.767657 20216 solver.cpp:314] Iteration 10000 (3.24144 iter/s, 30.8504s/100 iter), loss = 0.0681242
I0916 17:35:56.767684 20216 solver.cpp:336]     Train net output #0: loss = 0.0681239 (* 1 = 0.0681239 loss)
I0916 17:35:56.767691 20216 sgd_solver.cpp:136] Iteration 10000, lr = 0.01, m = 0.9
I0916 17:36:16.069154 20216 solver.cpp:314] Iteration 10100 (5.18109 iter/s, 19.3009s/100 iter), loss = 0.0752725
I0916 17:36:16.069212 20216 solver.cpp:336]     Train net output #0: loss = 0.0752721 (* 1 = 0.0752721 loss)
I0916 17:36:16.069221 20216 sgd_solver.cpp:136] Iteration 10100, lr = 0.01, m = 0.9
I0916 17:36:35.430485 20216 solver.cpp:314] Iteration 10200 (5.16508 iter/s, 19.3608s/100 iter), loss = 0.12103
I0916 17:36:35.430511 20216 solver.cpp:336]     Train net output #0: loss = 0.12103 (* 1 = 0.12103 loss)
I0916 17:36:35.430517 20216 sgd_solver.cpp:136] Iteration 10200, lr = 0.01, m = 0.9
I0916 17:36:43.945358 20195 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 17:36:55.031854 20216 solver.cpp:314] Iteration 10300 (5.10405 iter/s, 19.5923s/100 iter), loss = 0.0844408
I0916 17:36:55.032376 20216 solver.cpp:336]     Train net output #0: loss = 0.0844404 (* 1 = 0.0844404 loss)
I0916 17:36:55.032498 20216 sgd_solver.cpp:136] Iteration 10300, lr = 0.01, m = 0.9
I0916 17:37:14.811975 20216 solver.cpp:314] Iteration 10400 (5.05572 iter/s, 19.7796s/100 iter), loss = 0.0557976
I0916 17:37:14.812003 20216 solver.cpp:336]     Train net output #0: loss = 0.0557972 (* 1 = 0.0557972 loss)
I0916 17:37:14.812008 20216 sgd_solver.cpp:136] Iteration 10400, lr = 0.01, m = 0.9
I0916 17:37:34.319171 20216 solver.cpp:314] Iteration 10500 (5.12646 iter/s, 19.5066s/100 iter), loss = 0.0617972
I0916 17:37:34.325795 20216 solver.cpp:336]     Train net output #0: loss = 0.0617968 (* 1 = 0.0617968 loss)
I0916 17:37:34.325867 20216 sgd_solver.cpp:136] Iteration 10500, lr = 0.01, m = 0.9
I0916 17:37:48.588306 20224 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 17:37:53.568374 20216 solver.cpp:314] Iteration 10600 (5.19517 iter/s, 19.2487s/100 iter), loss = 0.0949798
I0916 17:37:53.568398 20216 solver.cpp:336]     Train net output #0: loss = 0.0949795 (* 1 = 0.0949795 loss)
I0916 17:37:53.568403 20216 sgd_solver.cpp:136] Iteration 10600, lr = 0.01, m = 0.9
I0916 17:38:12.855937 20216 solver.cpp:314] Iteration 10700 (5.18483 iter/s, 19.287s/100 iter), loss = 0.0467802
I0916 17:38:12.856024 20216 solver.cpp:336]     Train net output #0: loss = 0.0467799 (* 1 = 0.0467799 loss)
I0916 17:38:12.856030 20216 sgd_solver.cpp:136] Iteration 10700, lr = 0.01, m = 0.9
I0916 17:38:20.659703 20195 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 17:38:32.320540 20216 solver.cpp:314] Iteration 10800 (5.13768 iter/s, 19.4641s/100 iter), loss = 0.109642
I0916 17:38:32.320562 20216 solver.cpp:336]     Train net output #0: loss = 0.109641 (* 1 = 0.109641 loss)
I0916 17:38:32.320567 20216 sgd_solver.cpp:136] Iteration 10800, lr = 0.01, m = 0.9
I0916 17:38:51.738890 20216 solver.cpp:314] Iteration 10900 (5.14991 iter/s, 19.4178s/100 iter), loss = 0.0469256
I0916 17:38:51.738945 20216 solver.cpp:336]     Train net output #0: loss = 0.0469253 (* 1 = 0.0469253 loss)
I0916 17:38:51.738950 20216 sgd_solver.cpp:136] Iteration 10900, lr = 0.01, m = 0.9
I0916 17:39:11.118367 20216 solver.cpp:314] Iteration 11000 (5.16024 iter/s, 19.3789s/100 iter), loss = 0.082404
I0916 17:39:11.118393 20216 solver.cpp:336]     Train net output #0: loss = 0.0824037 (* 1 = 0.0824037 loss)
I0916 17:39:11.118401 20216 sgd_solver.cpp:136] Iteration 11000, lr = 0.01, m = 0.9
I0916 17:39:24.736809 20220 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 17:39:30.588650 20216 solver.cpp:314] Iteration 11100 (5.13618 iter/s, 19.4697s/100 iter), loss = 0.0820266
I0916 17:39:30.588675 20216 solver.cpp:336]     Train net output #0: loss = 0.0820263 (* 1 = 0.0820263 loss)
I0916 17:39:30.588681 20216 sgd_solver.cpp:136] Iteration 11100, lr = 0.01, m = 0.9
I0916 17:39:50.015389 20216 solver.cpp:314] Iteration 11200 (5.14769 iter/s, 19.4262s/100 iter), loss = 0.0864309
I0916 17:39:50.015417 20216 solver.cpp:336]     Train net output #0: loss = 0.0864306 (* 1 = 0.0864306 loss)
I0916 17:39:50.015424 20216 sgd_solver.cpp:136] Iteration 11200, lr = 0.01, m = 0.9
I0916 17:40:09.482028 20216 solver.cpp:314] Iteration 11300 (5.13714 iter/s, 19.4661s/100 iter), loss = 0.0823764
I0916 17:40:09.482080 20216 solver.cpp:336]     Train net output #0: loss = 0.0823762 (* 1 = 0.0823762 loss)
I0916 17:40:09.482087 20216 sgd_solver.cpp:136] Iteration 11300, lr = 0.01, m = 0.9
I0916 17:40:28.498455 20216 solver.cpp:314] Iteration 11400 (5.25876 iter/s, 19.0159s/100 iter), loss = 0.0554919
I0916 17:40:28.498477 20216 solver.cpp:336]     Train net output #0: loss = 0.0554917 (* 1 = 0.0554917 loss)
I0916 17:40:28.498483 20216 sgd_solver.cpp:136] Iteration 11400, lr = 0.01, m = 0.9
I0916 17:40:28.725814 20219 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 17:40:48.497755 20216 solver.cpp:314] Iteration 11500 (5.00032 iter/s, 19.9987s/100 iter), loss = 0.0869469
I0916 17:40:48.497826 20216 solver.cpp:336]     Train net output #0: loss = 0.0869466 (* 1 = 0.0869466 loss)
I0916 17:40:48.497834 20216 sgd_solver.cpp:136] Iteration 11500, lr = 0.01, m = 0.9
I0916 17:41:08.779372 20216 solver.cpp:314] Iteration 11600 (4.93071 iter/s, 20.281s/100 iter), loss = 0.0977212
I0916 17:41:08.779407 20216 solver.cpp:336]     Train net output #0: loss = 0.0977209 (* 1 = 0.0977209 loss)
I0916 17:41:08.779412 20216 sgd_solver.cpp:136] Iteration 11600, lr = 0.01, m = 0.9
I0916 17:41:29.069613 20216 solver.cpp:314] Iteration 11700 (4.92862 iter/s, 20.2897s/100 iter), loss = 0.0433001
I0916 17:41:29.069669 20216 solver.cpp:336]     Train net output #0: loss = 0.0432998 (* 1 = 0.0432998 loss)
I0916 17:41:29.069676 20216 sgd_solver.cpp:136] Iteration 11700, lr = 0.01, m = 0.9
I0916 17:41:35.367566 20197 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 17:41:49.081416 20216 solver.cpp:314] Iteration 11800 (4.99719 iter/s, 20.0112s/100 iter), loss = 0.0677215
I0916 17:41:49.081444 20216 solver.cpp:336]     Train net output #0: loss = 0.0677212 (* 1 = 0.0677212 loss)
I0916 17:41:49.081450 20216 sgd_solver.cpp:136] Iteration 11800, lr = 0.01, m = 0.9
I0916 17:42:08.512344 20219 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 17:42:09.288568 20216 solver.cpp:314] Iteration 11900 (4.94888 iter/s, 20.2066s/100 iter), loss = 0.0669838
I0916 17:42:09.288594 20216 solver.cpp:336]     Train net output #0: loss = 0.0669835 (* 1 = 0.0669835 loss)
I0916 17:42:09.288597 20216 sgd_solver.cpp:136] Iteration 11900, lr = 0.01, m = 0.9
I0916 17:42:29.459095 20216 solver.cpp:563] Iteration 12000, Testing net (#0)
I0916 17:42:41.260184 20204 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 17:42:41.756243 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.936579
I0916 17:42:41.756264 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 0.999998
I0916 17:42:41.756269 20216 solver.cpp:655]     Test net output #2: loss = 0.185516 (* 1 = 0.185516 loss)
I0916 17:42:41.756301 20216 solver.cpp:265] [MultiGPU] Tests completed in 12.2969s
I0916 17:42:41.941153 20216 solver.cpp:314] Iteration 12000 (3.06263 iter/s, 32.6517s/100 iter), loss = 0.0463821
I0916 17:42:41.941180 20216 solver.cpp:336]     Train net output #0: loss = 0.0463818 (* 1 = 0.0463818 loss)
I0916 17:42:41.941187 20216 sgd_solver.cpp:136] Iteration 12000, lr = 0.01, m = 0.9
I0916 17:43:01.831161 20216 solver.cpp:314] Iteration 12100 (5.02779 iter/s, 19.8894s/100 iter), loss = 0.11638
I0916 17:43:01.831187 20216 solver.cpp:336]     Train net output #0: loss = 0.11638 (* 1 = 0.11638 loss)
I0916 17:43:01.831193 20216 sgd_solver.cpp:136] Iteration 12100, lr = 0.01, m = 0.9
I0916 17:43:22.169139 20216 solver.cpp:314] Iteration 12200 (4.91705 iter/s, 20.3374s/100 iter), loss = 0.0677313
I0916 17:43:22.169240 20216 solver.cpp:336]     Train net output #0: loss = 0.0677309 (* 1 = 0.0677309 loss)
I0916 17:43:22.169248 20216 sgd_solver.cpp:136] Iteration 12200, lr = 0.01, m = 0.9
I0916 17:43:27.700543 20197 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 17:43:42.312300 20216 solver.cpp:314] Iteration 12300 (4.9646 iter/s, 20.1426s/100 iter), loss = 0.0661459
I0916 17:43:42.312325 20216 solver.cpp:336]     Train net output #0: loss = 0.0661456 (* 1 = 0.0661456 loss)
I0916 17:43:42.312330 20216 sgd_solver.cpp:136] Iteration 12300, lr = 0.01, m = 0.9
I0916 17:44:01.016595 20220 data_reader.cpp:305] Starting prefetch of epoch 10
I0916 17:44:02.552428 20216 solver.cpp:314] Iteration 12400 (4.94082 iter/s, 20.2396s/100 iter), loss = 0.0682469
I0916 17:44:02.552453 20216 solver.cpp:336]     Train net output #0: loss = 0.0682465 (* 1 = 0.0682465 loss)
I0916 17:44:02.552459 20216 sgd_solver.cpp:136] Iteration 12400, lr = 0.01, m = 0.9
I0916 17:44:22.343866 20216 solver.cpp:314] Iteration 12500 (5.05283 iter/s, 19.7909s/100 iter), loss = 0.0870621
I0916 17:44:22.343891 20216 solver.cpp:336]     Train net output #0: loss = 0.0870617 (* 1 = 0.0870617 loss)
I0916 17:44:22.343896 20216 sgd_solver.cpp:136] Iteration 12500, lr = 0.01, m = 0.9
I0916 17:44:41.771278 20216 solver.cpp:314] Iteration 12600 (5.14751 iter/s, 19.4269s/100 iter), loss = 0.0512303
I0916 17:44:41.771327 20216 solver.cpp:336]     Train net output #0: loss = 0.0512299 (* 1 = 0.0512299 loss)
I0916 17:44:41.771334 20216 sgd_solver.cpp:136] Iteration 12600, lr = 0.01, m = 0.9
I0916 17:45:01.452935 20216 solver.cpp:314] Iteration 12700 (5.08102 iter/s, 19.6811s/100 iter), loss = 0.191793
I0916 17:45:01.452963 20216 solver.cpp:336]     Train net output #0: loss = 0.191793 (* 1 = 0.191793 loss)
I0916 17:45:01.452968 20216 sgd_solver.cpp:136] Iteration 12700, lr = 0.01, m = 0.9
I0916 17:45:06.041791 20220 data_reader.cpp:305] Starting prefetch of epoch 11
I0916 17:45:20.786303 20216 solver.cpp:314] Iteration 12800 (5.17255 iter/s, 19.3328s/100 iter), loss = 0.0614057
I0916 17:45:20.786352 20216 solver.cpp:336]     Train net output #0: loss = 0.0614054 (* 1 = 0.0614054 loss)
I0916 17:45:20.786357 20216 sgd_solver.cpp:136] Iteration 12800, lr = 0.01, m = 0.9
I0916 17:45:40.452123 20216 solver.cpp:314] Iteration 12900 (5.08511 iter/s, 19.6653s/100 iter), loss = 0.0780624
I0916 17:45:40.452153 20216 solver.cpp:336]     Train net output #0: loss = 0.078062 (* 1 = 0.078062 loss)
I0916 17:45:40.452160 20216 sgd_solver.cpp:136] Iteration 12900, lr = 0.01, m = 0.9
I0916 17:46:00.072892 20216 solver.cpp:314] Iteration 13000 (5.09678 iter/s, 19.6202s/100 iter), loss = 0.0569269
I0916 17:46:00.072978 20216 solver.cpp:336]     Train net output #0: loss = 0.0569265 (* 1 = 0.0569265 loss)
I0916 17:46:00.072986 20216 sgd_solver.cpp:136] Iteration 13000, lr = 0.01, m = 0.9
I0916 17:46:10.428333 20197 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 17:46:19.561451 20216 solver.cpp:314] Iteration 13100 (5.13136 iter/s, 19.488s/100 iter), loss = 0.101684
I0916 17:46:19.561473 20216 solver.cpp:336]     Train net output #0: loss = 0.101684 (* 1 = 0.101684 loss)
I0916 17:46:19.561477 20216 sgd_solver.cpp:136] Iteration 13100, lr = 0.01, m = 0.9
I0916 17:46:39.161173 20216 solver.cpp:314] Iteration 13200 (5.10226 iter/s, 19.5992s/100 iter), loss = 0.0530747
I0916 17:46:39.161228 20216 solver.cpp:336]     Train net output #0: loss = 0.0530743 (* 1 = 0.0530743 loss)
I0916 17:46:39.161234 20216 sgd_solver.cpp:136] Iteration 13200, lr = 0.01, m = 0.9
I0916 17:46:42.866981 20219 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 17:46:58.484273 20216 solver.cpp:314] Iteration 13300 (5.1753 iter/s, 19.3226s/100 iter), loss = 0.0669893
I0916 17:46:58.484300 20216 solver.cpp:336]     Train net output #0: loss = 0.0669889 (* 1 = 0.0669889 loss)
I0916 17:46:58.484307 20216 sgd_solver.cpp:136] Iteration 13300, lr = 0.01, m = 0.9
I0916 17:47:18.417423 20216 solver.cpp:314] Iteration 13400 (5.01691 iter/s, 19.9326s/100 iter), loss = 0.0647814
I0916 17:47:18.417508 20216 solver.cpp:336]     Train net output #0: loss = 0.0647811 (* 1 = 0.0647811 loss)
I0916 17:47:18.417515 20216 sgd_solver.cpp:136] Iteration 13400, lr = 0.01, m = 0.9
I0916 17:47:38.025936 20216 solver.cpp:314] Iteration 13500 (5.09997 iter/s, 19.608s/100 iter), loss = 0.0973614
I0916 17:47:38.025959 20216 solver.cpp:336]     Train net output #0: loss = 0.097361 (* 1 = 0.097361 loss)
I0916 17:47:38.025962 20216 sgd_solver.cpp:136] Iteration 13500, lr = 0.01, m = 0.9
I0916 17:47:47.592839 20219 data_reader.cpp:305] Starting prefetch of epoch 10
I0916 17:47:57.530673 20216 solver.cpp:314] Iteration 13600 (5.1271 iter/s, 19.5042s/100 iter), loss = 0.0779749
I0916 17:47:57.530724 20216 solver.cpp:336]     Train net output #0: loss = 0.0779746 (* 1 = 0.0779746 loss)
I0916 17:47:57.530730 20216 sgd_solver.cpp:136] Iteration 13600, lr = 0.01, m = 0.9
I0916 17:48:16.975174 20216 solver.cpp:314] Iteration 13700 (5.14299 iter/s, 19.444s/100 iter), loss = 0.0591573
I0916 17:48:16.975196 20216 solver.cpp:336]     Train net output #0: loss = 0.0591569 (* 1 = 0.0591569 loss)
I0916 17:48:16.975203 20216 sgd_solver.cpp:136] Iteration 13700, lr = 0.01, m = 0.9
I0916 17:48:36.692287 20216 solver.cpp:314] Iteration 13800 (5.07188 iter/s, 19.7166s/100 iter), loss = 0.0857937
I0916 17:48:36.692342 20216 solver.cpp:336]     Train net output #0: loss = 0.0857933 (* 1 = 0.0857933 loss)
I0916 17:48:36.692348 20216 sgd_solver.cpp:136] Iteration 13800, lr = 0.01, m = 0.9
I0916 17:48:52.209857 20223 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 17:48:56.142163 20216 solver.cpp:314] Iteration 13900 (5.14156 iter/s, 19.4493s/100 iter), loss = 0.0892602
I0916 17:48:56.142186 20216 solver.cpp:336]     Train net output #0: loss = 0.0892599 (* 1 = 0.0892599 loss)
I0916 17:48:56.142194 20216 sgd_solver.cpp:136] Iteration 13900, lr = 0.01, m = 0.9
I0916 17:49:15.851693 20216 solver.cpp:563] Iteration 14000, Testing net (#0)
I0916 17:49:23.648319 20202 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 17:49:27.864349 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.946475
I0916 17:49:27.864370 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 17:49:27.864377 20216 solver.cpp:655]     Test net output #2: loss = 0.165586 (* 1 = 0.165586 loss)
I0916 17:49:27.864405 20216 solver.cpp:265] [MultiGPU] Tests completed in 12.0124s
I0916 17:49:28.079048 20216 solver.cpp:314] Iteration 14000 (3.13126 iter/s, 31.936s/100 iter), loss = 0.114693
I0916 17:49:28.079087 20216 solver.cpp:336]     Train net output #0: loss = 0.114693 (* 1 = 0.114693 loss)
I0916 17:49:28.079094 20216 sgd_solver.cpp:136] Iteration 14000, lr = 0.01, m = 0.9
I0916 17:49:48.091027 20216 solver.cpp:314] Iteration 14100 (4.99715 iter/s, 20.0114s/100 iter), loss = 0.104047
I0916 17:49:48.091087 20216 solver.cpp:336]     Train net output #0: loss = 0.104047 (* 1 = 0.104047 loss)
I0916 17:49:48.091095 20216 sgd_solver.cpp:136] Iteration 14100, lr = 0.01, m = 0.9
I0916 17:50:07.922500 20216 solver.cpp:314] Iteration 14200 (5.04263 iter/s, 19.8309s/100 iter), loss = 0.0734515
I0916 17:50:07.922549 20216 solver.cpp:336]     Train net output #0: loss = 0.0734512 (* 1 = 0.0734512 loss)
I0916 17:50:07.922564 20216 sgd_solver.cpp:136] Iteration 14200, lr = 0.01, m = 0.9
I0916 17:50:09.894647 20195 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 17:50:27.788020 20216 solver.cpp:314] Iteration 14300 (5.03399 iter/s, 19.865s/100 iter), loss = 0.0918481
I0916 17:50:27.788076 20216 solver.cpp:336]     Train net output #0: loss = 0.0918477 (* 1 = 0.0918477 loss)
I0916 17:50:27.788084 20216 sgd_solver.cpp:136] Iteration 14300, lr = 0.01, m = 0.9
I0916 17:50:47.966452 20216 solver.cpp:314] Iteration 14400 (4.95592 iter/s, 20.1779s/100 iter), loss = 0.0830364
I0916 17:50:47.966480 20216 solver.cpp:336]     Train net output #0: loss = 0.0830361 (* 1 = 0.0830361 loss)
I0916 17:50:47.966486 20216 sgd_solver.cpp:136] Iteration 14400, lr = 0.01, m = 0.9
I0916 17:51:08.094210 20216 solver.cpp:314] Iteration 14500 (4.9684 iter/s, 20.1272s/100 iter), loss = 0.0892277
I0916 17:51:08.094305 20216 solver.cpp:336]     Train net output #0: loss = 0.0892274 (* 1 = 0.0892274 loss)
I0916 17:51:08.094321 20216 sgd_solver.cpp:136] Iteration 14500, lr = 0.01, m = 0.9
I0916 17:51:16.211709 20224 data_reader.cpp:305] Starting prefetch of epoch 10
I0916 17:51:27.983129 20216 solver.cpp:314] Iteration 14600 (5.02807 iter/s, 19.8884s/100 iter), loss = 0.0817998
I0916 17:51:27.983151 20216 solver.cpp:336]     Train net output #0: loss = 0.0817995 (* 1 = 0.0817995 loss)
I0916 17:51:27.983155 20216 sgd_solver.cpp:136] Iteration 14600, lr = 0.01, m = 0.9
I0916 17:51:48.108212 20216 solver.cpp:314] Iteration 14700 (4.96906 iter/s, 20.1245s/100 iter), loss = 0.0899649
I0916 17:51:48.108297 20216 solver.cpp:336]     Train net output #0: loss = 0.0899646 (* 1 = 0.0899646 loss)
I0916 17:51:48.108311 20216 sgd_solver.cpp:136] Iteration 14700, lr = 0.01, m = 0.9
I0916 17:51:49.359139 20219 data_reader.cpp:305] Starting prefetch of epoch 11
I0916 17:52:08.118484 20216 solver.cpp:314] Iteration 14800 (4.99757 iter/s, 20.0097s/100 iter), loss = 0.0671742
I0916 17:52:08.118517 20216 solver.cpp:336]     Train net output #0: loss = 0.067174 (* 1 = 0.067174 loss)
I0916 17:52:08.118523 20216 sgd_solver.cpp:136] Iteration 14800, lr = 0.01, m = 0.9
I0916 17:52:27.968421 20216 solver.cpp:314] Iteration 14900 (5.03794 iter/s, 19.8494s/100 iter), loss = 0.236483
I0916 17:52:27.968508 20216 solver.cpp:336]     Train net output #0: loss = 0.236483 (* 1 = 0.236483 loss)
I0916 17:52:27.968516 20216 sgd_solver.cpp:136] Iteration 14900, lr = 0.01, m = 0.9
I0916 17:52:47.826380 20216 solver.cpp:314] Iteration 15000 (5.03591 iter/s, 19.8574s/100 iter), loss = 0.0892772
I0916 17:52:47.826407 20216 solver.cpp:336]     Train net output #0: loss = 0.089277 (* 1 = 0.089277 loss)
I0916 17:52:47.826414 20216 sgd_solver.cpp:136] Iteration 15000, lr = 0.01, m = 0.9
I0916 17:52:55.056923 20220 data_reader.cpp:305] Starting prefetch of epoch 12
I0916 17:53:07.334544 20216 solver.cpp:314] Iteration 15100 (5.1262 iter/s, 19.5076s/100 iter), loss = 0.142289
I0916 17:53:07.334599 20216 solver.cpp:336]     Train net output #0: loss = 0.142289 (* 1 = 0.142289 loss)
I0916 17:53:07.334605 20216 sgd_solver.cpp:136] Iteration 15100, lr = 0.01, m = 0.9
I0916 17:53:26.745555 20216 solver.cpp:314] Iteration 15200 (5.15226 iter/s, 19.409s/100 iter), loss = 0.0876849
I0916 17:53:26.745640 20216 solver.cpp:336]     Train net output #0: loss = 0.0876847 (* 1 = 0.0876847 loss)
I0916 17:53:26.745661 20216 sgd_solver.cpp:136] Iteration 15200, lr = 0.01, m = 0.9
I0916 17:53:46.069818 20216 solver.cpp:314] Iteration 15300 (5.17499 iter/s, 19.3237s/100 iter), loss = 0.0466966
I0916 17:53:46.069871 20216 solver.cpp:336]     Train net output #0: loss = 0.0466964 (* 1 = 0.0466964 loss)
I0916 17:53:46.069876 20216 sgd_solver.cpp:136] Iteration 15300, lr = 0.01, m = 0.9
I0916 17:53:59.199497 20224 data_reader.cpp:305] Starting prefetch of epoch 11
I0916 17:54:05.505010 20216 solver.cpp:314] Iteration 15400 (5.14545 iter/s, 19.4346s/100 iter), loss = 0.0750829
I0916 17:54:05.505034 20216 solver.cpp:336]     Train net output #0: loss = 0.0750826 (* 1 = 0.0750826 loss)
I0916 17:54:05.505039 20216 sgd_solver.cpp:136] Iteration 15400, lr = 0.01, m = 0.9
I0916 17:54:25.009024 20216 solver.cpp:314] Iteration 15500 (5.12729 iter/s, 19.5035s/100 iter), loss = 0.0756028
I0916 17:54:25.009083 20216 solver.cpp:336]     Train net output #0: loss = 0.0756026 (* 1 = 0.0756026 loss)
I0916 17:54:25.009089 20216 sgd_solver.cpp:136] Iteration 15500, lr = 0.01, m = 0.9
I0916 17:54:31.472761 20195 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 17:54:44.309609 20216 solver.cpp:314] Iteration 15600 (5.18133 iter/s, 19.3s/100 iter), loss = 0.0676534
I0916 17:54:44.309630 20216 solver.cpp:336]     Train net output #0: loss = 0.0676532 (* 1 = 0.0676532 loss)
I0916 17:54:44.309635 20216 sgd_solver.cpp:136] Iteration 15600, lr = 0.01, m = 0.9
I0916 17:55:03.709817 20216 solver.cpp:314] Iteration 15700 (5.15473 iter/s, 19.3997s/100 iter), loss = 0.101651
I0916 17:55:03.709892 20216 solver.cpp:336]     Train net output #0: loss = 0.10165 (* 1 = 0.10165 loss)
I0916 17:55:03.709897 20216 sgd_solver.cpp:136] Iteration 15700, lr = 0.01, m = 0.9
I0916 17:55:23.206876 20216 solver.cpp:314] Iteration 15800 (5.12912 iter/s, 19.4965s/100 iter), loss = 0.0815011
I0916 17:55:23.206902 20216 solver.cpp:336]     Train net output #0: loss = 0.0815009 (* 1 = 0.0815009 loss)
I0916 17:55:23.206907 20216 sgd_solver.cpp:136] Iteration 15800, lr = 0.01, m = 0.9
I0916 17:55:35.598996 20219 data_reader.cpp:305] Starting prefetch of epoch 12
I0916 17:55:42.750195 20216 solver.cpp:314] Iteration 15900 (5.11698 iter/s, 19.5428s/100 iter), loss = 0.0510579
I0916 17:55:42.750222 20216 solver.cpp:336]     Train net output #0: loss = 0.0510576 (* 1 = 0.0510576 loss)
I0916 17:55:42.750229 20216 sgd_solver.cpp:136] Iteration 15900, lr = 0.01, m = 0.9
I0916 17:56:02.018666 20216 solver.cpp:563] Iteration 16000, Testing net (#0)
I0916 17:56:12.290490 20248 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 17:56:12.810972 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.945786
I0916 17:56:12.810993 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 17:56:12.810998 20216 solver.cpp:655]     Test net output #2: loss = 0.177928 (* 1 = 0.177928 loss)
I0916 17:56:12.811079 20216 solver.cpp:265] [MultiGPU] Tests completed in 10.7921s
I0916 17:56:13.035038 20216 solver.cpp:314] Iteration 16000 (3.30207 iter/s, 30.284s/100 iter), loss = 0.087145
I0916 17:56:13.035063 20216 solver.cpp:336]     Train net output #0: loss = 0.0871447 (* 1 = 0.0871447 loss)
I0916 17:56:13.035068 20216 sgd_solver.cpp:136] Iteration 16000, lr = 0.01, m = 0.9
I0916 17:56:18.509675 20195 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 17:56:32.359614 20216 solver.cpp:314] Iteration 16100 (5.1749 iter/s, 19.324s/100 iter), loss = 0.102278
I0916 17:56:32.359642 20216 solver.cpp:336]     Train net output #0: loss = 0.102278 (* 1 = 0.102278 loss)
I0916 17:56:32.359649 20216 sgd_solver.cpp:136] Iteration 16100, lr = 0.01, m = 0.9
I0916 17:56:51.831537 20216 solver.cpp:314] Iteration 16200 (5.13575 iter/s, 19.4714s/100 iter), loss = 0.125623
I0916 17:56:51.831589 20216 solver.cpp:336]     Train net output #0: loss = 0.125622 (* 1 = 0.125622 loss)
I0916 17:56:51.831596 20216 sgd_solver.cpp:136] Iteration 16200, lr = 0.01, m = 0.9
I0916 17:57:11.104058 20216 solver.cpp:314] Iteration 16300 (5.18888 iter/s, 19.272s/100 iter), loss = 0.068096
I0916 17:57:11.104079 20216 solver.cpp:336]     Train net output #0: loss = 0.0680959 (* 1 = 0.0680959 loss)
I0916 17:57:11.104084 20216 sgd_solver.cpp:136] Iteration 16300, lr = 0.01, m = 0.9
I0916 17:57:22.624392 20195 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 17:57:30.429483 20216 solver.cpp:314] Iteration 16400 (5.17468 iter/s, 19.3249s/100 iter), loss = 0.065664
I0916 17:57:30.429513 20216 solver.cpp:336]     Train net output #0: loss = 0.0656639 (* 1 = 0.0656639 loss)
I0916 17:57:30.429520 20216 sgd_solver.cpp:136] Iteration 16400, lr = 0.01, m = 0.9
I0916 17:57:49.970305 20216 solver.cpp:314] Iteration 16500 (5.11764 iter/s, 19.5403s/100 iter), loss = 0.0735381
I0916 17:57:49.970331 20216 solver.cpp:336]     Train net output #0: loss = 0.0735379 (* 1 = 0.0735379 loss)
I0916 17:57:49.970335 20216 sgd_solver.cpp:136] Iteration 16500, lr = 0.01, m = 0.9
I0916 17:58:09.599433 20216 solver.cpp:314] Iteration 16600 (5.09461 iter/s, 19.6286s/100 iter), loss = 0.0760547
I0916 17:58:09.599510 20216 solver.cpp:336]     Train net output #0: loss = 0.0760545 (* 1 = 0.0760545 loss)
I0916 17:58:09.599519 20216 sgd_solver.cpp:136] Iteration 16600, lr = 0.01, m = 0.9
I0916 17:58:27.047715 20219 data_reader.cpp:305] Starting prefetch of epoch 13
I0916 17:58:29.076601 20216 solver.cpp:314] Iteration 16700 (5.13436 iter/s, 19.4766s/100 iter), loss = 0.19043
I0916 17:58:29.076650 20216 solver.cpp:336]     Train net output #0: loss = 0.19043 (* 1 = 0.19043 loss)
I0916 17:58:29.076663 20216 sgd_solver.cpp:136] Iteration 16700, lr = 0.01, m = 0.9
I0916 17:58:49.168865 20216 solver.cpp:314] Iteration 16800 (4.97718 iter/s, 20.0917s/100 iter), loss = 0.134322
I0916 17:58:49.168937 20216 solver.cpp:336]     Train net output #0: loss = 0.134322 (* 1 = 0.134322 loss)
I0916 17:58:49.168946 20216 sgd_solver.cpp:136] Iteration 16800, lr = 0.01, m = 0.9
I0916 17:59:09.435042 20216 solver.cpp:314] Iteration 16900 (4.93447 iter/s, 20.2656s/100 iter), loss = 0.0690393
I0916 17:59:09.435075 20216 solver.cpp:336]     Train net output #0: loss = 0.0690392 (* 1 = 0.0690392 loss)
I0916 17:59:09.435081 20216 sgd_solver.cpp:136] Iteration 16900, lr = 0.01, m = 0.9
I0916 17:59:29.441757 20216 solver.cpp:314] Iteration 17000 (4.99846 iter/s, 20.0062s/100 iter), loss = 0.137397
I0916 17:59:29.441884 20216 solver.cpp:336]     Train net output #0: loss = 0.137397 (* 1 = 0.137397 loss)
I0916 17:59:29.441892 20216 sgd_solver.cpp:136] Iteration 17000, lr = 0.01, m = 0.9
I0916 17:59:33.496917 20224 data_reader.cpp:305] Starting prefetch of epoch 12
I0916 17:59:49.373986 20216 solver.cpp:314] Iteration 17100 (5.01714 iter/s, 19.9317s/100 iter), loss = 0.0753106
I0916 17:59:49.374012 20216 solver.cpp:336]     Train net output #0: loss = 0.0753104 (* 1 = 0.0753104 loss)
I0916 17:59:49.374018 20216 sgd_solver.cpp:136] Iteration 17100, lr = 0.01, m = 0.9
I0916 18:00:06.620605 20219 data_reader.cpp:305] Starting prefetch of epoch 14
I0916 18:00:09.596313 20216 solver.cpp:314] Iteration 17200 (4.94517 iter/s, 20.2218s/100 iter), loss = 0.086843
I0916 18:00:09.596340 20216 solver.cpp:336]     Train net output #0: loss = 0.0868429 (* 1 = 0.0868429 loss)
I0916 18:00:09.596345 20216 sgd_solver.cpp:136] Iteration 17200, lr = 0.01, m = 0.9
I0916 18:00:29.745640 20216 solver.cpp:314] Iteration 17300 (4.96309 iter/s, 20.1488s/100 iter), loss = 0.078741
I0916 18:00:29.745697 20216 solver.cpp:336]     Train net output #0: loss = 0.0787408 (* 1 = 0.0787408 loss)
I0916 18:00:29.745724 20216 sgd_solver.cpp:136] Iteration 17300, lr = 0.01, m = 0.9
I0916 18:00:49.871052 20216 solver.cpp:314] Iteration 17400 (4.96898 iter/s, 20.1248s/100 iter), loss = 0.0529712
I0916 18:00:49.871106 20216 solver.cpp:336]     Train net output #0: loss = 0.052971 (* 1 = 0.052971 loss)
I0916 18:00:49.871117 20216 sgd_solver.cpp:136] Iteration 17400, lr = 0.01, m = 0.9
I0916 18:01:10.059880 20216 solver.cpp:314] Iteration 17500 (4.95337 iter/s, 20.1883s/100 iter), loss = 0.063841
I0916 18:01:10.059906 20216 solver.cpp:336]     Train net output #0: loss = 0.0638409 (* 1 = 0.0638409 loss)
I0916 18:01:10.059913 20216 sgd_solver.cpp:136] Iteration 17500, lr = 0.01, m = 0.9
I0916 18:01:13.318928 20195 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 18:01:30.453135 20216 solver.cpp:314] Iteration 17600 (4.90372 iter/s, 20.3927s/100 iter), loss = 0.0858521
I0916 18:01:30.453219 20216 solver.cpp:336]     Train net output #0: loss = 0.0858519 (* 1 = 0.0858519 loss)
I0916 18:01:30.453227 20216 sgd_solver.cpp:136] Iteration 17600, lr = 0.01, m = 0.9
I0916 18:01:50.430434 20216 solver.cpp:314] Iteration 17700 (5.00582 iter/s, 19.9767s/100 iter), loss = 0.0707769
I0916 18:01:50.430464 20216 solver.cpp:336]     Train net output #0: loss = 0.0707767 (* 1 = 0.0707767 loss)
I0916 18:01:50.430470 20216 sgd_solver.cpp:136] Iteration 17700, lr = 0.01, m = 0.9
I0916 18:02:10.249703 20216 solver.cpp:314] Iteration 17800 (5.04574 iter/s, 19.8187s/100 iter), loss = 0.0787063
I0916 18:02:10.249824 20216 solver.cpp:336]     Train net output #0: loss = 0.0787062 (* 1 = 0.0787062 loss)
I0916 18:02:10.249830 20216 sgd_solver.cpp:136] Iteration 17800, lr = 0.01, m = 0.9
I0916 18:02:19.606284 20223 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 18:02:30.306793 20216 solver.cpp:314] Iteration 17900 (4.98591 iter/s, 20.0565s/100 iter), loss = 0.0890306
I0916 18:02:30.306823 20216 solver.cpp:336]     Train net output #0: loss = 0.0890304 (* 1 = 0.0890304 loss)
I0916 18:02:30.306829 20216 sgd_solver.cpp:136] Iteration 17900, lr = 0.01, m = 0.9
I0916 18:02:50.170586 20216 solver.cpp:563] Iteration 18000, Testing net (#0)
I0916 18:02:57.594008 20202 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 18:03:01.805646 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.941738
I0916 18:03:01.805670 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 18:03:01.805676 20216 solver.cpp:655]     Test net output #2: loss = 0.197965 (* 1 = 0.197965 loss)
I0916 18:03:01.805704 20216 solver.cpp:265] [MultiGPU] Tests completed in 11.6348s
I0916 18:03:02.016052 20216 solver.cpp:314] Iteration 18000 (3.15374 iter/s, 31.7084s/100 iter), loss = 0.141896
I0916 18:03:02.016077 20216 solver.cpp:336]     Train net output #0: loss = 0.141896 (* 1 = 0.141896 loss)
I0916 18:03:02.016083 20216 sgd_solver.cpp:136] Iteration 18000, lr = 0.01, m = 0.9
I0916 18:03:21.803602 20216 solver.cpp:314] Iteration 18100 (5.05383 iter/s, 19.787s/100 iter), loss = 0.0748648
I0916 18:03:21.803653 20216 solver.cpp:336]     Train net output #0: loss = 0.0748647 (* 1 = 0.0748647 loss)
I0916 18:03:21.803658 20216 sgd_solver.cpp:136] Iteration 18100, lr = 0.01, m = 0.9
I0916 18:03:37.230576 20220 data_reader.cpp:305] Starting prefetch of epoch 13
I0916 18:03:41.851393 20216 solver.cpp:314] Iteration 18200 (4.98822 iter/s, 20.0472s/100 iter), loss = 0.0710703
I0916 18:03:41.851419 20216 solver.cpp:336]     Train net output #0: loss = 0.0710701 (* 1 = 0.0710701 loss)
I0916 18:03:41.851425 20216 sgd_solver.cpp:136] Iteration 18200, lr = 0.01, m = 0.9
I0916 18:04:02.095932 20216 solver.cpp:314] Iteration 18300 (4.93974 iter/s, 20.244s/100 iter), loss = 0.104358
I0916 18:04:02.096012 20216 solver.cpp:336]     Train net output #0: loss = 0.104358 (* 1 = 0.104358 loss)
I0916 18:04:02.096019 20216 sgd_solver.cpp:136] Iteration 18300, lr = 0.01, m = 0.9
I0916 18:04:21.789393 20216 solver.cpp:314] Iteration 18400 (5.07797 iter/s, 19.6929s/100 iter), loss = 0.0708261
I0916 18:04:21.789422 20216 solver.cpp:336]     Train net output #0: loss = 0.0708259 (* 1 = 0.0708259 loss)
I0916 18:04:21.789427 20216 sgd_solver.cpp:136] Iteration 18400, lr = 0.01, m = 0.9
I0916 18:04:41.784521 20216 solver.cpp:314] Iteration 18500 (5.00136 iter/s, 19.9946s/100 iter), loss = 0.098051
I0916 18:04:41.784580 20216 solver.cpp:336]     Train net output #0: loss = 0.0980508 (* 1 = 0.0980508 loss)
I0916 18:04:41.784587 20216 sgd_solver.cpp:136] Iteration 18500, lr = 0.01, m = 0.9
I0916 18:04:43.398036 20224 data_reader.cpp:305] Starting prefetch of epoch 13
I0916 18:05:01.721658 20216 solver.cpp:314] Iteration 18600 (5.01591 iter/s, 19.9366s/100 iter), loss = 0.101695
I0916 18:05:01.721683 20216 solver.cpp:336]     Train net output #0: loss = 0.101695 (* 1 = 0.101695 loss)
I0916 18:05:01.721688 20216 sgd_solver.cpp:136] Iteration 18600, lr = 0.01, m = 0.9
I0916 18:05:16.344594 20195 data_reader.cpp:305] Starting prefetch of epoch 9
I0916 18:05:21.567337 20216 solver.cpp:314] Iteration 18700 (5.03902 iter/s, 19.8451s/100 iter), loss = 0.0514444
I0916 18:05:21.567438 20216 solver.cpp:336]     Train net output #0: loss = 0.0514443 (* 1 = 0.0514443 loss)
I0916 18:05:21.567477 20216 sgd_solver.cpp:136] Iteration 18700, lr = 0.01, m = 0.9
I0916 18:05:41.452039 20216 solver.cpp:314] Iteration 18800 (5.02913 iter/s, 19.8841s/100 iter), loss = 0.240441
I0916 18:05:41.452065 20216 solver.cpp:336]     Train net output #0: loss = 0.24044 (* 1 = 0.24044 loss)
I0916 18:05:41.452071 20216 sgd_solver.cpp:136] Iteration 18800, lr = 0.01, m = 0.9
I0916 18:06:01.422524 20216 solver.cpp:314] Iteration 18900 (5.00753 iter/s, 19.9699s/100 iter), loss = 0.083131
I0916 18:06:01.422621 20216 solver.cpp:336]     Train net output #0: loss = 0.0831308 (* 1 = 0.0831308 loss)
I0916 18:06:01.422638 20216 sgd_solver.cpp:136] Iteration 18900, lr = 0.01, m = 0.9
I0916 18:06:22.117764 20216 solver.cpp:314] Iteration 19000 (4.83216 iter/s, 20.6947s/100 iter), loss = 0.178727
I0916 18:06:22.117785 20216 solver.cpp:336]     Train net output #0: loss = 0.178727 (* 1 = 0.178727 loss)
I0916 18:06:22.117790 20216 sgd_solver.cpp:136] Iteration 19000, lr = 0.01, m = 0.9
I0916 18:06:22.741112 20219 data_reader.cpp:305] Starting prefetch of epoch 15
I0916 18:06:41.967100 20216 solver.cpp:314] Iteration 19100 (5.03809 iter/s, 19.8488s/100 iter), loss = 0.0592058
I0916 18:06:41.967166 20216 solver.cpp:336]     Train net output #0: loss = 0.0592057 (* 1 = 0.0592057 loss)
I0916 18:06:41.967173 20216 sgd_solver.cpp:136] Iteration 19100, lr = 0.01, m = 0.9
I0916 18:07:02.281898 20216 solver.cpp:314] Iteration 19200 (4.92266 iter/s, 20.3142s/100 iter), loss = 0.105693
I0916 18:07:02.281921 20216 solver.cpp:336]     Train net output #0: loss = 0.105693 (* 1 = 0.105693 loss)
I0916 18:07:02.281927 20216 sgd_solver.cpp:136] Iteration 19200, lr = 0.01, m = 0.9
I0916 18:07:21.748831 20216 solver.cpp:314] Iteration 19300 (5.13706 iter/s, 19.4664s/100 iter), loss = 0.0943788
I0916 18:07:21.748913 20216 solver.cpp:336]     Train net output #0: loss = 0.0943786 (* 1 = 0.0943786 loss)
I0916 18:07:21.748920 20216 sgd_solver.cpp:136] Iteration 19300, lr = 0.01, m = 0.9
I0916 18:07:28.375494 20197 data_reader.cpp:305] Starting prefetch of epoch 10
I0916 18:07:41.021060 20216 solver.cpp:314] Iteration 19400 (5.18896 iter/s, 19.2717s/100 iter), loss = 0.114119
I0916 18:07:41.021091 20216 solver.cpp:336]     Train net output #0: loss = 0.114119 (* 1 = 0.114119 loss)
I0916 18:07:41.021097 20216 sgd_solver.cpp:136] Iteration 19400, lr = 0.01, m = 0.9
I0916 18:08:00.363957 20220 data_reader.cpp:305] Starting prefetch of epoch 14
I0916 18:08:00.512583 20216 solver.cpp:314] Iteration 19500 (5.13058 iter/s, 19.491s/100 iter), loss = 0.0747218
I0916 18:08:00.512609 20216 solver.cpp:336]     Train net output #0: loss = 0.0747217 (* 1 = 0.0747217 loss)
I0916 18:08:00.512615 20216 sgd_solver.cpp:136] Iteration 19500, lr = 0.01, m = 0.9
I0916 18:08:19.957547 20216 solver.cpp:314] Iteration 19600 (5.14286 iter/s, 19.4444s/100 iter), loss = 0.0742194
I0916 18:08:19.957578 20216 solver.cpp:336]     Train net output #0: loss = 0.0742193 (* 1 = 0.0742193 loss)
I0916 18:08:19.957586 20216 sgd_solver.cpp:136] Iteration 19600, lr = 0.01, m = 0.9
I0916 18:08:39.606406 20216 solver.cpp:314] Iteration 19700 (5.0895 iter/s, 19.6483s/100 iter), loss = 0.711585
I0916 18:08:39.606515 20216 solver.cpp:336]     Train net output #0: loss = 0.711585 (* 1 = 0.711585 loss)
I0916 18:08:39.606526 20216 sgd_solver.cpp:136] Iteration 19700, lr = 0.01, m = 0.9
I0916 18:08:59.276347 20216 solver.cpp:314] Iteration 19800 (5.08404 iter/s, 19.6694s/100 iter), loss = 0.102435
I0916 18:08:59.276366 20216 solver.cpp:336]     Train net output #0: loss = 0.102434 (* 1 = 0.102434 loss)
I0916 18:08:59.276371 20216 sgd_solver.cpp:136] Iteration 19800, lr = 0.01, m = 0.9
I0916 18:09:05.020537 20219 data_reader.cpp:305] Starting prefetch of epoch 16
I0916 18:09:18.658861 20216 solver.cpp:314] Iteration 19900 (5.15943 iter/s, 19.382s/100 iter), loss = 0.0996114
I0916 18:09:18.658946 20216 solver.cpp:336]     Train net output #0: loss = 0.0996113 (* 1 = 0.0996113 loss)
I0916 18:09:18.658954 20216 sgd_solver.cpp:136] Iteration 19900, lr = 0.01, m = 0.9
I0916 18:09:37.973647 20216 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/cityscapes5_jsegnet21v2_iter_20000.caffemodel
I0916 18:09:37.997355 20216 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/cityscapes5_jsegnet21v2_iter_20000.solverstate
I0916 18:09:38.002852 20216 solver.cpp:563] Iteration 20000, Testing net (#0)
I0916 18:09:41.280521 20241 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 18:09:48.676574 20202 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 18:09:48.982574 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.931713
I0916 18:09:48.982595 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 18:09:48.982600 20216 solver.cpp:655]     Test net output #2: loss = 0.1935 (* 1 = 0.1935 loss)
I0916 18:09:48.982626 20216 solver.cpp:265] [MultiGPU] Tests completed in 10.9795s
I0916 18:09:49.207232 20216 solver.cpp:314] Iteration 20000 (3.27361 iter/s, 30.5473s/100 iter), loss = 0.0641762
I0916 18:09:49.207257 20216 solver.cpp:336]     Train net output #0: loss = 0.0641761 (* 1 = 0.0641761 loss)
I0916 18:09:49.207262 20216 sgd_solver.cpp:136] Iteration 20000, lr = 0.01, m = 0.9
I0916 18:10:08.559284 20216 solver.cpp:314] Iteration 20100 (5.16756 iter/s, 19.3515s/100 iter), loss = 0.057958
I0916 18:10:08.559317 20216 solver.cpp:336]     Train net output #0: loss = 0.0579579 (* 1 = 0.0579579 loss)
I0916 18:10:08.559324 20216 sgd_solver.cpp:136] Iteration 20100, lr = 0.01, m = 0.9
I0916 18:10:28.324395 20216 solver.cpp:314] Iteration 20200 (5.05956 iter/s, 19.7646s/100 iter), loss = 0.0993884
I0916 18:10:28.330124 20216 solver.cpp:336]     Train net output #0: loss = 0.0993884 (* 1 = 0.0993884 loss)
I0916 18:10:28.330152 20216 sgd_solver.cpp:136] Iteration 20200, lr = 0.01, m = 0.9
I0916 18:10:47.759388 20216 solver.cpp:314] Iteration 20300 (5.1455 iter/s, 19.4345s/100 iter), loss = 0.0702966
I0916 18:10:47.759414 20216 solver.cpp:336]     Train net output #0: loss = 0.0702965 (* 1 = 0.0702965 loss)
I0916 18:10:47.759419 20216 sgd_solver.cpp:136] Iteration 20300, lr = 0.01, m = 0.9
I0916 18:10:52.806346 20220 data_reader.cpp:305] Starting prefetch of epoch 15
I0916 18:11:07.220510 20216 solver.cpp:314] Iteration 20400 (5.13859 iter/s, 19.4606s/100 iter), loss = 0.0981854
I0916 18:11:07.220602 20216 solver.cpp:336]     Train net output #0: loss = 0.0981853 (* 1 = 0.0981853 loss)
I0916 18:11:07.220608 20216 sgd_solver.cpp:136] Iteration 20400, lr = 0.01, m = 0.9
I0916 18:11:26.640249 20216 solver.cpp:314] Iteration 20500 (5.14954 iter/s, 19.4192s/100 iter), loss = 0.0723137
I0916 18:11:26.640275 20216 solver.cpp:336]     Train net output #0: loss = 0.0723136 (* 1 = 0.0723136 loss)
I0916 18:11:26.640281 20216 sgd_solver.cpp:136] Iteration 20500, lr = 0.01, m = 0.9
I0916 18:11:46.132048 20216 solver.cpp:314] Iteration 20600 (5.13051 iter/s, 19.4913s/100 iter), loss = 0.0759239
I0916 18:11:46.132104 20216 solver.cpp:336]     Train net output #0: loss = 0.0759239 (* 1 = 0.0759239 loss)
I0916 18:11:46.132112 20216 sgd_solver.cpp:136] Iteration 20600, lr = 0.01, m = 0.9
I0916 18:11:57.073192 20224 data_reader.cpp:305] Starting prefetch of epoch 14
I0916 18:12:05.618557 20216 solver.cpp:314] Iteration 20700 (5.1319 iter/s, 19.486s/100 iter), loss = 0.0626716
I0916 18:12:05.618579 20216 solver.cpp:336]     Train net output #0: loss = 0.0626716 (* 1 = 0.0626716 loss)
I0916 18:12:05.618583 20216 sgd_solver.cpp:136] Iteration 20700, lr = 0.01, m = 0.9
I0916 18:12:24.921635 20216 solver.cpp:314] Iteration 20800 (5.18067 iter/s, 19.3025s/100 iter), loss = 0.0886055
I0916 18:12:24.921690 20216 solver.cpp:336]     Train net output #0: loss = 0.0886055 (* 1 = 0.0886055 loss)
I0916 18:12:24.921697 20216 sgd_solver.cpp:136] Iteration 20800, lr = 0.01, m = 0.9
I0916 18:12:44.434221 20216 solver.cpp:314] Iteration 20900 (5.12504 iter/s, 19.512s/100 iter), loss = 0.062091
I0916 18:12:44.434248 20216 solver.cpp:336]     Train net output #0: loss = 0.0620909 (* 1 = 0.0620909 loss)
I0916 18:12:44.434253 20216 sgd_solver.cpp:136] Iteration 20900, lr = 0.01, m = 0.9
I0916 18:13:01.186573 20223 data_reader.cpp:305] Starting prefetch of epoch 10
I0916 18:13:03.642938 20216 solver.cpp:314] Iteration 21000 (5.20612 iter/s, 19.2082s/100 iter), loss = 0.399974
I0916 18:13:03.642962 20216 solver.cpp:336]     Train net output #0: loss = 0.399974 (* 1 = 0.399974 loss)
I0916 18:13:03.642968 20216 sgd_solver.cpp:136] Iteration 21000, lr = 0.01, m = 0.9
I0916 18:13:22.966612 20216 solver.cpp:314] Iteration 21100 (5.17514 iter/s, 19.3231s/100 iter), loss = 0.0623929
I0916 18:13:22.966635 20216 solver.cpp:336]     Train net output #0: loss = 0.0623928 (* 1 = 0.0623928 loss)
I0916 18:13:22.966639 20216 sgd_solver.cpp:136] Iteration 21100, lr = 0.01, m = 0.9
I0916 18:13:33.085875 20220 data_reader.cpp:305] Starting prefetch of epoch 16
I0916 18:13:42.460515 20216 solver.cpp:314] Iteration 21200 (5.12995 iter/s, 19.4934s/100 iter), loss = 0.0981262
I0916 18:13:42.460541 20216 solver.cpp:336]     Train net output #0: loss = 0.0981261 (* 1 = 0.0981261 loss)
I0916 18:13:42.460546 20216 sgd_solver.cpp:136] Iteration 21200, lr = 0.01, m = 0.9
I0916 18:14:01.927284 20216 solver.cpp:314] Iteration 21300 (5.1371 iter/s, 19.4662s/100 iter), loss = 0.0898188
I0916 18:14:01.927309 20216 solver.cpp:336]     Train net output #0: loss = 0.0898188 (* 1 = 0.0898188 loss)
I0916 18:14:01.927314 20216 sgd_solver.cpp:136] Iteration 21300, lr = 0.01, m = 0.9
I0916 18:14:21.282480 20216 solver.cpp:314] Iteration 21400 (5.16672 iter/s, 19.3547s/100 iter), loss = 0.105858
I0916 18:14:21.282541 20216 solver.cpp:336]     Train net output #0: loss = 0.105858 (* 1 = 0.105858 loss)
I0916 18:14:21.282547 20216 sgd_solver.cpp:136] Iteration 21400, lr = 0.01, m = 0.9
I0916 18:14:37.476773 20220 data_reader.cpp:305] Starting prefetch of epoch 17
I0916 18:14:40.853727 20216 solver.cpp:314] Iteration 21500 (5.10968 iter/s, 19.5707s/100 iter), loss = 0.0940993
I0916 18:14:40.853754 20216 solver.cpp:336]     Train net output #0: loss = 0.0940992 (* 1 = 0.0940992 loss)
I0916 18:14:40.853760 20216 sgd_solver.cpp:136] Iteration 21500, lr = 0.01, m = 0.9
I0916 18:15:00.376976 20216 solver.cpp:314] Iteration 21600 (5.12224 iter/s, 19.5227s/100 iter), loss = 0.100378
I0916 18:15:00.377035 20216 solver.cpp:336]     Train net output #0: loss = 0.100378 (* 1 = 0.100378 loss)
I0916 18:15:00.377043 20216 sgd_solver.cpp:136] Iteration 21600, lr = 0.01, m = 0.9
I0916 18:15:19.909394 20216 solver.cpp:314] Iteration 21700 (5.11984 iter/s, 19.5319s/100 iter), loss = 0.0794934
I0916 18:15:19.909415 20216 solver.cpp:336]     Train net output #0: loss = 0.0794933 (* 1 = 0.0794933 loss)
I0916 18:15:19.909420 20216 sgd_solver.cpp:136] Iteration 21700, lr = 0.01, m = 0.9
I0916 18:15:39.420907 20216 solver.cpp:314] Iteration 21800 (5.12532 iter/s, 19.511s/100 iter), loss = 0.222141
I0916 18:15:39.420958 20216 solver.cpp:336]     Train net output #0: loss = 0.222141 (* 1 = 0.222141 loss)
I0916 18:15:39.420965 20216 sgd_solver.cpp:136] Iteration 21800, lr = 0.01, m = 0.9
I0916 18:15:41.874260 20224 data_reader.cpp:305] Starting prefetch of epoch 15
I0916 18:15:58.769665 20216 solver.cpp:314] Iteration 21900 (5.16844 iter/s, 19.3482s/100 iter), loss = 0.0791143
I0916 18:15:58.769690 20216 solver.cpp:336]     Train net output #0: loss = 0.0791143 (* 1 = 0.0791143 loss)
I0916 18:15:58.769696 20216 sgd_solver.cpp:136] Iteration 21900, lr = 0.01, m = 0.9
I0916 18:16:13.939558 20195 data_reader.cpp:305] Starting prefetch of epoch 10
I0916 18:16:17.951642 20216 solver.cpp:563] Iteration 22000, Testing net (#0)
I0916 18:16:28.625697 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.942431
I0916 18:16:28.625716 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 18:16:28.625723 20216 solver.cpp:655]     Test net output #2: loss = 0.167626 (* 1 = 0.167626 loss)
I0916 18:16:28.625749 20216 solver.cpp:265] [MultiGPU] Tests completed in 10.6738s
I0916 18:16:28.842542 20216 solver.cpp:314] Iteration 22000 (3.32535 iter/s, 30.072s/100 iter), loss = 0.0939352
I0916 18:16:28.842566 20216 solver.cpp:336]     Train net output #0: loss = 0.0939351 (* 1 = 0.0939351 loss)
I0916 18:16:28.842571 20216 sgd_solver.cpp:136] Iteration 22000, lr = 0.01, m = 0.9
I0916 18:16:48.059376 20216 solver.cpp:314] Iteration 22100 (5.20392 iter/s, 19.2163s/100 iter), loss = 0.0829897
I0916 18:16:48.059427 20216 solver.cpp:336]     Train net output #0: loss = 0.0829896 (* 1 = 0.0829896 loss)
I0916 18:16:48.059433 20216 sgd_solver.cpp:136] Iteration 22100, lr = 0.01, m = 0.9
I0916 18:16:56.499188 20223 data_reader.cpp:305] Starting prefetch of epoch 11
I0916 18:17:07.138917 20216 solver.cpp:314] Iteration 22200 (5.24136 iter/s, 19.079s/100 iter), loss = 0.0744715
I0916 18:17:07.138939 20216 solver.cpp:336]     Train net output #0: loss = 0.0744714 (* 1 = 0.0744714 loss)
I0916 18:17:07.138943 20216 sgd_solver.cpp:136] Iteration 22200, lr = 0.01, m = 0.9
I0916 18:17:26.534307 20216 solver.cpp:314] Iteration 22300 (5.15601 iter/s, 19.3948s/100 iter), loss = 0.0557851
I0916 18:17:26.534417 20216 solver.cpp:336]     Train net output #0: loss = 0.055785 (* 1 = 0.055785 loss)
I0916 18:17:26.534425 20216 sgd_solver.cpp:136] Iteration 22300, lr = 0.01, m = 0.9
I0916 18:17:45.850251 20216 solver.cpp:314] Iteration 22400 (5.17721 iter/s, 19.3154s/100 iter), loss = 0.0783654
I0916 18:17:45.850325 20216 solver.cpp:336]     Train net output #0: loss = 0.0783652 (* 1 = 0.0783652 loss)
I0916 18:17:45.850345 20216 sgd_solver.cpp:136] Iteration 22400, lr = 0.01, m = 0.9
I0916 18:18:00.372755 20224 data_reader.cpp:305] Starting prefetch of epoch 16
I0916 18:18:05.388422 20216 solver.cpp:314] Iteration 22500 (5.11833 iter/s, 19.5376s/100 iter), loss = 0.143084
I0916 18:18:05.388480 20216 solver.cpp:336]     Train net output #0: loss = 0.143084 (* 1 = 0.143084 loss)
I0916 18:18:05.388499 20216 sgd_solver.cpp:136] Iteration 22500, lr = 0.01, m = 0.9
I0916 18:18:24.740048 20216 solver.cpp:314] Iteration 22600 (5.16767 iter/s, 19.3511s/100 iter), loss = 0.0734221
I0916 18:18:24.740073 20216 solver.cpp:336]     Train net output #0: loss = 0.0734219 (* 1 = 0.0734219 loss)
I0916 18:18:24.740078 20216 sgd_solver.cpp:136] Iteration 22600, lr = 0.01, m = 0.9
I0916 18:18:32.449525 20220 data_reader.cpp:305] Starting prefetch of epoch 18
I0916 18:18:43.938145 20216 solver.cpp:314] Iteration 22700 (5.209 iter/s, 19.1976s/100 iter), loss = 0.0945848
I0916 18:18:43.938171 20216 solver.cpp:336]     Train net output #0: loss = 0.0945847 (* 1 = 0.0945847 loss)
I0916 18:18:43.938177 20216 sgd_solver.cpp:136] Iteration 22700, lr = 0.01, m = 0.9
I0916 18:19:03.387431 20216 solver.cpp:314] Iteration 22800 (5.14172 iter/s, 19.4487s/100 iter), loss = 0.0448582
I0916 18:19:03.387807 20216 solver.cpp:336]     Train net output #0: loss = 0.0448581 (* 1 = 0.0448581 loss)
I0916 18:19:03.387825 20216 sgd_solver.cpp:136] Iteration 22800, lr = 0.01, m = 0.9
I0916 18:19:23.191980 20216 solver.cpp:314] Iteration 22900 (5.04949 iter/s, 19.804s/100 iter), loss = 0.072031
I0916 18:19:23.192006 20216 solver.cpp:336]     Train net output #0: loss = 0.0720309 (* 1 = 0.0720309 loss)
I0916 18:19:23.192013 20216 sgd_solver.cpp:136] Iteration 22900, lr = 0.01, m = 0.9
I0916 18:19:36.774101 20197 data_reader.cpp:305] Starting prefetch of epoch 11
I0916 18:19:42.623795 20216 solver.cpp:314] Iteration 23000 (5.14634 iter/s, 19.4313s/100 iter), loss = 0.149682
I0916 18:19:42.623818 20216 solver.cpp:336]     Train net output #0: loss = 0.149682 (* 1 = 0.149682 loss)
I0916 18:19:42.623822 20216 sgd_solver.cpp:136] Iteration 23000, lr = 0.01, m = 0.9
I0916 18:20:02.029603 20216 solver.cpp:314] Iteration 23100 (5.15324 iter/s, 19.4053s/100 iter), loss = 0.0880017
I0916 18:20:02.029626 20216 solver.cpp:336]     Train net output #0: loss = 0.0880015 (* 1 = 0.0880015 loss)
I0916 18:20:02.029630 20216 sgd_solver.cpp:136] Iteration 23100, lr = 0.01, m = 0.9
I0916 18:20:21.333549 20216 solver.cpp:314] Iteration 23200 (5.18043 iter/s, 19.3034s/100 iter), loss = 0.105589
I0916 18:20:21.333602 20216 solver.cpp:336]     Train net output #0: loss = 0.105589 (* 1 = 0.105589 loss)
I0916 18:20:21.333607 20216 sgd_solver.cpp:136] Iteration 23200, lr = 0.01, m = 0.9
I0916 18:20:40.839179 20216 solver.cpp:314] Iteration 23300 (5.12687 iter/s, 19.5051s/100 iter), loss = 0.0552198
I0916 18:20:40.839205 20216 solver.cpp:336]     Train net output #0: loss = 0.0552197 (* 1 = 0.0552197 loss)
I0916 18:20:40.839211 20216 sgd_solver.cpp:136] Iteration 23300, lr = 0.01, m = 0.9
I0916 18:20:41.027537 20197 data_reader.cpp:305] Starting prefetch of epoch 12
I0916 18:21:00.167559 20216 solver.cpp:314] Iteration 23400 (5.17388 iter/s, 19.3278s/100 iter), loss = 0.0913001
I0916 18:21:00.167629 20216 solver.cpp:336]     Train net output #0: loss = 0.0913 (* 1 = 0.0913 loss)
I0916 18:21:00.167637 20216 sgd_solver.cpp:136] Iteration 23400, lr = 0.01, m = 0.9
I0916 18:21:13.255970 20219 data_reader.cpp:305] Starting prefetch of epoch 17
I0916 18:21:19.910956 20216 solver.cpp:314] Iteration 23500 (5.06513 iter/s, 19.7428s/100 iter), loss = 0.335162
I0916 18:21:19.910986 20216 solver.cpp:336]     Train net output #0: loss = 0.335161 (* 1 = 0.335161 loss)
I0916 18:21:19.910993 20216 sgd_solver.cpp:136] Iteration 23500, lr = 0.01, m = 0.9
I0916 18:21:39.544318 20216 solver.cpp:314] Iteration 23600 (5.09351 iter/s, 19.6328s/100 iter), loss = 0.135992
I0916 18:21:39.544378 20216 solver.cpp:336]     Train net output #0: loss = 0.135992 (* 1 = 0.135992 loss)
I0916 18:21:39.544384 20216 sgd_solver.cpp:136] Iteration 23600, lr = 0.01, m = 0.9
I0916 18:21:58.942833 20216 solver.cpp:314] Iteration 23700 (5.15518 iter/s, 19.398s/100 iter), loss = 0.0638801
I0916 18:21:58.942863 20216 solver.cpp:336]     Train net output #0: loss = 0.0638799 (* 1 = 0.0638799 loss)
I0916 18:21:58.942870 20216 sgd_solver.cpp:136] Iteration 23700, lr = 0.01, m = 0.9
I0916 18:22:17.519209 20223 data_reader.cpp:305] Starting prefetch of epoch 12
I0916 18:22:18.309865 20216 solver.cpp:314] Iteration 23800 (5.16356 iter/s, 19.3665s/100 iter), loss = 0.11343
I0916 18:22:18.309886 20216 solver.cpp:336]     Train net output #0: loss = 0.11343 (* 1 = 0.11343 loss)
I0916 18:22:18.309891 20216 sgd_solver.cpp:136] Iteration 23800, lr = 0.01, m = 0.9
I0916 18:22:37.989051 20216 solver.cpp:314] Iteration 23900 (5.08165 iter/s, 19.6786s/100 iter), loss = 0.0687884
I0916 18:22:37.989081 20216 solver.cpp:336]     Train net output #0: loss = 0.0687883 (* 1 = 0.0687883 loss)
I0916 18:22:37.989089 20216 sgd_solver.cpp:136] Iteration 23900, lr = 0.01, m = 0.9
I0916 18:22:57.136773 20216 solver.cpp:563] Iteration 24000, Testing net (#0)
I0916 18:23:00.525503 20250 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 18:23:11.029795 20243 data_reader.cpp:305] Starting prefetch of epoch 1
I0916 18:23:11.365911 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.929268
I0916 18:23:11.365932 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 18:23:11.365937 20216 solver.cpp:655]     Test net output #2: loss = 0.199519 (* 1 = 0.199519 loss)
I0916 18:23:11.366005 20216 solver.cpp:265] [MultiGPU] Tests completed in 14.2288s
I0916 18:23:11.578400 20216 solver.cpp:314] Iteration 24000 (2.97722 iter/s, 33.5884s/100 iter), loss = 0.0860809
I0916 18:23:11.578451 20216 solver.cpp:336]     Train net output #0: loss = 0.0860807 (* 1 = 0.0860807 loss)
I0916 18:23:11.578464 20216 sgd_solver.cpp:136] Iteration 24000, lr = 0.01, m = 0.9
I0916 18:23:30.905170 20216 solver.cpp:314] Iteration 24100 (5.17432 iter/s, 19.3262s/100 iter), loss = 0.0977296
I0916 18:23:30.905223 20216 solver.cpp:336]     Train net output #0: loss = 0.0977294 (* 1 = 0.0977294 loss)
I0916 18:23:30.905230 20216 sgd_solver.cpp:136] Iteration 24100, lr = 0.01, m = 0.9
I0916 18:23:50.517299 20216 solver.cpp:314] Iteration 24200 (5.09903 iter/s, 19.6116s/100 iter), loss = 0.226808
I0916 18:23:50.517328 20216 solver.cpp:336]     Train net output #0: loss = 0.226808 (* 1 = 0.226808 loss)
I0916 18:23:50.517334 20216 sgd_solver.cpp:136] Iteration 24200, lr = 0.01, m = 0.9
I0916 18:24:08.742429 20197 data_reader.cpp:305] Starting prefetch of epoch 13
I0916 18:24:10.229096 20216 solver.cpp:314] Iteration 24300 (5.07325 iter/s, 19.7112s/100 iter), loss = 0.0562733
I0916 18:24:10.229121 20216 solver.cpp:336]     Train net output #0: loss = 0.0562731 (* 1 = 0.0562731 loss)
I0916 18:24:10.229127 20216 sgd_solver.cpp:136] Iteration 24300, lr = 0.01, m = 0.9
I0916 18:24:30.030309 20216 solver.cpp:314] Iteration 24400 (5.05034 iter/s, 19.8007s/100 iter), loss = 0.155323
I0916 18:24:30.030333 20216 solver.cpp:336]     Train net output #0: loss = 0.155323 (* 1 = 0.155323 loss)
I0916 18:24:30.030339 20216 sgd_solver.cpp:136] Iteration 24400, lr = 0.01, m = 0.9
I0916 18:24:49.780738 20216 solver.cpp:314] Iteration 24500 (5.06332 iter/s, 19.7499s/100 iter), loss = 0.0810393
I0916 18:24:49.781255 20216 solver.cpp:336]     Train net output #0: loss = 0.0810391 (* 1 = 0.0810391 loss)
I0916 18:24:49.781283 20216 sgd_solver.cpp:136] Iteration 24500, lr = 0.01, m = 0.9
I0916 18:25:09.388394 20216 solver.cpp:314] Iteration 24600 (5.10019 iter/s, 19.6071s/100 iter), loss = 0.16717
I0916 18:25:09.388422 20216 solver.cpp:336]     Train net output #0: loss = 0.16717 (* 1 = 0.16717 loss)
I0916 18:25:09.388427 20216 sgd_solver.cpp:136] Iteration 24600, lr = 0.01, m = 0.9
I0916 18:25:13.904758 20224 data_reader.cpp:305] Starting prefetch of epoch 17
I0916 18:25:28.794512 20216 solver.cpp:314] Iteration 24700 (5.15316 iter/s, 19.4056s/100 iter), loss = 0.0678228
I0916 18:25:28.794570 20216 solver.cpp:336]     Train net output #0: loss = 0.0678227 (* 1 = 0.0678227 loss)
I0916 18:25:28.794579 20216 sgd_solver.cpp:136] Iteration 24700, lr = 0.01, m = 0.9
I0916 18:25:45.979974 20220 data_reader.cpp:305] Starting prefetch of epoch 19
I0916 18:25:48.347796 20216 solver.cpp:314] Iteration 24800 (5.11437 iter/s, 19.5527s/100 iter), loss = 0.0959877
I0916 18:25:48.347821 20216 solver.cpp:336]     Train net output #0: loss = 0.0959876 (* 1 = 0.0959876 loss)
I0916 18:25:48.347827 20216 sgd_solver.cpp:136] Iteration 24800, lr = 0.01, m = 0.9
I0916 18:26:07.809923 20216 solver.cpp:314] Iteration 24900 (5.13833 iter/s, 19.4616s/100 iter), loss = 0.0657845
I0916 18:26:07.809983 20216 solver.cpp:336]     Train net output #0: loss = 0.0657844 (* 1 = 0.0657844 loss)
I0916 18:26:07.809988 20216 sgd_solver.cpp:136] Iteration 24900, lr = 0.01, m = 0.9
I0916 18:26:27.106564 20216 solver.cpp:314] Iteration 25000 (5.18239 iter/s, 19.2961s/100 iter), loss = 0.0965429
I0916 18:26:27.106592 20216 solver.cpp:336]     Train net output #0: loss = 0.0965428 (* 1 = 0.0965428 loss)
I0916 18:26:27.106600 20216 sgd_solver.cpp:136] Iteration 25000, lr = 0.01, m = 0.9
I0916 18:26:46.491710 20216 solver.cpp:314] Iteration 25100 (5.15873 iter/s, 19.3846s/100 iter), loss = 0.084208
I0916 18:26:46.491770 20216 solver.cpp:336]     Train net output #0: loss = 0.0842079 (* 1 = 0.0842079 loss)
I0916 18:26:46.491780 20216 sgd_solver.cpp:136] Iteration 25100, lr = 0.01, m = 0.9
I0916 18:26:50.260960 20224 data_reader.cpp:305] Starting prefetch of epoch 18
I0916 18:27:06.115773 20216 solver.cpp:314] Iteration 25200 (5.09593 iter/s, 19.6235s/100 iter), loss = 0.0940382
I0916 18:27:06.115797 20216 solver.cpp:336]     Train net output #0: loss = 0.0940381 (* 1 = 0.0940381 loss)
I0916 18:27:06.115803 20216 sgd_solver.cpp:136] Iteration 25200, lr = 0.01, m = 0.9
I0916 18:27:25.733495 20216 solver.cpp:314] Iteration 25300 (5.09757 iter/s, 19.6172s/100 iter), loss = 0.0848853
I0916 18:27:25.733546 20216 solver.cpp:336]     Train net output #0: loss = 0.0848851 (* 1 = 0.0848851 loss)
I0916 18:27:25.733552 20216 sgd_solver.cpp:136] Iteration 25300, lr = 0.01, m = 0.9
I0916 18:27:45.200810 20216 solver.cpp:314] Iteration 25400 (5.13696 iter/s, 19.4668s/100 iter), loss = 0.0880736
I0916 18:27:45.200842 20216 solver.cpp:336]     Train net output #0: loss = 0.0880734 (* 1 = 0.0880734 loss)
I0916 18:27:45.200848 20216 sgd_solver.cpp:136] Iteration 25400, lr = 0.01, m = 0.9
I0916 18:27:54.700268 20223 data_reader.cpp:305] Starting prefetch of epoch 13
I0916 18:28:04.640081 20216 solver.cpp:314] Iteration 25500 (5.14437 iter/s, 19.4387s/100 iter), loss = 0.0572578
I0916 18:28:04.640128 20216 solver.cpp:336]     Train net output #0: loss = 0.0572576 (* 1 = 0.0572576 loss)
I0916 18:28:04.640135 20216 sgd_solver.cpp:136] Iteration 25500, lr = 0.01, m = 0.9
I0916 18:28:24.174603 20216 solver.cpp:314] Iteration 25600 (5.11928 iter/s, 19.534s/100 iter), loss = 0.104715
I0916 18:28:24.174628 20216 solver.cpp:336]     Train net output #0: loss = 0.104715 (* 1 = 0.104715 loss)
I0916 18:28:24.174633 20216 sgd_solver.cpp:136] Iteration 25600, lr = 0.01, m = 0.9
I0916 18:28:27.149354 20220 data_reader.cpp:305] Starting prefetch of epoch 20
I0916 18:28:43.772878 20216 solver.cpp:314] Iteration 25700 (5.10263 iter/s, 19.5977s/100 iter), loss = 0.0536044
I0916 18:28:43.772946 20216 solver.cpp:336]     Train net output #0: loss = 0.0536043 (* 1 = 0.0536043 loss)
I0916 18:28:43.772951 20216 sgd_solver.cpp:136] Iteration 25700, lr = 0.01, m = 0.9
I0916 18:29:03.232700 20216 solver.cpp:314] Iteration 25800 (5.13894 iter/s, 19.4593s/100 iter), loss = 0.0741796
I0916 18:29:03.232729 20216 solver.cpp:336]     Train net output #0: loss = 0.0741794 (* 1 = 0.0741794 loss)
I0916 18:29:03.232736 20216 sgd_solver.cpp:136] Iteration 25800, lr = 0.01, m = 0.9
I0916 18:29:22.689258 20216 solver.cpp:314] Iteration 25900 (5.1398 iter/s, 19.456s/100 iter), loss = 0.0675953
I0916 18:29:22.689314 20216 solver.cpp:336]     Train net output #0: loss = 0.0675951 (* 1 = 0.0675951 loss)
I0916 18:29:22.689321 20216 sgd_solver.cpp:136] Iteration 25900, lr = 0.01, m = 0.9
I0916 18:29:31.584825 20219 data_reader.cpp:305] Starting prefetch of epoch 18
I0916 18:29:42.328706 20216 solver.cpp:563] Iteration 26000, Testing net (#0)
I0916 18:30:00.544147 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.952049
I0916 18:30:00.544199 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 18:30:00.544208 20216 solver.cpp:655]     Test net output #2: loss = 0.152382 (* 1 = 0.152382 loss)
I0916 18:30:00.544770 20216 solver.cpp:265] [MultiGPU] Tests completed in 18.2156s
I0916 18:30:00.767398 20216 solver.cpp:314] Iteration 26000 (2.62625 iter/s, 38.0771s/100 iter), loss = 0.12312
I0916 18:30:00.767421 20216 solver.cpp:336]     Train net output #0: loss = 0.12312 (* 1 = 0.12312 loss)
I0916 18:30:00.767426 20216 sgd_solver.cpp:136] Iteration 26000, lr = 0.01, m = 0.9
I0916 18:30:20.070683 20216 solver.cpp:314] Iteration 26100 (5.18061 iter/s, 19.3027s/100 iter), loss = 0.0590496
I0916 18:30:20.070710 20216 solver.cpp:336]     Train net output #0: loss = 0.0590495 (* 1 = 0.0590495 loss)
I0916 18:30:20.070718 20216 sgd_solver.cpp:136] Iteration 26100, lr = 0.01, m = 0.9
I0916 18:30:21.987054 20224 data_reader.cpp:305] Starting prefetch of epoch 19
I0916 18:30:39.586000 20216 solver.cpp:314] Iteration 26200 (5.12432 iter/s, 19.5148s/100 iter), loss = 0.101331
I0916 18:30:39.586055 20216 solver.cpp:336]     Train net output #0: loss = 0.101331 (* 1 = 0.101331 loss)
I0916 18:30:39.586061 20216 sgd_solver.cpp:136] Iteration 26200, lr = 0.01, m = 0.9
I0916 18:30:54.411337 20219 data_reader.cpp:305] Starting prefetch of epoch 19
I0916 18:30:59.021880 20216 solver.cpp:314] Iteration 26300 (5.14527 iter/s, 19.4353s/100 iter), loss = 0.0833558
I0916 18:30:59.021901 20216 solver.cpp:336]     Train net output #0: loss = 0.0833557 (* 1 = 0.0833557 loss)
I0916 18:30:59.021905 20216 sgd_solver.cpp:136] Iteration 26300, lr = 0.01, m = 0.9
I0916 18:31:18.614497 20216 solver.cpp:314] Iteration 26400 (5.10411 iter/s, 19.5921s/100 iter), loss = 0.0949952
I0916 18:31:18.614554 20216 solver.cpp:336]     Train net output #0: loss = 0.0949951 (* 1 = 0.0949951 loss)
I0916 18:31:18.614562 20216 sgd_solver.cpp:136] Iteration 26400, lr = 0.01, m = 0.9
I0916 18:31:38.315135 20216 solver.cpp:314] Iteration 26500 (5.07612 iter/s, 19.7001s/100 iter), loss = 0.0639697
I0916 18:31:38.315165 20216 solver.cpp:336]     Train net output #0: loss = 0.0639695 (* 1 = 0.0639695 loss)
I0916 18:31:38.315168 20216 sgd_solver.cpp:136] Iteration 26500, lr = 0.01, m = 0.9
I0916 18:31:57.864563 20216 solver.cpp:314] Iteration 26600 (5.11538 iter/s, 19.5489s/100 iter), loss = 0.0728599
I0916 18:31:57.864619 20216 solver.cpp:336]     Train net output #0: loss = 0.0728599 (* 1 = 0.0728599 loss)
I0916 18:31:57.864626 20216 sgd_solver.cpp:136] Iteration 26600, lr = 0.01, m = 0.9
I0916 18:31:59.086907 20219 data_reader.cpp:305] Starting prefetch of epoch 20
I0916 18:32:17.036933 20216 solver.cpp:314] Iteration 26700 (5.21599 iter/s, 19.1718s/100 iter), loss = 0.07899
I0916 18:32:17.036954 20216 solver.cpp:336]     Train net output #0: loss = 0.0789899 (* 1 = 0.0789899 loss)
I0916 18:32:17.036959 20216 sgd_solver.cpp:136] Iteration 26700, lr = 0.01, m = 0.9
I0916 18:32:36.232961 20216 solver.cpp:314] Iteration 26800 (5.20956 iter/s, 19.1955s/100 iter), loss = 0.0907153
I0916 18:32:36.233053 20216 solver.cpp:336]     Train net output #0: loss = 0.0907152 (* 1 = 0.0907152 loss)
I0916 18:32:36.233062 20216 sgd_solver.cpp:136] Iteration 26800, lr = 0.01, m = 0.9
I0916 18:32:55.717803 20216 solver.cpp:314] Iteration 26900 (5.13234 iter/s, 19.4843s/100 iter), loss = 0.0546463
I0916 18:32:55.717828 20216 solver.cpp:336]     Train net output #0: loss = 0.0546462 (* 1 = 0.0546462 loss)
I0916 18:32:55.717831 20216 sgd_solver.cpp:136] Iteration 26900, lr = 0.01, m = 0.9
I0916 18:33:02.939129 20197 data_reader.cpp:305] Starting prefetch of epoch 14
I0916 18:33:15.137692 20216 solver.cpp:314] Iteration 27000 (5.1495 iter/s, 19.4193s/100 iter), loss = 0.133019
I0916 18:33:15.137743 20216 solver.cpp:336]     Train net output #0: loss = 0.133019 (* 1 = 0.133019 loss)
I0916 18:33:15.137750 20216 sgd_solver.cpp:136] Iteration 27000, lr = 0.01, m = 0.9
I0916 18:33:34.752406 20216 solver.cpp:314] Iteration 27100 (5.09836 iter/s, 19.6142s/100 iter), loss = 0.073498
I0916 18:33:34.752431 20216 solver.cpp:336]     Train net output #0: loss = 0.0734979 (* 1 = 0.0734979 loss)
I0916 18:33:34.752435 20216 sgd_solver.cpp:136] Iteration 27100, lr = 0.01, m = 0.9
I0916 18:33:35.185250 20220 data_reader.cpp:305] Starting prefetch of epoch 21
I0916 18:33:54.131327 20216 solver.cpp:314] Iteration 27200 (5.16039 iter/s, 19.3784s/100 iter), loss = 0.0489
I0916 18:33:54.131598 20216 solver.cpp:336]     Train net output #0: loss = 0.0488999 (* 1 = 0.0488999 loss)
I0916 18:33:54.131608 20216 sgd_solver.cpp:136] Iteration 27200, lr = 0.01, m = 0.9
I0916 18:34:13.684103 20216 solver.cpp:314] Iteration 27300 (5.11451 iter/s, 19.5522s/100 iter), loss = 0.0833308
I0916 18:34:13.684129 20216 solver.cpp:336]     Train net output #0: loss = 0.0833307 (* 1 = 0.0833307 loss)
I0916 18:34:13.684135 20216 sgd_solver.cpp:136] Iteration 27300, lr = 0.01, m = 0.9
I0916 18:34:32.955271 20216 solver.cpp:314] Iteration 27400 (5.18925 iter/s, 19.2706s/100 iter), loss = 0.125643
I0916 18:34:32.955354 20216 solver.cpp:336]     Train net output #0: loss = 0.125643 (* 1 = 0.125643 loss)
I0916 18:34:32.955363 20216 sgd_solver.cpp:136] Iteration 27400, lr = 0.01, m = 0.9
I0916 18:34:39.306468 20220 data_reader.cpp:305] Starting prefetch of epoch 22
I0916 18:34:52.264324 20216 solver.cpp:314] Iteration 27500 (5.17906 iter/s, 19.3085s/100 iter), loss = 0.0726224
I0916 18:34:52.264353 20216 solver.cpp:336]     Train net output #0: loss = 0.0726223 (* 1 = 0.0726223 loss)
I0916 18:34:52.264358 20216 sgd_solver.cpp:136] Iteration 27500, lr = 0.01, m = 0.9
I0916 18:35:12.743260 20216 solver.cpp:314] Iteration 27600 (4.8832 iter/s, 20.4784s/100 iter), loss = 0.0931627
I0916 18:35:12.743320 20216 solver.cpp:336]     Train net output #0: loss = 0.0931626 (* 1 = 0.0931626 loss)
I0916 18:35:12.743329 20216 sgd_solver.cpp:136] Iteration 27600, lr = 0.01, m = 0.9
I0916 18:35:32.945623 20216 solver.cpp:314] Iteration 27700 (4.95006 iter/s, 20.2018s/100 iter), loss = 0.0829781
I0916 18:35:32.945650 20216 solver.cpp:336]     Train net output #0: loss = 0.082978 (* 1 = 0.082978 loss)
I0916 18:35:32.945657 20216 sgd_solver.cpp:136] Iteration 27700, lr = 0.01, m = 0.9
I0916 18:35:45.748052 20220 data_reader.cpp:305] Starting prefetch of epoch 23
I0916 18:35:53.246608 20216 solver.cpp:314] Iteration 27800 (4.92601 iter/s, 20.3004s/100 iter), loss = 0.0499002
I0916 18:35:53.246631 20216 solver.cpp:336]     Train net output #0: loss = 0.0499001 (* 1 = 0.0499001 loss)
I0916 18:35:53.246637 20216 sgd_solver.cpp:136] Iteration 27800, lr = 0.01, m = 0.9
I0916 18:36:13.390928 20216 solver.cpp:314] Iteration 27900 (4.96432 iter/s, 20.1438s/100 iter), loss = 0.0880518
I0916 18:36:13.390969 20216 solver.cpp:336]     Train net output #0: loss = 0.0880517 (* 1 = 0.0880517 loss)
I0916 18:36:13.390980 20216 sgd_solver.cpp:136] Iteration 27900, lr = 0.01, m = 0.9
I0916 18:36:33.784565 20216 solver.cpp:563] Iteration 28000, Testing net (#0)
I0916 18:36:45.762359 20202 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 18:36:45.762359 20241 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 18:37:06.462535 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.938414
I0916 18:37:06.462658 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 18:37:06.462668 20216 solver.cpp:655]     Test net output #2: loss = 0.181639 (* 1 = 0.181639 loss)
I0916 18:37:06.462694 20216 solver.cpp:265] [MultiGPU] Tests completed in 32.6772s
I0916 18:37:06.674069 20216 solver.cpp:314] Iteration 28000 (1.87682 iter/s, 53.2816s/100 iter), loss = 0.0940403
I0916 18:37:06.674099 20216 solver.cpp:336]     Train net output #0: loss = 0.0940402 (* 1 = 0.0940402 loss)
I0916 18:37:06.674104 20216 sgd_solver.cpp:136] Iteration 28000, lr = 0.01, m = 0.9
I0916 18:37:24.709111 20224 data_reader.cpp:305] Starting prefetch of epoch 20
I0916 18:37:25.843905 20216 solver.cpp:314] Iteration 28100 (5.21668 iter/s, 19.1693s/100 iter), loss = 0.0715187
I0916 18:37:25.843930 20216 solver.cpp:336]     Train net output #0: loss = 0.0715186 (* 1 = 0.0715186 loss)
I0916 18:37:25.843935 20216 sgd_solver.cpp:136] Iteration 28100, lr = 0.01, m = 0.9
I0916 18:37:44.995159 20216 solver.cpp:314] Iteration 28200 (5.22174 iter/s, 19.1507s/100 iter), loss = 0.0902162
I0916 18:37:44.995219 20216 solver.cpp:336]     Train net output #0: loss = 0.0902162 (* 1 = 0.0902162 loss)
I0916 18:37:44.995224 20216 sgd_solver.cpp:136] Iteration 28200, lr = 0.01, m = 0.9
I0916 18:38:04.207305 20216 solver.cpp:314] Iteration 28300 (5.20519 iter/s, 19.2116s/100 iter), loss = 0.06866
I0916 18:38:04.207332 20216 solver.cpp:336]     Train net output #0: loss = 0.0686599 (* 1 = 0.0686599 loss)
I0916 18:38:04.207337 20216 sgd_solver.cpp:136] Iteration 28300, lr = 0.01, m = 0.9
I0916 18:38:23.641163 20216 solver.cpp:314] Iteration 28400 (5.1458 iter/s, 19.4333s/100 iter), loss = 0.0856421
I0916 18:38:23.641225 20216 solver.cpp:336]     Train net output #0: loss = 0.0856421 (* 1 = 0.0856421 loss)
I0916 18:38:23.641233 20216 sgd_solver.cpp:136] Iteration 28400, lr = 0.01, m = 0.9
I0916 18:38:28.437764 20197 data_reader.cpp:305] Starting prefetch of epoch 15
I0916 18:38:43.312618 20216 solver.cpp:314] Iteration 28500 (5.08365 iter/s, 19.6709s/100 iter), loss = 0.229064
I0916 18:38:43.312667 20216 solver.cpp:336]     Train net output #0: loss = 0.229064 (* 1 = 0.229064 loss)
I0916 18:38:43.312690 20216 sgd_solver.cpp:136] Iteration 28500, lr = 0.01, m = 0.9
I0916 18:39:01.107282 20220 data_reader.cpp:305] Starting prefetch of epoch 24
I0916 18:39:02.983024 20216 solver.cpp:314] Iteration 28600 (5.08392 iter/s, 19.6699s/100 iter), loss = 0.133703
I0916 18:39:02.983052 20216 solver.cpp:336]     Train net output #0: loss = 0.133703 (* 1 = 0.133703 loss)
I0916 18:39:02.983058 20216 sgd_solver.cpp:136] Iteration 28600, lr = 0.01, m = 0.9
I0916 18:39:22.556768 20216 solver.cpp:314] Iteration 28700 (5.10903 iter/s, 19.5732s/100 iter), loss = 0.127712
I0916 18:39:22.556797 20216 solver.cpp:336]     Train net output #0: loss = 0.127712 (* 1 = 0.127712 loss)
I0916 18:39:22.556802 20216 sgd_solver.cpp:136] Iteration 28700, lr = 0.01, m = 0.9
I0916 18:39:41.955832 20216 solver.cpp:314] Iteration 28800 (5.15503 iter/s, 19.3985s/100 iter), loss = 0.0819333
I0916 18:39:41.955884 20216 solver.cpp:336]     Train net output #0: loss = 0.0819333 (* 1 = 0.0819333 loss)
I0916 18:39:41.955890 20216 sgd_solver.cpp:136] Iteration 28800, lr = 0.01, m = 0.9
I0916 18:40:01.354840 20216 solver.cpp:314] Iteration 28900 (5.15505 iter/s, 19.3985s/100 iter), loss = 0.161948
I0916 18:40:01.354867 20216 solver.cpp:336]     Train net output #0: loss = 0.161948 (* 1 = 0.161948 loss)
I0916 18:40:01.354871 20216 sgd_solver.cpp:136] Iteration 28900, lr = 0.01, m = 0.9
I0916 18:40:05.256429 20219 data_reader.cpp:305] Starting prefetch of epoch 21
I0916 18:40:20.864804 20216 solver.cpp:314] Iteration 29000 (5.12573 iter/s, 19.5094s/100 iter), loss = 0.0824135
I0916 18:40:20.864859 20216 solver.cpp:336]     Train net output #0: loss = 0.0824136 (* 1 = 0.0824136 loss)
I0916 18:40:20.864866 20216 sgd_solver.cpp:136] Iteration 29000, lr = 0.01, m = 0.9
I0916 18:40:40.454286 20216 solver.cpp:314] Iteration 29100 (5.10492 iter/s, 19.5889s/100 iter), loss = 0.0775144
I0916 18:40:40.454310 20216 solver.cpp:336]     Train net output #0: loss = 0.0775145 (* 1 = 0.0775145 loss)
I0916 18:40:40.454316 20216 sgd_solver.cpp:136] Iteration 29100, lr = 0.01, m = 0.9
I0916 18:40:59.819272 20216 solver.cpp:314] Iteration 29200 (5.1641 iter/s, 19.3644s/100 iter), loss = 0.0631669
I0916 18:40:59.819454 20216 solver.cpp:336]     Train net output #0: loss = 0.063167 (* 1 = 0.063167 loss)
I0916 18:40:59.819463 20216 sgd_solver.cpp:136] Iteration 29200, lr = 0.01, m = 0.9
I0916 18:41:09.541152 20220 data_reader.cpp:305] Starting prefetch of epoch 25
I0916 18:41:19.090515 20216 solver.cpp:314] Iteration 29300 (5.18922 iter/s, 19.2707s/100 iter), loss = 0.0595184
I0916 18:41:19.090539 20216 solver.cpp:336]     Train net output #0: loss = 0.0595185 (* 1 = 0.0595185 loss)
I0916 18:41:19.090545 20216 sgd_solver.cpp:136] Iteration 29300, lr = 0.01, m = 0.9
I0916 18:41:38.828028 20216 solver.cpp:314] Iteration 29400 (5.06664 iter/s, 19.737s/100 iter), loss = 0.0599829
I0916 18:41:38.828114 20216 solver.cpp:336]     Train net output #0: loss = 0.0599829 (* 1 = 0.0599829 loss)
I0916 18:41:38.828122 20216 sgd_solver.cpp:136] Iteration 29400, lr = 0.01, m = 0.9
I0916 18:41:58.244016 20216 solver.cpp:314] Iteration 29500 (5.15054 iter/s, 19.4154s/100 iter), loss = 0.144637
I0916 18:41:58.244045 20216 solver.cpp:336]     Train net output #0: loss = 0.144637 (* 1 = 0.144637 loss)
I0916 18:41:58.244051 20216 sgd_solver.cpp:136] Iteration 29500, lr = 0.01, m = 0.9
I0916 18:42:14.072659 20224 data_reader.cpp:305] Starting prefetch of epoch 21
I0916 18:42:17.614300 20216 solver.cpp:314] Iteration 29600 (5.16269 iter/s, 19.3697s/100 iter), loss = 0.067109
I0916 18:42:17.614321 20216 solver.cpp:336]     Train net output #0: loss = 0.0671091 (* 1 = 0.0671091 loss)
I0916 18:42:17.614327 20216 sgd_solver.cpp:136] Iteration 29600, lr = 0.01, m = 0.9
I0916 18:42:37.149590 20216 solver.cpp:314] Iteration 29700 (5.11908 iter/s, 19.5347s/100 iter), loss = 0.0729557
I0916 18:42:37.149619 20216 solver.cpp:336]     Train net output #0: loss = 0.0729558 (* 1 = 0.0729558 loss)
I0916 18:42:37.149627 20216 sgd_solver.cpp:136] Iteration 29700, lr = 0.01, m = 0.9
I0916 18:42:56.610298 20216 solver.cpp:314] Iteration 29800 (5.1387 iter/s, 19.4602s/100 iter), loss = 0.141528
I0916 18:42:56.617969 20216 solver.cpp:336]     Train net output #0: loss = 0.141528 (* 1 = 0.141528 loss)
I0916 18:42:56.618001 20216 sgd_solver.cpp:136] Iteration 29800, lr = 0.01, m = 0.9
I0916 18:43:16.322773 20216 solver.cpp:314] Iteration 29900 (5.07307 iter/s, 19.7119s/100 iter), loss = 0.0784908
I0916 18:43:16.322799 20216 solver.cpp:336]     Train net output #0: loss = 0.0784909 (* 1 = 0.0784909 loss)
I0916 18:43:16.322808 20216 sgd_solver.cpp:136] Iteration 29900, lr = 0.01, m = 0.9
I0916 18:43:18.745353 20197 data_reader.cpp:305] Starting prefetch of epoch 16
I0916 18:43:35.965090 20216 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/cityscapes5_jsegnet21v2_iter_30000.caffemodel
I0916 18:43:36.354102 20216 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/cityscapes5_jsegnet21v2_iter_30000.solverstate
I0916 18:43:36.358435 20216 solver.cpp:563] Iteration 30000, Testing net (#0)
I0916 18:43:43.389469 20204 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 18:43:47.407966 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.952704
I0916 18:43:47.407989 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 18:43:47.407994 20216 solver.cpp:655]     Test net output #2: loss = 0.162434 (* 1 = 0.162434 loss)
I0916 18:43:47.408021 20216 solver.cpp:265] [MultiGPU] Tests completed in 11.0493s
I0916 18:43:47.526149 20266 sgd_solver.cpp:48] MultiStep Status: Iteration 30000, step = 1
I0916 18:43:47.526149 20267 sgd_solver.cpp:48] MultiStep Status: Iteration 30000, step = 1
I0916 18:43:47.526245 20268 sgd_solver.cpp:48] MultiStep Status: Iteration 30000, step = 1
I0916 18:43:47.621229 20216 solver.cpp:314] Iteration 30000 (3.19513 iter/s, 31.2976s/100 iter), loss = 0.200347
I0916 18:43:47.621258 20216 solver.cpp:336]     Train net output #0: loss = 0.200348 (* 1 = 0.200348 loss)
I0916 18:43:47.621263 20216 sgd_solver.cpp:136] Iteration 30000, lr = 0.001, m = 0.9
I0916 18:44:06.943439 20216 solver.cpp:314] Iteration 30100 (5.17554 iter/s, 19.3217s/100 iter), loss = 0.0622953
I0916 18:44:06.943524 20216 solver.cpp:336]     Train net output #0: loss = 0.0622954 (* 1 = 0.0622954 loss)
I0916 18:44:06.943531 20216 sgd_solver.cpp:136] Iteration 30100, lr = 0.001, m = 0.9
I0916 18:44:26.171859 20216 solver.cpp:314] Iteration 30200 (5.20078 iter/s, 19.2279s/100 iter), loss = 0.0659689
I0916 18:44:26.171882 20216 solver.cpp:336]     Train net output #0: loss = 0.065969 (* 1 = 0.065969 loss)
I0916 18:44:26.171888 20216 sgd_solver.cpp:136] Iteration 30200, lr = 0.001, m = 0.9
I0916 18:44:34.295228 20224 data_reader.cpp:305] Starting prefetch of epoch 22
I0916 18:44:45.696749 20216 solver.cpp:314] Iteration 30300 (5.12181 iter/s, 19.5243s/100 iter), loss = 0.0770236
I0916 18:44:45.696801 20216 solver.cpp:336]     Train net output #0: loss = 0.0770237 (* 1 = 0.0770237 loss)
I0916 18:44:45.696808 20216 sgd_solver.cpp:136] Iteration 30300, lr = 0.001, m = 0.9
I0916 18:45:05.374202 20216 solver.cpp:314] Iteration 30400 (5.0821 iter/s, 19.6769s/100 iter), loss = 0.0713458
I0916 18:45:05.374228 20216 solver.cpp:336]     Train net output #0: loss = 0.0713459 (* 1 = 0.0713459 loss)
I0916 18:45:05.374231 20216 sgd_solver.cpp:136] Iteration 30400, lr = 0.001, m = 0.9
I0916 18:45:24.909066 20216 solver.cpp:314] Iteration 30500 (5.11919 iter/s, 19.5343s/100 iter), loss = 0.0847558
I0916 18:45:24.909116 20216 solver.cpp:336]     Train net output #0: loss = 0.0847559 (* 1 = 0.0847559 loss)
I0916 18:45:24.909121 20216 sgd_solver.cpp:136] Iteration 30500, lr = 0.001, m = 0.9
I0916 18:45:39.257985 20197 data_reader.cpp:305] Starting prefetch of epoch 17
I0916 18:45:44.686408 20216 solver.cpp:314] Iteration 30600 (5.05643 iter/s, 19.7768s/100 iter), loss = 0.0555314
I0916 18:45:44.686435 20216 solver.cpp:336]     Train net output #0: loss = 0.0555314 (* 1 = 0.0555314 loss)
I0916 18:45:44.686441 20216 sgd_solver.cpp:136] Iteration 30600, lr = 0.001, m = 0.9
I0916 18:46:04.542682 20216 solver.cpp:314] Iteration 30700 (5.03633 iter/s, 19.8557s/100 iter), loss = 0.178002
I0916 18:46:04.542737 20216 solver.cpp:336]     Train net output #0: loss = 0.178002 (* 1 = 0.178002 loss)
I0916 18:46:04.542742 20216 sgd_solver.cpp:136] Iteration 30700, lr = 0.001, m = 0.9
I0916 18:46:12.135844 20197 data_reader.cpp:305] Starting prefetch of epoch 18
I0916 18:46:24.301138 20216 solver.cpp:314] Iteration 30800 (5.06126 iter/s, 19.7579s/100 iter), loss = 0.0567264
I0916 18:46:24.301162 20216 solver.cpp:336]     Train net output #0: loss = 0.0567265 (* 1 = 0.0567265 loss)
I0916 18:46:24.301167 20216 sgd_solver.cpp:136] Iteration 30800, lr = 0.001, m = 0.9
I0916 18:46:43.694195 20216 solver.cpp:314] Iteration 30900 (5.15663 iter/s, 19.3925s/100 iter), loss = 0.0817302
I0916 18:46:43.694278 20216 solver.cpp:336]     Train net output #0: loss = 0.0817302 (* 1 = 0.0817302 loss)
I0916 18:46:43.694285 20216 sgd_solver.cpp:136] Iteration 30900, lr = 0.001, m = 0.9
I0916 18:47:03.432962 20216 solver.cpp:314] Iteration 31000 (5.06631 iter/s, 19.7382s/100 iter), loss = 0.070202
I0916 18:47:03.432991 20216 solver.cpp:336]     Train net output #0: loss = 0.0702021 (* 1 = 0.0702021 loss)
I0916 18:47:03.432996 20216 sgd_solver.cpp:136] Iteration 31000, lr = 0.001, m = 0.9
I0916 18:47:16.818208 20224 data_reader.cpp:305] Starting prefetch of epoch 23
I0916 18:47:22.706475 20216 solver.cpp:314] Iteration 31100 (5.18861 iter/s, 19.273s/100 iter), loss = 0.0653389
I0916 18:47:22.706571 20216 solver.cpp:336]     Train net output #0: loss = 0.065339 (* 1 = 0.065339 loss)
I0916 18:47:22.706595 20216 sgd_solver.cpp:136] Iteration 31100, lr = 0.001, m = 0.9
I0916 18:47:42.138851 20216 solver.cpp:314] Iteration 31200 (5.14619 iter/s, 19.4318s/100 iter), loss = 0.10858
I0916 18:47:42.138873 20216 solver.cpp:336]     Train net output #0: loss = 0.10858 (* 1 = 0.10858 loss)
I0916 18:47:42.138877 20216 sgd_solver.cpp:136] Iteration 31200, lr = 0.001, m = 0.9
I0916 18:48:01.829407 20216 solver.cpp:314] Iteration 31300 (5.07872 iter/s, 19.69s/100 iter), loss = 0.0884442
I0916 18:48:01.829484 20216 solver.cpp:336]     Train net output #0: loss = 0.0884443 (* 1 = 0.0884443 loss)
I0916 18:48:01.829491 20216 sgd_solver.cpp:136] Iteration 31300, lr = 0.001, m = 0.9
I0916 18:48:21.016893 20197 data_reader.cpp:305] Starting prefetch of epoch 19
I0916 18:48:21.201232 20216 solver.cpp:314] Iteration 31400 (5.16228 iter/s, 19.3713s/100 iter), loss = 0.0521486
I0916 18:48:21.201258 20216 solver.cpp:336]     Train net output #0: loss = 0.0521487 (* 1 = 0.0521487 loss)
I0916 18:48:21.201262 20216 sgd_solver.cpp:136] Iteration 31400, lr = 0.001, m = 0.9
I0916 18:48:40.684855 20216 solver.cpp:314] Iteration 31500 (5.13266 iter/s, 19.4831s/100 iter), loss = 0.0500479
I0916 18:48:40.684911 20216 solver.cpp:336]     Train net output #0: loss = 0.050048 (* 1 = 0.050048 loss)
I0916 18:48:40.684917 20216 sgd_solver.cpp:136] Iteration 31500, lr = 0.001, m = 0.9
I0916 18:48:53.332856 20220 data_reader.cpp:305] Starting prefetch of epoch 26
I0916 18:49:00.247565 20216 solver.cpp:314] Iteration 31600 (5.11191 iter/s, 19.5622s/100 iter), loss = 0.229671
I0916 18:49:00.247589 20216 solver.cpp:336]     Train net output #0: loss = 0.229671 (* 1 = 0.229671 loss)
I0916 18:49:00.247594 20216 sgd_solver.cpp:136] Iteration 31600, lr = 0.001, m = 0.9
I0916 18:49:19.849268 20216 solver.cpp:314] Iteration 31700 (5.10174 iter/s, 19.6012s/100 iter), loss = 0.0510296
I0916 18:49:19.849320 20216 solver.cpp:336]     Train net output #0: loss = 0.0510297 (* 1 = 0.0510297 loss)
I0916 18:49:19.849328 20216 sgd_solver.cpp:136] Iteration 31700, lr = 0.001, m = 0.9
I0916 18:49:39.359239 20216 solver.cpp:314] Iteration 31800 (5.12573 iter/s, 19.5094s/100 iter), loss = 0.0714204
I0916 18:49:39.359269 20216 solver.cpp:336]     Train net output #0: loss = 0.0714205 (* 1 = 0.0714205 loss)
I0916 18:49:39.359277 20216 sgd_solver.cpp:136] Iteration 31800, lr = 0.001, m = 0.9
I0916 18:49:57.827383 20219 data_reader.cpp:305] Starting prefetch of epoch 22
I0916 18:49:58.776474 20216 solver.cpp:314] Iteration 31900 (5.15021 iter/s, 19.4167s/100 iter), loss = 0.0340111
I0916 18:49:58.776500 20216 solver.cpp:336]     Train net output #0: loss = 0.0340112 (* 1 = 0.0340112 loss)
I0916 18:49:58.776505 20216 sgd_solver.cpp:136] Iteration 31900, lr = 0.001, m = 0.9
I0916 18:50:17.910006 20216 solver.cpp:563] Iteration 32000, Testing net (#0)
I0916 18:50:35.245177 20241 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 18:50:35.703531 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.952376
I0916 18:50:35.703553 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 18:50:35.703559 20216 solver.cpp:655]     Test net output #2: loss = 0.139993 (* 1 = 0.139993 loss)
I0916 18:50:35.703605 20216 solver.cpp:265] [MultiGPU] Tests completed in 17.7931s
I0916 18:50:35.917285 20216 solver.cpp:314] Iteration 32000 (2.69253 iter/s, 37.1398s/100 iter), loss = 0.0556578
I0916 18:50:35.917311 20216 solver.cpp:336]     Train net output #0: loss = 0.0556579 (* 1 = 0.0556579 loss)
I0916 18:50:35.917317 20216 sgd_solver.cpp:136] Iteration 32000, lr = 0.001, m = 0.9
I0916 18:50:47.484015 20219 data_reader.cpp:305] Starting prefetch of epoch 23
I0916 18:50:55.056968 20216 solver.cpp:314] Iteration 32100 (5.2249 iter/s, 19.1391s/100 iter), loss = 0.0941514
I0916 18:50:55.056993 20216 solver.cpp:336]     Train net output #0: loss = 0.0941515 (* 1 = 0.0941515 loss)
I0916 18:50:55.056999 20216 sgd_solver.cpp:136] Iteration 32100, lr = 0.001, m = 0.9
I0916 18:51:14.609938 20216 solver.cpp:314] Iteration 32200 (5.11446 iter/s, 19.5524s/100 iter), loss = 0.0559827
I0916 18:51:14.610002 20216 solver.cpp:336]     Train net output #0: loss = 0.0559828 (* 1 = 0.0559828 loss)
I0916 18:51:14.610008 20216 sgd_solver.cpp:136] Iteration 32200, lr = 0.001, m = 0.9
I0916 18:51:34.218010 20216 solver.cpp:314] Iteration 32300 (5.10008 iter/s, 19.6075s/100 iter), loss = 0.0632078
I0916 18:51:34.218034 20216 solver.cpp:336]     Train net output #0: loss = 0.0632079 (* 1 = 0.0632079 loss)
I0916 18:51:34.218040 20216 sgd_solver.cpp:136] Iteration 32300, lr = 0.001, m = 0.9
I0916 18:51:51.850239 20219 data_reader.cpp:305] Starting prefetch of epoch 24
I0916 18:51:53.549710 20216 solver.cpp:314] Iteration 32400 (5.173 iter/s, 19.3312s/100 iter), loss = 0.0568432
I0916 18:51:53.549736 20216 solver.cpp:336]     Train net output #0: loss = 0.0568433 (* 1 = 0.0568433 loss)
I0916 18:51:53.549741 20216 sgd_solver.cpp:136] Iteration 32400, lr = 0.001, m = 0.9
I0916 18:52:12.844264 20216 solver.cpp:314] Iteration 32500 (5.18296 iter/s, 19.294s/100 iter), loss = 0.0594617
I0916 18:52:12.844288 20216 solver.cpp:336]     Train net output #0: loss = 0.0594618 (* 1 = 0.0594618 loss)
I0916 18:52:12.844295 20216 sgd_solver.cpp:136] Iteration 32500, lr = 0.001, m = 0.9
I0916 18:52:32.214092 20216 solver.cpp:314] Iteration 32600 (5.16281 iter/s, 19.3693s/100 iter), loss = 0.0463058
I0916 18:52:32.214143 20216 solver.cpp:336]     Train net output #0: loss = 0.0463059 (* 1 = 0.0463059 loss)
I0916 18:52:32.214149 20216 sgd_solver.cpp:136] Iteration 32600, lr = 0.001, m = 0.9
I0916 18:52:51.698633 20216 solver.cpp:314] Iteration 32700 (5.13242 iter/s, 19.484s/100 iter), loss = 0.0627425
I0916 18:52:51.698664 20216 solver.cpp:336]     Train net output #0: loss = 0.0627426 (* 1 = 0.0627426 loss)
I0916 18:52:51.698671 20216 sgd_solver.cpp:136] Iteration 32700, lr = 0.001, m = 0.9
I0916 18:52:55.682122 20224 data_reader.cpp:305] Starting prefetch of epoch 24
I0916 18:53:11.244705 20216 solver.cpp:314] Iteration 32800 (5.11626 iter/s, 19.5455s/100 iter), loss = 0.0591683
I0916 18:53:11.244959 20216 solver.cpp:336]     Train net output #0: loss = 0.0591684 (* 1 = 0.0591684 loss)
I0916 18:53:11.255120 20216 sgd_solver.cpp:136] Iteration 32800, lr = 0.001, m = 0.9
I0916 18:53:28.392000 20219 data_reader.cpp:305] Starting prefetch of epoch 25
I0916 18:53:30.833562 20216 solver.cpp:314] Iteration 32900 (5.10509 iter/s, 19.5883s/100 iter), loss = 0.0796334
I0916 18:53:30.833591 20216 solver.cpp:336]     Train net output #0: loss = 0.0796335 (* 1 = 0.0796335 loss)
I0916 18:53:30.833598 20216 sgd_solver.cpp:136] Iteration 32900, lr = 0.001, m = 0.9
I0916 18:53:50.278328 20216 solver.cpp:314] Iteration 33000 (5.14292 iter/s, 19.4442s/100 iter), loss = 0.0633031
I0916 18:53:50.278388 20216 solver.cpp:336]     Train net output #0: loss = 0.0633033 (* 1 = 0.0633033 loss)
I0916 18:53:50.278393 20216 sgd_solver.cpp:136] Iteration 33000, lr = 0.001, m = 0.9
I0916 18:54:09.695581 20216 solver.cpp:314] Iteration 33100 (5.15021 iter/s, 19.4167s/100 iter), loss = 0.0677081
I0916 18:54:09.695602 20216 solver.cpp:336]     Train net output #0: loss = 0.0677082 (* 1 = 0.0677082 loss)
I0916 18:54:09.695607 20216 sgd_solver.cpp:136] Iteration 33100, lr = 0.001, m = 0.9
I0916 18:54:29.070919 20216 solver.cpp:314] Iteration 33200 (5.16135 iter/s, 19.3748s/100 iter), loss = 0.0818252
I0916 18:54:29.070973 20216 solver.cpp:336]     Train net output #0: loss = 0.0818253 (* 1 = 0.0818253 loss)
I0916 18:54:29.070979 20216 sgd_solver.cpp:136] Iteration 33200, lr = 0.001, m = 0.9
I0916 18:54:32.408188 20219 data_reader.cpp:305] Starting prefetch of epoch 26
I0916 18:54:48.605355 20216 solver.cpp:314] Iteration 33300 (5.11931 iter/s, 19.5339s/100 iter), loss = 0.0649468
I0916 18:54:48.605377 20216 solver.cpp:336]     Train net output #0: loss = 0.064947 (* 1 = 0.064947 loss)
I0916 18:54:48.605383 20216 sgd_solver.cpp:136] Iteration 33300, lr = 0.001, m = 0.9
I0916 18:55:08.102262 20216 solver.cpp:314] Iteration 33400 (5.12916 iter/s, 19.4964s/100 iter), loss = 0.053372
I0916 18:55:08.102319 20216 solver.cpp:336]     Train net output #0: loss = 0.0533722 (* 1 = 0.0533722 loss)
I0916 18:55:08.102326 20216 sgd_solver.cpp:136] Iteration 33400, lr = 0.001, m = 0.9
I0916 18:55:27.520299 20216 solver.cpp:314] Iteration 33500 (5.15 iter/s, 19.4175s/100 iter), loss = 0.0650325
I0916 18:55:27.520361 20216 solver.cpp:336]     Train net output #0: loss = 0.0650327 (* 1 = 0.0650327 loss)
I0916 18:55:27.520375 20216 sgd_solver.cpp:136] Iteration 33500, lr = 0.001, m = 0.9
I0916 18:55:36.966827 20223 data_reader.cpp:305] Starting prefetch of epoch 14
I0916 18:55:47.317200 20216 solver.cpp:314] Iteration 33600 (5.05144 iter/s, 19.7963s/100 iter), loss = 0.0559228
I0916 18:55:47.317314 20216 solver.cpp:336]     Train net output #0: loss = 0.0559229 (* 1 = 0.0559229 loss)
I0916 18:55:47.317322 20216 sgd_solver.cpp:136] Iteration 33600, lr = 0.001, m = 0.9
I0916 18:56:06.937256 20216 solver.cpp:314] Iteration 33700 (5.09697 iter/s, 19.6195s/100 iter), loss = 0.11815
I0916 18:56:06.937288 20216 solver.cpp:336]     Train net output #0: loss = 0.11815 (* 1 = 0.11815 loss)
I0916 18:56:06.937295 20216 sgd_solver.cpp:136] Iteration 33700, lr = 0.001, m = 0.9
I0916 18:56:09.580379 20195 data_reader.cpp:305] Starting prefetch of epoch 11
I0916 18:56:26.542970 20216 solver.cpp:314] Iteration 33800 (5.1007 iter/s, 19.6052s/100 iter), loss = 0.0527528
I0916 18:56:26.543043 20216 solver.cpp:336]     Train net output #0: loss = 0.0527529 (* 1 = 0.0527529 loss)
I0916 18:56:26.543051 20216 sgd_solver.cpp:136] Iteration 33800, lr = 0.001, m = 0.9
I0916 18:56:46.046152 20216 solver.cpp:314] Iteration 33900 (5.12751 iter/s, 19.5026s/100 iter), loss = 0.0480229
I0916 18:56:46.046174 20216 solver.cpp:336]     Train net output #0: loss = 0.048023 (* 1 = 0.048023 loss)
I0916 18:56:46.046178 20216 sgd_solver.cpp:136] Iteration 33900, lr = 0.001, m = 0.9
I0916 18:57:05.250099 20216 solver.cpp:563] Iteration 34000, Testing net (#0)
I0916 18:57:12.174511 20250 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 18:57:16.190225 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.95642
I0916 18:57:16.190248 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 18:57:16.190253 20216 solver.cpp:655]     Test net output #2: loss = 0.154197 (* 1 = 0.154197 loss)
I0916 18:57:16.190279 20216 solver.cpp:265] [MultiGPU] Tests completed in 10.9399s
I0916 18:57:16.399001 20216 solver.cpp:314] Iteration 34000 (3.29468 iter/s, 30.352s/100 iter), loss = 0.0933967
I0916 18:57:16.399025 20216 solver.cpp:336]     Train net output #0: loss = 0.0933968 (* 1 = 0.0933968 loss)
I0916 18:57:16.399030 20216 sgd_solver.cpp:136] Iteration 34000, lr = 0.001, m = 0.9
I0916 18:57:35.853349 20216 solver.cpp:314] Iteration 34100 (5.14038 iter/s, 19.4538s/100 iter), loss = 0.0569183
I0916 18:57:35.853622 20216 solver.cpp:336]     Train net output #0: loss = 0.0569184 (* 1 = 0.0569184 loss)
I0916 18:57:35.853629 20216 sgd_solver.cpp:136] Iteration 34100, lr = 0.001, m = 0.9
I0916 18:57:55.372088 20216 solver.cpp:314] Iteration 34200 (5.12343 iter/s, 19.5182s/100 iter), loss = 0.043982
I0916 18:57:55.372115 20216 solver.cpp:336]     Train net output #0: loss = 0.0439822 (* 1 = 0.0439822 loss)
I0916 18:57:55.372120 20216 sgd_solver.cpp:136] Iteration 34200, lr = 0.001, m = 0.9
I0916 18:57:57.127060 20197 data_reader.cpp:305] Starting prefetch of epoch 20
I0916 18:58:14.684836 20216 solver.cpp:314] Iteration 34300 (5.17807 iter/s, 19.3122s/100 iter), loss = 0.0531904
I0916 18:58:14.698179 20216 solver.cpp:336]     Train net output #0: loss = 0.0531906 (* 1 = 0.0531906 loss)
I0916 18:58:14.698232 20216 sgd_solver.cpp:136] Iteration 34300, lr = 0.001, m = 0.9
I0916 18:58:34.064692 20216 solver.cpp:314] Iteration 34400 (5.16014 iter/s, 19.3793s/100 iter), loss = 0.0598831
I0916 18:58:34.064713 20216 solver.cpp:336]     Train net output #0: loss = 0.0598833 (* 1 = 0.0598833 loss)
I0916 18:58:34.064718 20216 sgd_solver.cpp:136] Iteration 34400, lr = 0.001, m = 0.9
I0916 18:58:53.381711 20216 solver.cpp:314] Iteration 34500 (5.17693 iter/s, 19.3165s/100 iter), loss = 0.138205
I0916 18:58:53.381773 20216 solver.cpp:336]     Train net output #0: loss = 0.138205 (* 1 = 0.138205 loss)
I0916 18:58:53.381780 20216 sgd_solver.cpp:136] Iteration 34500, lr = 0.001, m = 0.9
I0916 18:59:01.103173 20197 data_reader.cpp:305] Starting prefetch of epoch 21
I0916 18:59:12.627598 20216 solver.cpp:314] Iteration 34600 (5.19606 iter/s, 19.2453s/100 iter), loss = 0.0783648
I0916 18:59:12.627634 20216 solver.cpp:336]     Train net output #0: loss = 0.0783649 (* 1 = 0.0783649 loss)
I0916 18:59:12.627640 20216 sgd_solver.cpp:136] Iteration 34600, lr = 0.001, m = 0.9
I0916 18:59:32.405452 20216 solver.cpp:314] Iteration 34700 (5.05635 iter/s, 19.7771s/100 iter), loss = 0.0466685
I0916 18:59:32.405563 20216 solver.cpp:336]     Train net output #0: loss = 0.0466686 (* 1 = 0.0466686 loss)
I0916 18:59:32.405571 20216 sgd_solver.cpp:136] Iteration 34700, lr = 0.001, m = 0.9
I0916 18:59:33.497597 20219 data_reader.cpp:305] Starting prefetch of epoch 27
I0916 18:59:51.871831 20216 solver.cpp:314] Iteration 34800 (5.13721 iter/s, 19.4658s/100 iter), loss = 0.064645
I0916 18:59:51.871867 20216 solver.cpp:336]     Train net output #0: loss = 0.0646451 (* 1 = 0.0646451 loss)
I0916 18:59:51.871872 20216 sgd_solver.cpp:136] Iteration 34800, lr = 0.001, m = 0.9
I0916 19:00:11.299962 20216 solver.cpp:314] Iteration 34900 (5.14732 iter/s, 19.4276s/100 iter), loss = 0.0731461
I0916 19:00:11.300019 20216 solver.cpp:336]     Train net output #0: loss = 0.0731462 (* 1 = 0.0731462 loss)
I0916 19:00:11.300026 20216 sgd_solver.cpp:136] Iteration 34900, lr = 0.001, m = 0.9
I0916 19:00:30.968544 20216 solver.cpp:314] Iteration 35000 (5.08439 iter/s, 19.668s/100 iter), loss = 0.0612922
I0916 19:00:30.968566 20216 solver.cpp:336]     Train net output #0: loss = 0.0612924 (* 1 = 0.0612924 loss)
I0916 19:00:30.968572 20216 sgd_solver.cpp:136] Iteration 35000, lr = 0.001, m = 0.9
I0916 19:00:37.897804 20219 data_reader.cpp:305] Starting prefetch of epoch 28
I0916 19:00:50.517982 20216 solver.cpp:314] Iteration 35100 (5.11538 iter/s, 19.5489s/100 iter), loss = 0.0661126
I0916 19:00:50.518085 20216 solver.cpp:336]     Train net output #0: loss = 0.0661128 (* 1 = 0.0661128 loss)
I0916 19:00:50.518091 20216 sgd_solver.cpp:136] Iteration 35100, lr = 0.001, m = 0.9
I0916 19:01:10.123559 20216 solver.cpp:314] Iteration 35200 (5.10073 iter/s, 19.605s/100 iter), loss = 0.0456435
I0916 19:01:10.123586 20216 solver.cpp:336]     Train net output #0: loss = 0.0456436 (* 1 = 0.0456436 loss)
I0916 19:01:10.123592 20216 sgd_solver.cpp:136] Iteration 35200, lr = 0.001, m = 0.9
I0916 19:01:29.660202 20216 solver.cpp:314] Iteration 35300 (5.11873 iter/s, 19.5361s/100 iter), loss = 0.0703739
I0916 19:01:29.660286 20216 solver.cpp:336]     Train net output #0: loss = 0.070374 (* 1 = 0.070374 loss)
I0916 19:01:29.660291 20216 sgd_solver.cpp:136] Iteration 35300, lr = 0.001, m = 0.9
I0916 19:01:42.645586 20224 data_reader.cpp:305] Starting prefetch of epoch 25
I0916 19:01:49.220105 20216 solver.cpp:314] Iteration 35400 (5.11264 iter/s, 19.5594s/100 iter), loss = 0.0625583
I0916 19:01:49.220134 20216 solver.cpp:336]     Train net output #0: loss = 0.0625584 (* 1 = 0.0625584 loss)
I0916 19:01:49.220141 20216 sgd_solver.cpp:136] Iteration 35400, lr = 0.001, m = 0.9
I0916 19:02:08.755250 20216 solver.cpp:314] Iteration 35500 (5.11912 iter/s, 19.5346s/100 iter), loss = 0.041792
I0916 19:02:08.755306 20216 solver.cpp:336]     Train net output #0: loss = 0.0417921 (* 1 = 0.0417921 loss)
I0916 19:02:08.755313 20216 sgd_solver.cpp:136] Iteration 35500, lr = 0.001, m = 0.9
I0916 19:02:14.766671 20220 data_reader.cpp:305] Starting prefetch of epoch 27
I0916 19:02:28.143056 20216 solver.cpp:314] Iteration 35600 (5.15802 iter/s, 19.3873s/100 iter), loss = 0.073099
I0916 19:02:28.143080 20216 solver.cpp:336]     Train net output #0: loss = 0.0730992 (* 1 = 0.0730992 loss)
I0916 19:02:28.143086 20216 sgd_solver.cpp:136] Iteration 35600, lr = 0.001, m = 0.9
I0916 19:02:47.506088 20216 solver.cpp:314] Iteration 35700 (5.16463 iter/s, 19.3625s/100 iter), loss = 0.0489297
I0916 19:02:47.506145 20216 solver.cpp:336]     Train net output #0: loss = 0.0489299 (* 1 = 0.0489299 loss)
I0916 19:02:47.506152 20216 sgd_solver.cpp:136] Iteration 35700, lr = 0.001, m = 0.9
I0916 19:03:06.879691 20216 solver.cpp:314] Iteration 35800 (5.16181 iter/s, 19.3731s/100 iter), loss = 0.0567843
I0916 19:03:06.879716 20216 solver.cpp:336]     Train net output #0: loss = 0.0567844 (* 1 = 0.0567844 loss)
I0916 19:03:06.879721 20216 sgd_solver.cpp:136] Iteration 35800, lr = 0.001, m = 0.9
I0916 19:03:19.028264 20224 data_reader.cpp:305] Starting prefetch of epoch 26
I0916 19:03:26.312796 20216 solver.cpp:314] Iteration 35900 (5.146 iter/s, 19.4326s/100 iter), loss = 0.062649
I0916 19:03:26.312822 20216 solver.cpp:336]     Train net output #0: loss = 0.0626492 (* 1 = 0.0626492 loss)
I0916 19:03:26.312829 20216 sgd_solver.cpp:136] Iteration 35900, lr = 0.001, m = 0.9
I0916 19:03:45.443786 20216 solver.cpp:563] Iteration 36000, Testing net (#0)
I0916 19:04:00.039221 20202 data_reader.cpp:305] Starting prefetch of epoch 7
I0916 19:04:00.505813 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.953803
I0916 19:04:00.505836 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 19:04:00.505841 20216 solver.cpp:655]     Test net output #2: loss = 0.142396 (* 1 = 0.142396 loss)
I0916 19:04:00.505913 20216 solver.cpp:265] [MultiGPU] Tests completed in 15.0617s
I0916 19:04:00.703058 20216 solver.cpp:314] Iteration 36000 (2.90788 iter/s, 34.3893s/100 iter), loss = 0.0729639
I0916 19:04:00.703084 20216 solver.cpp:336]     Train net output #0: loss = 0.072964 (* 1 = 0.072964 loss)
I0916 19:04:00.703089 20216 sgd_solver.cpp:136] Iteration 36000, lr = 0.001, m = 0.9
I0916 19:04:05.977577 20195 data_reader.cpp:305] Starting prefetch of epoch 12
I0916 19:04:20.075834 20216 solver.cpp:314] Iteration 36100 (5.16203 iter/s, 19.3722s/100 iter), loss = 0.118119
I0916 19:04:20.075858 20216 solver.cpp:336]     Train net output #0: loss = 0.118119 (* 1 = 0.118119 loss)
I0916 19:04:20.075865 20216 sgd_solver.cpp:136] Iteration 36100, lr = 0.001, m = 0.9
I0916 19:04:39.523936 20216 solver.cpp:314] Iteration 36200 (5.14203 iter/s, 19.4476s/100 iter), loss = 0.0430572
I0916 19:04:39.524057 20216 solver.cpp:336]     Train net output #0: loss = 0.0430573 (* 1 = 0.0430573 loss)
I0916 19:04:39.524066 20216 sgd_solver.cpp:136] Iteration 36200, lr = 0.001, m = 0.9
I0916 19:04:58.848348 20216 solver.cpp:314] Iteration 36300 (5.17495 iter/s, 19.3239s/100 iter), loss = 0.0511251
I0916 19:04:58.848374 20216 solver.cpp:336]     Train net output #0: loss = 0.0511253 (* 1 = 0.0511253 loss)
I0916 19:04:58.848379 20216 sgd_solver.cpp:136] Iteration 36300, lr = 0.001, m = 0.9
I0916 19:05:10.185422 20195 data_reader.cpp:305] Starting prefetch of epoch 13
I0916 19:05:18.291105 20216 solver.cpp:314] Iteration 36400 (5.14345 iter/s, 19.4422s/100 iter), loss = 0.0479042
I0916 19:05:18.291127 20216 solver.cpp:336]     Train net output #0: loss = 0.0479043 (* 1 = 0.0479043 loss)
I0916 19:05:18.291133 20216 sgd_solver.cpp:136] Iteration 36400, lr = 0.001, m = 0.9
I0916 19:05:37.694006 20216 solver.cpp:314] Iteration 36500 (5.15401 iter/s, 19.4024s/100 iter), loss = 0.0795036
I0916 19:05:37.694034 20216 solver.cpp:336]     Train net output #0: loss = 0.0795038 (* 1 = 0.0795038 loss)
I0916 19:05:37.694041 20216 sgd_solver.cpp:136] Iteration 36500, lr = 0.001, m = 0.9
I0916 19:05:57.338719 20216 solver.cpp:314] Iteration 36600 (5.09057 iter/s, 19.6442s/100 iter), loss = 0.0641449
I0916 19:05:57.338799 20216 solver.cpp:336]     Train net output #0: loss = 0.0641451 (* 1 = 0.0641451 loss)
I0916 19:05:57.338806 20216 sgd_solver.cpp:136] Iteration 36600, lr = 0.001, m = 0.9
I0916 19:06:14.483000 20223 data_reader.cpp:305] Starting prefetch of epoch 15
I0916 19:06:16.764622 20216 solver.cpp:314] Iteration 36700 (5.14791 iter/s, 19.4254s/100 iter), loss = 0.0576656
I0916 19:06:16.764652 20216 solver.cpp:336]     Train net output #0: loss = 0.0576657 (* 1 = 0.0576657 loss)
I0916 19:06:16.764659 20216 sgd_solver.cpp:136] Iteration 36700, lr = 0.001, m = 0.9
I0916 19:06:36.179425 20216 solver.cpp:314] Iteration 36800 (5.15085 iter/s, 19.4143s/100 iter), loss = 0.0554914
I0916 19:06:36.179499 20216 solver.cpp:336]     Train net output #0: loss = 0.0554916 (* 1 = 0.0554916 loss)
I0916 19:06:36.179507 20216 sgd_solver.cpp:136] Iteration 36800, lr = 0.001, m = 0.9
I0916 19:06:46.577702 20219 data_reader.cpp:305] Starting prefetch of epoch 29
I0916 19:06:55.701792 20216 solver.cpp:314] Iteration 36900 (5.12247 iter/s, 19.5218s/100 iter), loss = 0.0575411
I0916 19:06:55.701819 20216 solver.cpp:336]     Train net output #0: loss = 0.0575413 (* 1 = 0.0575413 loss)
I0916 19:06:55.701825 20216 sgd_solver.cpp:136] Iteration 36900, lr = 0.001, m = 0.9
I0916 19:07:15.482702 20216 solver.cpp:314] Iteration 37000 (5.05552 iter/s, 19.7804s/100 iter), loss = 0.0601313
I0916 19:07:15.482754 20216 solver.cpp:336]     Train net output #0: loss = 0.0601315 (* 1 = 0.0601315 loss)
I0916 19:07:15.482761 20216 sgd_solver.cpp:136] Iteration 37000, lr = 0.001, m = 0.9
I0916 19:07:35.108541 20216 solver.cpp:314] Iteration 37100 (5.09547 iter/s, 19.6253s/100 iter), loss = 0.0715058
I0916 19:07:35.108563 20216 solver.cpp:336]     Train net output #0: loss = 0.071506 (* 1 = 0.071506 loss)
I0916 19:07:35.108569 20216 sgd_solver.cpp:136] Iteration 37100, lr = 0.001, m = 0.9
I0916 19:07:51.225901 20195 data_reader.cpp:305] Starting prefetch of epoch 14
I0916 19:07:54.277974 20216 solver.cpp:314] Iteration 37200 (5.21678 iter/s, 19.1689s/100 iter), loss = 0.0514527
I0916 19:07:54.277999 20216 solver.cpp:336]     Train net output #0: loss = 0.0514529 (* 1 = 0.0514529 loss)
I0916 19:07:54.278003 20216 sgd_solver.cpp:136] Iteration 37200, lr = 0.001, m = 0.9
I0916 19:08:13.593729 20216 solver.cpp:314] Iteration 37300 (5.17727 iter/s, 19.3152s/100 iter), loss = 0.0636414
I0916 19:08:13.593758 20216 solver.cpp:336]     Train net output #0: loss = 0.0636416 (* 1 = 0.0636416 loss)
I0916 19:08:13.593765 20216 sgd_solver.cpp:136] Iteration 37300, lr = 0.001, m = 0.9
I0916 19:08:33.094812 20216 solver.cpp:314] Iteration 37400 (5.12806 iter/s, 19.5005s/100 iter), loss = 0.0738609
I0916 19:08:33.094866 20216 solver.cpp:336]     Train net output #0: loss = 0.0738611 (* 1 = 0.0738611 loss)
I0916 19:08:33.094871 20216 sgd_solver.cpp:136] Iteration 37400, lr = 0.001, m = 0.9
I0916 19:08:52.526270 20216 solver.cpp:314] Iteration 37500 (5.14644 iter/s, 19.4309s/100 iter), loss = 0.043533
I0916 19:08:52.526296 20216 solver.cpp:336]     Train net output #0: loss = 0.0435332 (* 1 = 0.0435332 loss)
I0916 19:08:52.526304 20216 sgd_solver.cpp:136] Iteration 37500, lr = 0.001, m = 0.9
I0916 19:08:55.465584 20197 data_reader.cpp:305] Starting prefetch of epoch 22
I0916 19:09:12.054749 20216 solver.cpp:314] Iteration 37600 (5.12087 iter/s, 19.5279s/100 iter), loss = 0.0378196
I0916 19:09:12.054800 20216 solver.cpp:336]     Train net output #0: loss = 0.0378198 (* 1 = 0.0378198 loss)
I0916 19:09:12.054806 20216 sgd_solver.cpp:136] Iteration 37600, lr = 0.001, m = 0.9
I0916 19:09:31.778599 20216 solver.cpp:314] Iteration 37700 (5.07015 iter/s, 19.7233s/100 iter), loss = 0.0636438
I0916 19:09:31.778625 20216 solver.cpp:336]     Train net output #0: loss = 0.0636439 (* 1 = 0.0636439 loss)
I0916 19:09:31.778630 20216 sgd_solver.cpp:136] Iteration 37700, lr = 0.001, m = 0.9
I0916 19:09:51.130893 20216 solver.cpp:314] Iteration 37800 (5.16749 iter/s, 19.3518s/100 iter), loss = 0.0462049
I0916 19:09:51.130981 20216 solver.cpp:336]     Train net output #0: loss = 0.0462051 (* 1 = 0.0462051 loss)
I0916 19:09:51.130990 20216 sgd_solver.cpp:136] Iteration 37800, lr = 0.001, m = 0.9
I0916 19:09:59.730793 20223 data_reader.cpp:305] Starting prefetch of epoch 16
I0916 19:10:10.435570 20216 solver.cpp:314] Iteration 37900 (5.18024 iter/s, 19.3041s/100 iter), loss = 0.0665248
I0916 19:10:10.435603 20216 solver.cpp:336]     Train net output #0: loss = 0.066525 (* 1 = 0.066525 loss)
I0916 19:10:10.435611 20216 sgd_solver.cpp:136] Iteration 37900, lr = 0.001, m = 0.9
I0916 19:10:29.676525 20216 solver.cpp:563] Iteration 38000, Testing net (#0)
I0916 19:10:38.613641 20243 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 19:10:42.411550 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.956852
I0916 19:10:42.411576 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 19:10:42.411582 20216 solver.cpp:655]     Test net output #2: loss = 0.163453 (* 1 = 0.163453 loss)
I0916 19:10:42.411608 20216 solver.cpp:265] [MultiGPU] Tests completed in 12.7347s
I0916 19:10:42.615193 20216 solver.cpp:314] Iteration 38000 (3.10764 iter/s, 32.1787s/100 iter), loss = 0.0555672
I0916 19:10:42.615218 20216 solver.cpp:336]     Train net output #0: loss = 0.0555674 (* 1 = 0.0555674 loss)
I0916 19:10:42.615226 20216 sgd_solver.cpp:136] Iteration 38000, lr = 0.001, m = 0.9
I0916 19:11:02.000867 20216 solver.cpp:314] Iteration 38100 (5.1586 iter/s, 19.3851s/100 iter), loss = 0.0749946
I0916 19:11:02.000962 20216 solver.cpp:336]     Train net output #0: loss = 0.0749948 (* 1 = 0.0749948 loss)
I0916 19:11:02.000969 20216 sgd_solver.cpp:136] Iteration 38100, lr = 0.001, m = 0.9
I0916 19:11:16.948406 20195 data_reader.cpp:305] Starting prefetch of epoch 15
I0916 19:11:21.518239 20216 solver.cpp:314] Iteration 38200 (5.12379 iter/s, 19.5168s/100 iter), loss = 0.0745441
I0916 19:11:21.518265 20216 solver.cpp:336]     Train net output #0: loss = 0.0745442 (* 1 = 0.0745442 loss)
I0916 19:11:21.518270 20216 sgd_solver.cpp:136] Iteration 38200, lr = 0.001, m = 0.9
I0916 19:11:41.010331 20216 solver.cpp:314] Iteration 38300 (5.13043 iter/s, 19.4915s/100 iter), loss = 0.0572347
I0916 19:11:41.010421 20216 solver.cpp:336]     Train net output #0: loss = 0.0572349 (* 1 = 0.0572349 loss)
I0916 19:11:41.010429 20216 sgd_solver.cpp:136] Iteration 38300, lr = 0.001, m = 0.9
I0916 19:12:00.362439 20216 solver.cpp:314] Iteration 38400 (5.16754 iter/s, 19.3516s/100 iter), loss = 0.0605259
I0916 19:12:00.362462 20216 solver.cpp:336]     Train net output #0: loss = 0.060526 (* 1 = 0.060526 loss)
I0916 19:12:00.362468 20216 sgd_solver.cpp:136] Iteration 38400, lr = 0.001, m = 0.9
I0916 19:12:19.758021 20216 solver.cpp:314] Iteration 38500 (5.15596 iter/s, 19.395s/100 iter), loss = 0.0571834
I0916 19:12:19.758075 20216 solver.cpp:336]     Train net output #0: loss = 0.0571836 (* 1 = 0.0571836 loss)
I0916 19:12:19.758083 20216 sgd_solver.cpp:136] Iteration 38500, lr = 0.001, m = 0.9
I0916 19:12:20.891371 20224 data_reader.cpp:305] Starting prefetch of epoch 27
I0916 19:12:39.098579 20216 solver.cpp:314] Iteration 38600 (5.17063 iter/s, 19.34s/100 iter), loss = 0.0494841
I0916 19:12:39.098604 20216 solver.cpp:336]     Train net output #0: loss = 0.0494843 (* 1 = 0.0494843 loss)
I0916 19:12:39.098613 20216 sgd_solver.cpp:136] Iteration 38600, lr = 0.001, m = 0.9
I0916 19:12:52.906915 20220 data_reader.cpp:305] Starting prefetch of epoch 28
I0916 19:12:58.501399 20216 solver.cpp:314] Iteration 38700 (5.15403 iter/s, 19.4023s/100 iter), loss = 0.081061
I0916 19:12:58.501426 20216 solver.cpp:336]     Train net output #0: loss = 0.0810612 (* 1 = 0.0810612 loss)
I0916 19:12:58.501432 20216 sgd_solver.cpp:136] Iteration 38700, lr = 0.001, m = 0.9
I0916 19:13:17.962388 20216 solver.cpp:314] Iteration 38800 (5.13863 iter/s, 19.4604s/100 iter), loss = 0.0760306
I0916 19:13:17.962414 20216 solver.cpp:336]     Train net output #0: loss = 0.0760307 (* 1 = 0.0760307 loss)
I0916 19:13:17.962420 20216 sgd_solver.cpp:136] Iteration 38800, lr = 0.001, m = 0.9
I0916 19:13:37.567113 20216 solver.cpp:314] Iteration 38900 (5.10096 iter/s, 19.6042s/100 iter), loss = 0.143033
I0916 19:13:37.567174 20216 solver.cpp:336]     Train net output #0: loss = 0.143033 (* 1 = 0.143033 loss)
I0916 19:13:37.567181 20216 sgd_solver.cpp:136] Iteration 38900, lr = 0.001, m = 0.9
I0916 19:13:57.003072 20216 solver.cpp:314] Iteration 39000 (5.14525 iter/s, 19.4354s/100 iter), loss = 0.0601723
I0916 19:13:57.003096 20216 solver.cpp:336]     Train net output #0: loss = 0.0601724 (* 1 = 0.0601724 loss)
I0916 19:13:57.003101 20216 sgd_solver.cpp:136] Iteration 39000, lr = 0.001, m = 0.9
I0916 19:13:57.417217 20195 data_reader.cpp:305] Starting prefetch of epoch 16
I0916 19:14:16.537184 20216 solver.cpp:314] Iteration 39100 (5.11939 iter/s, 19.5336s/100 iter), loss = 0.03149
I0916 19:14:16.537292 20216 solver.cpp:336]     Train net output #0: loss = 0.0314901 (* 1 = 0.0314901 loss)
I0916 19:14:16.537299 20216 sgd_solver.cpp:136] Iteration 39100, lr = 0.001, m = 0.9
I0916 19:14:36.041937 20216 solver.cpp:314] Iteration 39200 (5.1271 iter/s, 19.5042s/100 iter), loss = 0.0667224
I0916 19:14:36.041960 20216 solver.cpp:336]     Train net output #0: loss = 0.0667225 (* 1 = 0.0667225 loss)
I0916 19:14:36.041965 20216 sgd_solver.cpp:136] Iteration 39200, lr = 0.001, m = 0.9
I0916 19:14:55.657625 20216 solver.cpp:314] Iteration 39300 (5.0981 iter/s, 19.6151s/100 iter), loss = 0.0548848
I0916 19:14:55.657686 20216 solver.cpp:336]     Train net output #0: loss = 0.0548849 (* 1 = 0.0548849 loss)
I0916 19:14:55.657693 20216 sgd_solver.cpp:136] Iteration 39300, lr = 0.001, m = 0.9
I0916 19:15:02.093142 20197 data_reader.cpp:305] Starting prefetch of epoch 23
I0916 19:15:15.268862 20216 solver.cpp:314] Iteration 39400 (5.09926 iter/s, 19.6107s/100 iter), loss = 0.0540241
I0916 19:15:15.268887 20216 solver.cpp:336]     Train net output #0: loss = 0.0540242 (* 1 = 0.0540242 loss)
I0916 19:15:15.268892 20216 sgd_solver.cpp:136] Iteration 39400, lr = 0.001, m = 0.9
I0916 19:15:34.408946 20220 data_reader.cpp:305] Starting prefetch of epoch 29
I0916 19:15:34.754010 20216 solver.cpp:314] Iteration 39500 (5.13226 iter/s, 19.4846s/100 iter), loss = 0.0514948
I0916 19:15:34.754037 20216 solver.cpp:336]     Train net output #0: loss = 0.051495 (* 1 = 0.051495 loss)
I0916 19:15:34.754043 20216 sgd_solver.cpp:136] Iteration 39500, lr = 0.001, m = 0.9
I0916 19:15:54.409126 20216 solver.cpp:314] Iteration 39600 (5.08828 iter/s, 19.653s/100 iter), loss = 0.0649157
I0916 19:15:54.409160 20216 solver.cpp:336]     Train net output #0: loss = 0.0649159 (* 1 = 0.0649159 loss)
I0916 19:15:54.409166 20216 sgd_solver.cpp:136] Iteration 39600, lr = 0.001, m = 0.9
I0916 19:16:14.285799 20216 solver.cpp:314] Iteration 39700 (5.03117 iter/s, 19.8761s/100 iter), loss = 0.0608769
I0916 19:16:14.285888 20216 solver.cpp:336]     Train net output #0: loss = 0.0608771 (* 1 = 0.0608771 loss)
I0916 19:16:14.285903 20216 sgd_solver.cpp:136] Iteration 39700, lr = 0.001, m = 0.9
I0916 19:16:34.171052 20216 solver.cpp:314] Iteration 39800 (5.02899 iter/s, 19.8847s/100 iter), loss = 0.0497209
I0916 19:16:34.171077 20216 solver.cpp:336]     Train net output #0: loss = 0.049721 (* 1 = 0.049721 loss)
I0916 19:16:34.171084 20216 sgd_solver.cpp:136] Iteration 39800, lr = 0.001, m = 0.9
I0916 19:16:39.620805 20220 data_reader.cpp:305] Starting prefetch of epoch 30
I0916 19:16:53.798207 20216 solver.cpp:314] Iteration 39900 (5.09512 iter/s, 19.6266s/100 iter), loss = 0.0643509
I0916 19:16:53.798295 20216 solver.cpp:336]     Train net output #0: loss = 0.064351 (* 1 = 0.064351 loss)
I0916 19:16:53.798301 20216 sgd_solver.cpp:136] Iteration 39900, lr = 0.001, m = 0.9
I0916 19:17:13.119015 20216 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/cityscapes5_jsegnet21v2_iter_40000.caffemodel
I0916 19:17:13.263355 20216 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/cityscapes5_jsegnet21v2_iter_40000.solverstate
I0916 19:17:13.269207 20216 solver.cpp:563] Iteration 40000, Testing net (#0)
I0916 19:17:24.253942 20250 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 19:17:24.253942 20243 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 19:17:40.301115 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.954239
I0916 19:17:40.301137 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 19:17:40.301144 20216 solver.cpp:655]     Test net output #2: loss = 0.145345 (* 1 = 0.145345 loss)
I0916 19:17:40.301174 20216 solver.cpp:265] [MultiGPU] Tests completed in 27.0312s
I0916 19:17:40.507498 20216 solver.cpp:314] Iteration 40000 (2.14096 iter/s, 46.708s/100 iter), loss = 0.0899561
I0916 19:17:40.507524 20216 solver.cpp:336]     Train net output #0: loss = 0.0899562 (* 1 = 0.0899562 loss)
I0916 19:17:40.507530 20216 sgd_solver.cpp:136] Iteration 40000, lr = 0.001, m = 0.9
I0916 19:18:00.011442 20216 solver.cpp:314] Iteration 40100 (5.12731 iter/s, 19.5034s/100 iter), loss = 0.0591968
I0916 19:18:00.011521 20216 solver.cpp:336]     Train net output #0: loss = 0.0591969 (* 1 = 0.0591969 loss)
I0916 19:18:00.011529 20216 sgd_solver.cpp:136] Iteration 40100, lr = 0.001, m = 0.9
I0916 19:18:11.609560 20224 data_reader.cpp:305] Starting prefetch of epoch 28
I0916 19:18:19.810853 20216 solver.cpp:314] Iteration 40200 (5.0508 iter/s, 19.7989s/100 iter), loss = 0.0403331
I0916 19:18:19.810881 20216 solver.cpp:336]     Train net output #0: loss = 0.0403333 (* 1 = 0.0403333 loss)
I0916 19:18:19.810887 20216 sgd_solver.cpp:136] Iteration 40200, lr = 0.001, m = 0.9
I0916 19:18:39.767352 20216 solver.cpp:314] Iteration 40300 (5.01104 iter/s, 19.9559s/100 iter), loss = 0.0712959
I0916 19:18:39.767444 20216 solver.cpp:336]     Train net output #0: loss = 0.0712961 (* 1 = 0.0712961 loss)
I0916 19:18:39.767452 20216 sgd_solver.cpp:136] Iteration 40300, lr = 0.001, m = 0.9
I0916 19:18:44.562410 20195 data_reader.cpp:305] Starting prefetch of epoch 17
I0916 19:18:59.905891 20216 solver.cpp:314] Iteration 40400 (4.96574 iter/s, 20.138s/100 iter), loss = 0.078479
I0916 19:18:59.905920 20216 solver.cpp:336]     Train net output #0: loss = 0.0784791 (* 1 = 0.0784791 loss)
I0916 19:18:59.905927 20216 sgd_solver.cpp:136] Iteration 40400, lr = 0.001, m = 0.9
I0916 19:19:19.723223 20216 solver.cpp:314] Iteration 40500 (5.04623 iter/s, 19.8168s/100 iter), loss = 0.0650843
I0916 19:19:19.723284 20216 solver.cpp:336]     Train net output #0: loss = 0.0650845 (* 1 = 0.0650845 loss)
I0916 19:19:19.723289 20216 sgd_solver.cpp:136] Iteration 40500, lr = 0.001, m = 0.9
I0916 19:19:39.766801 20216 solver.cpp:314] Iteration 40600 (4.98927 iter/s, 20.043s/100 iter), loss = 0.0635055
I0916 19:19:39.766829 20216 solver.cpp:336]     Train net output #0: loss = 0.0635056 (* 1 = 0.0635056 loss)
I0916 19:19:39.766835 20216 sgd_solver.cpp:136] Iteration 40600, lr = 0.001, m = 0.9
I0916 19:19:50.880558 20219 data_reader.cpp:305] Starting prefetch of epoch 30
I0916 19:19:59.599300 20216 solver.cpp:314] Iteration 40700 (5.04237 iter/s, 19.8319s/100 iter), loss = 0.0655935
I0916 19:19:59.599325 20216 solver.cpp:336]     Train net output #0: loss = 0.0655936 (* 1 = 0.0655936 loss)
I0916 19:19:59.599331 20216 sgd_solver.cpp:136] Iteration 40700, lr = 0.001, m = 0.9
I0916 19:20:19.219476 20216 solver.cpp:314] Iteration 40800 (5.09694 iter/s, 19.6196s/100 iter), loss = 0.098044
I0916 19:20:19.219506 20216 solver.cpp:336]     Train net output #0: loss = 0.0980442 (* 1 = 0.0980442 loss)
I0916 19:20:19.219512 20216 sgd_solver.cpp:136] Iteration 40800, lr = 0.001, m = 0.9
I0916 19:20:38.695466 20216 solver.cpp:314] Iteration 40900 (5.13467 iter/s, 19.4754s/100 iter), loss = 0.0508452
I0916 19:20:38.695519 20216 solver.cpp:336]     Train net output #0: loss = 0.0508453 (* 1 = 0.0508453 loss)
I0916 19:20:38.695524 20216 sgd_solver.cpp:136] Iteration 40900, lr = 0.001, m = 0.9
I0916 19:20:55.308068 20224 data_reader.cpp:305] Starting prefetch of epoch 29
I0916 19:20:58.209605 20216 solver.cpp:314] Iteration 41000 (5.12463 iter/s, 19.5136s/100 iter), loss = 0.0562186
I0916 19:20:58.209630 20216 solver.cpp:336]     Train net output #0: loss = 0.0562187 (* 1 = 0.0562187 loss)
I0916 19:20:58.209635 20216 sgd_solver.cpp:136] Iteration 41000, lr = 0.001, m = 0.9
I0916 19:21:17.719581 20216 solver.cpp:314] Iteration 41100 (5.12573 iter/s, 19.5094s/100 iter), loss = 0.0494201
I0916 19:21:17.719640 20216 solver.cpp:336]     Train net output #0: loss = 0.0494202 (* 1 = 0.0494202 loss)
I0916 19:21:17.719646 20216 sgd_solver.cpp:136] Iteration 41100, lr = 0.001, m = 0.9
I0916 19:21:27.796334 20220 data_reader.cpp:305] Starting prefetch of epoch 31
I0916 19:21:37.446902 20216 solver.cpp:314] Iteration 41200 (5.06925 iter/s, 19.7268s/100 iter), loss = 0.0466859
I0916 19:21:37.446933 20216 solver.cpp:336]     Train net output #0: loss = 0.0466861 (* 1 = 0.0466861 loss)
I0916 19:21:37.446940 20216 sgd_solver.cpp:136] Iteration 41200, lr = 0.001, m = 0.9
I0916 19:21:56.979166 20216 solver.cpp:314] Iteration 41300 (5.11988 iter/s, 19.5317s/100 iter), loss = 0.0296535
I0916 19:21:56.979305 20216 solver.cpp:336]     Train net output #0: loss = 0.0296537 (* 1 = 0.0296537 loss)
I0916 19:21:56.979326 20216 sgd_solver.cpp:136] Iteration 41300, lr = 0.001, m = 0.9
I0916 19:22:16.311303 20216 solver.cpp:314] Iteration 41400 (5.17288 iter/s, 19.3316s/100 iter), loss = 0.0931662
I0916 19:22:16.311331 20216 solver.cpp:336]     Train net output #0: loss = 0.0931663 (* 1 = 0.0931663 loss)
I0916 19:22:16.311336 20216 sgd_solver.cpp:136] Iteration 41400, lr = 0.001, m = 0.9
I0916 19:22:32.178009 20219 data_reader.cpp:305] Starting prefetch of epoch 31
I0916 19:22:35.799299 20216 solver.cpp:314] Iteration 41500 (5.13151 iter/s, 19.4875s/100 iter), loss = 0.0683348
I0916 19:22:35.799326 20216 solver.cpp:336]     Train net output #0: loss = 0.0683349 (* 1 = 0.0683349 loss)
I0916 19:22:35.799334 20216 sgd_solver.cpp:136] Iteration 41500, lr = 0.001, m = 0.9
I0916 19:22:55.687737 20216 solver.cpp:314] Iteration 41600 (5.02819 iter/s, 19.8879s/100 iter), loss = 0.0419055
I0916 19:22:55.687759 20216 solver.cpp:336]     Train net output #0: loss = 0.0419056 (* 1 = 0.0419056 loss)
I0916 19:22:55.687765 20216 sgd_solver.cpp:136] Iteration 41600, lr = 0.001, m = 0.9
I0916 19:23:16.031281 20216 solver.cpp:314] Iteration 41700 (4.9157 iter/s, 20.343s/100 iter), loss = 0.0798878
I0916 19:23:16.031335 20216 solver.cpp:336]     Train net output #0: loss = 0.0798879 (* 1 = 0.0798879 loss)
I0916 19:23:16.031342 20216 sgd_solver.cpp:136] Iteration 41700, lr = 0.001, m = 0.9
I0916 19:23:36.316645 20216 solver.cpp:314] Iteration 41800 (4.9298 iter/s, 20.2848s/100 iter), loss = 0.0550721
I0916 19:23:36.316673 20216 solver.cpp:336]     Train net output #0: loss = 0.0550722 (* 1 = 0.0550722 loss)
I0916 19:23:36.316679 20216 sgd_solver.cpp:136] Iteration 41800, lr = 0.001, m = 0.9
I0916 19:23:38.721918 20197 data_reader.cpp:305] Starting prefetch of epoch 24
I0916 19:23:56.106935 20216 solver.cpp:314] Iteration 41900 (5.05312 iter/s, 19.7897s/100 iter), loss = 0.0631242
I0916 19:23:56.106990 20216 solver.cpp:336]     Train net output #0: loss = 0.0631243 (* 1 = 0.0631243 loss)
I0916 19:23:56.106997 20216 sgd_solver.cpp:136] Iteration 41900, lr = 0.001, m = 0.9
I0916 19:24:12.017446 20219 data_reader.cpp:305] Starting prefetch of epoch 32
I0916 19:24:16.467857 20216 solver.cpp:563] Iteration 42000, Testing net (#0)
I0916 19:24:28.450134 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.956798
I0916 19:24:28.450191 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 19:24:28.450198 20216 solver.cpp:655]     Test net output #2: loss = 0.164333 (* 1 = 0.164333 loss)
I0916 19:24:28.450227 20216 solver.cpp:265] [MultiGPU] Tests completed in 11.982s
I0916 19:24:28.715129 20216 solver.cpp:314] Iteration 42000 (3.0668 iter/s, 32.6073s/100 iter), loss = 0.0483215
I0916 19:24:28.715160 20216 solver.cpp:336]     Train net output #0: loss = 0.0483216 (* 1 = 0.0483216 loss)
I0916 19:24:28.715167 20216 sgd_solver.cpp:136] Iteration 42000, lr = 0.001, m = 0.9
I0916 19:24:48.807770 20216 solver.cpp:314] Iteration 42100 (4.97709 iter/s, 20.0921s/100 iter), loss = 0.0420584
I0916 19:24:48.807793 20216 solver.cpp:336]     Train net output #0: loss = 0.0420586 (* 1 = 0.0420586 loss)
I0916 19:24:48.807799 20216 sgd_solver.cpp:136] Iteration 42100, lr = 0.001, m = 0.9
I0916 19:24:57.132053 20220 data_reader.cpp:305] Starting prefetch of epoch 32
I0916 19:25:08.507392 20216 solver.cpp:314] Iteration 42200 (5.07638 iter/s, 19.6991s/100 iter), loss = 0.0539177
I0916 19:25:08.507447 20216 solver.cpp:336]     Train net output #0: loss = 0.0539178 (* 1 = 0.0539178 loss)
I0916 19:25:08.507454 20216 sgd_solver.cpp:136] Iteration 42200, lr = 0.001, m = 0.9
I0916 19:25:28.522318 20216 solver.cpp:314] Iteration 42300 (4.99641 iter/s, 20.0144s/100 iter), loss = 0.0667785
I0916 19:25:28.522346 20216 solver.cpp:336]     Train net output #0: loss = 0.0667786 (* 1 = 0.0667786 loss)
I0916 19:25:28.522351 20216 sgd_solver.cpp:136] Iteration 42300, lr = 0.001, m = 0.9
I0916 19:25:48.803905 20216 solver.cpp:314] Iteration 42400 (4.93072 iter/s, 20.281s/100 iter), loss = 0.0505098
I0916 19:25:48.803977 20216 solver.cpp:336]     Train net output #0: loss = 0.0505099 (* 1 = 0.0505099 loss)
I0916 19:25:48.803985 20216 sgd_solver.cpp:136] Iteration 42400, lr = 0.001, m = 0.9
I0916 19:26:03.464998 20224 data_reader.cpp:305] Starting prefetch of epoch 30
I0916 19:26:08.704375 20216 solver.cpp:314] Iteration 42500 (5.02515 iter/s, 19.8999s/100 iter), loss = 0.0531794
I0916 19:26:08.704397 20216 solver.cpp:336]     Train net output #0: loss = 0.0531795 (* 1 = 0.0531795 loss)
I0916 19:26:08.704401 20216 sgd_solver.cpp:136] Iteration 42500, lr = 0.001, m = 0.9
I0916 19:26:28.443922 20216 solver.cpp:314] Iteration 42600 (5.06611 iter/s, 19.739s/100 iter), loss = 0.0733216
I0916 19:26:28.443982 20216 solver.cpp:336]     Train net output #0: loss = 0.0733218 (* 1 = 0.0733218 loss)
I0916 19:26:28.443989 20216 sgd_solver.cpp:136] Iteration 42600, lr = 0.001, m = 0.9
I0916 19:26:36.024938 20219 data_reader.cpp:305] Starting prefetch of epoch 33
I0916 19:26:48.385996 20216 solver.cpp:314] Iteration 42700 (5.01466 iter/s, 19.9415s/100 iter), loss = 0.0479362
I0916 19:26:48.386026 20216 solver.cpp:336]     Train net output #0: loss = 0.0479364 (* 1 = 0.0479364 loss)
I0916 19:26:48.386032 20216 sgd_solver.cpp:136] Iteration 42700, lr = 0.001, m = 0.9
I0916 19:27:08.419466 20216 solver.cpp:314] Iteration 42800 (4.99179 iter/s, 20.0329s/100 iter), loss = 0.0513236
I0916 19:27:08.419776 20216 solver.cpp:336]     Train net output #0: loss = 0.0513238 (* 1 = 0.0513238 loss)
I0916 19:27:08.419792 20216 sgd_solver.cpp:136] Iteration 42800, lr = 0.001, m = 0.9
I0916 19:27:28.385995 20216 solver.cpp:314] Iteration 42900 (5.00852 iter/s, 19.966s/100 iter), loss = 0.0425653
I0916 19:27:28.386023 20216 solver.cpp:336]     Train net output #0: loss = 0.0425655 (* 1 = 0.0425655 loss)
I0916 19:27:28.386027 20216 sgd_solver.cpp:136] Iteration 42900, lr = 0.001, m = 0.9
I0916 19:27:42.469509 20219 data_reader.cpp:305] Starting prefetch of epoch 34
I0916 19:27:48.489513 20216 solver.cpp:314] Iteration 43000 (4.97439 iter/s, 20.103s/100 iter), loss = 0.040863
I0916 19:27:48.489538 20216 solver.cpp:336]     Train net output #0: loss = 0.0408631 (* 1 = 0.0408631 loss)
I0916 19:27:48.489544 20216 sgd_solver.cpp:136] Iteration 43000, lr = 0.001, m = 0.9
I0916 19:28:08.481428 20216 solver.cpp:314] Iteration 43100 (5.00216 iter/s, 19.9914s/100 iter), loss = 0.0793262
I0916 19:28:08.481457 20216 solver.cpp:336]     Train net output #0: loss = 0.0793264 (* 1 = 0.0793264 loss)
I0916 19:28:08.481462 20216 sgd_solver.cpp:136] Iteration 43100, lr = 0.001, m = 0.9
I0916 19:28:28.469324 20216 solver.cpp:314] Iteration 43200 (5.00317 iter/s, 19.9873s/100 iter), loss = 0.0777677
I0916 19:28:28.469377 20216 solver.cpp:336]     Train net output #0: loss = 0.0777679 (* 1 = 0.0777679 loss)
I0916 19:28:28.469383 20216 sgd_solver.cpp:136] Iteration 43200, lr = 0.001, m = 0.9
I0916 19:28:47.800300 20197 data_reader.cpp:305] Starting prefetch of epoch 25
I0916 19:28:47.995169 20216 solver.cpp:314] Iteration 43300 (5.12156 iter/s, 19.5253s/100 iter), loss = 0.0438524
I0916 19:28:47.995195 20216 solver.cpp:336]     Train net output #0: loss = 0.0438525 (* 1 = 0.0438525 loss)
I0916 19:28:47.995199 20216 sgd_solver.cpp:136] Iteration 43300, lr = 0.001, m = 0.9
I0916 19:29:07.901747 20216 solver.cpp:314] Iteration 43400 (5.02361 iter/s, 19.906s/100 iter), loss = 0.0716235
I0916 19:29:07.901829 20216 solver.cpp:336]     Train net output #0: loss = 0.0716237 (* 1 = 0.0716237 loss)
I0916 19:29:07.901841 20216 sgd_solver.cpp:136] Iteration 43400, lr = 0.001, m = 0.9
I0916 19:29:20.802422 20220 data_reader.cpp:305] Starting prefetch of epoch 33
I0916 19:29:27.859405 20216 solver.cpp:314] Iteration 43500 (5.01075 iter/s, 19.9571s/100 iter), loss = 0.0885851
I0916 19:29:27.859436 20216 solver.cpp:336]     Train net output #0: loss = 0.0885853 (* 1 = 0.0885853 loss)
I0916 19:29:27.859441 20216 sgd_solver.cpp:136] Iteration 43500, lr = 0.001, m = 0.9
I0916 19:29:47.606608 20216 solver.cpp:314] Iteration 43600 (5.06415 iter/s, 19.7466s/100 iter), loss = 0.0506257
I0916 19:29:47.606688 20216 solver.cpp:336]     Train net output #0: loss = 0.0506259 (* 1 = 0.0506259 loss)
I0916 19:29:47.606698 20216 sgd_solver.cpp:136] Iteration 43600, lr = 0.001, m = 0.9
I0916 19:30:07.306819 20216 solver.cpp:314] Iteration 43700 (5.07623 iter/s, 19.6997s/100 iter), loss = 0.0801471
I0916 19:30:07.306849 20216 solver.cpp:336]     Train net output #0: loss = 0.0801472 (* 1 = 0.0801472 loss)
I0916 19:30:07.306855 20216 sgd_solver.cpp:136] Iteration 43700, lr = 0.001, m = 0.9
I0916 19:30:25.972018 20219 data_reader.cpp:305] Starting prefetch of epoch 35
I0916 19:30:26.899343 20216 solver.cpp:314] Iteration 43800 (5.10413 iter/s, 19.592s/100 iter), loss = 0.0328851
I0916 19:30:26.899381 20216 solver.cpp:336]     Train net output #0: loss = 0.0328853 (* 1 = 0.0328853 loss)
I0916 19:30:26.899389 20216 sgd_solver.cpp:136] Iteration 43800, lr = 0.001, m = 0.9
I0916 19:30:46.700165 20216 solver.cpp:314] Iteration 43900 (5.05044 iter/s, 19.8003s/100 iter), loss = 0.0419999
I0916 19:30:46.700191 20216 solver.cpp:336]     Train net output #0: loss = 0.042 (* 1 = 0.042 loss)
I0916 19:30:46.700196 20216 sgd_solver.cpp:136] Iteration 43900, lr = 0.001, m = 0.9
I0916 19:31:06.345010 20216 solver.cpp:563] Iteration 44000, Testing net (#0)
I0916 19:31:09.578774 20248 data_reader.cpp:305] Starting prefetch of epoch 2
I0916 19:31:17.116742 20202 data_reader.cpp:305] Starting prefetch of epoch 8
I0916 19:31:17.434168 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.954245
I0916 19:31:17.434190 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 19:31:17.434195 20216 solver.cpp:655]     Test net output #2: loss = 0.146614 (* 1 = 0.146614 loss)
I0916 19:31:17.434222 20216 solver.cpp:265] [MultiGPU] Tests completed in 11.0889s
I0916 19:31:17.653337 20216 solver.cpp:314] Iteration 44000 (3.23078 iter/s, 30.9523s/100 iter), loss = 0.0790999
I0916 19:31:17.653365 20216 solver.cpp:336]     Train net output #0: loss = 0.0791 (* 1 = 0.0791 loss)
I0916 19:31:17.653373 20216 sgd_solver.cpp:136] Iteration 44000, lr = 0.001, m = 0.9
I0916 19:31:36.796557 20216 solver.cpp:314] Iteration 44100 (5.22393 iter/s, 19.1427s/100 iter), loss = 0.0546359
I0916 19:31:36.796615 20216 solver.cpp:336]     Train net output #0: loss = 0.0546361 (* 1 = 0.0546361 loss)
I0916 19:31:36.796622 20216 sgd_solver.cpp:136] Iteration 44100, lr = 0.001, m = 0.9
I0916 19:31:56.281131 20216 solver.cpp:314] Iteration 44200 (5.13241 iter/s, 19.484s/100 iter), loss = 0.0573775
I0916 19:31:56.281157 20216 solver.cpp:336]     Train net output #0: loss = 0.0573776 (* 1 = 0.0573776 loss)
I0916 19:31:56.281164 20216 sgd_solver.cpp:136] Iteration 44200, lr = 0.001, m = 0.9
I0916 19:32:14.099333 20195 data_reader.cpp:305] Starting prefetch of epoch 18
I0916 19:32:15.787106 20216 solver.cpp:314] Iteration 44300 (5.12678 iter/s, 19.5054s/100 iter), loss = 0.0396712
I0916 19:32:15.787132 20216 solver.cpp:336]     Train net output #0: loss = 0.0396713 (* 1 = 0.0396713 loss)
I0916 19:32:15.787137 20216 sgd_solver.cpp:136] Iteration 44300, lr = 0.001, m = 0.9
I0916 19:32:35.013705 20216 solver.cpp:314] Iteration 44400 (5.20132 iter/s, 19.2259s/100 iter), loss = 0.050518
I0916 19:32:35.013757 20216 solver.cpp:336]     Train net output #0: loss = 0.0505181 (* 1 = 0.0505181 loss)
I0916 19:32:35.013770 20216 sgd_solver.cpp:136] Iteration 44400, lr = 0.001, m = 0.9
I0916 19:32:54.727306 20216 solver.cpp:314] Iteration 44500 (5.07278 iter/s, 19.713s/100 iter), loss = 0.0506201
I0916 19:32:54.727423 20216 solver.cpp:336]     Train net output #0: loss = 0.0506202 (* 1 = 0.0506202 loss)
I0916 19:32:54.727432 20216 sgd_solver.cpp:136] Iteration 44500, lr = 0.001, m = 0.9
I0916 19:33:14.227926 20216 solver.cpp:314] Iteration 44600 (5.12819 iter/s, 19.5001s/100 iter), loss = 0.0513007
I0916 19:33:14.227948 20216 solver.cpp:336]     Train net output #0: loss = 0.0513009 (* 1 = 0.0513009 loss)
I0916 19:33:14.227952 20216 sgd_solver.cpp:136] Iteration 44600, lr = 0.001, m = 0.9
I0916 19:33:18.353102 20223 data_reader.cpp:305] Starting prefetch of epoch 17
I0916 19:33:33.817881 20216 solver.cpp:314] Iteration 44700 (5.1048 iter/s, 19.5894s/100 iter), loss = 0.0529278
I0916 19:33:33.817981 20216 solver.cpp:336]     Train net output #0: loss = 0.0529279 (* 1 = 0.0529279 loss)
I0916 19:33:33.817988 20216 sgd_solver.cpp:136] Iteration 44700, lr = 0.001, m = 0.9
I0916 19:33:50.528596 20195 data_reader.cpp:305] Starting prefetch of epoch 19
I0916 19:33:52.914793 20216 solver.cpp:314] Iteration 44800 (5.2366 iter/s, 19.0964s/100 iter), loss = 0.0728593
I0916 19:33:52.914822 20216 solver.cpp:336]     Train net output #0: loss = 0.0728594 (* 1 = 0.0728594 loss)
I0916 19:33:52.914830 20216 sgd_solver.cpp:136] Iteration 44800, lr = 0.001, m = 0.9
I0916 19:34:12.255352 20216 solver.cpp:314] Iteration 44900 (5.17063 iter/s, 19.34s/100 iter), loss = 0.0515324
I0916 19:34:12.255403 20216 solver.cpp:336]     Train net output #0: loss = 0.0515325 (* 1 = 0.0515325 loss)
I0916 19:34:12.255410 20216 sgd_solver.cpp:136] Iteration 44900, lr = 0.001, m = 0.9
I0916 19:34:31.462203 20266 sgd_solver.cpp:48] MultiStep Status: Iteration 45000, step = 2
I0916 19:34:31.462203 20268 sgd_solver.cpp:48] MultiStep Status: Iteration 45000, step = 2
I0916 19:34:31.462208 20267 sgd_solver.cpp:48] MultiStep Status: Iteration 45000, step = 2
I0916 19:34:31.571507 20216 solver.cpp:314] Iteration 45000 (5.17716 iter/s, 19.3156s/100 iter), loss = 0.0606193
I0916 19:34:31.571533 20216 solver.cpp:336]     Train net output #0: loss = 0.0606194 (* 1 = 0.0606194 loss)
I0916 19:34:31.571539 20216 sgd_solver.cpp:136] Iteration 45000, lr = 0.0001, m = 0.9
I0916 19:34:51.051836 20216 solver.cpp:314] Iteration 45100 (5.13353 iter/s, 19.4798s/100 iter), loss = 0.0828582
I0916 19:34:51.051885 20216 solver.cpp:336]     Train net output #0: loss = 0.0828583 (* 1 = 0.0828583 loss)
I0916 19:34:51.051890 20216 sgd_solver.cpp:136] Iteration 45100, lr = 0.0001, m = 0.9
I0916 19:34:54.408318 20223 data_reader.cpp:305] Starting prefetch of epoch 18
I0916 19:35:10.620555 20216 solver.cpp:314] Iteration 45200 (5.11034 iter/s, 19.5682s/100 iter), loss = 0.0511216
I0916 19:35:10.620581 20216 solver.cpp:336]     Train net output #0: loss = 0.0511217 (* 1 = 0.0511217 loss)
I0916 19:35:10.620587 20216 sgd_solver.cpp:136] Iteration 45200, lr = 0.0001, m = 0.9
I0916 19:35:30.060351 20216 solver.cpp:314] Iteration 45300 (5.14423 iter/s, 19.4393s/100 iter), loss = 0.0622558
I0916 19:35:30.060434 20216 solver.cpp:336]     Train net output #0: loss = 0.062256 (* 1 = 0.062256 loss)
I0916 19:35:30.060441 20216 sgd_solver.cpp:136] Iteration 45300, lr = 0.0001, m = 0.9
I0916 19:35:49.574007 20216 solver.cpp:314] Iteration 45400 (5.12476 iter/s, 19.5131s/100 iter), loss = 0.0540446
I0916 19:35:49.574033 20216 solver.cpp:336]     Train net output #0: loss = 0.0540447 (* 1 = 0.0540447 loss)
I0916 19:35:49.574038 20216 sgd_solver.cpp:136] Iteration 45400, lr = 0.0001, m = 0.9
I0916 19:35:58.972699 20197 data_reader.cpp:305] Starting prefetch of epoch 26
I0916 19:36:08.923717 20216 solver.cpp:314] Iteration 45500 (5.16818 iter/s, 19.3492s/100 iter), loss = 0.0607774
I0916 19:36:08.923805 20216 solver.cpp:336]     Train net output #0: loss = 0.0607775 (* 1 = 0.0607775 loss)
I0916 19:36:08.923813 20216 sgd_solver.cpp:136] Iteration 45500, lr = 0.0001, m = 0.9
I0916 19:36:28.275133 20216 solver.cpp:314] Iteration 45600 (5.16772 iter/s, 19.3509s/100 iter), loss = 0.0702267
I0916 19:36:28.275162 20216 solver.cpp:336]     Train net output #0: loss = 0.0702268 (* 1 = 0.0702268 loss)
I0916 19:36:28.275169 20216 sgd_solver.cpp:136] Iteration 45600, lr = 0.0001, m = 0.9
I0916 19:36:30.841073 20195 data_reader.cpp:305] Starting prefetch of epoch 20
I0916 19:36:47.742496 20216 solver.cpp:314] Iteration 45700 (5.13695 iter/s, 19.4668s/100 iter), loss = 0.034348
I0916 19:36:47.742558 20216 solver.cpp:336]     Train net output #0: loss = 0.0343481 (* 1 = 0.0343481 loss)
I0916 19:36:47.742565 20216 sgd_solver.cpp:136] Iteration 45700, lr = 0.0001, m = 0.9
I0916 19:37:07.017997 20216 solver.cpp:314] Iteration 45800 (5.18808 iter/s, 19.275s/100 iter), loss = 0.0780336
I0916 19:37:07.018025 20216 solver.cpp:336]     Train net output #0: loss = 0.0780338 (* 1 = 0.0780338 loss)
I0916 19:37:07.018033 20216 sgd_solver.cpp:136] Iteration 45800, lr = 0.0001, m = 0.9
I0916 19:37:26.584286 20216 solver.cpp:314] Iteration 45900 (5.11097 iter/s, 19.5657s/100 iter), loss = 0.0369362
I0916 19:37:26.584357 20216 solver.cpp:336]     Train net output #0: loss = 0.0369363 (* 1 = 0.0369363 loss)
I0916 19:37:26.584364 20216 sgd_solver.cpp:136] Iteration 45900, lr = 0.0001, m = 0.9
I0916 19:37:35.211249 20219 data_reader.cpp:305] Starting prefetch of epoch 36
I0916 19:37:45.741160 20216 solver.cpp:563] Iteration 46000, Testing net (#0)
I0916 19:37:57.648190 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.957167
I0916 19:37:57.648242 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 19:37:57.648252 20216 solver.cpp:655]     Test net output #2: loss = 0.167751 (* 1 = 0.167751 loss)
I0916 19:37:57.648285 20216 solver.cpp:265] [MultiGPU] Tests completed in 11.9068s
I0916 19:37:57.854068 20216 solver.cpp:314] Iteration 46000 (3.19806 iter/s, 31.2689s/100 iter), loss = 0.048376
I0916 19:37:57.854099 20216 solver.cpp:336]     Train net output #0: loss = 0.0483761 (* 1 = 0.0483761 loss)
I0916 19:37:57.854105 20216 sgd_solver.cpp:136] Iteration 46000, lr = 0.0001, m = 0.9
I0916 19:38:17.041867 20216 solver.cpp:314] Iteration 46100 (5.21179 iter/s, 19.1873s/100 iter), loss = 0.0373107
I0916 19:38:17.041889 20216 solver.cpp:336]     Train net output #0: loss = 0.0373108 (* 1 = 0.0373108 loss)
I0916 19:38:17.041893 20216 sgd_solver.cpp:136] Iteration 46100, lr = 0.0001, m = 0.9
I0916 19:38:18.771662 20197 data_reader.cpp:305] Starting prefetch of epoch 27
I0916 19:38:36.810194 20216 solver.cpp:314] Iteration 46200 (5.05874 iter/s, 19.7678s/100 iter), loss = 0.0361158
I0916 19:38:36.810252 20216 solver.cpp:336]     Train net output #0: loss = 0.036116 (* 1 = 0.036116 loss)
I0916 19:38:36.810258 20216 sgd_solver.cpp:136] Iteration 46200, lr = 0.0001, m = 0.9
I0916 19:38:51.161049 20219 data_reader.cpp:305] Starting prefetch of epoch 37
I0916 19:38:56.142454 20216 solver.cpp:314] Iteration 46300 (5.17285 iter/s, 19.3317s/100 iter), loss = 0.0499427
I0916 19:38:56.142477 20216 solver.cpp:336]     Train net output #0: loss = 0.0499428 (* 1 = 0.0499428 loss)
I0916 19:38:56.142483 20216 sgd_solver.cpp:136] Iteration 46300, lr = 0.0001, m = 0.9
I0916 19:39:15.389133 20216 solver.cpp:314] Iteration 46400 (5.19585 iter/s, 19.2461s/100 iter), loss = 0.0465312
I0916 19:39:15.389192 20216 solver.cpp:336]     Train net output #0: loss = 0.0465313 (* 1 = 0.0465313 loss)
I0916 19:39:15.389199 20216 sgd_solver.cpp:136] Iteration 46400, lr = 0.0001, m = 0.9
I0916 19:39:35.063045 20216 solver.cpp:314] Iteration 46500 (5.08301 iter/s, 19.6734s/100 iter), loss = 0.0801943
I0916 19:39:35.063067 20216 solver.cpp:336]     Train net output #0: loss = 0.0801944 (* 1 = 0.0801944 loss)
I0916 19:39:35.063072 20216 sgd_solver.cpp:136] Iteration 46500, lr = 0.0001, m = 0.9
I0916 19:39:54.345592 20216 solver.cpp:314] Iteration 46600 (5.18618 iter/s, 19.282s/100 iter), loss = 0.0343039
I0916 19:39:54.345649 20216 solver.cpp:336]     Train net output #0: loss = 0.034304 (* 1 = 0.034304 loss)
I0916 19:39:54.345654 20216 sgd_solver.cpp:136] Iteration 46600, lr = 0.0001, m = 0.9
I0916 19:39:55.404551 20195 data_reader.cpp:305] Starting prefetch of epoch 21
I0916 19:40:14.010046 20216 solver.cpp:314] Iteration 46700 (5.08546 iter/s, 19.6639s/100 iter), loss = 0.059381
I0916 19:40:14.010068 20216 solver.cpp:336]     Train net output #0: loss = 0.0593811 (* 1 = 0.0593811 loss)
I0916 19:40:14.010082 20216 sgd_solver.cpp:136] Iteration 46700, lr = 0.0001, m = 0.9
I0916 19:40:33.461313 20216 solver.cpp:314] Iteration 46800 (5.1412 iter/s, 19.4507s/100 iter), loss = 0.0727642
I0916 19:40:33.461401 20216 solver.cpp:336]     Train net output #0: loss = 0.0727643 (* 1 = 0.0727643 loss)
I0916 19:40:33.461410 20216 sgd_solver.cpp:136] Iteration 46800, lr = 0.0001, m = 0.9
I0916 19:40:53.007936 20216 solver.cpp:314] Iteration 46900 (5.11612 iter/s, 19.5461s/100 iter), loss = 0.0639873
I0916 19:40:53.007961 20216 solver.cpp:336]     Train net output #0: loss = 0.0639874 (* 1 = 0.0639874 loss)
I0916 19:40:53.007967 20216 sgd_solver.cpp:136] Iteration 46900, lr = 0.0001, m = 0.9
I0916 19:40:59.826179 20220 data_reader.cpp:305] Starting prefetch of epoch 34
I0916 19:41:12.234274 20216 solver.cpp:314] Iteration 47000 (5.20134 iter/s, 19.2258s/100 iter), loss = 0.0408358
I0916 19:41:12.234336 20216 solver.cpp:336]     Train net output #0: loss = 0.0408359 (* 1 = 0.0408359 loss)
I0916 19:41:12.234344 20216 sgd_solver.cpp:136] Iteration 47000, lr = 0.0001, m = 0.9
I0916 19:41:31.898895 20216 solver.cpp:314] Iteration 47100 (5.08542 iter/s, 19.6641s/100 iter), loss = 0.0581835
I0916 19:41:31.898918 20216 solver.cpp:336]     Train net output #0: loss = 0.0581836 (* 1 = 0.0581836 loss)
I0916 19:41:31.898924 20216 sgd_solver.cpp:136] Iteration 47100, lr = 0.0001, m = 0.9
I0916 19:41:52.013916 20216 solver.cpp:314] Iteration 47200 (4.97155 iter/s, 20.1145s/100 iter), loss = 0.0479227
I0916 19:41:52.013962 20216 solver.cpp:336]     Train net output #0: loss = 0.0479228 (* 1 = 0.0479228 loss)
I0916 19:41:52.013967 20216 sgd_solver.cpp:136] Iteration 47200, lr = 0.0001, m = 0.9
I0916 19:42:05.160537 20197 data_reader.cpp:305] Starting prefetch of epoch 28
I0916 19:42:11.953490 20216 solver.cpp:314] Iteration 47300 (5.01529 iter/s, 19.939s/100 iter), loss = 0.120858
I0916 19:42:11.953521 20216 solver.cpp:336]     Train net output #0: loss = 0.120858 (* 1 = 0.120858 loss)
I0916 19:42:11.953527 20216 sgd_solver.cpp:136] Iteration 47300, lr = 0.0001, m = 0.9
I0916 19:42:31.509690 20216 solver.cpp:314] Iteration 47400 (5.11361 iter/s, 19.5557s/100 iter), loss = 0.0341166
I0916 19:42:31.509748 20216 solver.cpp:336]     Train net output #0: loss = 0.0341167 (* 1 = 0.0341167 loss)
I0916 19:42:31.509755 20216 sgd_solver.cpp:136] Iteration 47400, lr = 0.0001, m = 0.9
I0916 19:42:37.883622 20219 data_reader.cpp:305] Starting prefetch of epoch 38
I0916 19:42:51.591768 20216 solver.cpp:314] Iteration 47500 (4.9797 iter/s, 20.0815s/100 iter), loss = 0.0462127
I0916 19:42:51.591790 20216 solver.cpp:336]     Train net output #0: loss = 0.0462128 (* 1 = 0.0462128 loss)
I0916 19:42:51.591796 20216 sgd_solver.cpp:136] Iteration 47500, lr = 0.0001, m = 0.9
I0916 19:43:11.310124 20216 solver.cpp:314] Iteration 47600 (5.07156 iter/s, 19.7178s/100 iter), loss = 0.0731876
I0916 19:43:11.310178 20216 solver.cpp:336]     Train net output #0: loss = 0.0731877 (* 1 = 0.0731877 loss)
I0916 19:43:11.310184 20216 sgd_solver.cpp:136] Iteration 47600, lr = 0.0001, m = 0.9
I0916 19:43:31.087307 20216 solver.cpp:314] Iteration 47700 (5.05647 iter/s, 19.7766s/100 iter), loss = 0.057329
I0916 19:43:31.087330 20216 solver.cpp:336]     Train net output #0: loss = 0.0573291 (* 1 = 0.0573291 loss)
I0916 19:43:31.087334 20216 sgd_solver.cpp:136] Iteration 47700, lr = 0.0001, m = 0.9
I0916 19:43:43.462625 20219 data_reader.cpp:305] Starting prefetch of epoch 39
I0916 19:43:50.967846 20216 solver.cpp:314] Iteration 47800 (5.03019 iter/s, 19.88s/100 iter), loss = 0.0862389
I0916 19:43:50.967872 20216 solver.cpp:336]     Train net output #0: loss = 0.086239 (* 1 = 0.086239 loss)
I0916 19:43:50.967878 20216 sgd_solver.cpp:136] Iteration 47800, lr = 0.0001, m = 0.9
I0916 19:44:10.787302 20216 solver.cpp:314] Iteration 47900 (5.04569 iter/s, 19.8189s/100 iter), loss = 0.0606068
I0916 19:44:10.787331 20216 solver.cpp:336]     Train net output #0: loss = 0.0606069 (* 1 = 0.0606069 loss)
I0916 19:44:10.787338 20216 sgd_solver.cpp:136] Iteration 47900, lr = 0.0001, m = 0.9
I0916 19:44:30.578368 20216 solver.cpp:563] Iteration 48000, Testing net (#0)
I0916 19:44:33.887399 20248 data_reader.cpp:305] Starting prefetch of epoch 3
I0916 19:44:42.844071 20248 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 19:44:43.274318 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.955081
I0916 19:44:43.274338 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 19:44:43.274343 20216 solver.cpp:655]     Test net output #2: loss = 0.146799 (* 1 = 0.146799 loss)
I0916 19:44:43.274369 20216 solver.cpp:265] [MultiGPU] Tests completed in 12.6956s
I0916 19:44:43.464685 20216 solver.cpp:314] Iteration 48000 (3.06031 iter/s, 32.6765s/100 iter), loss = 0.079719
I0916 19:44:43.464707 20216 solver.cpp:336]     Train net output #0: loss = 0.0797191 (* 1 = 0.0797191 loss)
I0916 19:44:43.464711 20216 sgd_solver.cpp:136] Iteration 48000, lr = 0.0001, m = 0.9
I0916 19:45:02.820216 20216 solver.cpp:314] Iteration 48100 (5.16663 iter/s, 19.355s/100 iter), loss = 0.0357032
I0916 19:45:02.820305 20216 solver.cpp:336]     Train net output #0: loss = 0.0357033 (* 1 = 0.0357033 loss)
I0916 19:45:02.820313 20216 sgd_solver.cpp:136] Iteration 48100, lr = 0.0001, m = 0.9
I0916 19:45:22.871057 20216 solver.cpp:314] Iteration 48200 (4.98746 iter/s, 20.0503s/100 iter), loss = 0.0556976
I0916 19:45:22.871086 20216 solver.cpp:336]     Train net output #0: loss = 0.0556977 (* 1 = 0.0556977 loss)
I0916 19:45:22.871093 20216 sgd_solver.cpp:136] Iteration 48200, lr = 0.0001, m = 0.9
I0916 19:45:34.171511 20219 data_reader.cpp:305] Starting prefetch of epoch 40
I0916 19:45:42.390204 20216 solver.cpp:314] Iteration 48300 (5.12332 iter/s, 19.5186s/100 iter), loss = 0.0307195
I0916 19:45:42.390228 20216 solver.cpp:336]     Train net output #0: loss = 0.0307196 (* 1 = 0.0307196 loss)
I0916 19:45:42.390233 20216 sgd_solver.cpp:136] Iteration 48300, lr = 0.0001, m = 0.9
I0916 19:46:01.955366 20216 solver.cpp:314] Iteration 48400 (5.11127 iter/s, 19.5646s/100 iter), loss = 0.0507358
I0916 19:46:01.955394 20216 solver.cpp:336]     Train net output #0: loss = 0.0507359 (* 1 = 0.0507359 loss)
I0916 19:46:01.955400 20216 sgd_solver.cpp:136] Iteration 48400, lr = 0.0001, m = 0.9
I0916 19:46:21.756500 20216 solver.cpp:314] Iteration 48500 (5.05036 iter/s, 19.8006s/100 iter), loss = 0.0454401
I0916 19:46:21.756546 20216 solver.cpp:336]     Train net output #0: loss = 0.0454402 (* 1 = 0.0454402 loss)
I0916 19:46:21.756552 20216 sgd_solver.cpp:136] Iteration 48500, lr = 0.0001, m = 0.9
I0916 19:46:38.901748 20195 data_reader.cpp:305] Starting prefetch of epoch 22
I0916 19:46:41.232898 20216 solver.cpp:314] Iteration 48600 (5.13456 iter/s, 19.4758s/100 iter), loss = 0.0442247
I0916 19:46:41.232926 20216 solver.cpp:336]     Train net output #0: loss = 0.0442248 (* 1 = 0.0442248 loss)
I0916 19:46:41.232933 20216 sgd_solver.cpp:136] Iteration 48600, lr = 0.0001, m = 0.9
I0916 19:47:00.949406 20216 solver.cpp:314] Iteration 48700 (5.07204 iter/s, 19.716s/100 iter), loss = 0.0442474
I0916 19:47:00.949457 20216 solver.cpp:336]     Train net output #0: loss = 0.0442475 (* 1 = 0.0442475 loss)
I0916 19:47:00.949463 20216 sgd_solver.cpp:136] Iteration 48700, lr = 0.0001, m = 0.9
I0916 19:47:20.411185 20216 solver.cpp:314] Iteration 48800 (5.13842 iter/s, 19.4612s/100 iter), loss = 0.0761857
I0916 19:47:20.411211 20216 solver.cpp:336]     Train net output #0: loss = 0.0761859 (* 1 = 0.0761859 loss)
I0916 19:47:20.411214 20216 sgd_solver.cpp:136] Iteration 48800, lr = 0.0001, m = 0.9
I0916 19:47:40.365365 20216 solver.cpp:314] Iteration 48900 (5.01162 iter/s, 19.9536s/100 iter), loss = 0.0506539
I0916 19:47:40.365440 20216 solver.cpp:336]     Train net output #0: loss = 0.050654 (* 1 = 0.050654 loss)
I0916 19:47:40.365448 20216 sgd_solver.cpp:136] Iteration 48900, lr = 0.0001, m = 0.9
I0916 19:47:44.212476 20224 data_reader.cpp:305] Starting prefetch of epoch 31
I0916 19:48:00.320250 20216 solver.cpp:314] Iteration 49000 (5.01145 iter/s, 19.9543s/100 iter), loss = 0.0693169
I0916 19:48:00.320276 20216 solver.cpp:336]     Train net output #0: loss = 0.069317 (* 1 = 0.069317 loss)
I0916 19:48:00.320282 20216 sgd_solver.cpp:136] Iteration 49000, lr = 0.0001, m = 0.9
I0916 19:48:16.792748 20220 data_reader.cpp:305] Starting prefetch of epoch 35
I0916 19:48:19.845459 20216 solver.cpp:314] Iteration 49100 (5.12173 iter/s, 19.5247s/100 iter), loss = 0.0518335
I0916 19:48:19.845482 20216 solver.cpp:336]     Train net output #0: loss = 0.0518336 (* 1 = 0.0518336 loss)
I0916 19:48:19.845487 20216 sgd_solver.cpp:136] Iteration 49100, lr = 0.0001, m = 0.9
I0916 19:48:40.040357 20216 solver.cpp:314] Iteration 49200 (4.95189 iter/s, 20.1943s/100 iter), loss = 0.0543663
I0916 19:48:40.040388 20216 solver.cpp:336]     Train net output #0: loss = 0.0543664 (* 1 = 0.0543664 loss)
I0916 19:48:40.040392 20216 sgd_solver.cpp:136] Iteration 49200, lr = 0.0001, m = 0.9
I0916 19:48:59.953105 20216 solver.cpp:314] Iteration 49300 (5.02205 iter/s, 19.9122s/100 iter), loss = 0.0732568
I0916 19:48:59.963603 20216 solver.cpp:336]     Train net output #0: loss = 0.0732569 (* 1 = 0.0732569 loss)
I0916 19:48:59.963634 20216 sgd_solver.cpp:136] Iteration 49300, lr = 0.0001, m = 0.9
I0916 19:49:19.905824 20216 solver.cpp:314] Iteration 49400 (5.01199 iter/s, 19.9522s/100 iter), loss = 0.0571453
I0916 19:49:19.905890 20216 solver.cpp:336]     Train net output #0: loss = 0.0571454 (* 1 = 0.0571454 loss)
I0916 19:49:19.905910 20216 sgd_solver.cpp:136] Iteration 49400, lr = 0.0001, m = 0.9
I0916 19:49:22.843848 20195 data_reader.cpp:305] Starting prefetch of epoch 23
I0916 19:49:39.376570 20216 solver.cpp:314] Iteration 49500 (5.13605 iter/s, 19.4702s/100 iter), loss = 0.044314
I0916 19:49:39.376626 20216 solver.cpp:336]     Train net output #0: loss = 0.0443142 (* 1 = 0.0443142 loss)
I0916 19:49:39.376632 20216 sgd_solver.cpp:136] Iteration 49500, lr = 0.0001, m = 0.9
I0916 19:49:59.519239 20216 solver.cpp:314] Iteration 49600 (4.96473 iter/s, 20.1421s/100 iter), loss = 0.0531559
I0916 19:49:59.519266 20216 solver.cpp:336]     Train net output #0: loss = 0.053156 (* 1 = 0.053156 loss)
I0916 19:49:59.519270 20216 sgd_solver.cpp:136] Iteration 49600, lr = 0.0001, m = 0.9
I0916 19:50:19.539409 20216 solver.cpp:314] Iteration 49700 (4.9951 iter/s, 20.0196s/100 iter), loss = 0.0601718
I0916 19:50:19.539639 20216 solver.cpp:336]     Train net output #0: loss = 0.0601719 (* 1 = 0.0601719 loss)
I0916 19:50:19.539649 20216 sgd_solver.cpp:136] Iteration 49700, lr = 0.0001, m = 0.9
I0916 19:50:28.497938 20224 data_reader.cpp:305] Starting prefetch of epoch 32
I0916 19:50:39.407058 20216 solver.cpp:314] Iteration 49800 (5.03345 iter/s, 19.8671s/100 iter), loss = 0.0656823
I0916 19:50:39.407081 20216 solver.cpp:336]     Train net output #0: loss = 0.0656824 (* 1 = 0.0656824 loss)
I0916 19:50:39.407088 20216 sgd_solver.cpp:136] Iteration 49800, lr = 0.0001, m = 0.9
I0916 19:50:59.177528 20216 solver.cpp:314] Iteration 49900 (5.05819 iter/s, 19.7699s/100 iter), loss = 0.0368935
I0916 19:50:59.177608 20216 solver.cpp:336]     Train net output #0: loss = 0.0368937 (* 1 = 0.0368937 loss)
I0916 19:50:59.177613 20216 sgd_solver.cpp:136] Iteration 49900, lr = 0.0001, m = 0.9
I0916 19:51:01.202430 20220 data_reader.cpp:305] Starting prefetch of epoch 36
I0916 19:51:19.012413 20216 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/cityscapes5_jsegnet21v2_iter_50000.caffemodel
I0916 19:51:19.239899 20216 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/cityscapes5_jsegnet21v2_iter_50000.solverstate
I0916 19:51:19.246620 20216 solver.cpp:563] Iteration 50000, Testing net (#0)
I0916 19:51:31.060118 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.957335
I0916 19:51:31.060168 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 19:51:31.060175 20216 solver.cpp:655]     Test net output #2: loss = 0.167795 (* 1 = 0.167795 loss)
I0916 19:51:31.060197 20216 solver.cpp:265] [MultiGPU] Tests completed in 11.8132s
I0916 19:51:31.265677 20216 solver.cpp:314] Iteration 50000 (3.1165 iter/s, 32.0872s/100 iter), loss = 0.0545652
I0916 19:51:31.265703 20216 solver.cpp:336]     Train net output #0: loss = 0.0545653 (* 1 = 0.0545653 loss)
I0916 19:51:31.265709 20216 sgd_solver.cpp:136] Iteration 50000, lr = 0.0001, m = 0.9
I0916 19:51:46.275606 20197 data_reader.cpp:305] Starting prefetch of epoch 29
I0916 19:51:51.129431 20216 solver.cpp:314] Iteration 50100 (5.03444 iter/s, 19.8632s/100 iter), loss = 0.0641584
I0916 19:51:51.129454 20216 solver.cpp:336]     Train net output #0: loss = 0.0641586 (* 1 = 0.0641586 loss)
I0916 19:51:51.129461 20216 sgd_solver.cpp:136] Iteration 50100, lr = 0.0001, m = 0.9
I0916 19:52:10.949658 20216 solver.cpp:314] Iteration 50200 (5.04549 iter/s, 19.8197s/100 iter), loss = 0.0688256
I0916 19:52:10.949759 20216 solver.cpp:336]     Train net output #0: loss = 0.0688258 (* 1 = 0.0688258 loss)
I0916 19:52:10.949766 20216 sgd_solver.cpp:136] Iteration 50200, lr = 0.0001, m = 0.9
I0916 19:52:30.976518 20216 solver.cpp:314] Iteration 50300 (4.99343 iter/s, 20.0263s/100 iter), loss = 0.0376291
I0916 19:52:30.976546 20216 solver.cpp:336]     Train net output #0: loss = 0.0376292 (* 1 = 0.0376292 loss)
I0916 19:52:30.976552 20216 sgd_solver.cpp:136] Iteration 50300, lr = 0.0001, m = 0.9
I0916 19:52:50.852319 20216 solver.cpp:314] Iteration 50400 (5.03139 iter/s, 19.8752s/100 iter), loss = 0.0464863
I0916 19:52:50.852378 20216 solver.cpp:336]     Train net output #0: loss = 0.0464864 (* 1 = 0.0464864 loss)
I0916 19:52:50.852383 20216 sgd_solver.cpp:136] Iteration 50400, lr = 0.0001, m = 0.9
I0916 19:52:52.089648 20223 data_reader.cpp:305] Starting prefetch of epoch 19
I0916 19:53:11.000077 20216 solver.cpp:314] Iteration 50500 (4.96347 iter/s, 20.1472s/100 iter), loss = 0.0593894
I0916 19:53:11.000102 20216 solver.cpp:336]     Train net output #0: loss = 0.0593895 (* 1 = 0.0593895 loss)
I0916 19:53:11.000109 20216 sgd_solver.cpp:136] Iteration 50500, lr = 0.0001, m = 0.9
I0916 19:53:25.530199 20195 data_reader.cpp:305] Starting prefetch of epoch 24
I0916 19:53:31.378013 20216 solver.cpp:314] Iteration 50600 (4.90741 iter/s, 20.3774s/100 iter), loss = 0.0795164
I0916 19:53:31.378043 20216 solver.cpp:336]     Train net output #0: loss = 0.0795165 (* 1 = 0.0795165 loss)
I0916 19:53:31.378049 20216 sgd_solver.cpp:136] Iteration 50600, lr = 0.0001, m = 0.9
I0916 19:53:51.029281 20216 solver.cpp:314] Iteration 50700 (5.08887 iter/s, 19.6507s/100 iter), loss = 0.0430249
I0916 19:53:51.029305 20216 solver.cpp:336]     Train net output #0: loss = 0.043025 (* 1 = 0.043025 loss)
I0916 19:53:51.029314 20216 sgd_solver.cpp:136] Iteration 50700, lr = 0.0001, m = 0.9
I0916 19:54:10.964315 20216 solver.cpp:314] Iteration 50800 (5.01644 iter/s, 19.9345s/100 iter), loss = 0.0779049
I0916 19:54:10.964416 20216 solver.cpp:336]     Train net output #0: loss = 0.077905 (* 1 = 0.077905 loss)
I0916 19:54:10.964422 20216 sgd_solver.cpp:136] Iteration 50800, lr = 0.0001, m = 0.9
I0916 19:54:31.017009 20216 solver.cpp:314] Iteration 50900 (4.987 iter/s, 20.0521s/100 iter), loss = 0.0538926
I0916 19:54:31.017035 20216 solver.cpp:336]     Train net output #0: loss = 0.0538927 (* 1 = 0.0538927 loss)
I0916 19:54:31.017041 20216 sgd_solver.cpp:136] Iteration 50900, lr = 0.0001, m = 0.9
I0916 19:54:31.466584 20197 data_reader.cpp:305] Starting prefetch of epoch 30
I0916 19:54:51.308573 20216 solver.cpp:314] Iteration 51000 (4.9283 iter/s, 20.291s/100 iter), loss = 0.0215775
I0916 19:54:51.308626 20216 solver.cpp:336]     Train net output #0: loss = 0.0215776 (* 1 = 0.0215776 loss)
I0916 19:54:51.308632 20216 sgd_solver.cpp:136] Iteration 51000, lr = 0.0001, m = 0.9
I0916 19:55:11.254516 20216 solver.cpp:314] Iteration 51100 (5.01369 iter/s, 19.9454s/100 iter), loss = 0.0677243
I0916 19:55:11.254541 20216 solver.cpp:336]     Train net output #0: loss = 0.0677244 (* 1 = 0.0677244 loss)
I0916 19:55:11.254547 20216 sgd_solver.cpp:136] Iteration 51100, lr = 0.0001, m = 0.9
I0916 19:55:30.975841 20216 solver.cpp:314] Iteration 51200 (5.0708 iter/s, 19.7208s/100 iter), loss = 0.0681909
I0916 19:55:30.975896 20216 solver.cpp:336]     Train net output #0: loss = 0.068191 (* 1 = 0.068191 loss)
I0916 19:55:30.975905 20216 sgd_solver.cpp:136] Iteration 51200, lr = 0.0001, m = 0.9
I0916 19:55:37.484431 20224 data_reader.cpp:305] Starting prefetch of epoch 33
I0916 19:55:50.835644 20216 solver.cpp:314] Iteration 51300 (5.03544 iter/s, 19.8592s/100 iter), loss = 0.0649089
I0916 19:55:50.835669 20216 solver.cpp:336]     Train net output #0: loss = 0.064909 (* 1 = 0.064909 loss)
I0916 19:55:50.835676 20216 sgd_solver.cpp:136] Iteration 51300, lr = 0.0001, m = 0.9
I0916 19:56:10.639139 20219 data_reader.cpp:305] Starting prefetch of epoch 41
I0916 19:56:10.989797 20216 solver.cpp:314] Iteration 51400 (4.96189 iter/s, 20.1536s/100 iter), loss = 0.0537636
I0916 19:56:10.989826 20216 solver.cpp:336]     Train net output #0: loss = 0.0537637 (* 1 = 0.0537637 loss)
I0916 19:56:10.989833 20216 sgd_solver.cpp:136] Iteration 51400, lr = 0.0001, m = 0.9
I0916 19:56:31.296744 20216 solver.cpp:314] Iteration 51500 (4.92456 iter/s, 20.3064s/100 iter), loss = 0.0342098
I0916 19:56:31.296774 20216 solver.cpp:336]     Train net output #0: loss = 0.0342099 (* 1 = 0.0342099 loss)
I0916 19:56:31.296782 20216 sgd_solver.cpp:136] Iteration 51500, lr = 0.0001, m = 0.9
I0916 19:56:51.508007 20216 solver.cpp:314] Iteration 51600 (4.94787 iter/s, 20.2107s/100 iter), loss = 0.0527578
I0916 19:56:51.508059 20216 solver.cpp:336]     Train net output #0: loss = 0.0527579 (* 1 = 0.0527579 loss)
I0916 19:56:51.508065 20216 sgd_solver.cpp:136] Iteration 51600, lr = 0.0001, m = 0.9
I0916 19:57:11.230521 20216 solver.cpp:314] Iteration 51700 (5.07049 iter/s, 19.722s/100 iter), loss = 0.0549528
I0916 19:57:11.230546 20216 solver.cpp:336]     Train net output #0: loss = 0.0549529 (* 1 = 0.0549529 loss)
I0916 19:57:11.230551 20216 sgd_solver.cpp:136] Iteration 51700, lr = 0.0001, m = 0.9
I0916 19:57:16.881464 20223 data_reader.cpp:305] Starting prefetch of epoch 20
I0916 19:57:31.099666 20216 solver.cpp:314] Iteration 51800 (5.03307 iter/s, 19.8686s/100 iter), loss = 0.0523119
I0916 19:57:31.099758 20216 solver.cpp:336]     Train net output #0: loss = 0.0523121 (* 1 = 0.0523121 loss)
I0916 19:57:31.099766 20216 sgd_solver.cpp:136] Iteration 51800, lr = 0.0001, m = 0.9
I0916 19:57:50.935533 20216 solver.cpp:314] Iteration 51900 (5.04151 iter/s, 19.8353s/100 iter), loss = 0.0725203
I0916 19:57:50.935559 20216 solver.cpp:336]     Train net output #0: loss = 0.0725205 (* 1 = 0.0725205 loss)
I0916 19:57:50.935564 20216 sgd_solver.cpp:136] Iteration 51900, lr = 0.0001, m = 0.9
I0916 19:58:10.534937 20216 solver.cpp:563] Iteration 52000, Testing net (#0)
I0916 19:58:13.886718 20250 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 19:58:21.897552 20204 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 19:58:22.226562 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.954923
I0916 19:58:22.226583 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 19:58:22.226588 20216 solver.cpp:655]     Test net output #2: loss = 0.146935 (* 1 = 0.146935 loss)
I0916 19:58:22.226614 20216 solver.cpp:265] [MultiGPU] Tests completed in 11.6914s
I0916 19:58:22.436189 20216 solver.cpp:314] Iteration 52000 (3.17462 iter/s, 31.4998s/100 iter), loss = 0.0517698
I0916 19:58:22.436216 20216 solver.cpp:336]     Train net output #0: loss = 0.05177 (* 1 = 0.05177 loss)
I0916 19:58:22.436221 20216 sgd_solver.cpp:136] Iteration 52000, lr = 0.0001, m = 0.9
I0916 19:58:42.197443 20216 solver.cpp:314] Iteration 52100 (5.06055 iter/s, 19.7607s/100 iter), loss = 0.0297729
I0916 19:58:42.197501 20216 solver.cpp:336]     Train net output #0: loss = 0.029773 (* 1 = 0.029773 loss)
I0916 19:58:42.197506 20216 sgd_solver.cpp:136] Iteration 52100, lr = 0.0001, m = 0.9
I0916 19:59:01.600831 20216 solver.cpp:314] Iteration 52200 (5.15388 iter/s, 19.4028s/100 iter), loss = 0.053763
I0916 19:59:01.600854 20216 solver.cpp:336]     Train net output #0: loss = 0.0537632 (* 1 = 0.0537632 loss)
I0916 19:59:01.600859 20216 sgd_solver.cpp:136] Iteration 52200, lr = 0.0001, m = 0.9
I0916 19:59:06.411396 20224 data_reader.cpp:305] Starting prefetch of epoch 34
I0916 19:59:21.444191 20216 solver.cpp:314] Iteration 52300 (5.03961 iter/s, 19.8428s/100 iter), loss = 0.0757802
I0916 19:59:21.444254 20216 solver.cpp:336]     Train net output #0: loss = 0.0757803 (* 1 = 0.0757803 loss)
I0916 19:59:21.444260 20216 sgd_solver.cpp:136] Iteration 52300, lr = 0.0001, m = 0.9
I0916 19:59:41.072996 20216 solver.cpp:314] Iteration 52400 (5.0947 iter/s, 19.6283s/100 iter), loss = 0.0438005
I0916 19:59:41.073019 20216 solver.cpp:336]     Train net output #0: loss = 0.0438007 (* 1 = 0.0438007 loss)
I0916 19:59:41.073025 20216 sgd_solver.cpp:136] Iteration 52400, lr = 0.0001, m = 0.9
I0916 20:00:00.807246 20216 solver.cpp:314] Iteration 52500 (5.06747 iter/s, 19.7337s/100 iter), loss = 0.0678241
I0916 20:00:00.807334 20216 solver.cpp:336]     Train net output #0: loss = 0.0678243 (* 1 = 0.0678243 loss)
I0916 20:00:00.807343 20216 sgd_solver.cpp:136] Iteration 52500, lr = 0.0001, m = 0.9
I0916 20:00:11.553490 20223 data_reader.cpp:305] Starting prefetch of epoch 21
I0916 20:00:20.376658 20216 solver.cpp:314] Iteration 52600 (5.11016 iter/s, 19.5689s/100 iter), loss = 0.0650704
I0916 20:00:20.376683 20216 solver.cpp:336]     Train net output #0: loss = 0.0650706 (* 1 = 0.0650706 loss)
I0916 20:00:20.376688 20216 sgd_solver.cpp:136] Iteration 52600, lr = 0.0001, m = 0.9
I0916 20:00:40.031862 20216 solver.cpp:314] Iteration 52700 (5.08785 iter/s, 19.6547s/100 iter), loss = 0.0864689
I0916 20:00:40.031947 20216 solver.cpp:336]     Train net output #0: loss = 0.0864691 (* 1 = 0.0864691 loss)
I0916 20:00:40.031955 20216 sgd_solver.cpp:136] Iteration 52700, lr = 0.0001, m = 0.9
I0916 20:00:44.061483 20195 data_reader.cpp:305] Starting prefetch of epoch 25
I0916 20:00:59.978498 20216 solver.cpp:314] Iteration 52800 (5.01352 iter/s, 19.9461s/100 iter), loss = 0.0675042
I0916 20:00:59.978528 20216 solver.cpp:336]     Train net output #0: loss = 0.0675044 (* 1 = 0.0675044 loss)
I0916 20:00:59.978533 20216 sgd_solver.cpp:136] Iteration 52800, lr = 0.0001, m = 0.9
I0916 20:01:19.468199 20216 solver.cpp:314] Iteration 52900 (5.13106 iter/s, 19.4892s/100 iter), loss = 0.0454022
I0916 20:01:19.468263 20216 solver.cpp:336]     Train net output #0: loss = 0.0454024 (* 1 = 0.0454024 loss)
I0916 20:01:19.468271 20216 sgd_solver.cpp:136] Iteration 52900, lr = 0.0001, m = 0.9
I0916 20:01:39.055238 20216 solver.cpp:314] Iteration 53000 (5.10556 iter/s, 19.5865s/100 iter), loss = 0.045528
I0916 20:01:39.055264 20216 solver.cpp:336]     Train net output #0: loss = 0.0455282 (* 1 = 0.0455282 loss)
I0916 20:01:39.055271 20216 sgd_solver.cpp:136] Iteration 53000, lr = 0.0001, m = 0.9
I0916 20:01:49.104908 20197 data_reader.cpp:305] Starting prefetch of epoch 31
I0916 20:01:58.803562 20216 solver.cpp:314] Iteration 53100 (5.06386 iter/s, 19.7478s/100 iter), loss = 0.0494181
I0916 20:01:58.803648 20216 solver.cpp:336]     Train net output #0: loss = 0.0494183 (* 1 = 0.0494183 loss)
I0916 20:01:58.803656 20216 sgd_solver.cpp:136] Iteration 53100, lr = 0.0001, m = 0.9
I0916 20:02:18.594730 20216 solver.cpp:314] Iteration 53200 (5.0529 iter/s, 19.7906s/100 iter), loss = 0.048279
I0916 20:02:18.594763 20216 solver.cpp:336]     Train net output #0: loss = 0.0482792 (* 1 = 0.0482792 loss)
I0916 20:02:18.594770 20216 sgd_solver.cpp:136] Iteration 53200, lr = 0.0001, m = 0.9
I0916 20:02:38.123630 20216 solver.cpp:314] Iteration 53300 (5.12076 iter/s, 19.5283s/100 iter), loss = 0.055814
I0916 20:02:38.123780 20216 solver.cpp:336]     Train net output #0: loss = 0.0558142 (* 1 = 0.0558142 loss)
I0916 20:02:38.123805 20216 sgd_solver.cpp:136] Iteration 53300, lr = 0.0001, m = 0.9
I0916 20:02:54.074610 20224 data_reader.cpp:305] Starting prefetch of epoch 35
I0916 20:02:57.844539 20216 solver.cpp:314] Iteration 53400 (5.0709 iter/s, 19.7204s/100 iter), loss = 0.0597222
I0916 20:02:57.844609 20216 solver.cpp:336]     Train net output #0: loss = 0.0597224 (* 1 = 0.0597224 loss)
I0916 20:02:57.844635 20216 sgd_solver.cpp:136] Iteration 53400, lr = 0.0001, m = 0.9
I0916 20:03:18.020486 20216 solver.cpp:314] Iteration 53500 (4.95654 iter/s, 20.1754s/100 iter), loss = 0.042818
I0916 20:03:18.020547 20216 solver.cpp:336]     Train net output #0: loss = 0.0428182 (* 1 = 0.0428182 loss)
I0916 20:03:18.020555 20216 sgd_solver.cpp:136] Iteration 53500, lr = 0.0001, m = 0.9
I0916 20:03:27.352751 20219 data_reader.cpp:305] Starting prefetch of epoch 42
I0916 20:03:37.994956 20216 solver.cpp:314] Iteration 53600 (5.00653 iter/s, 19.9739s/100 iter), loss = 0.0827209
I0916 20:03:37.994982 20216 solver.cpp:336]     Train net output #0: loss = 0.0827211 (* 1 = 0.0827211 loss)
I0916 20:03:37.994987 20216 sgd_solver.cpp:136] Iteration 53600, lr = 0.0001, m = 0.9
I0916 20:03:57.956082 20216 solver.cpp:314] Iteration 53700 (5.00988 iter/s, 19.9606s/100 iter), loss = 0.0527835
I0916 20:03:57.956156 20216 solver.cpp:336]     Train net output #0: loss = 0.0527837 (* 1 = 0.0527837 loss)
I0916 20:03:57.956164 20216 sgd_solver.cpp:136] Iteration 53700, lr = 0.0001, m = 0.9
I0916 20:04:18.065117 20216 solver.cpp:314] Iteration 53800 (4.97303 iter/s, 20.1085s/100 iter), loss = 0.0477695
I0916 20:04:18.065141 20216 solver.cpp:336]     Train net output #0: loss = 0.0477696 (* 1 = 0.0477696 loss)
I0916 20:04:18.065148 20216 sgd_solver.cpp:136] Iteration 53800, lr = 0.0001, m = 0.9
I0916 20:04:33.130897 20223 data_reader.cpp:305] Starting prefetch of epoch 22
I0916 20:04:37.671393 20216 solver.cpp:314] Iteration 53900 (5.10055 iter/s, 19.6057s/100 iter), loss = 0.0467622
I0916 20:04:37.671419 20216 solver.cpp:336]     Train net output #0: loss = 0.0467623 (* 1 = 0.0467623 loss)
I0916 20:04:37.671424 20216 sgd_solver.cpp:136] Iteration 53900, lr = 0.0001, m = 0.9
I0916 20:04:57.253887 20216 solver.cpp:563] Iteration 54000, Testing net (#0)
I0916 20:05:09.063454 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.957436
I0916 20:05:09.063560 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 20:05:09.063570 20216 solver.cpp:655]     Test net output #2: loss = 0.168188 (* 1 = 0.168188 loss)
I0916 20:05:09.063597 20216 solver.cpp:265] [MultiGPU] Tests completed in 11.8094s
I0916 20:05:09.264817 20216 solver.cpp:314] Iteration 54000 (3.1653 iter/s, 31.5925s/100 iter), loss = 0.055974
I0916 20:05:09.264848 20216 solver.cpp:336]     Train net output #0: loss = 0.0559741 (* 1 = 0.0559741 loss)
I0916 20:05:09.264854 20216 sgd_solver.cpp:136] Iteration 54000, lr = 0.0001, m = 0.9
I0916 20:05:17.659122 20197 data_reader.cpp:305] Starting prefetch of epoch 32
I0916 20:05:29.302458 20216 solver.cpp:314] Iteration 54100 (4.99075 iter/s, 20.0371s/100 iter), loss = 0.0519949
I0916 20:05:29.302484 20216 solver.cpp:336]     Train net output #0: loss = 0.051995 (* 1 = 0.051995 loss)
I0916 20:05:29.302490 20216 sgd_solver.cpp:136] Iteration 54100, lr = 0.0001, m = 0.9
I0916 20:05:49.038712 20216 solver.cpp:314] Iteration 54200 (5.06696 iter/s, 19.7357s/100 iter), loss = 0.0626577
I0916 20:05:49.038764 20216 solver.cpp:336]     Train net output #0: loss = 0.0626578 (* 1 = 0.0626578 loss)
I0916 20:05:49.038771 20216 sgd_solver.cpp:136] Iteration 54200, lr = 0.0001, m = 0.9
I0916 20:05:50.636569 20220 data_reader.cpp:305] Starting prefetch of epoch 37
I0916 20:06:08.887816 20216 solver.cpp:314] Iteration 54300 (5.03815 iter/s, 19.8485s/100 iter), loss = 0.0719034
I0916 20:06:08.887845 20216 solver.cpp:336]     Train net output #0: loss = 0.0719035 (* 1 = 0.0719035 loss)
I0916 20:06:08.887851 20216 sgd_solver.cpp:136] Iteration 54300, lr = 0.0001, m = 0.9
I0916 20:06:28.697309 20216 solver.cpp:314] Iteration 54400 (5.04823 iter/s, 19.8089s/100 iter), loss = 0.0389455
I0916 20:06:28.697362 20216 solver.cpp:336]     Train net output #0: loss = 0.0389456 (* 1 = 0.0389456 loss)
I0916 20:06:28.697369 20216 sgd_solver.cpp:136] Iteration 54400, lr = 0.0001, m = 0.9
I0916 20:06:48.462004 20216 solver.cpp:314] Iteration 54500 (5.05967 iter/s, 19.7641s/100 iter), loss = 0.102898
I0916 20:06:48.462041 20216 solver.cpp:336]     Train net output #0: loss = 0.102898 (* 1 = 0.102898 loss)
I0916 20:06:48.462049 20216 sgd_solver.cpp:136] Iteration 54500, lr = 0.0001, m = 0.9
I0916 20:06:56.184355 20224 data_reader.cpp:305] Starting prefetch of epoch 36
I0916 20:07:08.401298 20216 solver.cpp:314] Iteration 54600 (5.01536 iter/s, 19.9387s/100 iter), loss = 0.0504665
I0916 20:07:08.401394 20216 solver.cpp:336]     Train net output #0: loss = 0.0504666 (* 1 = 0.0504666 loss)
I0916 20:07:08.401401 20216 sgd_solver.cpp:136] Iteration 54600, lr = 0.0001, m = 0.9
I0916 20:07:28.354248 20216 solver.cpp:314] Iteration 54700 (5.01193 iter/s, 19.9524s/100 iter), loss = 0.06371
I0916 20:07:28.354276 20216 solver.cpp:336]     Train net output #0: loss = 0.0637102 (* 1 = 0.0637102 loss)
I0916 20:07:28.354280 20216 sgd_solver.cpp:136] Iteration 54700, lr = 0.0001, m = 0.9
I0916 20:07:48.452826 20216 solver.cpp:314] Iteration 54800 (4.97562 iter/s, 20.098s/100 iter), loss = 0.0515298
I0916 20:07:48.452901 20216 solver.cpp:336]     Train net output #0: loss = 0.05153 (* 1 = 0.05153 loss)
I0916 20:07:48.452911 20216 sgd_solver.cpp:136] Iteration 54800, lr = 0.0001, m = 0.9
I0916 20:08:02.381479 20223 data_reader.cpp:305] Starting prefetch of epoch 23
I0916 20:08:08.615212 20216 solver.cpp:314] Iteration 54900 (4.95987 iter/s, 20.1618s/100 iter), loss = 0.0551676
I0916 20:08:08.615236 20216 solver.cpp:336]     Train net output #0: loss = 0.0551677 (* 1 = 0.0551677 loss)
I0916 20:08:08.615243 20216 sgd_solver.cpp:136] Iteration 54900, lr = 0.0001, m = 0.9
I0916 20:08:28.584183 20216 solver.cpp:314] Iteration 55000 (5.00791 iter/s, 19.9684s/100 iter), loss = 0.0999661
I0916 20:08:28.584267 20216 solver.cpp:336]     Train net output #0: loss = 0.0999662 (* 1 = 0.0999662 loss)
I0916 20:08:28.584278 20216 sgd_solver.cpp:136] Iteration 55000, lr = 0.0001, m = 0.9
I0916 20:08:35.610749 20220 data_reader.cpp:305] Starting prefetch of epoch 38
I0916 20:08:48.794566 20216 solver.cpp:314] Iteration 55100 (4.94809 iter/s, 20.2098s/100 iter), loss = 0.0725234
I0916 20:08:48.794600 20216 solver.cpp:336]     Train net output #0: loss = 0.0725235 (* 1 = 0.0725235 loss)
I0916 20:08:48.794607 20216 sgd_solver.cpp:136] Iteration 55100, lr = 0.0001, m = 0.9
I0916 20:09:08.749090 20216 solver.cpp:314] Iteration 55200 (5.01154 iter/s, 19.954s/100 iter), loss = 0.0419128
I0916 20:09:08.749397 20216 solver.cpp:336]     Train net output #0: loss = 0.0419129 (* 1 = 0.0419129 loss)
I0916 20:09:08.749408 20216 sgd_solver.cpp:136] Iteration 55200, lr = 0.0001, m = 0.9
I0916 20:09:28.620136 20216 solver.cpp:314] Iteration 55300 (5.03259 iter/s, 19.8705s/100 iter), loss = 0.0616943
I0916 20:09:28.620167 20216 solver.cpp:336]     Train net output #0: loss = 0.0616944 (* 1 = 0.0616944 loss)
I0916 20:09:28.620173 20216 sgd_solver.cpp:136] Iteration 55300, lr = 0.0001, m = 0.9
I0916 20:09:41.529086 20224 data_reader.cpp:305] Starting prefetch of epoch 37
I0916 20:09:48.579453 20216 solver.cpp:314] Iteration 55400 (5.01033 iter/s, 19.9588s/100 iter), loss = 0.042525
I0916 20:09:48.579696 20216 solver.cpp:336]     Train net output #0: loss = 0.0425251 (* 1 = 0.0425251 loss)
I0916 20:09:48.584236 20216 sgd_solver.cpp:136] Iteration 55400, lr = 0.0001, m = 0.9
I0916 20:10:08.337648 20216 solver.cpp:314] Iteration 55500 (5.06133 iter/s, 19.7576s/100 iter), loss = 0.0441657
I0916 20:10:08.337677 20216 solver.cpp:336]     Train net output #0: loss = 0.0441659 (* 1 = 0.0441659 loss)
I0916 20:10:08.337682 20216 sgd_solver.cpp:136] Iteration 55500, lr = 0.0001, m = 0.9
I0916 20:10:28.533582 20216 solver.cpp:314] Iteration 55600 (4.95163 iter/s, 20.1954s/100 iter), loss = 0.057772
I0916 20:10:28.533659 20216 solver.cpp:336]     Train net output #0: loss = 0.0577721 (* 1 = 0.0577721 loss)
I0916 20:10:28.533668 20216 sgd_solver.cpp:136] Iteration 55600, lr = 0.0001, m = 0.9
I0916 20:10:47.532928 20223 data_reader.cpp:305] Starting prefetch of epoch 24
I0916 20:10:48.540740 20216 solver.cpp:314] Iteration 55700 (4.99835 iter/s, 20.0066s/100 iter), loss = 0.0354502
I0916 20:10:48.540828 20216 solver.cpp:336]     Train net output #0: loss = 0.0354503 (* 1 = 0.0354503 loss)
I0916 20:10:48.540848 20216 sgd_solver.cpp:136] Iteration 55700, lr = 0.0001, m = 0.9
I0916 20:11:08.667811 20216 solver.cpp:314] Iteration 55800 (4.96858 iter/s, 20.1265s/100 iter), loss = 0.0479862
I0916 20:11:08.694149 20216 solver.cpp:336]     Train net output #0: loss = 0.0479863 (* 1 = 0.0479863 loss)
I0916 20:11:08.694432 20216 sgd_solver.cpp:136] Iteration 55800, lr = 0.0001, m = 0.9
I0916 20:11:20.603847 20195 data_reader.cpp:305] Starting prefetch of epoch 26
I0916 20:11:28.604326 20216 solver.cpp:314] Iteration 55900 (5.01606 iter/s, 19.936s/100 iter), loss = 0.085463
I0916 20:11:28.604391 20216 solver.cpp:336]     Train net output #0: loss = 0.0854632 (* 1 = 0.0854632 loss)
I0916 20:11:28.604409 20216 sgd_solver.cpp:136] Iteration 55900, lr = 0.0001, m = 0.9
I0916 20:11:48.685719 20216 solver.cpp:563] Iteration 56000, Testing net (#0)
I0916 20:12:02.330919 20241 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 20:12:02.556265 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.95494
I0916 20:12:02.556287 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 20:12:02.556293 20216 solver.cpp:655]     Test net output #2: loss = 0.146093 (* 1 = 0.146093 loss)
I0916 20:12:02.556372 20216 solver.cpp:265] [MultiGPU] Tests completed in 13.8703s
I0916 20:12:02.759585 20216 solver.cpp:314] Iteration 56000 (2.92789 iter/s, 34.1543s/100 iter), loss = 0.0608156
I0916 20:12:02.759611 20216 solver.cpp:336]     Train net output #0: loss = 0.0608158 (* 1 = 0.0608158 loss)
I0916 20:12:02.759615 20216 sgd_solver.cpp:136] Iteration 56000, lr = 0.0001, m = 0.9
I0916 20:12:22.243700 20216 solver.cpp:314] Iteration 56100 (5.13253 iter/s, 19.4836s/100 iter), loss = 0.0744146
I0916 20:12:22.243790 20216 solver.cpp:336]     Train net output #0: loss = 0.0744147 (* 1 = 0.0744147 loss)
I0916 20:12:22.243798 20216 sgd_solver.cpp:136] Iteration 56100, lr = 0.0001, m = 0.9
I0916 20:12:40.371466 20197 data_reader.cpp:305] Starting prefetch of epoch 33
I0916 20:12:42.143050 20216 solver.cpp:314] Iteration 56200 (5.02543 iter/s, 19.8988s/100 iter), loss = 0.0496425
I0916 20:12:42.143074 20216 solver.cpp:336]     Train net output #0: loss = 0.0496426 (* 1 = 0.0496426 loss)
I0916 20:12:42.143079 20216 sgd_solver.cpp:136] Iteration 56200, lr = 0.0001, m = 0.9
I0916 20:13:02.119839 20216 solver.cpp:314] Iteration 56300 (5.00595 iter/s, 19.9762s/100 iter), loss = 0.0504875
I0916 20:13:02.119902 20216 solver.cpp:336]     Train net output #0: loss = 0.0504876 (* 1 = 0.0504876 loss)
I0916 20:13:02.119910 20216 sgd_solver.cpp:136] Iteration 56300, lr = 0.0001, m = 0.9
I0916 20:13:13.416491 20219 data_reader.cpp:305] Starting prefetch of epoch 43
I0916 20:13:22.256814 20216 solver.cpp:314] Iteration 56400 (4.96613 iter/s, 20.1364s/100 iter), loss = 0.0821847
I0916 20:13:22.256839 20216 solver.cpp:336]     Train net output #0: loss = 0.0821848 (* 1 = 0.0821848 loss)
I0916 20:13:22.256844 20216 sgd_solver.cpp:136] Iteration 56400, lr = 0.0001, m = 0.9
I0916 20:13:42.018115 20216 solver.cpp:314] Iteration 56500 (5.06054 iter/s, 19.7607s/100 iter), loss = 0.0624651
I0916 20:13:42.029260 20216 solver.cpp:336]     Train net output #0: loss = 0.0624652 (* 1 = 0.0624652 loss)
I0916 20:13:42.029279 20216 sgd_solver.cpp:136] Iteration 56500, lr = 0.0001, m = 0.9
I0916 20:14:01.851074 20216 solver.cpp:314] Iteration 56600 (5.04225 iter/s, 19.8324s/100 iter), loss = 0.0540481
I0916 20:14:01.851107 20216 solver.cpp:336]     Train net output #0: loss = 0.0540483 (* 1 = 0.0540483 loss)
I0916 20:14:01.851114 20216 sgd_solver.cpp:136] Iteration 56600, lr = 0.0001, m = 0.9
I0916 20:14:19.102849 20219 data_reader.cpp:305] Starting prefetch of epoch 44
I0916 20:14:21.665583 20216 solver.cpp:314] Iteration 56700 (5.04695 iter/s, 19.814s/100 iter), loss = 0.0630405
I0916 20:14:21.665611 20216 solver.cpp:336]     Train net output #0: loss = 0.0630406 (* 1 = 0.0630406 loss)
I0916 20:14:21.665618 20216 sgd_solver.cpp:136] Iteration 56700, lr = 0.0001, m = 0.9
I0916 20:14:41.201230 20216 solver.cpp:314] Iteration 56800 (5.11899 iter/s, 19.5351s/100 iter), loss = 0.0657645
I0916 20:14:41.201257 20216 solver.cpp:336]     Train net output #0: loss = 0.0657646 (* 1 = 0.0657646 loss)
I0916 20:14:41.201262 20216 sgd_solver.cpp:136] Iteration 56800, lr = 0.0001, m = 0.9
I0916 20:15:01.145164 20216 solver.cpp:314] Iteration 56900 (5.0142 iter/s, 19.9434s/100 iter), loss = 0.0435983
I0916 20:15:01.145265 20216 solver.cpp:336]     Train net output #0: loss = 0.0435984 (* 1 = 0.0435984 loss)
I0916 20:15:01.145273 20216 sgd_solver.cpp:136] Iteration 56900, lr = 0.0001, m = 0.9
I0916 20:15:20.967084 20216 solver.cpp:314] Iteration 57000 (5.04506 iter/s, 19.8214s/100 iter), loss = 0.0643915
I0916 20:15:20.967118 20216 solver.cpp:336]     Train net output #0: loss = 0.0643916 (* 1 = 0.0643916 loss)
I0916 20:15:20.967125 20216 sgd_solver.cpp:136] Iteration 57000, lr = 0.0001, m = 0.9
I0916 20:15:24.297533 20224 data_reader.cpp:305] Starting prefetch of epoch 38
I0916 20:15:40.547138 20216 solver.cpp:314] Iteration 57100 (5.10738 iter/s, 19.5795s/100 iter), loss = 0.0698923
I0916 20:15:40.547195 20216 solver.cpp:336]     Train net output #0: loss = 0.0698924 (* 1 = 0.0698924 loss)
I0916 20:15:40.547200 20216 sgd_solver.cpp:136] Iteration 57100, lr = 0.0001, m = 0.9
I0916 20:15:56.997056 20220 data_reader.cpp:305] Starting prefetch of epoch 39
I0916 20:16:00.288813 20216 solver.cpp:314] Iteration 57200 (5.06557 iter/s, 19.7411s/100 iter), loss = 0.0480078
I0916 20:16:00.288837 20216 solver.cpp:336]     Train net output #0: loss = 0.0480079 (* 1 = 0.0480079 loss)
I0916 20:16:00.288842 20216 sgd_solver.cpp:136] Iteration 57200, lr = 0.0001, m = 0.9
I0916 20:16:20.124600 20216 solver.cpp:314] Iteration 57300 (5.04153 iter/s, 19.8352s/100 iter), loss = 0.0632591
I0916 20:16:20.124650 20216 solver.cpp:336]     Train net output #0: loss = 0.0632592 (* 1 = 0.0632592 loss)
I0916 20:16:20.124655 20216 sgd_solver.cpp:136] Iteration 57300, lr = 0.0001, m = 0.9
I0916 20:16:39.968519 20216 solver.cpp:314] Iteration 57400 (5.03947 iter/s, 19.8434s/100 iter), loss = 0.0459265
I0916 20:16:39.968554 20216 solver.cpp:336]     Train net output #0: loss = 0.0459266 (* 1 = 0.0459266 loss)
I0916 20:16:39.968559 20216 sgd_solver.cpp:136] Iteration 57400, lr = 0.0001, m = 0.9
I0916 20:16:59.831657 20216 solver.cpp:314] Iteration 57500 (5.03459 iter/s, 19.8626s/100 iter), loss = 0.0835289
I0916 20:16:59.831712 20216 solver.cpp:336]     Train net output #0: loss = 0.083529 (* 1 = 0.083529 loss)
I0916 20:16:59.831717 20216 sgd_solver.cpp:136] Iteration 57500, lr = 0.0001, m = 0.9
I0916 20:17:02.405951 20195 data_reader.cpp:305] Starting prefetch of epoch 27
I0916 20:17:19.168907 20216 solver.cpp:314] Iteration 57600 (5.17151 iter/s, 19.3367s/100 iter), loss = 0.0427224
I0916 20:17:19.168931 20216 solver.cpp:336]     Train net output #0: loss = 0.0427225 (* 1 = 0.0427225 loss)
I0916 20:17:19.168936 20216 sgd_solver.cpp:136] Iteration 57600, lr = 0.0001, m = 0.9
I0916 20:17:38.725216 20216 solver.cpp:314] Iteration 57700 (5.11358 iter/s, 19.5558s/100 iter), loss = 0.0613167
I0916 20:17:38.725297 20216 solver.cpp:336]     Train net output #0: loss = 0.0613168 (* 1 = 0.0613168 loss)
I0916 20:17:38.725303 20216 sgd_solver.cpp:136] Iteration 57700, lr = 0.0001, m = 0.9
I0916 20:17:58.299479 20216 solver.cpp:314] Iteration 57800 (5.10889 iter/s, 19.5737s/100 iter), loss = 0.0328406
I0916 20:17:58.299510 20216 solver.cpp:336]     Train net output #0: loss = 0.0328407 (* 1 = 0.0328407 loss)
I0916 20:17:58.299516 20216 sgd_solver.cpp:136] Iteration 57800, lr = 0.0001, m = 0.9
I0916 20:18:06.962812 20223 data_reader.cpp:305] Starting prefetch of epoch 25
I0916 20:18:18.077920 20216 solver.cpp:314] Iteration 57900 (5.05615 iter/s, 19.7779s/100 iter), loss = 0.0333292
I0916 20:18:18.078021 20216 solver.cpp:336]     Train net output #0: loss = 0.0333293 (* 1 = 0.0333293 loss)
I0916 20:18:18.078034 20216 sgd_solver.cpp:136] Iteration 57900, lr = 0.0001, m = 0.9
I0916 20:18:37.697520 20216 solver.cpp:563] Iteration 58000, Testing net (#0)
I0916 20:18:46.333200 20241 data_reader.cpp:305] Starting prefetch of epoch 5
I0916 20:18:50.554177 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.957319
I0916 20:18:50.554278 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 20:18:50.554288 20216 solver.cpp:655]     Test net output #2: loss = 0.167713 (* 1 = 0.167713 loss)
I0916 20:18:50.554314 20216 solver.cpp:265] [MultiGPU] Tests completed in 12.8564s
I0916 20:18:50.764966 20216 solver.cpp:314] Iteration 58000 (3.0594 iter/s, 32.6861s/100 iter), loss = 0.0330061
I0916 20:18:50.764991 20216 solver.cpp:336]     Train net output #0: loss = 0.0330062 (* 1 = 0.0330062 loss)
I0916 20:18:50.764994 20216 sgd_solver.cpp:136] Iteration 58000, lr = 0.0001, m = 0.9
I0916 20:19:10.968441 20216 solver.cpp:314] Iteration 58100 (4.94978 iter/s, 20.2029s/100 iter), loss = 0.0458601
I0916 20:19:10.968466 20216 solver.cpp:336]     Train net output #0: loss = 0.0458602 (* 1 = 0.0458602 loss)
I0916 20:19:10.968471 20216 sgd_solver.cpp:136] Iteration 58100, lr = 0.0001, m = 0.9
I0916 20:19:25.726198 20219 data_reader.cpp:305] Starting prefetch of epoch 45
I0916 20:19:30.883913 20216 solver.cpp:314] Iteration 58200 (5.02136 iter/s, 19.9149s/100 iter), loss = 0.066312
I0916 20:19:30.883939 20216 solver.cpp:336]     Train net output #0: loss = 0.0663121 (* 1 = 0.0663121 loss)
I0916 20:19:30.883944 20216 sgd_solver.cpp:136] Iteration 58200, lr = 0.0001, m = 0.9
I0916 20:19:50.750663 20216 solver.cpp:314] Iteration 58300 (5.03368 iter/s, 19.8662s/100 iter), loss = 0.0354339
I0916 20:19:50.750689 20216 solver.cpp:336]     Train net output #0: loss = 0.035434 (* 1 = 0.035434 loss)
I0916 20:19:50.750695 20216 sgd_solver.cpp:136] Iteration 58300, lr = 0.0001, m = 0.9
I0916 20:20:10.806777 20216 solver.cpp:314] Iteration 58400 (4.98615 iter/s, 20.0556s/100 iter), loss = 0.0717984
I0916 20:20:10.806895 20216 solver.cpp:336]     Train net output #0: loss = 0.0717985 (* 1 = 0.0717985 loss)
I0916 20:20:10.806905 20216 sgd_solver.cpp:136] Iteration 58400, lr = 0.0001, m = 0.9
I0916 20:20:30.924041 20216 solver.cpp:314] Iteration 58500 (4.97099 iter/s, 20.1167s/100 iter), loss = 0.0307386
I0916 20:20:30.924068 20216 solver.cpp:336]     Train net output #0: loss = 0.0307387 (* 1 = 0.0307387 loss)
I0916 20:20:30.924072 20216 sgd_solver.cpp:136] Iteration 58500, lr = 0.0001, m = 0.9
I0916 20:20:31.973170 20223 data_reader.cpp:305] Starting prefetch of epoch 26
I0916 20:20:50.670367 20216 solver.cpp:314] Iteration 58600 (5.06438 iter/s, 19.7458s/100 iter), loss = 0.0684625
I0916 20:20:50.670447 20216 solver.cpp:336]     Train net output #0: loss = 0.0684627 (* 1 = 0.0684627 loss)
I0916 20:20:50.670457 20216 sgd_solver.cpp:136] Iteration 58600, lr = 0.0001, m = 0.9
I0916 20:21:05.087064 20195 data_reader.cpp:305] Starting prefetch of epoch 28
I0916 20:21:11.202807 20216 solver.cpp:314] Iteration 58700 (4.87048 iter/s, 20.5319s/100 iter), loss = 0.088402
I0916 20:21:11.202833 20216 solver.cpp:336]     Train net output #0: loss = 0.0884021 (* 1 = 0.0884021 loss)
I0916 20:21:11.202838 20216 sgd_solver.cpp:136] Iteration 58700, lr = 0.0001, m = 0.9
I0916 20:21:31.584801 20216 solver.cpp:314] Iteration 58800 (4.90643 iter/s, 20.3814s/100 iter), loss = 0.0639708
I0916 20:21:31.584847 20216 solver.cpp:336]     Train net output #0: loss = 0.0639709 (* 1 = 0.0639709 loss)
I0916 20:21:31.584853 20216 sgd_solver.cpp:136] Iteration 58800, lr = 0.0001, m = 0.9
I0916 20:21:51.664202 20216 solver.cpp:314] Iteration 58900 (4.98037 iter/s, 20.0788s/100 iter), loss = 0.0495426
I0916 20:21:51.664227 20216 solver.cpp:336]     Train net output #0: loss = 0.0495428 (* 1 = 0.0495428 loss)
I0916 20:21:51.664232 20216 sgd_solver.cpp:136] Iteration 58900, lr = 0.0001, m = 0.9
I0916 20:22:11.837088 20216 solver.cpp:314] Iteration 59000 (4.95729 iter/s, 20.1723s/100 iter), loss = 0.0457402
I0916 20:22:11.837177 20216 solver.cpp:336]     Train net output #0: loss = 0.0457404 (* 1 = 0.0457404 loss)
I0916 20:22:11.837185 20216 sgd_solver.cpp:136] Iteration 59000, lr = 0.0001, m = 0.9
I0916 20:22:12.069550 20224 data_reader.cpp:305] Starting prefetch of epoch 39
I0916 20:22:32.091253 20216 solver.cpp:314] Iteration 59100 (4.93777 iter/s, 20.252s/100 iter), loss = 0.0468025
I0916 20:22:32.091312 20216 solver.cpp:336]     Train net output #0: loss = 0.0468026 (* 1 = 0.0468026 loss)
I0916 20:22:32.091326 20216 sgd_solver.cpp:136] Iteration 59100, lr = 0.0001, m = 0.9
I0916 20:22:52.263814 20216 solver.cpp:314] Iteration 59200 (4.95737 iter/s, 20.172s/100 iter), loss = 0.0520372
I0916 20:22:52.263890 20216 solver.cpp:336]     Train net output #0: loss = 0.0520373 (* 1 = 0.0520373 loss)
I0916 20:22:52.263898 20216 sgd_solver.cpp:136] Iteration 59200, lr = 0.0001, m = 0.9
I0916 20:23:11.911548 20216 solver.cpp:314] Iteration 59300 (5.08979 iter/s, 19.6472s/100 iter), loss = 0.037459
I0916 20:23:11.911578 20216 solver.cpp:336]     Train net output #0: loss = 0.0374591 (* 1 = 0.0374591 loss)
I0916 20:23:11.911586 20216 sgd_solver.cpp:136] Iteration 59300, lr = 0.0001, m = 0.9
I0916 20:23:18.135131 20220 data_reader.cpp:305] Starting prefetch of epoch 40
I0916 20:23:32.026746 20216 solver.cpp:314] Iteration 59400 (4.97151 iter/s, 20.1146s/100 iter), loss = 0.051275
I0916 20:23:32.026804 20216 solver.cpp:336]     Train net output #0: loss = 0.0512751 (* 1 = 0.0512751 loss)
I0916 20:23:32.026810 20216 sgd_solver.cpp:136] Iteration 59400, lr = 0.0001, m = 0.9
I0916 20:23:51.517132 20219 data_reader.cpp:305] Starting prefetch of epoch 46
I0916 20:23:52.257676 20216 solver.cpp:314] Iteration 59500 (4.94306 iter/s, 20.2304s/100 iter), loss = 0.0527432
I0916 20:23:52.257705 20216 solver.cpp:336]     Train net output #0: loss = 0.0527433 (* 1 = 0.0527433 loss)
I0916 20:23:52.257711 20216 sgd_solver.cpp:136] Iteration 59500, lr = 0.0001, m = 0.9
I0916 20:24:12.323619 20216 solver.cpp:314] Iteration 59600 (4.98371 iter/s, 20.0654s/100 iter), loss = 0.0462759
I0916 20:24:12.323678 20216 solver.cpp:336]     Train net output #0: loss = 0.046276 (* 1 = 0.046276 loss)
I0916 20:24:12.323683 20216 sgd_solver.cpp:136] Iteration 59600, lr = 0.0001, m = 0.9
I0916 20:24:32.586323 20216 solver.cpp:314] Iteration 59700 (4.93531 iter/s, 20.2621s/100 iter), loss = 0.0717289
I0916 20:24:32.586345 20216 solver.cpp:336]     Train net output #0: loss = 0.071729 (* 1 = 0.071729 loss)
I0916 20:24:32.586349 20216 sgd_solver.cpp:136] Iteration 59700, lr = 0.0001, m = 0.9
I0916 20:24:53.057204 20216 solver.cpp:314] Iteration 59800 (4.88512 iter/s, 20.4703s/100 iter), loss = 0.0836862
I0916 20:24:53.057303 20216 solver.cpp:336]     Train net output #0: loss = 0.0836863 (* 1 = 0.0836863 loss)
I0916 20:24:53.057312 20216 sgd_solver.cpp:136] Iteration 59800, lr = 0.0001, m = 0.9
I0916 20:24:58.458498 20220 data_reader.cpp:305] Starting prefetch of epoch 41
I0916 20:25:12.763021 20216 solver.cpp:314] Iteration 59900 (5.07479 iter/s, 19.7053s/100 iter), loss = 0.0540514
I0916 20:25:12.763046 20216 solver.cpp:336]     Train net output #0: loss = 0.0540515 (* 1 = 0.0540515 loss)
I0916 20:25:12.763051 20216 sgd_solver.cpp:136] Iteration 59900, lr = 0.0001, m = 0.9
I0916 20:25:32.396756 20216 solver.cpp:314] Iteration 59999 (5.04248 iter/s, 19.6332s/99 iter), loss = 0.054542
I0916 20:25:32.396836 20216 solver.cpp:336]     Train net output #0: loss = 0.0545421 (* 1 = 0.0545421 loss)
I0916 20:25:32.396844 20216 solver.cpp:825] Snapshotting to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/cityscapes5_jsegnet21v2_iter_60000.caffemodel
I0916 20:25:32.645040 20216 sgd_solver.cpp:345] Snapshotting solver state to binary proto file training/cityscapes5_jsegnet21v2_2017-09-16_10-06-43/l1reg/cityscapes5_jsegnet21v2_iter_60000.solverstate
I0916 20:25:32.719274 20216 solver.cpp:538] Iteration 60000, loss = 0.0498918
I0916 20:25:32.719323 20216 solver.cpp:563] Iteration 60000, Testing net (#0)
I0916 20:25:38.061920 20243 data_reader.cpp:305] Starting prefetch of epoch 4
I0916 20:25:48.822120 20241 data_reader.cpp:305] Starting prefetch of epoch 6
I0916 20:25:49.489050 20216 solver.cpp:655]     Test net output #0: accuracy/top1 = 0.954699
I0916 20:25:49.489071 20216 solver.cpp:655]     Test net output #1: accuracy/top5 = 1
I0916 20:25:49.489076 20216 solver.cpp:655]     Test net output #2: loss = 0.147399 (* 1 = 0.147399 loss)
I0916 20:25:49.620254 20128 parallel.cpp:71] Root Solver performance on device 0: 4.894 * 6 = 29.36 img/sec (60000 itr in 1.226e+04 sec)
I0916 20:25:49.620367 20128 parallel.cpp:76]      Solver performance on device 1: 4.894 * 6 = 29.36 img/sec (60000 itr in 1.226e+04 sec)
I0916 20:25:49.620376 20128 parallel.cpp:76]      Solver performance on device 2: 4.894 * 6 = 29.36 img/sec (60000 itr in 1.226e+04 sec)
I0916 20:25:49.620380 20128 parallel.cpp:79] Overall multi-GPU performance: 88.0888 img/sec
I0916 20:25:51.277590 20128 caffe.cpp:253] Optimization Done in 3h 24m 45s
